{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Spark Basics - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Data_Engineering/">Data Engineering</a>
    <span class="separator">/</span>
    <span class="current">Apache Spark Basics</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>Apache Spark Basics</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Data_Engineering/06_Prefect_Modern_Orchestration.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Prefect Modern Orchestration</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Data_Engineering/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Data_Engineering/08_PySpark_DataFrames.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">PySpark DataFrame</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#1-spark-overview">1. Spark Overview</a><ul>
<li><a href="#11-spark-features">1.1 Spark Features</a></li>
<li><a href="#12-spark-ecosystem">1.2 Spark Ecosystem</a></li>
</ul>
</li>
<li><a href="#2-spark-architecture">2. Spark Architecture</a><ul>
<li><a href="#21-cluster-configuration">2.1 Cluster Configuration</a></li>
<li><a href="#22-core-concepts">2.2 Core Concepts</a></li>
<li><a href="#23-execution-flow">2.3 Execution Flow</a></li>
</ul>
</li>
<li><a href="#3-rdd-resilient-distributed-dataset">3. RDD (Resilient Distributed Dataset)</a><ul>
<li><a href="#31-rdd-concept">3.1 RDD Concept</a></li>
<li><a href="#32-rdd-operations">3.2 RDD Operations</a></li>
<li><a href="#33-pair-rdd-operations">3.3 Pair RDD Operations</a></li>
</ul>
</li>
<li><a href="#4-installation-and-execution">4. Installation and Execution</a><ul>
<li><a href="#41-local-installation-pyspark">4.1 Local Installation (PySpark)</a></li>
<li><a href="#42-docker-installation">4.2 Docker Installation</a></li>
<li><a href="#43-cluster-mode">4.3 Cluster Mode</a></li>
</ul>
</li>
<li><a href="#5-sparksession">5. SparkSession</a><ul>
<li><a href="#51-creating-sparksession">5.1 Creating SparkSession</a></li>
<li><a href="#52-common-configurations">5.2 Common Configurations</a></li>
</ul>
</li>
<li><a href="#6-basic-examples">6. Basic Examples</a><ul>
<li><a href="#61-word-count">6.1 Word Count</a></li>
<li><a href="#62-dataframe-basics">6.2 DataFrame Basics</a></li>
</ul>
</li>
<li><a href="#practice-problems">Practice Problems</a><ul>
<li><a href="#problem-1-basic-rdd-operations">Problem 1: Basic RDD Operations</a></li>
<li><a href="#problem-2-pair-rdd">Problem 2: Pair RDD</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="apache-spark-basics">Apache Spark Basics<a class="header-link" href="#apache-spark-basics" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="header-link" href="#overview" title="Permanent link">&para;</a></h2>
<p>Apache Spark is a unified analytics engine for large-scale data processing. It provides faster performance than Hadoop MapReduce through in-memory processing and supports both batch processing and streaming.</p>
<hr />
<h2 id="1-spark-overview">1. Spark Overview<a class="header-link" href="#1-spark-overview" title="Permanent link">&para;</a></h2>
<h3 id="11-spark-features">1.1 Spark Features<a class="header-link" href="#11-spark-features" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">                    </span><span class="n">Apache</span><span class="w"> </span><span class="n">Spark</span><span class="w"> </span><span class="n">Features</span><span class="w">                        </span><span class="err">â”‚</span>
<span class="err">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span>
<span class="err">â”‚</span><span class="w">                                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">   </span><span class="mf">1.</span><span class="w"> </span><span class="n">Speed</span><span class="w">                                                     </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="mi">100</span><span class="n">x</span><span class="w"> </span><span class="n">faster</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">Hadoop</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="ow">in</span><span class="o">-</span><span class="n">memory</span><span class="w"> </span><span class="n">processing</span><span class="w">       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="mi">10</span><span class="n">x</span><span class="w"> </span><span class="n">faster</span><span class="w"> </span><span class="n">than</span><span class="w"> </span><span class="n">disk</span><span class="o">-</span><span class="n">based</span><span class="w"> </span><span class="n">processing</span><span class="w">                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">   </span><span class="mf">2.</span><span class="w"> </span><span class="n">Ease</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">Use</span><span class="w">                                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">Supports</span><span class="w"> </span><span class="n">Python</span><span class="p">,</span><span class="w"> </span><span class="n">Scala</span><span class="p">,</span><span class="w"> </span><span class="n">Java</span><span class="p">,</span><span class="w"> </span><span class="n">R</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">Provides</span><span class="w"> </span><span class="n">SQL</span><span class="w"> </span><span class="n">interface</span><span class="w">                                  </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">   </span><span class="mf">3.</span><span class="w"> </span><span class="n">Generality</span><span class="w">                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">SQL</span><span class="p">,</span><span class="w"> </span><span class="n">streaming</span><span class="p">,</span><span class="w"> </span><span class="n">ML</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="w"> </span><span class="n">processing</span><span class="w">                    </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">Diverse</span><span class="w"> </span><span class="n">workloads</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">engine</span><span class="w">                       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">   </span><span class="mf">4.</span><span class="w"> </span><span class="n">Compatibility</span><span class="w">                                             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">Various</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">sources</span><span class="p">:</span><span class="w"> </span><span class="n">HDFS</span><span class="p">,</span><span class="w"> </span><span class="n">S3</span><span class="p">,</span><span class="w"> </span><span class="n">Cassandra</span><span class="p">,</span><span class="w"> </span><span class="n">etc</span><span class="o">.</span><span class="w">         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">      </span><span class="o">-</span><span class="w"> </span><span class="n">YARN</span><span class="p">,</span><span class="w"> </span><span class="n">Kubernetes</span><span class="p">,</span><span class="w"> </span><span class="n">Standalone</span><span class="w"> </span><span class="n">clusters</span><span class="w">                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<h3 id="12-spark-ecosystem">1.2 Spark Ecosystem<a class="header-link" href="#12-spark-ecosystem" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Spark Ecosystem                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Spark SQL â”‚ â”‚ Streaming  â”‚ â”‚   MLlib    â”‚ â”‚  GraphX    â”‚  â”‚
â”‚   â”‚    + DF    â”‚ â”‚ (Structured)â”‚ â”‚(Machine   â”‚ â”‚  (Graph)   â”‚  â”‚
â”‚   â”‚            â”‚ â”‚             â”‚ â”‚ Learning) â”‚ â”‚            â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   â”‚                     Spark Core                           â”‚  â”‚
â”‚   â”‚                 (RDD, Task Scheduling)                   â”‚  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   â”‚    Standalone    â”‚    YARN    â”‚    Kubernetes    â”‚ Mesos â”‚  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   â”‚  HDFS  â”‚   S3   â”‚   GCS   â”‚  Cassandra  â”‚  JDBC  â”‚ etc â”‚  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<hr />
<h2 id="2-spark-architecture">2. Spark Architecture<a class="header-link" href="#2-spark-architecture" title="Permanent link">&para;</a></h2>
<h3 id="21-cluster-configuration">2.1 Cluster Configuration<a class="header-link" href="#21-cluster-configuration" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spark Cluster Architecture                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚                    Driver Program                      â”‚    â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚   â”‚   â”‚              SparkContext                        â”‚ â”‚    â”‚
â”‚   â”‚   â”‚   - Application entry point                      â”‚ â”‚    â”‚
â”‚   â”‚   â”‚   - Connects to cluster                          â”‚ â”‚    â”‚
â”‚   â”‚   â”‚   - Job creation and scheduling                  â”‚ â”‚    â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â†“                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚                  Cluster Manager                       â”‚    â”‚
â”‚   â”‚       (Standalone, YARN, Kubernetes, Mesos)            â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â†“                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚   Worker    â”‚  â”‚   Worker    â”‚  â”‚   Worker    â”‚           â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚           â”‚
â”‚   â”‚  â”‚Executorâ”‚ â”‚  â”‚  â”‚Executorâ”‚ â”‚  â”‚  â”‚Executorâ”‚ â”‚           â”‚
â”‚   â”‚  â”‚ Task  â”‚  â”‚  â”‚  â”‚ Task  â”‚  â”‚  â”‚  â”‚ Task  â”‚  â”‚           â”‚
â”‚   â”‚  â”‚ Task  â”‚  â”‚  â”‚  â”‚ Task  â”‚  â”‚  â”‚  â”‚ Task  â”‚  â”‚           â”‚
â”‚   â”‚  â”‚ Cache â”‚  â”‚  â”‚  â”‚ Cache â”‚  â”‚  â”‚  â”‚ Cache â”‚  â”‚           â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="22-core-concepts">2.2 Core Concepts<a class="header-link" href="#22-core-concepts" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Driver</strong></td>
<td>Executes main program, creates SparkContext</td>
</tr>
<tr>
<td><strong>Executor</strong></td>
<td>Executes tasks on worker nodes</td>
</tr>
<tr>
<td><strong>Task</strong></td>
<td>Basic unit of execution</td>
</tr>
<tr>
<td><strong>Job</strong></td>
<td>Parallel computation triggered by an action</td>
</tr>
<tr>
<td><strong>Stage</strong></td>
<td>Group of tasks within a job (shuffle boundary)</td>
</tr>
<tr>
<td><strong>Partition</strong></td>
<td>Logical division unit of data</td>
</tr>
</tbody>
</table>
<h3 id="23-execution-flow">2.3 Execution Flow<a class="header-link" href="#23-execution-flow" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Spark execution flow:</span>
<span class="sd">1. Create SparkContext in Driver</span>
<span class="sd">2. Parse application code</span>
<span class="sd">3. Transformations â†’ Create DAG (Directed Acyclic Graph)</span>
<span class="sd">4. Create job when action is called</span>
<span class="sd">5. Decompose job â†’ Stages â†’ Tasks</span>
<span class="sd">6. Cluster Manager assigns tasks to Executors</span>
<span class="sd">7. Executors execute tasks</span>
<span class="sd">8. Return results to Driver</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Example code flow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Example&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Transformations (Lazy - not executed)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Read plan</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">age</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">)</span>                  <span class="c1"># Filter plan</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;city&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>             <span class="c1"># Aggregation plan</span>

<span class="c1"># Action (triggers actual execution)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">df3</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="c1"># Create job â†’ Stages â†’ Tasks â†’ Execute</span>
</code></pre></div>

<hr />
<h2 id="3-rdd-resilient-distributed-dataset">3. RDD (Resilient Distributed Dataset)<a class="header-link" href="#3-rdd-resilient-distributed-dataset" title="Permanent link">&para;</a></h2>
<h3 id="31-rdd-concept">3.1 RDD Concept<a class="header-link" href="#31-rdd-concept" title="Permanent link">&para;</a></h3>
<p>RDD is Spark's fundamental data structure, an immutable distributed collection of data.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkContext</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s2">&quot;local[*]&quot;</span><span class="p">,</span> <span class="s2">&quot;RDD Example&quot;</span><span class="p">)</span>

<span class="c1"># Ways to create RDD</span>
<span class="c1"># 1. From collection</span>
<span class="n">rdd1</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>

<span class="c1"># 2. From external data</span>
<span class="n">rdd2</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data.txt&quot;</span><span class="p">)</span>

<span class="c1"># 3. From existing RDD transformation</span>
<span class="n">rdd3</span> <span class="o">=</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># RDD properties</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">R - Resilient: Fault-recoverable (recompute via lineage)</span>
<span class="sd">D - Distributed: Distributed across cluster</span>
<span class="sd">D - Dataset: Data collection</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<h3 id="32-rdd-operations">3.2 RDD Operations<a class="header-link" href="#32-rdd-operations" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Transformations (Lazy)</span>
<span class="c1"># - Return new RDD</span>
<span class="c1"># - Only create execution plan</span>

<span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="c1"># map: Apply function to each element</span>
<span class="n">mapped</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># [2, 4, 6, ...]</span>

<span class="c1"># filter: Select elements matching condition</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># [2, 4, 6, 8, 10]</span>

<span class="c1"># flatMap: map then flatten</span>
<span class="n">flat</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># [1, 2, 2, 4, 3, 6, ...]</span>

<span class="c1"># distinct: Remove duplicates</span>
<span class="n">distinct</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span>

<span class="c1"># union: Merge two RDDs</span>
<span class="n">union</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]))</span>

<span class="c1"># groupByKey: Group by key</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>
<span class="n">grouped</span> <span class="o">=</span> <span class="n">pairs</span><span class="o">.</span><span class="n">groupByKey</span><span class="p">()</span>  <span class="c1"># [(&quot;a&quot;, [1, 3]), (&quot;b&quot;, [2])]</span>

<span class="c1"># reduceByKey: Reduce by key</span>
<span class="n">reduced</span> <span class="o">=</span> <span class="n">pairs</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># [(&quot;a&quot;, 4), (&quot;b&quot;, 2)]</span>


<span class="c1"># Actions (Eager)</span>
<span class="c1"># - Return results or save</span>
<span class="c1"># - Trigger actual execution</span>

<span class="c1"># collect: Return all elements to Driver</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="c1"># [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</span>

<span class="c1"># count: Count elements</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># 10</span>

<span class="c1"># first / take: First element / n elements</span>
<span class="n">first</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>  <span class="c1"># 1</span>
<span class="n">take3</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># [1, 2, 3]</span>

<span class="c1"># reduce: Reduce all</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">rdd</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># 55</span>

<span class="c1"># foreach: Apply function to each element (side effect)</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># saveAsTextFile: Save to file</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s2">&quot;output/&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="33-pair-rdd-operations">3.3 Pair RDD Operations<a class="header-link" href="#33-pair-rdd-operations" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Key-Value pair RDD operations</span>
<span class="n">sales</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;Electronics&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Clothing&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Electronics&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Clothing&quot;</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Food&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
<span class="p">])</span>

<span class="c1"># Sum by key</span>
<span class="n">total_by_category</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="c1"># [(&quot;Electronics&quot;, 300), (&quot;Clothing&quot;, 125), (&quot;Food&quot;, 30)]</span>

<span class="c1"># Average by key</span>
<span class="n">count_sum</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">combineByKey</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>                      <span class="c1"># createCombiner</span>
    <span class="k">lambda</span> <span class="n">acc</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="p">(</span><span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">,</span> <span class="n">acc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># mergeValue</span>
    <span class="k">lambda</span> <span class="n">acc1</span><span class="p">,</span> <span class="n">acc2</span><span class="p">:</span> <span class="p">(</span><span class="n">acc1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">acc2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">acc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">acc2</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># mergeCombiner</span>
<span class="p">)</span>
<span class="n">avg_by_category</span> <span class="o">=</span> <span class="n">count_sum</span><span class="o">.</span><span class="n">mapValues</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Sort</span>
<span class="n">sorted_rdd</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">sortByKey</span><span class="p">()</span>

<span class="c1"># Join</span>
<span class="n">inventory</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;Electronics&quot;</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Clothing&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
<span class="p">])</span>

<span class="n">joined</span> <span class="o">=</span> <span class="n">sales</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">inventory</span><span class="p">)</span>
<span class="c1"># [(&quot;Electronics&quot;, (100, 50)), (&quot;Electronics&quot;, (200, 50)), ...]</span>
</code></pre></div>

<hr />
<h2 id="4-installation-and-execution">4. Installation and Execution<a class="header-link" href="#4-installation-and-execution" title="Permanent link">&para;</a></h2>
<h3 id="41-local-installation-pyspark">4.1 Local Installation (PySpark)<a class="header-link" href="#41-local-installation-pyspark" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># pip installation</span>
pip<span class="w"> </span>install<span class="w"> </span>pyspark

<span class="c1"># Check version</span>
pyspark<span class="w"> </span>--version

<span class="c1"># Start PySpark shell</span>
pyspark

<span class="c1"># Execute script with spark-submit</span>
spark-submit<span class="w"> </span>my_script.py
</code></pre></div>

<h3 id="42-docker-installation">4.2 Docker Installation<a class="header-link" href="#42-docker-installation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># docker-compose.yaml</span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3&#39;</span>

<span class="nt">services</span><span class="p">:</span>
<span class="w">  </span><span class="nt">spark-master</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bitnami/spark:3.4</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SPARK_MODE=master</span>
<span class="w">    </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;8080:8080&quot;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;7077:7077&quot;</span>

<span class="w">  </span><span class="nt">spark-worker</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bitnami/spark:3.4</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SPARK_MODE=worker</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SPARK_MASTER_URL=spark://spark-master:7077</span>
<span class="w">    </span><span class="nt">depends_on</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">spark-master</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># Run</span>
docker-compose<span class="w"> </span>up<span class="w"> </span>-d

<span class="c1"># Submit job to cluster</span>
spark-submit<span class="w"> </span>--master<span class="w"> </span>spark://localhost:7077<span class="w"> </span>my_script.py
</code></pre></div>

<h3 id="43-cluster-mode">4.3 Cluster Mode<a class="header-link" href="#43-cluster-mode" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Standalone cluster</span>
spark-submit<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--master<span class="w"> </span>spark://master:7077<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-memory<span class="w"> </span>4G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-cores<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-executors<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>my_script.py

<span class="c1"># YARN cluster</span>
spark-submit<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--master<span class="w"> </span>yarn<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--executor-memory<span class="w"> </span>4G<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>my_script.py

<span class="c1"># Kubernetes cluster</span>
spark-submit<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--master<span class="w"> </span>k8s://https://k8s-master:6443<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deploy-mode<span class="w"> </span>cluster<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--conf<span class="w"> </span>spark.kubernetes.container.image<span class="o">=</span>my-spark-image<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>my_script.py
</code></pre></div>

<hr />
<h2 id="5-sparksession">5. SparkSession<a class="header-link" href="#5-sparksession" title="Permanent link">&para;</a></h2>
<h3 id="51-creating-sparksession">5.1 Creating SparkSession<a class="header-link" href="#51-creating-sparksession" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># Basic SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;My Application&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># With configuration</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;My Application&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[*]&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.shuffle.partitions&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">,</span> <span class="s2">&quot;4g&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.driver.memory&quot;</span><span class="p">,</span> <span class="s2">&quot;2g&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.adaptive.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Access SparkContext</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># Check configuration</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;spark.sql.shuffle.partitions&quot;</span><span class="p">))</span>

<span class="c1"># Stop session</span>
<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</code></pre></div>

<h3 id="52-common-configurations">5.2 Common Configurations<a class="header-link" href="#52-common-configurations" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Frequently used configurations</span>
<span class="n">common_configs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Memory settings</span>
    <span class="s2">&quot;spark.executor.memory&quot;</span><span class="p">:</span> <span class="s2">&quot;4g&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.driver.memory&quot;</span><span class="p">:</span> <span class="s2">&quot;2g&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.executor.memoryOverhead&quot;</span><span class="p">:</span> <span class="s2">&quot;512m&quot;</span><span class="p">,</span>

    <span class="c1"># Parallelism settings</span>
    <span class="s2">&quot;spark.executor.cores&quot;</span><span class="p">:</span> <span class="s2">&quot;4&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.default.parallelism&quot;</span><span class="p">:</span> <span class="s2">&quot;100&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.sql.shuffle.partitions&quot;</span><span class="p">:</span> <span class="s2">&quot;200&quot;</span><span class="p">,</span>

    <span class="c1"># Serialization settings</span>
    <span class="s2">&quot;spark.serializer&quot;</span><span class="p">:</span> <span class="s2">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="p">,</span>

    <span class="c1"># Adaptive Query Execution (Spark 3.0+)</span>
    <span class="s2">&quot;spark.sql.adaptive.enabled&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.sql.adaptive.coalescePartitions.enabled&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spark.sql.adaptive.skewJoin.enabled&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>

    <span class="c1"># Cache settings</span>
    <span class="s2">&quot;spark.storage.memoryFraction&quot;</span><span class="p">:</span> <span class="s2">&quot;0.6&quot;</span><span class="p">,</span>

    <span class="c1"># Shuffle settings</span>
    <span class="s2">&quot;spark.shuffle.compress&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Apply configuration example</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.shuffle.partitions&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.sql.adaptive.enabled&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="6-basic-examples">6. Basic Examples<a class="header-link" href="#6-basic-examples" title="Permanent link">&para;</a></h2>
<h3 id="61-word-count">6.1 Word Count<a class="header-link" href="#61-word-count" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># Create SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span> \
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;Word Count&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># Read text file</span>
<span class="n">text_rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;input.txt&quot;</span><span class="p">)</span>

<span class="c1"># Word count logic</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="n">text_rdd</span> \
    <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="mi">1</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">sortBy</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Print results</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Save to file</span>
<span class="n">word_counts</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s2">&quot;output/word_counts&quot;</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</code></pre></div>

<h3 id="62-dataframe-basics">6.2 DataFrame Basics<a class="header-link" href="#62-dataframe-basics" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">_sum</span><span class="p">,</span> <span class="n">avg</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;DataFrame Example&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="c1"># Create DataFrame</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Alice&quot;</span><span class="p">,</span> <span class="s2">&quot;Engineering&quot;</span><span class="p">,</span> <span class="mi">50000</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Bob&quot;</span><span class="p">,</span> <span class="s2">&quot;Engineering&quot;</span><span class="p">,</span> <span class="mi">60000</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Charlie&quot;</span><span class="p">,</span> <span class="s2">&quot;Marketing&quot;</span><span class="p">,</span> <span class="mi">45000</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Diana&quot;</span><span class="p">,</span> <span class="s2">&quot;Marketing&quot;</span><span class="p">,</span> <span class="mi">55000</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;department&quot;</span><span class="p">,</span> <span class="s2">&quot;salary&quot;</span><span class="p">])</span>

<span class="c1"># Basic operations</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>

<span class="c1"># Filtering</span>
<span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;salary&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50000</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Aggregation</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;department&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">agg</span><span class="p">(</span>
        <span class="n">_sum</span><span class="p">(</span><span class="s2">&quot;salary&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_salary&quot;</span><span class="p">),</span>
        <span class="n">avg</span><span class="p">(</span><span class="s2">&quot;salary&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;avg_salary&quot;</span><span class="p">)</span>
    <span class="p">)</span> \
    <span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Using SQL</span>
<span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;employees&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    SELECT department, AVG(salary) as avg_salary</span>
<span class="s2">    FROM employees</span>
<span class="s2">    GROUP BY department</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="practice-problems">Practice Problems<a class="header-link" href="#practice-problems" title="Permanent link">&para;</a></h2>
<h3 id="problem-1-basic-rdd-operations">Problem 1: Basic RDD Operations<a class="header-link" href="#problem-1-basic-rdd-operations" title="Permanent link">&para;</a></h3>
<p>Find the sum of squares of even numbers from 1 to 100.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Solution</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1"># 171700</span>
</code></pre></div>

<h3 id="problem-2-pair-rdd">Problem 2: Pair RDD<a class="header-link" href="#problem-2-pair-rdd" title="Permanent link">&para;</a></h3>
<p>Aggregate log counts by error level from a log file.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Input: &quot;2024-01-01 ERROR: Connection failed&quot;</span>
<span class="n">logs</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;logs.txt&quot;</span><span class="p">)</span>
<span class="n">error_counts</span> <span class="o">=</span> <span class="n">logs</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">level</span><span class="p">:</span> <span class="p">(</span><span class="n">level</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> \
    <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="summary">Summary<a class="header-link" href="#summary" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Spark</strong></td>
<td>Unified engine for large-scale data processing</td>
</tr>
<tr>
<td><strong>RDD</strong></td>
<td>Basic distributed data structure</td>
</tr>
<tr>
<td><strong>Transformation</strong></td>
<td>Creates new RDD (Lazy)</td>
</tr>
<tr>
<td><strong>Action</strong></td>
<td>Returns result (Eager)</td>
</tr>
<tr>
<td><strong>Driver</strong></td>
<td>Main program execution node</td>
</tr>
<tr>
<td><strong>Executor</strong></td>
<td>Task execution worker</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://spark.apache.org/docs/latest/">Apache Spark Documentation</a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/">PySpark API Reference</a></li>
<li><a href="https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/">Learning Spark (O'Reilly)</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Data_Engineering/06_Prefect_Modern_Orchestration.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Prefect Modern Orchestration</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Data_Engineering/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Data_Engineering/08_PySpark_DataFrames.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">PySpark DataFrame</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}