{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>37. Modern Deep Learning Architectures - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">üè†</span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">üíª</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        ÌïúÍµ≠Ïñ¥
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">‚òÄÔ∏è</span>
                    <span class="theme-icon dark">üåô</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Deep_Learning/">Deep Learning</a>
    <span class="separator">/</span>
    <span class="current">37. Modern Deep Learning Architectures</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>37. Modern Deep Learning Architectures</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Deep_Learning/36_Self_Supervised_Learning.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">36. Self-Supervised Learning</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Deep_Learning/38_Object_Detection.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">38. Object Detection</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#learning-objectives">Learning Objectives</a></li>
<li><a href="#1-architecture-evolution-timeline">1. Architecture Evolution Timeline</a><ul>
<li><a href="#key-trends">Key Trends</a></li>
</ul>
</li>
<li><a href="#2-convnext-modernizing-convnets">2. ConvNeXt: Modernizing ConvNets</a><ul>
<li><a href="#21-design-evolution-from-resnet-to-convnext">2.1 Design Evolution from ResNet to ConvNeXt</a></li>
<li><a href="#22-convnext-block-architecture">2.2 ConvNeXt Block Architecture</a></li>
<li><a href="#23-pytorch-implementation">2.3 PyTorch Implementation</a></li>
<li><a href="#24-convnext-v2-improvements-2023">2.4 ConvNeXt V2 Improvements (2023)</a></li>
</ul>
</li>
<li><a href="#3-efficientnetv2">3. EfficientNetV2</a><ul>
<li><a href="#31-fused-mbconv-vs-mbconv">3.1 Fused-MBConv vs. MBConv</a></li>
<li><a href="#32-progressive-training">3.2 Progressive Training</a></li>
<li><a href="#33-using-efficientnetv2-with-timm">3.3 Using EfficientNetV2 with timm</a></li>
</ul>
</li>
<li><a href="#4-dinov2-self-supervised-vision-foundation-model">4. DINOv2: Self-Supervised Vision Foundation Model</a><ul>
<li><a href="#41-key-innovations">4.1 Key Innovations</a></li>
<li><a href="#42-model-variants">4.2 Model Variants</a></li>
<li><a href="#43-using-pretrained-dinov2">4.3 Using Pretrained DINOv2</a></li>
<li><a href="#44-downstream-tasks-with-dinov2">4.4 Downstream Tasks with DINOv2</a></li>
</ul>
</li>
<li><a href="#5-latent-consistency-models-lcm">5. Latent Consistency Models (LCM)</a><ul>
<li><a href="#51-consistency-distillation">5.1 Consistency Distillation</a></li>
<li><a href="#52-lcm-training">5.2 LCM Training</a></li>
<li><a href="#53-lcm-lora-for-fast-fine-tuning">5.3 LCM-LoRA for Fast Fine-tuning</a></li>
<li><a href="#54-using-lcm-with-diffusers">5.4 Using LCM with Diffusers</a></li>
</ul>
</li>
<li><a href="#6-architecture-comparison-table">6. Architecture Comparison Table</a></li>
<li><a href="#7-using-pretrained-models-practical-guide">7. Using Pretrained Models: Practical Guide</a><ul>
<li><a href="#71-timm-library-pytorch-image-models">7.1 timm Library (PyTorch Image Models)</a></li>
<li><a href="#72-hugging-face-transformers">7.2 Hugging Face Transformers</a></li>
<li><a href="#73-transfer-learning-best-practices">7.3 Transfer Learning Best Practices</a></li>
</ul>
</li>
<li><a href="#8-architecture-selection-guide">8. Architecture Selection Guide</a><ul>
<li><a href="#81-decision-tree">8.1 Decision Tree</a></li>
<li><a href="#82-practical-recommendations">8.2 Practical Recommendations</a></li>
</ul>
</li>
<li><a href="#9-practice-problems">9. Practice Problems</a><ul>
<li><a href="#problem-1-convnext-block-implementation">Problem 1: ConvNeXt Block Implementation</a></li>
<li><a href="#problem-2-progressive-training-schedule">Problem 2: Progressive Training Schedule</a></li>
<li><a href="#problem-3-dinov2-feature-extraction">Problem 3: DINOv2 Feature Extraction</a></li>
<li><a href="#problem-4-lcm-fast-generation">Problem 4: LCM Fast Generation</a></li>
<li><a href="#problem-5-model-comparison">Problem 5: Model Comparison</a></li>
</ul>
</li>
<li><a href="#navigation">Navigation</a></li>
<li><a href="#further-reading">Further Reading</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <p><a href="./36_Self_Supervised_Learning.md">Previous: Self-Supervised Learning</a> | <a href="./38_Object_Detection.md">Next: Object Detection</a></p>
<hr />
<h1 id="37-modern-deep-learning-architectures">37. Modern Deep Learning Architectures<a class="header-link" href="#37-modern-deep-learning-architectures" title="Permanent link">&para;</a></h1>
<h2 id="learning-objectives">Learning Objectives<a class="header-link" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<ul>
<li>Survey recent architectural innovations in deep learning (2020-2024)</li>
<li>Understand ConvNeXt and the evolution of pure ConvNets in the Transformer era</li>
<li>Learn about EfficientNetV2 and progressive training strategies</li>
<li>Explore DINOv2 as a self-supervised vision foundation model</li>
<li>Understand Latent Consistency Models (LCM) for fast diffusion sampling</li>
<li>Apply pretrained modern architectures using timm and transformers libraries</li>
</ul>
<hr />
<h2 id="1-architecture-evolution-timeline">1. Architecture Evolution Timeline<a class="header-link" href="#1-architecture-evolution-timeline" title="Permanent link">&para;</a></h2>
<p>The landscape of deep learning architectures has evolved rapidly:</p>
<div class="highlight"><pre><span></span><code><span class="mi">2017</span><span class="o">:</span><span class="w"> </span><span class="n">ResNet</span><span class="o">/</span><span class="n">ResNeXt</span><span class="w"> </span><span class="n">dominance</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Bottleneck</span><span class="w"> </span><span class="n">blocks</span><span class="o">,</span><span class="w"> </span><span class="n">skip</span><span class="w"> </span><span class="n">connections</span>

<span class="mi">2017</span><span class="o">:</span><span class="w"> </span><span class="n">Transformer</span><span class="w"> </span><span class="o">(</span><span class="n">NLP</span><span class="o">)</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Self</span><span class="o">-</span><span class="n">attention</span><span class="o">,</span><span class="w"> </span><span class="n">positional</span><span class="w"> </span><span class="n">encoding</span>

<span class="mi">2020</span><span class="o">:</span><span class="w"> </span><span class="n">Vision</span><span class="w"> </span><span class="n">Transformer</span><span class="w"> </span><span class="o">(</span><span class="n">ViT</span><span class="o">)</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Pure</span><span class="w"> </span><span class="n">attention</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">vision</span>

<span class="mi">2021</span><span class="o">:</span><span class="w"> </span><span class="n">Swin</span><span class="w"> </span><span class="n">Transformer</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Hierarchical</span><span class="w"> </span><span class="n">vision</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">shifted</span><span class="w"> </span><span class="n">windows</span>

<span class="mi">2022</span><span class="o">:</span><span class="w"> </span><span class="n">ConvNeXt</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Modernized</span><span class="w"> </span><span class="n">ConvNet</span><span class="w"> </span><span class="n">matching</span><span class="w"> </span><span class="n">Transformers</span>

<span class="mi">2022</span><span class="o">:</span><span class="w"> </span><span class="n">EfficientNetV2</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Progressive</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Fused</span><span class="o">-</span><span class="n">MBConv</span>

<span class="mi">2023</span><span class="o">:</span><span class="w"> </span><span class="n">DINOv2</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Self</span><span class="o">-</span><span class="n">supervised</span><span class="w"> </span><span class="n">vision</span><span class="w"> </span><span class="n">foundation</span><span class="w"> </span><span class="n">model</span>

<span class="mi">2023</span><span class="o">:</span><span class="w"> </span><span class="n">Latent</span><span class="w"> </span><span class="n">Consistency</span><span class="w"> </span><span class="n">Models</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Fast</span><span class="w"> </span><span class="n">diffusion</span><span class="w"> </span><span class="n">sampling</span><span class="w"> </span><span class="o">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">4</span><span class="w"> </span><span class="n">steps</span><span class="o">)</span>

<span class="mi">2024</span><span class="o">:</span><span class="w"> </span><span class="n">ConvNeXt</span><span class="w"> </span><span class="n">V2</span><span class="o">,</span><span class="w"> </span><span class="n">Mamba</span><span class="o">,</span><span class="w"> </span><span class="n">Hyena</span>
<span class="w">      </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Continued</span><span class="w"> </span><span class="n">innovation</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">architectures</span>
</code></pre></div>

<h3 id="key-trends">Key Trends<a class="header-link" href="#key-trends" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Hybrid architectures</strong>: Combining convolutions and attention</li>
<li><strong>Self-supervised pretraining</strong>: DINO, MAE, CLIP</li>
<li><strong>Scaling laws</strong>: Bigger models, more data, longer training</li>
<li><strong>Efficiency</strong>: Reducing FLOPs, parameters, and latency</li>
<li><strong>Foundation models</strong>: General-purpose pretrained models</li>
</ol>
<hr />
<h2 id="2-convnext-modernizing-convnets">2. ConvNeXt: Modernizing ConvNets<a class="header-link" href="#2-convnext-modernizing-convnets" title="Permanent link">&para;</a></h2>
<p><strong>ConvNeXt</strong> (Liu et al., 2022) demonstrates that pure ConvNets can match Transformers when modernized with recent design choices.</p>
<h3 id="21-design-evolution-from-resnet-to-convnext">2.1 Design Evolution from ResNet to ConvNeXt<a class="header-link" href="#21-design-evolution-from-resnet-to-convnext" title="Permanent link">&para;</a></h3>
<p>Starting from ResNet-50, apply modern improvements step-by-step:</p>
<div class="highlight"><pre><span></span><code>Step 1: Training procedure (90 ‚Üí 300 epochs, AdamW, mixup, cutmix)
        Accuracy: 76.1% ‚Üí 78.8%

Step 2: Macro design (stage ratio 3:4:6:3 ‚Üí 3:3:9:3)
        Patchify stem (7√ó7 stride-2 ‚Üí 4√ó4 stride-4)
        Accuracy: 78.8% ‚Üí 79.4%

Step 3: ResNeXt-ify (grouped convolutions)
        Depthwise convolution (groups = channels)
        Accuracy: 79.4% ‚Üí 80.5%

Step 4: Inverted bottleneck (narrow ‚Üí wide ‚Üí narrow)
        Expansion ratio 4√ó (similar to Transformers&#39; MLP)
        Accuracy: 80.5% ‚Üí 80.6%

Step 5: Large kernel sizes (3√ó3 ‚Üí 7√ó7)
        Accuracy: 80.6% ‚Üí 81.0%

Step 6: Micro design (ReLU ‚Üí GELU, BN ‚Üí LN, fewer layers)
        Accuracy: 81.0% ‚Üí 82.0%

Final ConvNeXt-T: 82.0% (matches Swin-T)
</code></pre></div>

<h3 id="22-convnext-block-architecture">2.2 ConvNeXt Block Architecture<a class="header-link" href="#22-convnext-block-architecture" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>Input (C channels)
    |
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  (Residual connection)
    |                  |
Depthwise Conv 7√ó7     |
    |                  |
LayerNorm              |
    |                  |
1√ó1 Conv (4C)          |  (Expansion)
    |                  |
GELU                   |
    |                  |
1√ó1 Conv (C)           |  (Projection)
    |                  |
    +‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    |
Output (C channels)
</code></pre></div>

<p><strong>Key differences from ResNet</strong>:
- <strong>Depthwise convolution</strong> (7√ó7) instead of 3√ó3 standard conv
- <strong>Inverted bottleneck</strong>: expand to 4C, then project back to C
- <strong>LayerNorm</strong> instead of BatchNorm
- <strong>GELU</strong> instead of ReLU
- <strong>Fewer activation functions</strong>: only one per block</p>
<h3 id="23-pytorch-implementation">2.3 PyTorch Implementation<a class="header-link" href="#23-pytorch-implementation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ConvNeXtBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ConvNeXt block with inverted bottleneck design.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">expansion_ratio</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">layer_scale_init</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Depthwise convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">dim</span>
        <span class="p">)</span>

        <span class="c1"># Normalization and projection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">expansion_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># Expansion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">expansion_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># Projection</span>

        <span class="c1"># Layer scale (learned per-channel scaling)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">layer_scale_init</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span> <span class="k">if</span> <span class="n">layer_scale_init</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>

        <span class="c1"># Depthwise conv</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Permute for LayerNorm and pointwise convs</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>

        <span class="c1"># Inverted bottleneck with LayerNorm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Layer scale</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x</span>

        <span class="c1"># Permute back</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (N, H, W, C) -&gt; (N, C, H, W)</span>

        <span class="c1"># Residual connection</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span><span class="w"> </span><span class="nc">ConvNeXt</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ConvNeXt model.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">depths</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  <span class="c1"># Number of blocks per stage</span>
        <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="mi">96</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">768</span><span class="p">],</span>  <span class="c1"># Channels per stage</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Stem: patchify with 4√ó4 conv, stride 4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stem</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Build 4 stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stages</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="c1"># Downsampling layer (except first stage)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

            <span class="c1"># Stack ConvNeXt blocks</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span>
                <span class="n">ConvNeXtBlock</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depths</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="p">])</span>

            <span class="n">stage</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">downsample</span><span class="p">,</span> <span class="n">blocks</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>

        <span class="c1"># Head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Stem</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>

        <span class="c1"># Stages</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># -&gt; (N, C, H, W)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">stage</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># -&gt; (N, H, W, C)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>  <span class="c1"># Global average pooling</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Example usage</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNeXt</span><span class="p">(</span>
    <span class="n">depths</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>  <span class="c1"># ConvNeXt-T</span>
    <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="mi">96</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">768</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output shape: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (2, 1000)</span>
</code></pre></div>

<h3 id="24-convnext-v2-improvements-2023">2.4 ConvNeXt V2 Improvements (2023)<a class="header-link" href="#24-convnext-v2-improvements-2023" title="Permanent link">&para;</a></h3>
<p><strong>ConvNeXt V2</strong> introduced:
1. <strong>Global Response Normalization (GRN)</strong>: enhance inter-channel feature competition
2. <strong>Fully convolutional MAE</strong>: masked autoencoder pretraining for ConvNets
3. <strong>Improved performance</strong>: 87.3% on ImageNet-1K (ConvNeXt V2-H)</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">GRN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Global Response Normalization layer.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (N, H, W, C)</span>
        <span class="c1"># Compute global feature map</span>
        <span class="n">Gx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Normalize</span>
        <span class="n">Nx</span> <span class="o">=</span> <span class="n">Gx</span> <span class="o">/</span> <span class="p">(</span><span class="n">Gx</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
        <span class="c1"># Scale and shift</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">Nx</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="n">x</span>
</code></pre></div>

<hr />
<h2 id="3-efficientnetv2">3. EfficientNetV2<a class="header-link" href="#3-efficientnetv2" title="Permanent link">&para;</a></h2>
<p><strong>EfficientNetV2</strong> (Tan &amp; Le, 2021) improves training speed and parameter efficiency through:
1. <strong>Fused-MBConv blocks</strong>: fused expansion and depthwise convolution
2. <strong>Progressive training</strong>: gradually increase image size and regularization
3. <strong>Neural Architecture Search (NAS)</strong>: optimized for training speed</p>
<h3 id="31-fused-mbconv-vs-mbconv">3.1 Fused-MBConv vs. MBConv<a class="header-link" href="#31-fused-mbconv-vs-mbconv" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">MBConv</span><span class="w"> </span><span class="p">(</span><span class="n">MobileNetV2</span><span class="p">)</span><span class="o">:</span><span class="w">                </span><span class="n">Fused</span><span class="o">-</span><span class="n">MBConv</span><span class="o">:</span>
<span class="w">  </span><span class="n">Input</span><span class="w">                                </span><span class="n">Input</span>
<span class="w">    </span><span class="o">|</span><span class="w">                                    </span><span class="o">|</span>
<span class="w">  </span><span class="mi">1</span><span class="err">√ó</span><span class="mi">1</span><span class="w"> </span><span class="n">Conv</span><span class="w"> </span><span class="p">(</span><span class="n">expand</span><span class="p">)</span><span class="w">                    </span><span class="mi">3</span><span class="err">√ó</span><span class="mi">3</span><span class="w"> </span><span class="n">Conv</span><span class="w"> </span><span class="p">(</span><span class="n">expand</span><span class="p">)</span>
<span class="w">    </span><span class="o">|</span><span class="w">                                    </span><span class="o">|</span>
<span class="w">  </span><span class="n">DW</span><span class="w"> </span><span class="mi">3</span><span class="err">√ó</span><span class="mi">3</span><span class="w">                               </span><span class="p">[</span><span class="n">Fused</span><span class="w"> </span><span class="n">operation</span><span class="p">]</span>
<span class="w">    </span><span class="o">|</span><span class="w">                                    </span><span class="o">|</span>
<span class="w">  </span><span class="mi">1</span><span class="err">√ó</span><span class="mi">1</span><span class="w"> </span><span class="n">Conv</span><span class="w"> </span><span class="p">(</span><span class="n">project</span><span class="p">)</span><span class="w">                   </span><span class="mi">1</span><span class="err">√ó</span><span class="mi">1</span><span class="w"> </span><span class="n">Conv</span><span class="w"> </span><span class="p">(</span><span class="n">project</span><span class="p">)</span>
<span class="w">    </span><span class="o">|</span><span class="w">                                    </span><span class="o">|</span>
<span class="w">  </span><span class="n">Output</span><span class="w">                               </span><span class="n">Output</span>

<span class="w">  </span><span class="mi">3</span><span class="w"> </span><span class="n">separate</span><span class="w"> </span><span class="n">ops</span><span class="w">                       </span><span class="mi">2</span><span class="w"> </span><span class="n">ops</span><span class="w"> </span><span class="p">(</span><span class="n">faster</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">FLOPs</span><span class="p">)</span>
</code></pre></div>

<p><strong>Trade-off</strong>:
- <strong>MBConv</strong>: Better for larger models (fewer parameters)
- <strong>Fused-MBConv</strong>: Better for smaller models (faster training)</p>
<p>EfficientNetV2 uses <strong>both</strong> in different stages.</p>
<h3 id="32-progressive-training">3.2 Progressive Training<a class="header-link" href="#32-progressive-training" title="Permanent link">&para;</a></h3>
<p><strong>Key idea</strong>: Train with smaller images and weaker regularization initially, then gradually increase.</p>
<div class="highlight"><pre><span></span><code>Stage 1 (epochs 0-50):
  - Image size: 128√ó128
  - RandAugment magnitude: 5
  - Mixup alpha: 0

Stage 2 (epochs 50-100):
  - Image size: 192√ó192
  - RandAugment magnitude: 10
  - Mixup alpha: 0.2

Stage 3 (epochs 100-150):
  - Image size: 256√ó256
  - RandAugment magnitude: 15
  - Mixup alpha: 0.4
</code></pre></div>

<p><strong>Benefits</strong>:
- <strong>Faster convergence</strong>: Easier to optimize with smaller images
- <strong>Better regularization</strong>: Stronger augmentation on larger images
- <strong>Improved accuracy</strong>: 85.7% on ImageNet (EfficientNetV2-L)</p>
<h3 id="33-using-efficientnetv2-with-timm">3.3 Using EfficientNetV2 with timm<a class="header-link" href="#33-using-efficientnetv2-with-timm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">timm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># List available EfficientNetV2 models</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">list_models</span><span class="p">(</span><span class="s1">&#39;*efficientnetv2*&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
<span class="c1"># [&#39;tf_efficientnetv2_b0&#39;, &#39;tf_efficientnetv2_b1&#39;, ..., &#39;tf_efficientnetv2_l&#39;]</span>

<span class="c1"># Load pretrained EfficientNetV2-S</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;tf_efficientnetv2_s&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Get model info</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">M&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input size: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">default_cfg</span><span class="p">[</span><span class="s1">&#39;input_size&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Inference</span>
<span class="n">data_config</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">resolve_model_data_config</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">create_transform</span><span class="p">(</span><span class="o">**</span><span class="n">data_config</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, 3, 384, 384)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">top5_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Print top-5 predictions</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageNetInfo</span><span class="o">.</span><span class="n">label_names</span><span class="p">()</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">top5_idx</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="4-dinov2-self-supervised-vision-foundation-model">4. DINOv2: Self-Supervised Vision Foundation Model<a class="header-link" href="#4-dinov2-self-supervised-vision-foundation-model" title="Permanent link">&para;</a></h2>
<p><strong>DINOv2</strong> (Oquab et al., 2023) is a self-supervised Vision Transformer pretrained on 142M images without labels.</p>
<h3 id="41-key-innovations">4.1 Key Innovations<a class="header-link" href="#41-key-innovations" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Self-distillation with no labels</strong> (DINO framework)</li>
<li><strong>ViT backbone</strong> with register tokens</li>
<li><strong>Large-scale pretraining</strong> (142M images, LVD-142M dataset)</li>
<li><strong>Multi-task head</strong>: classification, segmentation, depth estimation</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="n">DINO</span><span class="w"> </span><span class="n">Self</span><span class="o">-</span><span class="nl">Distillation</span><span class="p">:</span>

<span class="w">   </span><span class="n">Student</span><span class="w"> </span><span class="p">(</span><span class="n">ViT</span><span class="o">-</span><span class="n">S</span><span class="p">)</span><span class="w">          </span><span class="n">Teacher</span><span class="w"> </span><span class="p">(</span><span class="n">EMA</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">Student</span><span class="p">)</span>
<span class="w">         </span><span class="o">|</span><span class="w">                          </span><span class="o">|</span>
<span class="w">    </span><span class="o">[</span><span class="n">CLS</span><span class="o">]</span><span class="w"> </span><span class="n">token</span><span class="w">               </span><span class="o">[</span><span class="n">CLS</span><span class="o">]</span><span class="w"> </span><span class="n">token</span>
<span class="w">         </span><span class="o">|</span><span class="w">                          </span><span class="o">|</span>
<span class="w">    </span><span class="err">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span><span class="w">              </span><span class="err">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span>
<span class="w">    </span><span class="err">‚îÇ</span><span class="w"> </span><span class="n">Predict</span><span class="w"> </span><span class="err">‚îÇ</span><span class="w">              </span><span class="err">‚îÇ</span><span class="w"> </span><span class="n">Target</span><span class="w">  </span><span class="err">‚îÇ</span>
<span class="w">    </span><span class="err">‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span><span class="w">              </span><span class="err">‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
<span class="w">         </span><span class="o">|</span><span class="w">                          </span><span class="o">|</span>
<span class="w">         </span><span class="err">‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span><span class="w"> </span><span class="k">Match</span><span class="w"> </span><span class="err">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
<span class="w">              </span><span class="p">(</span><span class="k">no</span><span class="w"> </span><span class="n">labels</span><span class="err">!</span><span class="p">)</span>

<span class="nl">Augmentations</span><span class="p">:</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="nl">Student</span><span class="p">:</span><span class="w"> </span><span class="n">strong</span><span class="w"> </span><span class="n">crops</span><span class="w"> </span><span class="p">(</span><span class="n">multi</span><span class="o">-</span><span class="n">crop</span><span class="p">)</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="nl">Teacher</span><span class="p">:</span><span class="w"> </span><span class="n">weak</span><span class="w"> </span><span class="n">crops</span><span class="w"> </span><span class="p">(</span><span class="k">global</span><span class="w"> </span><span class="n">views</span><span class="p">)</span>
</code></pre></div>

<ol>
<li><strong>Register tokens</strong> (additional learnable tokens):</li>
<li>Improve feature quality by absorbing background artifacts</li>
<li>
<p>Similar to [CLS] token but not used for classification</p>
</li>
<li>
<p><strong>Frozen backbone + linear probes</strong>:</p>
</li>
<li>Extract features with frozen DINOv2</li>
<li>Train lightweight heads for downstream tasks</li>
</ol>
<h3 id="42-model-variants">4.2 Model Variants<a class="header-link" href="#42-model-variants" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Params</th>
<th>Layers</th>
<th>Hidden Dim</th>
<th>Patch Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>DINOv2-S</td>
<td>22M</td>
<td>12</td>
<td>384</td>
<td>14√ó14</td>
</tr>
<tr>
<td>DINOv2-B</td>
<td>86M</td>
<td>12</td>
<td>768</td>
<td>14√ó14</td>
</tr>
<tr>
<td>DINOv2-L</td>
<td>304M</td>
<td>24</td>
<td>1024</td>
<td>14√ó14</td>
</tr>
<tr>
<td>DINOv2-g</td>
<td>1.1B</td>
<td>40</td>
<td>1536</td>
<td>14√ó14</td>
</tr>
</tbody>
</table>
<h3 id="43-using-pretrained-dinov2">4.3 Using Pretrained DINOv2<a class="header-link" href="#43-using-pretrained-dinov2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Load pretrained DINOv2-base</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/dinov2-base&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/dinov2-base&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Load image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>

<span class="c1"># Extract features</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="c1"># Get patch embeddings (excluding [CLS])</span>
<span class="n">patch_embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (1, num_patches, 768)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Patch embeddings shape: </span><span class="si">{</span><span class="n">patch_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Get [CLS] token (global image representation)</span>
<span class="n">cls_token</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (1, 768)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CLS token shape: </span><span class="si">{</span><span class="n">cls_token</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Use as feature extractor for downstream tasks</span>
<span class="c1"># Example: k-NN classification</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Assume we have a training set</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Extract from training images</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Fit k-NN</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_features</span><span class="p">),</span> <span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cls_token</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>

<h3 id="44-downstream-tasks-with-dinov2">4.4 Downstream Tasks with DINOv2<a class="header-link" href="#44-downstream-tasks-with-dinov2" title="Permanent link">&para;</a></h3>
<p><strong>1. Image Classification</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dinov2ForImageClassification</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Dinov2ForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s1">&#39;facebook/dinov2-base&#39;</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># Custom dataset</span>
    <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Fine-tune on custom dataset</span>
<span class="c1"># ... training loop ...</span>
</code></pre></div>

<p><strong>2. Semantic Segmentation</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Use patch embeddings for dense prediction</span>
<span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">patch_embeddings</span><span class="o">.</span><span class="n">shape</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># Assume square</span>

<span class="c1"># Reshape to spatial grid</span>
<span class="n">spatial_features</span> <span class="o">=</span> <span class="n">patch_embeddings</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">spatial_features</span> <span class="o">=</span> <span class="n">spatial_features</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, D, H, W)</span>

<span class="c1"># Add segmentation head</span>
<span class="n">seg_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">seg_head</span><span class="p">(</span><span class="n">spatial_features</span><span class="p">)</span>  <span class="c1"># (B, num_classes, H, W)</span>
</code></pre></div>

<p><strong>3. Depth Estimation</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Similar to segmentation, but regress depth</span>
<span class="n">depth_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">depth_map</span> <span class="o">=</span> <span class="n">depth_head</span><span class="p">(</span><span class="n">spatial_features</span><span class="p">)</span>  <span class="c1"># (B, 1, H, W)</span>
</code></pre></div>

<hr />
<h2 id="5-latent-consistency-models-lcm">5. Latent Consistency Models (LCM)<a class="header-link" href="#5-latent-consistency-models-lcm" title="Permanent link">&para;</a></h2>
<p><strong>Latent Consistency Models</strong> (Luo et al., 2023) enable fast sampling from diffusion models in 1-4 steps (vs. 25-50 steps for standard diffusion).</p>
<h3 id="51-consistency-distillation">5.1 Consistency Distillation<a class="header-link" href="#51-consistency-distillation" title="Permanent link">&para;</a></h3>
<p><strong>Key idea</strong>: Distill a pretrained diffusion model into a consistency model that maps any noisy latent directly to the clean latent.</p>
<div class="highlight"><pre><span></span><code>Standard Diffusion (DDPM):
  x_T (noise) ‚Üí x_{T-1} ‚Üí ... ‚Üí x_1 ‚Üí x_0 (clean)
  (50 steps, slow)

Latent Consistency Model:
  x_T (noise) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí x_0 (clean)
  (1-4 steps, fast!)

Consistency property:
  For any t, t&#39; ‚àà [0, T]:
    f(x_t, t) ‚âà f(x_{t&#39;}, t&#39;)
  (all noisy latents map to same clean latent)
</code></pre></div>

<h3 id="52-lcm-training">5.2 LCM Training<a class="header-link" href="#52-lcm-training" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Start with pretrained diffusion model</strong> (e.g., Stable Diffusion)</li>
<li><strong>Distill into LCM</strong> using consistency loss:</li>
</ol>
<div class="highlight"><pre><span></span><code>Consistency loss:
  L = E_{x, t, t&#39;} [ || f(x_t, t) - sg(f(x_{t&#39;}, t&#39;)) ||^2 ]

  where:
    <span class="k">-</span> x_t, x_{t&#39;} are noisy latents at different timesteps
    <span class="k">-</span> f is the consistency model (student)
    <span class="k">-</span> sg is stop-gradient (teacher is EMA of student)
</code></pre></div>

<ol>
<li><strong>Few-step sampling</strong>: Use ODE solver (e.g., DDIM) with 2-4 steps</li>
</ol>
<h3 id="53-lcm-lora-for-fast-fine-tuning">5.3 LCM-LoRA for Fast Fine-tuning<a class="header-link" href="#53-lcm-lora-for-fast-fine-tuning" title="Permanent link">&para;</a></h3>
<p><strong>LCM-LoRA</strong> applies Low-Rank Adaptation to consistency distillation:
- <strong>Faster training</strong>: Only train LoRA weights (~1-5% of parameters)
- <strong>Composable</strong>: Combine with other LoRAs (style, character, etc.)
- <strong>Efficient</strong>: Can distill on single GPU</p>
<h3 id="54-using-lcm-with-diffusers">5.4 Using LCM with Diffusers<a class="header-link" href="#54-using-lcm-with-diffusers" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiffusionPipeline</span><span class="p">,</span> <span class="n">LCMScheduler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Load LCM pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">DiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;SimianLuo/LCM_Dreamshaper_v7&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># LCM uses special scheduler</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LCMScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Generate with 4 steps (vs. 50 for standard diffusion!)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A beautiful sunset over mountains, highly detailed, 8k&quot;</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="c1"># Very fast!</span>
    <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># LCM works best with guidance_scale=1</span>
<span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;sunset_lcm.png&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Using LCM-LoRA</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionPipeline</span><span class="p">,</span> <span class="n">LCMScheduler</span>

<span class="c1"># Load base model</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="c1"># Load LCM-LoRA weights</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span><span class="s2">&quot;latent-consistency/lcm-lora-sdv1-5&quot;</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LCMScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Generate with 4-8 steps</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;Portrait of a cat, oil painting&quot;</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">1.0</span>
<span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>

<hr />
<h2 id="6-architecture-comparison-table">6. Architecture Comparison Table<a class="header-link" href="#6-architecture-comparison-table" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Params</th>
<th>FLOPs (G)</th>
<th>ImageNet Acc</th>
<th>Training Data</th>
<th>Pretraining Method</th>
</tr>
</thead>
<tbody>
<tr>
<td>ResNet-50</td>
<td>25M</td>
<td>4.1</td>
<td>76.2%</td>
<td>1.3M</td>
<td>Supervised</td>
</tr>
<tr>
<td>EfficientNet-B4</td>
<td>19M</td>
<td>4.5</td>
<td>82.9%</td>
<td>1.3M</td>
<td>Supervised + AutoAug</td>
</tr>
<tr>
<td>EfficientNetV2-S</td>
<td>24M</td>
<td>8.4</td>
<td>84.9%</td>
<td>1.3M</td>
<td>Supervised + Progressive</td>
</tr>
<tr>
<td>ViT-B/16</td>
<td>86M</td>
<td>17.6</td>
<td>84.5%</td>
<td>300M</td>
<td>Supervised (JFT-300M)</td>
</tr>
<tr>
<td>Swin-B</td>
<td>88M</td>
<td>15.4</td>
<td>85.2%</td>
<td>1.3M</td>
<td>Supervised</td>
</tr>
<tr>
<td>ConvNeXt-B</td>
<td>89M</td>
<td>15.4</td>
<td>85.8%</td>
<td>1.3M</td>
<td>Supervised</td>
</tr>
<tr>
<td>ConvNeXt V2-B</td>
<td>89M</td>
<td>15.4</td>
<td>86.8%</td>
<td>1.3M</td>
<td>FCMAE (self-supervised)</td>
</tr>
<tr>
<td>DINOv2-B</td>
<td>86M</td>
<td>17.6</td>
<td>84.5% (linear)</td>
<td>142M</td>
<td>Self-supervised (DINO)</td>
</tr>
<tr>
<td>DINOv2-g</td>
<td>1.1B</td>
<td>280</td>
<td>88.5% (linear)</td>
<td>142M</td>
<td>Self-supervised (DINO)</td>
</tr>
</tbody>
</table>
<p><strong>Notes</strong>:
- <strong>FLOPs</strong>: Measured at 224√ó224 resolution
- <strong>ImageNet Acc</strong>: Top-1 accuracy on ImageNet-1K validation set
- <strong>DINOv2 (linear)</strong>: Linear probe evaluation (frozen features + linear classifier)</p>
<hr />
<h2 id="7-using-pretrained-models-practical-guide">7. Using Pretrained Models: Practical Guide<a class="header-link" href="#7-using-pretrained-models-practical-guide" title="Permanent link">&para;</a></h2>
<h3 id="71-timm-library-pytorch-image-models">7.1 timm Library (PyTorch Image Models)<a class="header-link" href="#71-timm-library-pytorch-image-models" title="Permanent link">&para;</a></h3>
<p><strong>timm</strong> provides 700+ pretrained models with unified interface.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">timm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># List all models</span>
<span class="n">all_models</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">list_models</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total models: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_models</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Search for specific architecture</span>
<span class="n">convnext_models</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">list_models</span><span class="p">(</span><span class="s1">&#39;convnext*&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">convnext_models</span><span class="p">)</span>

<span class="c1"># Create model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
    <span class="s1">&#39;convnext_base.fb_in22k_ft_in1k&#39;</span><span class="p">,</span>  <span class="c1"># Pretrained on ImageNet-22k, fine-tuned on 1k</span>
    <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span>
<span class="p">)</span>

<span class="c1"># Inspect model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">default_cfg</span><span class="p">)</span>  <span class="c1"># Config dict</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">M&quot;</span><span class="p">)</span>

<span class="c1"># Feature extraction mode</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;convnext_base&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Returns features instead of logits</span>

<span class="c1"># Get intermediate features</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;convnext_base&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">features_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stage </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># Stage 0: (1, 128, 56, 56)</span>
<span class="c1"># Stage 1: (1, 256, 28, 28)</span>
<span class="c1"># Stage 2: (1, 512, 14, 14)</span>
<span class="c1"># Stage 3: (1, 1024, 7, 7)</span>
</code></pre></div>

<h3 id="72-hugging-face-transformers">7.2 Hugging Face Transformers<a class="header-link" href="#72-hugging-face-transformers" title="Permanent link">&para;</a></h3>
<p><strong>transformers</strong> library supports vision models via AutoModel.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="n">AutoModelForImageClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Load processor and model</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/swin-base-patch4-window7-224&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/swin-base-patch4-window7-224&quot;</span><span class="p">)</span>

<span class="c1"># Prepare input</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;cat.jpg&quot;</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="c1"># Inference</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted class: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">predicted_class</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="73-transfer-learning-best-practices">7.3 Transfer Learning Best Practices<a class="header-link" href="#73-transfer-learning-best-practices" title="Permanent link">&para;</a></h3>
<p><strong>1. Feature Extraction</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Freeze pretrained weights</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;convnext_base&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Replace classifier head</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">model</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Only train the head</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div>

<p><strong>2. Fine-tuning</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Unfreeze all layers</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Use lower learning rate for pretrained weights</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">([</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">stages</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">5e-5</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}</span>
<span class="p">])</span>
</code></pre></div>

<p><strong>3. Progressive unfreezing</strong> (ULMFiT strategy):</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Epoch 0-5: Train head only</span>
<span class="c1"># Epoch 5-10: Unfreeze last stage</span>
<span class="c1"># Epoch 10+: Unfreeze all</span>

<span class="k">def</span><span class="w"> </span><span class="nf">unfreeze_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="c1"># Freeze all except head</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">stages</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="c1"># Unfreeze last stage</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Unfreeze all</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div>

<hr />
<h2 id="8-architecture-selection-guide">8. Architecture Selection Guide<a class="header-link" href="#8-architecture-selection-guide" title="Permanent link">&para;</a></h2>
<h3 id="81-decision-tree">8.1 Decision Tree<a class="header-link" href="#81-decision-tree" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">‚îå‚îÄ</span><span class="w"> </span><span class="n">Need</span><span class="w"> </span><span class="n">supervised</span><span class="w"> </span><span class="n">pretraining</span><span class="err">?</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Yes</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Priority</span><span class="p">:</span><span class="w"> </span><span class="n">Accuracy</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">ConvNeXt</span><span class="w"> </span><span class="n">V2</span><span class="p">,</span><span class="w"> </span><span class="n">EfficientNetV2</span><span class="o">-</span><span class="n">L</span><span class="p">,</span><span class="w"> </span><span class="n">Swin</span><span class="o">-</span><span class="n">L</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Priority</span><span class="p">:</span><span class="w"> </span><span class="n">Speed</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">EfficientNetV2</span><span class="o">-</span><span class="n">S</span><span class="p">,</span><span class="w"> </span><span class="n">MobileNetV3</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">No</span><span class="w"> </span><span class="p">(</span><span class="bp">self</span><span class="o">-</span><span class="n">supervised</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Vision</span><span class="w"> </span><span class="n">foundation</span><span class="w"> </span><span class="n">model</span>
<span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">DINOv2</span><span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">g</span><span class="w"> </span><span class="p">(</span><span class="n">best</span><span class="w"> </span><span class="n">features</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Custom</span><span class="w"> </span><span class="n">dataset</span>
<span class="err">‚îÇ</span><span class="w">        </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">DINO</span><span class="p">,</span><span class="w"> </span><span class="n">MAE</span><span class="p">,</span><span class="w"> </span><span class="n">SimCLR</span>

<span class="err">‚îå‚îÄ</span><span class="w"> </span><span class="n">Need</span><span class="w"> </span><span class="n">generative</span><span class="w"> </span><span class="n">model</span><span class="err">?</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Fast</span><span class="w"> </span><span class="n">sampling</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">4</span><span class="w"> </span><span class="n">steps</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Latent</span><span class="w"> </span><span class="n">Consistency</span><span class="w"> </span><span class="n">Models</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Best</span><span class="w"> </span><span class="n">quality</span><span class="w"> </span><span class="p">(</span><span class="mi">25</span><span class="o">-</span><span class="mi">50</span><span class="w"> </span><span class="n">steps</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Stable</span><span class="w"> </span><span class="n">Diffusion</span><span class="p">,</span><span class="w"> </span><span class="n">DALL</span><span class="o">-</span><span class="n">E</span><span class="w"> </span><span class="mi">3</span>

<span class="err">‚îå‚îÄ</span><span class="w"> </span><span class="n">Deployment</span><span class="w"> </span><span class="n">constraints</span><span class="err">?</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Edge</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="p">(</span><span class="n">mobile</span><span class="p">,</span><span class="w"> </span><span class="n">IoT</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">MobileNetV3</span><span class="p">,</span><span class="w"> </span><span class="n">EfficientNet</span><span class="o">-</span><span class="n">B0</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îú‚îÄ</span><span class="w"> </span><span class="n">Low</span><span class="w"> </span><span class="n">latency</span><span class="w"> </span><span class="p">(</span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="n">ms</span><span class="p">)</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">ConvNeXt</span><span class="o">-</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">EfficientNetV2</span><span class="o">-</span><span class="n">S</span>
<span class="err">‚îÇ</span><span class="w">  </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">No</span><span class="w"> </span><span class="n">constraints</span>
<span class="err">‚îÇ</span><span class="w">     </span><span class="err">‚îî‚îÄ</span><span class="w"> </span><span class="n">Any</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">model</span>
</code></pre></div>

<h3 id="82-practical-recommendations">8.2 Practical Recommendations<a class="header-link" href="#82-practical-recommendations" title="Permanent link">&para;</a></h3>
<p><strong>General-purpose vision tasks</strong> (classification, detection, segmentation):
- <strong>DINOv2</strong>: Best frozen features for few-shot learning
- <strong>ConvNeXt V2</strong>: Best fine-tuning performance
- <strong>EfficientNetV2</strong>: Best speed-accuracy trade-off</p>
<p><strong>Generative tasks</strong> (image synthesis):
- <strong>Stable Diffusion XL</strong>: Best quality (50 steps)
- <strong>LCM</strong>: Best speed (4 steps)
- <strong>LCM-LoRA</strong>: Best customization</p>
<p><strong>Resource-constrained</strong>:
- <strong>MobileNetV3</strong>: Mobile deployment
- <strong>EfficientNet-B0/B1</strong>: Good accuracy on edge devices</p>
<hr />
<h2 id="9-practice-problems">9. Practice Problems<a class="header-link" href="#9-practice-problems" title="Permanent link">&para;</a></h2>
<h3 id="problem-1-convnext-block-implementation">Problem 1: ConvNeXt Block Implementation<a class="header-link" href="#problem-1-convnext-block-implementation" title="Permanent link">&para;</a></h3>
<p>Implement a ConvNeXt block from scratch without using the provided code. Include:
- Depthwise 7√ó7 convolution
- LayerNorm
- Inverted bottleneck (1√ó1 conv with 4√ó expansion)
- GELU activation
- Layer scale
- Residual connection</p>
<p>Test with input shape <code>(2, 64, 32, 32)</code>.</p>
<details>
<summary>Solution</summary>


<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ConvNeXtBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">expansion_ratio</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">layer_scale_init</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">expansion_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">expansion_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">layer_scale_init</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, C, H, W) -&gt; (N, H, W, C)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pwconv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (N, H, W, C) -&gt; (N, C, H, W)</span>
        <span class="k">return</span> <span class="n">shortcut</span> <span class="o">+</span> <span class="n">x</span>

<span class="c1"># Test</span>
<span class="n">block</span> <span class="o">=</span> <span class="n">ConvNeXtBlock</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ConvNeXt block test passed!&quot;</span><span class="p">)</span>
</code></pre></div>


</details>

<h3 id="problem-2-progressive-training-schedule">Problem 2: Progressive Training Schedule<a class="header-link" href="#problem-2-progressive-training-schedule" title="Permanent link">&para;</a></h3>
<p>Implement a progressive training scheduler for EfficientNetV2 that:
- Increases image size from 128 ‚Üí 192 ‚Üí 256
- Increases RandAugment magnitude from 5 ‚Üí 10 ‚Üí 15
- Increases Mixup alpha from 0 ‚Üí 0.2 ‚Üí 0.4
- Each stage lasts 50 epochs</p>
<details>
<summary>Solution</summary>


<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ProgressiveTrainingScheduler</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_epochs</span><span class="o">=</span><span class="mi">150</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">total_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="s1">&#39;img_size&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;mixup_alpha&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="s1">&#39;img_size&#39;</span><span class="p">:</span> <span class="mi">192</span><span class="p">,</span> <span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;mixup_alpha&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span> <span class="s1">&#39;img_size&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;mixup_alpha&#39;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
        <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stage</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">stage</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">return</span> <span class="p">{</span>
                    <span class="s1">&#39;img_size&#39;</span><span class="p">:</span> <span class="n">stage</span><span class="p">[</span><span class="s1">&#39;img_size&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">:</span> <span class="n">stage</span><span class="p">[</span><span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">],</span>
                    <span class="s1">&#39;mixup_alpha&#39;</span><span class="p">:</span> <span class="n">stage</span><span class="p">[</span><span class="s1">&#39;mixup_alpha&#39;</span><span class="p">]</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Return last stage config</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_config</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ProgressiveTrainingScheduler</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">125</span><span class="p">]:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: img_size=</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;img_size&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;rand_aug=</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;rand_aug_mag&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, mixup=</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;mixup_alpha&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>


</details>

<h3 id="problem-3-dinov2-feature-extraction">Problem 3: DINOv2 Feature Extraction<a class="header-link" href="#problem-3-dinov2-feature-extraction" title="Permanent link">&para;</a></h3>
<p>Extract patch-level features from DINOv2 and visualize feature similarity using cosine similarity.
1. Load DINOv2-small
2. Extract patch embeddings for an image
3. Compute pairwise cosine similarity between patches
4. Visualize as heatmap</p>
<details>
<summary>Solution</summary>


<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Load model</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/dinov2-small&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/dinov2-small&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Load image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cat.jpg&#39;</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>

<span class="c1"># Extract features</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">patch_embeddings</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># Exclude [CLS]</span>

<span class="c1"># Reshape to spatial grid</span>
<span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">patch_embeddings</span><span class="o">.</span><span class="n">shape</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">patches</span> <span class="o">=</span> <span class="n">patch_embeddings</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># (H, W, D)</span>

<span class="c1"># Compute cosine similarity</span>
<span class="n">patches_flat</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>  <span class="c1"># (H*W, D)</span>
<span class="c1"># Normalize</span>
<span class="n">patches_norm</span> <span class="o">=</span> <span class="n">patches_flat</span> <span class="o">/</span> <span class="n">patches_flat</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Cosine similarity matrix</span>
<span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">patches_norm</span> <span class="o">@</span> <span class="n">patches_norm</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># (H*W, H*W)</span>

<span class="c1"># Visualize</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sim_matrix</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cosine Similarity&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Patch-level Feature Similarity (DINOv2)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Patch index&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Patch index&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;dinov2_similarity.png&#39;</span><span class="p">)</span>
</code></pre></div>


</details>

<h3 id="problem-4-lcm-fast-generation">Problem 4: LCM Fast Generation<a class="header-link" href="#problem-4-lcm-fast-generation" title="Permanent link">&para;</a></h3>
<p>Compare generation speed and quality between standard DDIM (50 steps) and LCM (4 steps):
1. Load Stable Diffusion 1.5
2. Generate with DDIM (50 steps)
3. Load LCM-LoRA
4. Generate with LCM (4 steps)
5. Measure time for both</p>
<details>
<summary>Solution</summary>


<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionPipeline</span><span class="p">,</span> <span class="n">LCMScheduler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Load base model</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A serene lake with mountains in background, sunset, highly detailed&quot;</span>

<span class="c1"># Standard DDIM</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generating with DDIM (50 steps)...&quot;</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">image_ddim</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">7.5</span><span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ddim_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DDIM time: </span><span class="si">{</span><span class="n">ddim_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="n">image_ddim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ddim_50steps.png&quot;</span><span class="p">)</span>

<span class="c1"># Load LCM-LoRA</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span><span class="s2">&quot;latent-consistency/lcm-lora-sdv1-5&quot;</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LCMScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># LCM generation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generating with LCM (4 steps)...&quot;</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">image_lcm</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">lcm_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LCM time: </span><span class="si">{</span><span class="n">lcm_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="n">image_lcm</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;lcm_4steps.png&quot;</span><span class="p">)</span>

<span class="c1"># Speed comparison</span>
<span class="n">speedup</span> <span class="o">=</span> <span class="n">ddim_time</span> <span class="o">/</span> <span class="n">lcm_time</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Speedup: </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">x faster with LCM&quot;</span><span class="p">)</span>
</code></pre></div>


</details>

<h3 id="problem-5-model-comparison">Problem 5: Model Comparison<a class="header-link" href="#problem-5-model-comparison" title="Permanent link">&para;</a></h3>
<p>Compare ConvNeXt-T, EfficientNetV2-S, and DINOv2-S on a custom dataset:
1. Load all three models from timm/transformers
2. Extract features (frozen) for training set
3. Train linear SVM on features
4. Report accuracy and inference time</p>
<details>
<summary>Solution</summary>


<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">timm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="c1"># Assume we have a dataset loader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># DataLoader for training set</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="o">...</span>   <span class="c1"># DataLoader for test set</span>

<span class="k">def</span><span class="w"> </span><span class="nf">extract_features</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">is_dinov2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_dinov2</span><span class="p">:</span>
                <span class="c1"># DINOv2 uses different interface</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
                <span class="n">feats</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># [CLS]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">feats</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>  <span class="c1"># timm feature extractor</span>
            <span class="n">features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feats</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lbls</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># 1. ConvNeXt-T</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading ConvNeXt-T...&quot;</span><span class="p">)</span>
<span class="n">convnext</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;convnext_tiny&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">convnext</span> <span class="o">=</span> <span class="n">convnext</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">train_feats_cn</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">convnext</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
<span class="n">test_feats_cn</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">convnext</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
<span class="n">cn_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># 2. EfficientNetV2-S</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading EfficientNetV2-S...&quot;</span><span class="p">)</span>
<span class="n">effnet</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;tf_efficientnetv2_s&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">effnet</span> <span class="o">=</span> <span class="n">effnet</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">train_feats_eff</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">effnet</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
<span class="n">test_feats_eff</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">effnet</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
<span class="n">eff_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># 3. DINOv2-S</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading DINOv2-S...&quot;</span><span class="p">)</span>
<span class="n">dinov2</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/dinov2-small&#39;</span><span class="p">)</span>
<span class="n">dinov2</span> <span class="o">=</span> <span class="n">dinov2</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">train_feats_dino</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">dinov2</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">is_dinov2</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_feats_dino</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_features</span><span class="p">(</span><span class="n">dinov2</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">is_dinov2</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dino_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># Train linear SVM on each</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">train_feats</span><span class="p">,</span> <span class="n">test_feats</span><span class="p">,</span> <span class="n">infer_time</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;ConvNeXt-T&#39;</span><span class="p">,</span> <span class="n">train_feats_cn</span><span class="p">,</span> <span class="n">test_feats_cn</span><span class="p">,</span> <span class="n">cn_time</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;EfficientNetV2-S&#39;</span><span class="p">,</span> <span class="n">train_feats_eff</span><span class="p">,</span> <span class="n">test_feats_eff</span><span class="p">,</span> <span class="n">eff_time</span><span class="p">),</span>
    <span class="p">(</span><span class="s1">&#39;DINOv2-S&#39;</span><span class="p">,</span> <span class="n">train_feats_dino</span><span class="p">,</span> <span class="n">test_feats_dino</span><span class="p">,</span> <span class="n">dino_time</span><span class="p">)</span>
<span class="p">]:</span>
    <span class="n">svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_feats</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_feats</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: Accuracy=</span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Inference time=</span><span class="si">{</span><span class="n">infer_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</code></pre></div>


</details>

<hr />
<h2 id="navigation">Navigation<a class="header-link" href="#navigation" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Previous</strong>: <a href="26_Normalization_Layers.md">26. Normalization Layers</a></li>
<li><strong>Next</strong>: <a href="00_Overview.md">Overview</a></li>
</ul>
<hr />
<h2 id="further-reading">Further Reading<a class="header-link" href="#further-reading" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>ConvNeXt</strong>: <a href="https://arxiv.org/abs/2201.03545">A ConvNet for the 2020s</a> (Liu et al., 2022)</li>
<li><strong>ConvNeXt V2</strong>: <a href="https://arxiv.org/abs/2301.00808">Co-designing and Scaling ConvNets with Masked Autoencoders</a> (Woo et al., 2023)</li>
<li><strong>EfficientNetV2</strong>: <a href="https://arxiv.org/abs/2104.00298">Smaller Models and Faster Training</a> (Tan &amp; Le, 2021)</li>
<li><strong>DINOv2</strong>: <a href="https://arxiv.org/abs/2304.07193">Learning Robust Visual Features without Supervision</a> (Oquab et al., 2023)</li>
<li><strong>Latent Consistency Models</strong>: <a href="https://arxiv.org/abs/2310.04378">Synthesizing High-Resolution Images with Few-Step Inference</a> (Luo et al., 2023)</li>
<li><strong>timm Documentation</strong>: https://timm.fast.ai/</li>
<li><strong>Hugging Face Models</strong>: https://huggingface.co/models</li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Deep_Learning/36_Self_Supervised_Learning.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">36. Self-Supervised Learning</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Deep_Learning/38_Object_Detection.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">38. Object Detection</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">‚Üë</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}