{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>14. Unified Vision Models - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Foundation_Models/">Foundation Models</a>
    <span class="separator">/</span>
    <span class="current">14. Unified Vision Models</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>14. Unified Vision Models</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Foundation_Models/13_Segment_Anything.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Segment Anything Model (SAM)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Foundation_Models/15_Image_Generation_Advanced.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">15. Advanced Image Generation</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#1-paradigm-shift">1. Paradigm Shift</a><ul>
<li><a href="#11-traditional-approach-vs-unified-approach">1.1 Traditional Approach vs Unified Approach</a></li>
<li><a href="#12-major-model-comparison">1.2 Major Model Comparison</a></li>
</ul>
</li>
<li><a href="#2-florence-foundation-model-for-vision">2. Florence: Foundation Model for Vision</a><ul>
<li><a href="#21-architecture">2.1 Architecture</a></li>
<li><a href="#22-implementation-example">2.2 Implementation Example</a></li>
</ul>
</li>
<li><a href="#3-pali-pathways-language-and-image-model">3. PaLI (Pathways Language and Image model)</a><ul>
<li><a href="#31-architecture">3.1 Architecture</a></li>
<li><a href="#32-task-unification">3.2 Task Unification</a></li>
</ul>
</li>
<li><a href="#4-unified-io">4. Unified-IO</a><ul>
<li><a href="#41-true-unification-all-modalities">4.1 True Unification: All Modalities</a></li>
<li><a href="#42-implementation-concept">4.2 Implementation Concept</a></li>
</ul>
</li>
<li><a href="#5-practical-usage">5. Practical Usage</a><ul>
<li><a href="#51-using-florence-2-huggingface">5.1 Using Florence-2 (HuggingFace)</a></li>
<li><a href="#52-custom-task-training">5.2 Custom Task Training</a></li>
</ul>
</li>
<li><a href="#6-future-directions">6. Future Directions</a><ul>
<li><a href="#61-world-models">6.1 World Models</a></li>
<li><a href="#62-limitations-and-trade-offs-of-unification">6.2 Limitations and Trade-offs of Unification</a></li>
</ul>
</li>
<li><a href="#references">References</a><ul>
<li><a href="#papers">Papers</a></li>
<li><a href="#models">Models</a></li>
<li><a href="#related-lessons">Related Lessons</a></li>
</ul>
</li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="14-unified-vision-models">14. Unified Vision Models<a class="header-link" href="#14-unified-vision-models" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="header-link" href="#overview" title="Permanent link">&para;</a></h2>
<p>Unified Vision Models represent a paradigm that processes various vision tasks (classification, detection, segmentation, etc.) with a <strong>single model</strong>. Instead of task-specific models, the goal is to build general-purpose vision models.</p>
<hr />
<h2 id="1-paradigm-shift">1. Paradigm Shift<a class="header-link" href="#1-paradigm-shift" title="Permanent link">&para;</a></h2>
<h3 id="11-traditional-approach-vs-unified-approach">1.1 Traditional Approach vs Unified Approach<a class="header-link" href="#11-traditional-approach-vs-unified-approach" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vision Model Paradigms                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Traditional (Task-Specific):                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ ResNet       â”‚  â”‚ Faster R-CNN â”‚  â”‚ DeepLab      â”‚           â”‚
â”‚  â”‚ (classif.)   â”‚  â”‚ (detection)  â”‚  â”‚ (segment.)   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                  â”‚
â”‚  Unified (Task-Agnostic):                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚              Unified Vision Model              â”‚              â”‚
â”‚  â”‚  &quot;Classify this&quot; â†’ Classification result       â”‚              â”‚
â”‚  â”‚  &quot;Find objects&quot; â†’ Bounding boxes               â”‚              â”‚
â”‚  â”‚  &quot;Segment this&quot; â†’ Masks                        â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                  â”‚
â”‚  Advantages: Knowledge sharing, Easy maintenance, Zero-shot     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="12-major-model-comparison">1.2 Major Model Comparison<a class="header-link" href="#12-major-model-comparison" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Developer</th>
<th>Features</th>
<th>Supported Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Florence</strong></td>
<td>Microsoft</td>
<td>Large-scale Image-Text</td>
<td>Classification, Detection, Captioning, VQA</td>
</tr>
<tr>
<td><strong>PaLI</strong></td>
<td>Google</td>
<td>Multilingual VLM</td>
<td>Captioning, VQA, OCR</td>
</tr>
<tr>
<td><strong>Unified-IO</strong></td>
<td>Allen AI</td>
<td>All modalities</td>
<td>Image, Audio, Text</td>
</tr>
<tr>
<td><strong>OFA</strong></td>
<td>Alibaba</td>
<td>Seq2Seq unified</td>
<td>Various vision-language</td>
</tr>
<tr>
<td><strong>GPT-4V</strong></td>
<td>OpenAI</td>
<td>Commercial multimodal</td>
<td>General vision understanding</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-florence-foundation-model-for-vision">2. Florence: Foundation Model for Vision<a class="header-link" href="#2-florence-foundation-model-for-vision" title="Permanent link">&para;</a></h2>
<h3 id="21-architecture">2.1 Architecture<a class="header-link" href="#21-architecture" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">Florence</span><span class="w"> </span><span class="nl">Architecture:</span>

<span class="n">Image</span><span class="w"> </span><span class="nl">Encoder:</span><span class="w"> </span><span class="n">CoSwin</span><span class="w"> </span><span class="n">Transformer</span><span class="w"> </span><span class="p">(</span><span class="n">Hierarchical</span><span class="p">)</span>
<span class="n">Text</span><span class="w"> </span><span class="nl">Encoder:</span><span class="w"> </span><span class="n">UniCL</span><span class="w"> </span><span class="p">(</span><span class="n">Unified</span><span class="w"> </span><span class="n">Contrastive</span><span class="w"> </span><span class="n">Learning</span><span class="p">)</span>

<span class="nl">Training:</span>
<span class="mf">1.</span><span class="w"> </span><span class="n">Image</span><span class="o">-</span><span class="n">Text</span><span class="w"> </span><span class="n">Contrastive</span><span class="w"> </span><span class="p">(</span><span class="n">CLIP</span><span class="w"> </span><span class="n">style</span><span class="p">)</span>
<span class="mf">2.</span><span class="w"> </span><span class="n">Image</span><span class="o">-</span><span class="n">Text</span><span class="w"> </span><span class="n">Matching</span>
<span class="mf">3.</span><span class="w"> </span><span class="n">Masked</span><span class="w"> </span><span class="n">Language</span><span class="w"> </span><span class="n">Modeling</span>

<span class="nl">Features:</span>
<span class="o">-</span><span class="w"> </span><span class="n">Trained</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="mh">900</span><span class="n">M</span><span class="w"> </span><span class="n">Image</span><span class="o">-</span><span class="n">Text</span><span class="w"> </span><span class="n">pairs</span>
<span class="o">-</span><span class="w"> </span><span class="n">Various</span><span class="w"> </span><span class="n">granularity</span><span class="w"> </span><span class="p">(</span><span class="n">image</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">region</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">pixel</span><span class="p">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Dynamic</span><span class="w"> </span><span class="n">Head</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="k">task</span><span class="w"> </span><span class="n">adaptation</span>
</code></pre></div>

<h3 id="22-implementation-example">2.2 Implementation Example<a class="header-link" href="#22-implementation-example" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CLIPProcessor</span><span class="p">,</span> <span class="n">CLIPModel</span>

<span class="k">class</span><span class="w"> </span><span class="nc">FlorenceStyleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Florence-style Unified Vision Model (Simplified)</span>

<span class="sd">    Core: CLIP backbone + Task-specific Heads</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">clip_model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;openai/clip-vit-large-patch14&quot;</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_detection_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># CLIP backbone (Image + Text encoder)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip</span> <span class="o">=</span> <span class="n">CLIPModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">clip_model_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">clip_model_name</span><span class="p">)</span>

        <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="o">.</span><span class="n">hidden_size</span>

        <span class="c1"># Task Heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classification_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">detection_head</span> <span class="o">=</span> <span class="n">DetectionHead</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_detection_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segmentation_head</span> <span class="o">=</span> <span class="n">SegmentationHead</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">caption_head</span> <span class="o">=</span> <span class="n">CaptionHead</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;classification&quot;</span><span class="p">,</span>
        <span class="n">text_prompts</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            images: (B, 3, H, W)</span>
<span class="sd">            task: &quot;classification&quot;, &quot;detection&quot;, &quot;segmentation&quot;, &quot;caption&quot;</span>
<span class="sd">            text_prompts: Text prompts (for zero-shot)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Image features</span>
        <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>  <span class="c1"># (B, num_patches+1, hidden)</span>
        <span class="n">pooled_features</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="o">.</span><span class="n">pooler_output</span>  <span class="c1"># (B, hidden)</span>

        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;classification&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">text_prompts</span><span class="p">:</span>
                <span class="c1"># Zero-shot classification (CLIP style)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zero_shot_classify</span><span class="p">(</span><span class="n">pooled_features</span><span class="p">,</span> <span class="n">text_prompts</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classification_head</span><span class="p">(</span><span class="n">pooled_features</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;detection&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">detection_head</span><span class="p">(</span><span class="n">image_features</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;segmentation&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">segmentation_head</span><span class="p">(</span><span class="n">image_features</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;caption&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">caption_head</span><span class="p">(</span><span class="n">pooled_features</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_zero_shot_classify</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">text_prompts</span><span class="p">:</span> <span class="nb">list</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Zero-shot classification with text prompts&quot;&quot;&quot;</span>
        <span class="c1"># Text encoding</span>
        <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="n">text_prompts</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">image_features</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">get_text_features</span><span class="p">(</span><span class="o">**</span><span class="n">text_inputs</span><span class="p">)</span>

        <span class="c1"># Normalize</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="n">image_features</span> <span class="o">/</span> <span class="n">image_features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="n">text_features</span> <span class="o">/</span> <span class="n">text_features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Similarity</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">image_features</span> <span class="o">@</span> <span class="n">text_features</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">similarity</span>


<span class="k">class</span><span class="w"> </span><span class="nc">DetectionHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Object Detection Head (DETR style)&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_queries</span> <span class="o">=</span> <span class="n">num_queries</span>

        <span class="c1"># Object queries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_queries</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

        <span class="c1"># Transformer decoder</span>
        <span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoderLayer</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

        <span class="c1"># Prediction heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># +1 for no-object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bbox_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># (cx, cy, w, h)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Query embedding</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="n">hs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">image_features</span><span class="p">)</span>

        <span class="c1"># Predictions</span>
        <span class="n">class_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_head</span><span class="p">(</span><span class="n">hs</span><span class="p">)</span>
        <span class="n">bbox_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_head</span><span class="p">(</span><span class="n">hs</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;class_logits&#39;</span><span class="p">:</span> <span class="n">class_logits</span><span class="p">,</span>
            <span class="s1">&#39;bbox_pred&#39;</span><span class="p">:</span> <span class="n">bbox_pred</span>
        <span class="p">}</span>


<span class="k">class</span><span class="w"> </span><span class="nc">SegmentationHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Semantic Segmentation Head&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">150</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># FPN-style decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="c1"># Reshape patches to spatial</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># -1 for CLS token</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">image_features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">CaptionHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Image Captioning Head&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">text_config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">text_config</span><span class="o">.</span><span class="n">vocab_size</span>

        <span class="c1"># Cross-attention decoder</span>
        <span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoderLayer</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">target_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="c1"># Autoregressive during generation</span>
        <span class="c1"># Teacher forcing during training</span>
        <span class="k">pass</span>  <span class="c1"># Implementation omitted</span>
</code></pre></div>

<hr />
<h2 id="3-pali-pathways-language-and-image-model">3. PaLI (Pathways Language and Image model)<a class="header-link" href="#3-pali-pathways-language-and-image-model" title="Permanent link">&para;</a></h2>
<h3 id="31-architecture">3.1 Architecture<a class="header-link" href="#31-architecture" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">PaLI</span><span class="w"> </span><span class="k">Structure</span><span class="err">:</span>

<span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">                      </span><span class="n">PaLI</span><span class="w">                              </span><span class="err">â”‚</span>
<span class="err">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span>
<span class="err">â”‚</span><span class="w">                                                        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nc">Image</span><span class="w"> </span><span class="nl">Encoder</span><span class="p">:</span><span class="w"> </span><span class="n">ViT</span><span class="o">-</span><span class="n">e</span><span class="w"> </span><span class="p">(</span><span class="mi">4</span><span class="n">B</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">trained</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="mi">22</span><span class="n">B</span><span class="w"> </span><span class="n">imgs</span><span class="p">)</span><span class="w"> </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">       </span><span class="err">â†“</span><span class="w">                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="n">Visual</span><span class="w"> </span><span class="nl">Tokens</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">IMG1</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">IMG2</span><span class="o">]</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">[</span><span class="n">IMGn</span><span class="o">]</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">       </span><span class="err">â†“</span><span class="w">                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nc">Text</span><span class="w"> </span><span class="n">Encoder</span><span class="o">-</span><span class="nl">Decoder</span><span class="p">:</span><span class="w"> </span><span class="n">mT5</span><span class="w"> </span><span class="p">(</span><span class="n">multilingual</span><span class="p">)</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">       </span><span class="err">â†“</span><span class="w">                                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="k">Output</span><span class="err">:</span><span class="w"> </span><span class="nc">Text</span><span class="w"> </span><span class="p">(</span><span class="n">multilingual</span><span class="w"> </span><span class="n">support</span><span class="p">)</span><span class="w">                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="k">Input</span><span class="w"> </span><span class="nf">format</span><span class="err">:</span><span class="w">                                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="ss">&quot;&lt;image&gt; Describe this image&quot;</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="ss">&quot;A cat is...&quot;</span><span class="w">        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="ss">&quot;&lt;image&gt; What is in the image?&quot;</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="ss">&quot;A cat...&quot;</span><span class="w">         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                        </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<h3 id="32-task-unification">3.2 Task Unification<a class="header-link" href="#32-task-unification" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PaLITaskFormats</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PaLI task-specific input formats&quot;&quot;&quot;</span>

    <span class="n">TASK_FORMATS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Classification</span>
        <span class="s2">&quot;classification&quot;</span><span class="p">:</span> <span class="s2">&quot;What is in this image?&quot;</span><span class="p">,</span>
        <span class="s2">&quot;fine_grained&quot;</span><span class="p">:</span> <span class="s2">&quot;What species of bird is this?&quot;</span><span class="p">,</span>

        <span class="c1"># Captioning</span>
        <span class="s2">&quot;caption_en&quot;</span><span class="p">:</span> <span class="s2">&quot;Generate a caption for this image.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;caption_ko&quot;</span><span class="p">:</span> <span class="s2">&quot;Write a description for this image.&quot;</span><span class="p">,</span>

        <span class="c1"># VQA</span>
        <span class="s2">&quot;vqa&quot;</span><span class="p">:</span> <span class="s2">&quot;Question: </span><span class="si">{question}</span><span class="s2"> Answer:&quot;</span><span class="p">,</span>

        <span class="c1"># OCR</span>
        <span class="s2">&quot;ocr&quot;</span><span class="p">:</span> <span class="s2">&quot;What text is in this image?&quot;</span><span class="p">,</span>

        <span class="c1"># Detection (expressed as text)</span>
        <span class="s2">&quot;detection&quot;</span><span class="p">:</span> <span class="s2">&quot;Detect all objects in this image.&quot;</span><span class="p">,</span>
        <span class="c1"># Output: &quot;cat [100, 200, 300, 400]; dog [50, 60, 150, 200]&quot;</span>

        <span class="c1"># Referring segmentation</span>
        <span class="s2">&quot;referring&quot;</span><span class="p">:</span> <span class="s2">&quot;Segment the </span><span class="si">{object}</span><span class="s2">.&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">format_input</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">template</span> <span class="o">=</span> <span class="n">PaLITaskFormats</span><span class="o">.</span><span class="n">TASK_FORMATS</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="c1"># Usage example</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_with_pali</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PaLI-style processing&quot;&quot;&quot;</span>

    <span class="c1"># Task-specific prompt</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">PaLITaskFormats</span><span class="o">.</span><span class="n">format_input</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Visual tokens + Text tokens</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>

    <span class="c1"># Generate</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

    <span class="c1"># Parse output based on task</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;detection&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parse_detection_output</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;caption_en&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div>

<hr />
<h2 id="4-unified-io">4. Unified-IO<a class="header-link" href="#4-unified-io" title="Permanent link">&para;</a></h2>
<h3 id="41-true-unification-all-modalities">4.1 True Unification: All Modalities<a class="header-link" href="#41-true-unification-all-modalities" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>Unified-IO: Process all I/O with a single model

Input/Output formats:
- Image â†’ VQ-VAE tokens
- Text â†’ Subword tokens
- Bounding box â†’ Coordinate tokens (discretized)
- Mask â†’ VQ-VAE tokens
- Audio â†’ Spectrogram VQ-VAE

Convert everything to token sequences â†’ Seq2Seq Transformer
</code></pre></div>

<h3 id="42-implementation-concept">4.2 Implementation Concept<a class="header-link" href="#42-implementation-concept" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UnifiedIOTokenizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unified-IO style tokenization&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span> <span class="n">image_vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16384</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_vocab_size</span> <span class="o">=</span> <span class="n">image_vocab_size</span>

        <span class="c1"># Special tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">SPECIAL_TOKENS</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;&lt;image&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span><span class="p">,</span>
            <span class="s1">&#39;&lt;/image&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;&lt;box&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;&lt;/box&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;&lt;mask&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s1">&#39;&lt;/mask&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s1">&#39;&lt;audio&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">6</span><span class="p">,</span>
            <span class="s1">&#39;&lt;/audio&gt;&#39;</span><span class="p">:</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">7</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Coordinate discretization bins</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize image with VQ-VAE&quot;&quot;&quot;</span>
        <span class="c1"># Extract discrete codes with VQ-VAE encoder</span>
        <span class="c1"># codes shape: (H&#39;, W&#39;)</span>
        <span class="n">codes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vqvae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Flatten + offset</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">codes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">SPECIAL_TOKENS</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tokens</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_bbox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bbox</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Bounding box to discrete tokens</span>

<span class="sd">        bbox: (x1, y1, x2, y2) normalized [0, 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Discretize each coordinate to bins</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="p">(</span><span class="n">bbox</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="c1"># Special tokens + bins</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">SPECIAL_TOKENS</span><span class="p">[</span><span class="s1">&#39;&lt;box&gt;&#39;</span><span class="p">],</span>
            <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">SPECIAL_TOKENS</span><span class="p">[</span><span class="s1">&#39;&lt;/box&gt;&#39;</span><span class="p">]</span>
        <span class="p">])</span>

        <span class="k">return</span> <span class="n">tokens</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode_bbox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Restore bounding box from tokens&quot;&quot;&quot;</span>
        <span class="c1"># Find &lt;box&gt; token position</span>
        <span class="c1"># Extract 4 number tokens</span>
        <span class="c1"># Denormalize</span>
        <span class="k">pass</span>


<span class="k">class</span><span class="w"> </span><span class="nc">UnifiedIOModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unified-IO style model&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Unified Embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">({</span>
            <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">text_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
            <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
            <span class="s1">&#39;coord&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_bins</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
        <span class="p">})</span>

        <span class="c1"># Encoder-Decoder Transformer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">TransformerDecoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Unified LM Head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">total_vocab_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">,</span> <span class="n">output_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Seq2Seq forward</span>

<span class="sd">        input_tokens: Mixed modality tokens</span>
<span class="sd">        output_tokens: Target output tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Embedding by token type</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_embeddings</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)</span>

        <span class="c1"># Encoder</span>
        <span class="n">encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="k">if</span> <span class="n">output_tokens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_embeddings</span><span class="p">(</span><span class="n">output_tokens</span><span class="p">)</span>
            <span class="n">decoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">logits</span>

        <span class="k">return</span> <span class="n">encoder_output</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select appropriate embedding based on token type&quot;&quot;&quot;</span>
        <span class="c1"># Distinguish text/image/coord based on token range</span>
        <span class="k">pass</span>


<span class="c1"># Various task examples</span>
<span class="k">def</span><span class="w"> </span><span class="nf">unified_io_examples</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unified-IO task examples&quot;&quot;&quot;</span>

    <span class="n">examples</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Image Captioning</span>
        <span class="s2">&quot;caption&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; </span><span class="si">{image_tokens}</span><span class="s2"> &lt;/image&gt; Describe this image.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;A cat sitting on a windowsill.&quot;</span>
        <span class="p">},</span>

        <span class="c1"># Object Detection</span>
        <span class="s2">&quot;detection&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; </span><span class="si">{image_tokens}</span><span class="s2"> &lt;/image&gt; Detect all objects.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;cat &lt;box&gt; 100 200 300 400 &lt;/box&gt; dog &lt;box&gt; 50 60 150 200 &lt;/box&gt;&quot;</span>
        <span class="p">},</span>

        <span class="c1"># Segmentation</span>
        <span class="s2">&quot;segmentation&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; </span><span class="si">{image_tokens}</span><span class="s2"> &lt;/image&gt; Segment the cat.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;mask&gt; </span><span class="si">{mask_tokens}</span><span class="s2"> &lt;/mask&gt;&quot;</span>
        <span class="p">},</span>

        <span class="c1"># Image Generation (reverse)</span>
        <span class="s2">&quot;generation&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Generate an image of a sunset over mountains.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; </span><span class="si">{image_tokens}</span><span class="s2"> &lt;/image&gt;&quot;</span>
        <span class="p">},</span>

        <span class="c1"># VQA</span>
        <span class="s2">&quot;vqa&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;image&gt; </span><span class="si">{image_tokens}</span><span class="s2"> &lt;/image&gt; How many cats are there?&quot;</span><span class="p">,</span>
            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;2&quot;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">examples</span>
</code></pre></div>

<hr />
<h2 id="5-practical-usage">5. Practical Usage<a class="header-link" href="#5-practical-usage" title="Permanent link">&para;</a></h2>
<h3 id="51-using-florence-2-huggingface">5.1 Using Florence-2 (HuggingFace)<a class="header-link" href="#51-using-florence-2-huggingface" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>

<span class="k">def</span><span class="w"> </span><span class="nf">use_florence2</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Florence-2 practical usage&quot;&quot;&quot;</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;microsoft/Florence-2-large&quot;</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;microsoft/Florence-2-large&quot;</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://example.com/image.jpg&quot;</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>

    <span class="c1"># Various tasks</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;&lt;CAPTION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Short caption&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;DETAILED_CAPTION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Detailed caption&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;MORE_DETAILED_CAPTION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Very detailed caption&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;OD&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Object detection&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;DENSE_REGION_CAPTION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Region-wise caption&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;REGION_PROPOSAL&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Region proposal&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;CAPTION_TO_PHRASE_GROUNDING&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Textâ†’Region grounding&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;REFERRING_EXPRESSION_SEGMENTATION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Referring expression segmentation&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;OCR&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;OCR&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&lt;OCR_WITH_REGION&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;Region-wise OCR&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">task_prompt</span><span class="p">,</span> <span class="n">description</span> <span class="ow">in</span> <span class="n">tasks</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">task_prompt</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

        <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">],</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">num_beams</span><span class="o">=</span><span class="mi">3</span>
        <span class="p">)</span>

        <span class="n">generated_text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">post_process_generation</span><span class="p">(</span><span class="n">generated_text</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="n">task_prompt</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">description</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">task_prompt</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">parsed</span><span class="p">)</span>


<span class="c1"># Run</span>
<span class="n">use_florence2</span><span class="p">()</span>
</code></pre></div>

<h3 id="52-custom-task-training">5.2 Custom Task Training<a class="header-link" href="#52-custom-task-training" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>

<span class="k">def</span><span class="w"> </span><span class="nf">finetune_unified_vision</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fine-tuning unified vision model&quot;&quot;&quot;</span>

    <span class="c1"># Prepare multitask dataset</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_multitask_dataset</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Multiple tasks into one dataset&quot;&quot;&quot;</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Classification samples</span>
        <span class="k">for</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">classification_data</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img_path</span><span class="p">,</span>
                <span class="s1">&#39;task&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;CLASSIFICATION&gt;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;input_text&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;CLASSIFICATION&gt;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;output_text&#39;</span><span class="p">:</span> <span class="n">label</span>
            <span class="p">})</span>

        <span class="c1"># Caption samples</span>
        <span class="k">for</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">caption</span> <span class="ow">in</span> <span class="n">caption_data</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img_path</span><span class="p">,</span>
                <span class="s1">&#39;task&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;CAPTION&gt;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;input_text&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;CAPTION&gt;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;output_text&#39;</span><span class="p">:</span> <span class="n">caption</span>
            <span class="p">})</span>

        <span class="c1"># VQA samples</span>
        <span class="k">for</span> <span class="n">img_path</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">vqa_data</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img_path</span><span class="p">,</span>
                <span class="s1">&#39;task&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;VQA&gt;&#39;</span><span class="p">,</span>
                <span class="s1">&#39;input_text&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;&lt;VQA&gt; </span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="s1">&#39;output_text&#39;</span><span class="p">:</span> <span class="n">answer</span>
            <span class="p">})</span>

        <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_multitask_dataset</span><span class="p">()</span>

    <span class="c1"># Training</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./unified-vision-finetuned&quot;</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="c1"># Task sampling strategy</span>
        <span class="n">dataloader_drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="6-future-directions">6. Future Directions<a class="header-link" href="#6-future-directions" title="Permanent link">&para;</a></h2>
<h3 id="61-world-models">6.1 World Models<a class="header-link" href="#61-world-models" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">Next</span><span class="w"> </span><span class="nl">Step</span><span class="p">:</span><span class="w"> </span><span class="n">World</span><span class="w"> </span><span class="n">Models</span>

<span class="n">Vision</span><span class="w"> </span><span class="n">models</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Physical</span><span class="w"> </span><span class="n">understanding</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="k">Action</span><span class="w"> </span><span class="n">prediction</span>

<span class="nl">Examples</span><span class="p">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">Understanding</span><span class="w"> </span><span class="n">physics</span><span class="w"> </span><span class="n">laws</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">images</span>
<span class="o">-</span><span class="w"> </span><span class="ss">&quot;Where will the ball go if thrown?&quot;</span>
<span class="o">-</span><span class="w"> </span><span class="k">Next</span><span class="w"> </span><span class="n">frame</span><span class="w"> </span><span class="n">prediction</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">video</span>
<span class="o">-</span><span class="w"> </span><span class="n">Robot</span><span class="w"> </span><span class="n">manipulation</span><span class="w"> </span><span class="n">planning</span>
</code></pre></div>

<h3 id="62-limitations-and-trade-offs-of-unification">6.2 Limitations and Trade-offs of Unification<a class="header-link" href="#62-limitations-and-trade-offs-of-unification" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>Advantages:
âœ“ Knowledge sharing across tasks
âœ“ Single model maintenance
âœ“ Zero-shot transfer
âœ“ Easy adaptation to new tasks

Disadvantages:
âœ— May not achieve best performance on individual tasks
âœ— Training complexity
âœ— Task interference
âœ— Large model size

Trade-offs:
- Versatility vs Specialization
- Convenience vs Optimal performance
</code></pre></div>

<hr />
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="papers">Papers<a class="header-link" href="#papers" title="Permanent link">&para;</a></h3>
<ul>
<li>Yuan et al. (2021). "Florence: A New Foundation Model for Computer Vision"</li>
<li>Chen et al. (2022). "PaLI: A Jointly-Scaled Multilingual Language-Image Model"</li>
<li>Lu et al. (2022). "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"</li>
</ul>
<h3 id="models">Models<a class="header-link" href="#models" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://huggingface.co/microsoft/Florence-2-large">Florence-2</a></li>
<li><a href="https://github.com/google-research/pali">PaLI</a></li>
</ul>
<h3 id="related-lessons">Related Lessons<a class="header-link" href="#related-lessons" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="12_DINOv2_Self_Supervised.md">12_DINOv2_Self_Supervised.md</a></li>
<li><a href="13_Segment_Anything.md">13_Segment_Anything.md</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Foundation_Models/13_Segment_Anything.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Segment Anything Model (SAM)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Foundation_Models/15_Image_Generation_Advanced.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">15. Advanced Image Generation</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}