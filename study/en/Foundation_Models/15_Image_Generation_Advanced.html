{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>15. Advanced Image Generation - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Foundation_Models/">Foundation Models</a>
    <span class="separator">/</span>
    <span class="current">15. Advanced Image Generation</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>15. Advanced Image Generation</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Foundation_Models/14_Unified_Vision_Models.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">14. Unified Vision Models</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Foundation_Models/16_Vision_Language_Advanced.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">16. Advanced Vision-Language</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#1-sdxl-stable-diffusion-xl">1. SDXL (Stable Diffusion XL)</a><ul>
<li><a href="#11-architecture-improvements">1.1 Architecture Improvements</a></li>
<li><a href="#12-using-sdxl">1.2 Using SDXL</a></li>
<li><a href="#13-micro-conditioning">1.3 Micro-Conditioning</a></li>
</ul>
</li>
<li><a href="#2-controlnet">2. ControlNet</a><ul>
<li><a href="#21-concept">2.1 Concept</a></li>
<li><a href="#22-implementation-and-usage">2.2 Implementation and Usage</a></li>
</ul>
</li>
<li><a href="#3-ip-adapter-image-prompt-adapter">3. IP-Adapter (Image Prompt Adapter)</a><ul>
<li><a href="#31-concept">3.1 Concept</a></li>
<li><a href="#32-usage">3.2 Usage</a></li>
</ul>
</li>
<li><a href="#4-latent-consistency-models-lcm">4. Latent Consistency Models (LCM)</a><ul>
<li><a href="#41-concept">4.1 Concept</a></li>
<li><a href="#42-usage">4.2 Usage</a></li>
</ul>
</li>
<li><a href="#5-advanced-techniques">5. Advanced Techniques</a><ul>
<li><a href="#51-inpainting-outpainting">5.1 Inpainting &amp; Outpainting</a></li>
<li><a href="#52-image-to-image-translation">5.2 Image-to-Image Translation</a></li>
<li><a href="#53-text-embedding-manipulation">5.3 Text Embedding Manipulation</a></li>
</ul>
</li>
<li><a href="#6-optimization-techniques">6. Optimization Techniques</a><ul>
<li><a href="#61-memory-optimization">6.1 Memory Optimization</a></li>
</ul>
</li>
<li><a href="#references">References</a><ul>
<li><a href="#papers">Papers</a></li>
<li><a href="#models">Models</a></li>
<li><a href="#related-lessons">Related Lessons</a></li>
</ul>
</li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="15-advanced-image-generation">15. Advanced Image Generation<a class="header-link" href="#15-advanced-image-generation" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="header-link" href="#overview" title="Permanent link">&para;</a></h2>
<p>This lesson covers the latest image generation techniques after Stable Diffusion. We explore practical techniques including SDXL, ControlNet, IP-Adapter, and Latent Consistency Models.</p>
<hr />
<h2 id="1-sdxl-stable-diffusion-xl">1. SDXL (Stable Diffusion XL)<a class="header-link" href="#1-sdxl-stable-diffusion-xl" title="Permanent link">&para;</a></h2>
<h3 id="11-architecture-improvements">1.1 Architecture Improvements<a class="header-link" href="#11-architecture-improvements" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SDXL vs SD 1.5 Comparison                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  SD 1.5:                                                         â”‚
â”‚  - UNet: 860M params                                            â”‚
â”‚  - Text Encoder: CLIP ViT-L/14 (77 tokens)                      â”‚
â”‚  - Resolution: 512Ã—512                                          â”‚
â”‚  - VAE: 4Ã— downscale                                            â”‚
â”‚                                                                  â”‚
â”‚  SDXL:                                                           â”‚
â”‚  - UNet: 2.6B params (3x increase)                              â”‚
â”‚  - Text Encoder: CLIP ViT-L + OpenCLIP ViT-bigG (dual)          â”‚
â”‚  - Resolution: 1024Ã—1024                                        â”‚
â”‚  - VAE: Improved VAE-FT                                         â”‚
â”‚  - Refiner model (optional)                                      â”‚
â”‚                                                                  â”‚
â”‚  Key Improvements:                                               â”‚
â”‚  - Richer text understanding (dual encoder)                     â”‚
â”‚  - High resolution generation (4x pixels)                       â”‚
â”‚  - Micro-conditioning (size, aspect ratio)                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="12-using-sdxl">1.2 Using SDXL<a class="header-link" href="#12-using-sdxl" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionXLPipeline</span><span class="p">,</span> <span class="n">StableDiffusionXLImg2ImgPipeline</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sdxl_generation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SDXL image generation&quot;&quot;&quot;</span>

    <span class="c1"># Load base model</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionXLPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">variant</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">,</span>
        <span class="n">use_safetensors</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Memory optimization</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_vae_slicing</span><span class="p">()</span>

    <span class="c1"># Generation</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A majestic lion in a savanna at sunset, photorealistic, 8k&quot;</span>
    <span class="n">negative_prompt</span> <span class="o">=</span> <span class="s2">&quot;blurry, low quality, distorted&quot;</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">width</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span><span class="w"> </span><span class="nf">sdxl_with_refiner</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SDXL Base + Refiner pipeline&quot;&quot;&quot;</span>

    <span class="c1"># Base</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">StableDiffusionXLPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Refiner</span>
    <span class="n">refiner</span> <span class="o">=</span> <span class="n">StableDiffusionXLImg2ImgPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A cyberpunk city at night, neon lights, rain&quot;</span>

    <span class="c1"># Stage 1: Base (80% denoising)</span>
    <span class="n">high_noise_frac</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="n">base_output</span> <span class="o">=</span> <span class="n">base</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
        <span class="n">denoising_end</span><span class="o">=</span><span class="n">high_noise_frac</span><span class="p">,</span>
        <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;latent&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span>

    <span class="c1"># Stage 2: Refiner (20% denoising)</span>
    <span class="n">refined_image</span> <span class="o">=</span> <span class="n">refiner</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="n">image</span><span class="o">=</span><span class="n">base_output</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
        <span class="n">denoising_start</span><span class="o">=</span><span class="n">high_noise_frac</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">refined_image</span>
</code></pre></div>

<h3 id="13-micro-conditioning">1.3 Micro-Conditioning<a class="header-link" href="#13-micro-conditioning" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">sdxl_micro_conditioning</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using SDXL Micro-Conditioning&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionXLPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A portrait of a woman&quot;</span>

    <span class="c1"># Generate with various aspect ratios</span>
    <span class="n">aspect_ratios</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>  <span class="c1"># 1:1</span>
        <span class="p">(</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">896</span><span class="p">),</span>   <span class="c1"># 4:3</span>
        <span class="p">(</span><span class="mi">896</span><span class="p">,</span> <span class="mi">1152</span><span class="p">),</span>   <span class="c1"># 3:4</span>
        <span class="p">(</span><span class="mi">1216</span><span class="p">,</span> <span class="mi">832</span><span class="p">),</span>   <span class="c1"># ~3:2</span>
        <span class="p">(</span><span class="mi">832</span><span class="p">,</span> <span class="mi">1216</span><span class="p">),</span>   <span class="c1"># ~2:3</span>
    <span class="p">]</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="ow">in</span> <span class="n">aspect_ratios</span><span class="p">:</span>
        <span class="c1"># Micro-conditioning: original resolution hint</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span>
            <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
            <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span>  <span class="c1"># Original size during training</span>
            <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span>    <span class="c1"># Target size</span>
            <span class="n">crops_coords_top_left</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>   <span class="c1"># Crop coordinates</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">images</span>
</code></pre></div>

<hr />
<h2 id="2-controlnet">2. ControlNet<a class="header-link" href="#2-controlnet" title="Permanent link">&para;</a></h2>
<h3 id="21-concept">2.1 Concept<a class="header-link" href="#21-concept" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">ControlNet</span><span class="o">:</span><span class="w"> </span><span class="n">Adding</span><span class="w"> </span><span class="n">Conditional</span><span class="w"> </span><span class="n">Control</span>

<span class="n">Inject</span><span class="w"> </span><span class="n">additional</span><span class="w"> </span><span class="n">control</span><span class="w"> </span><span class="n">signals</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">modifying</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">Diffusion</span><span class="w"> </span><span class="n">model</span>

<span class="n">Supported</span><span class="w"> </span><span class="n">conditions</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">Canny</span><span class="w"> </span><span class="n">Edge</span><span class="w"> </span><span class="o">(</span><span class="n">edges</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Depth</span><span class="w"> </span><span class="n">Map</span><span class="w"> </span><span class="o">(</span><span class="n">depth</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Pose</span><span class="w"> </span><span class="o">(</span><span class="n">pose</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Segmentation</span><span class="w"> </span><span class="o">(</span><span class="n">segmentation</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Normal</span><span class="w"> </span><span class="n">Map</span><span class="w"> </span><span class="o">(</span><span class="n">normals</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Scribble</span><span class="w"> </span><span class="o">(</span><span class="n">scribble</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Line</span><span class="w"> </span><span class="n">Art</span>

<span class="n">How</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">works</span><span class="o">:</span>
<span class="mi">1</span><span class="o">.</span><span class="w"> </span><span class="n">Condition</span><span class="w"> </span><span class="n">image</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Condition</span><span class="w"> </span><span class="n">encoder</span>
<span class="mi">2</span><span class="o">.</span><span class="w"> </span><span class="n">Encoded</span><span class="w"> </span><span class="n">condition</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Inject</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">UNet</span><span class="w"> </span><span class="o">(</span><span class="n">zero</span><span class="w"> </span><span class="n">convolution</span><span class="o">)</span>
<span class="mi">3</span><span class="o">.</span><span class="w"> </span><span class="n">Freeze</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="n">weights</span><span class="o">,</span><span class="w"> </span><span class="n">train</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">ControlNet</span>
</code></pre></div>

<h3 id="22-implementation-and-usage">2.2 Implementation and Usage<a class="header-link" href="#22-implementation-and-usage" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">StableDiffusionControlNetPipeline</span><span class="p">,</span>
    <span class="n">ControlNetModel</span><span class="p">,</span>
    <span class="n">UniPCMultistepScheduler</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">controlnet_aux</span><span class="w"> </span><span class="kn">import</span> <span class="n">CannyDetector</span><span class="p">,</span> <span class="n">OpenposeDetector</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ControlNetGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ControlNet-based image generation&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">controlnets</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">detectors</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;canny&#39;</span><span class="p">:</span> <span class="n">CannyDetector</span><span class="p">(),</span>
            <span class="s1">&#39;openpose&#39;</span><span class="p">:</span> <span class="n">OpenposeDetector</span><span class="p">(),</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_controlnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">control_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load ControlNet&quot;&quot;&quot;</span>
        <span class="n">controlnet_models</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;canny&#39;</span><span class="p">:</span> <span class="s2">&quot;lllyasviel/sd-controlnet-canny&quot;</span><span class="p">,</span>
            <span class="s1">&#39;depth&#39;</span><span class="p">:</span> <span class="s2">&quot;lllyasviel/sd-controlnet-depth&quot;</span><span class="p">,</span>
            <span class="s1">&#39;openpose&#39;</span><span class="p">:</span> <span class="s2">&quot;lllyasviel/sd-controlnet-openpose&quot;</span><span class="p">,</span>
            <span class="s1">&#39;scribble&#39;</span><span class="p">:</span> <span class="s2">&quot;lllyasviel/sd-controlnet-scribble&quot;</span><span class="p">,</span>
            <span class="s1">&#39;seg&#39;</span><span class="p">:</span> <span class="s2">&quot;lllyasviel/sd-controlnet-seg&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">control_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">controlnets</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">controlnets</span><span class="p">[</span><span class="n">control_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">ControlNetModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">controlnet_models</span><span class="p">[</span><span class="n">control_type</span><span class="p">],</span>
                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">controlnets</span><span class="p">[</span><span class="n">control_type</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_with_canny</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">low_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">high_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Canny Edge control&quot;&quot;&quot;</span>

        <span class="c1"># Extract Canny edges</span>
        <span class="n">canny_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">low_threshold</span><span class="p">,</span> <span class="n">high_threshold</span><span class="p">)</span>
        <span class="n">canny_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">canny_image</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Load ControlNet</span>
        <span class="n">controlnet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_controlnet</span><span class="p">(</span><span class="s1">&#39;canny&#39;</span><span class="p">)</span>

        <span class="c1"># Pipeline</span>
        <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span>
            <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnet</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">UniPCMultistepScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Generate</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">image</span><span class="o">=</span><span class="n">canny_image</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span>
            <span class="n">controlnet_conditioning_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Control strength</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">canny_image</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate_with_pose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pose control&quot;&quot;&quot;</span>

        <span class="c1"># Extract OpenPose</span>
        <span class="n">pose_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detectors</span><span class="p">[</span><span class="s1">&#39;openpose&#39;</span><span class="p">](</span><span class="n">image</span><span class="p">)</span>

        <span class="n">controlnet</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_controlnet</span><span class="p">(</span><span class="s1">&#39;openpose&#39;</span><span class="p">)</span>

        <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span>
            <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnet</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">image</span><span class="o">=</span><span class="n">pose_image</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">pose_image</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">multi_controlnet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">control_types</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;canny&#39;</span><span class="p">,</span> <span class="s1">&#39;depth&#39;</span><span class="p">]</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Multiple ControlNets&quot;&quot;&quot;</span>

        <span class="c1"># Load multiple ControlNets</span>
        <span class="n">controlnets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">load_controlnet</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="k">for</span> <span class="n">ct</span> <span class="ow">in</span> <span class="n">control_types</span><span class="p">]</span>

        <span class="c1"># Extract condition images</span>
        <span class="n">control_images</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ct</span> <span class="ow">in</span> <span class="n">control_types</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ct</span> <span class="o">==</span> <span class="s1">&#39;canny&#39;</span><span class="p">:</span>
                <span class="n">canny</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
                <span class="n">control_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">canny</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">ct</span> <span class="o">==</span> <span class="s1">&#39;depth&#39;</span><span class="p">:</span>
                <span class="c1"># Depth extraction (e.g., MiDaS)</span>
                <span class="n">depth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_depth</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
                <span class="n">control_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">depth</span><span class="p">)</span>

        <span class="c1"># Multi ControlNet pipeline</span>
        <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionControlNetPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span>
            <span class="n">controlnet</span><span class="o">=</span><span class="n">controlnets</span><span class="p">,</span>
            <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">image</span><span class="o">=</span><span class="n">control_images</span><span class="p">,</span>
            <span class="n">controlnet_conditioning_scale</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>  <span class="c1"># Strength for each</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">output</span>


<span class="c1"># Usage example</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">ControlNetGenerator</span><span class="p">()</span>

<span class="c1"># Keep composition from reference image while changing style</span>
<span class="n">reference_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;reference.jpg&quot;</span><span class="p">)</span>
<span class="n">result</span><span class="p">,</span> <span class="n">canny</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">generate_with_canny</span><span class="p">(</span>
    <span class="n">reference_image</span><span class="p">,</span>
    <span class="s2">&quot;A beautiful anime girl, studio ghibli style&quot;</span>
<span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="3-ip-adapter-image-prompt-adapter">3. IP-Adapter (Image Prompt Adapter)<a class="header-link" href="#3-ip-adapter-image-prompt-adapter" title="Permanent link">&para;</a></h2>
<h3 id="31-concept">3.1 Concept<a class="header-link" href="#31-concept" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>IP-Adapter: Using Images as Prompts

Direct style/content with images instead of/alongside text

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IP-Adapter Structure                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Reference Image â†’ CLIP Image Encoder â†’ Image Features     â”‚
â”‚                         â†“                                  â”‚
â”‚                  Projection Layer (trainable)              â”‚
â”‚                         â†“                                  â”‚
â”‚              Inject into Cross-Attention                   â”‚
â”‚                         â†“                                  â”‚
â”‚  Text Prompt + Image Features â†’ UNet â†’ Generated Image    â”‚
â”‚                                                            â”‚
â”‚  Use cases:                                                â”‚
â”‚  - Style transfer (style reference)                        â”‚
â”‚  - Face similarity preservation (face reference)           â”‚
â”‚  - Composition/color reference (composition)               â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="32-usage">3.2 Usage<a class="header-link" href="#32-usage" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CLIPVisionModelWithProjection</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">use_ip_adapter</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using IP-Adapter&quot;&quot;&quot;</span>

    <span class="c1"># Base pipeline</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Load IP-Adapter</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">load_ip_adapter</span><span class="p">(</span>
        <span class="s2">&quot;h94/IP-Adapter&quot;</span><span class="p">,</span>
        <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
        <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;ip-adapter_sd15.bin&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Set scale (0~1, higher = more reference image influence)</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">set_ip_adapter_scale</span><span class="p">(</span><span class="mf">0.6</span><span class="p">)</span>

    <span class="c1"># Reference image</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
    <span class="n">style_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;style_reference.jpg&quot;</span><span class="p">)</span>

    <span class="c1"># Generate</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A portrait of a woman&quot;</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="o">=</span><span class="n">style_image</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">output</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ip_adapter_face</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;IP-Adapter Face: Maintaining face similarity&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Face-specific IP-Adapter</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">load_ip_adapter</span><span class="p">(</span>
        <span class="s2">&quot;h94/IP-Adapter&quot;</span><span class="p">,</span>
        <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
        <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;ip-adapter-full-face_sd15.bin&quot;</span>
    <span class="p">)</span>

    <span class="n">pipe</span><span class="o">.</span><span class="n">set_ip_adapter_scale</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>

    <span class="c1"># Reference face</span>
    <span class="n">face_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;face_reference.jpg&quot;</span><span class="p">)</span>

    <span class="c1"># Generate in various styles</span>
    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;A person in a business suit, professional photo&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A person as a superhero, comic book style&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A person in ancient Rome, oil painting&quot;</span>
    <span class="p">]</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompts</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">ip_adapter_image</span><span class="o">=</span><span class="n">face_image</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ip_adapter_plus</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;IP-Adapter Plus: Stronger image conditioning&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Plus version (finer control)</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">load_ip_adapter</span><span class="p">(</span>
        <span class="s2">&quot;h94/IP-Adapter&quot;</span><span class="p">,</span>
        <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
        <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;ip-adapter-plus_sd15.bin&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Multiple image references</span>
    <span class="n">style_images</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;style1.jpg&quot;</span><span class="p">),</span>
        <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;style2.jpg&quot;</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A landscape&quot;</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="o">=</span><span class="n">style_images</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">output</span>
</code></pre></div>

<hr />
<h2 id="4-latent-consistency-models-lcm">4. Latent Consistency Models (LCM)<a class="header-link" href="#4-latent-consistency-models-lcm" title="Permanent link">&para;</a></h2>
<h3 id="41-concept">4.1 Concept<a class="header-link" href="#41-concept" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">LCM</span><span class="o">:</span><span class="w"> </span><span class="n">Ultra</span><span class="o">-</span><span class="n">fast</span><span class="w"> </span><span class="n">Image</span><span class="w"> </span><span class="n">Generation</span>

<span class="n">Traditional</span><span class="w"> </span><span class="n">Diffusion</span><span class="o">:</span><span class="w"> </span><span class="n">Requires</span><span class="w"> </span><span class="mi">20</span><span class="o">-</span><span class="mi">50</span><span class="w"> </span><span class="n">steps</span>
<span class="n">LCM</span><span class="o">:</span><span class="w"> </span><span class="n">High</span><span class="o">-</span><span class="n">quality</span><span class="w"> </span><span class="n">generation</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">2</span><span class="o">-</span><span class="mi">4</span><span class="w"> </span><span class="n">steps</span>

<span class="n">How</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">works</span><span class="o">:</span>
<span class="mi">1</span><span class="o">.</span><span class="w"> </span><span class="n">Distill</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="n">Diffusion</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">consistency</span><span class="w"> </span><span class="n">objective</span>
<span class="mi">2</span><span class="o">.</span><span class="w"> </span><span class="n">Map</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">noise</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="n">directly</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">clean</span><span class="w"> </span><span class="n">image</span>
<span class="mi">3</span><span class="o">.</span><span class="w"> </span><span class="n">Generate</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">few</span><span class="w"> </span><span class="n">steps</span>

<span class="n">Advantages</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">Real</span><span class="o">-</span><span class="n">time</span><span class="w"> </span><span class="n">generation</span><span class="w"> </span><span class="n">possible</span><span class="w"> </span><span class="o">(&lt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">second</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">Interactive</span><span class="w"> </span><span class="n">applications</span>
<span class="o">-</span><span class="w"> </span><span class="n">Low</span><span class="o">-</span><span class="n">power</span><span class="w"> </span><span class="n">devices</span><span class="w"> </span><span class="n">possible</span>
</code></pre></div>

<h3 id="42-usage">4.2 Usage<a class="header-link" href="#42-usage" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DiffusionPipeline</span><span class="p">,</span>
    <span class="n">LCMScheduler</span><span class="p">,</span>
    <span class="n">AutoPipelineForText2Image</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">lcm_generation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;LCM fast generation&quot;&quot;&quot;</span>

    <span class="c1"># Use LCM-LoRA (applies to existing models)</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">DiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">variant</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Load LCM-LoRA</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span><span class="s2">&quot;latent-consistency/lcm-lora-sdxl&quot;</span><span class="p">)</span>

    <span class="c1"># LCM scheduler</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LCMScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Fast generation (4 steps!)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A beautiful sunset over mountains&quot;</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="c1"># Very few steps</span>
        <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>     <span class="c1"># LCM recommends low guidance</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span><span class="w"> </span><span class="nf">lcm_real_time</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Real-time image generation demo&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">DiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;SimianLuo/LCM_Dreamshaper_v7&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LCMScheduler</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;A red apple&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A blue car&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A green forest&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A yellow sun&quot;</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompts</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">width</span><span class="o">=</span><span class="mi">512</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">turbo_generation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SDXL-Turbo: 1-4 step generation&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/sdxl-turbo&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">variant</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Just 1 step!</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A cinematic shot of a cat wearing a hat&quot;</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># Turbo doesn&#39;t need guidance</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">image</span>
</code></pre></div>

<hr />
<h2 id="5-advanced-techniques">5. Advanced Techniques<a class="header-link" href="#5-advanced-techniques" title="Permanent link">&para;</a></h2>
<h3 id="51-inpainting-outpainting">5.1 Inpainting &amp; Outpainting<a class="header-link" href="#51-inpainting-outpainting" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionInpaintPipeline</span>

<span class="k">def</span><span class="w"> </span><span class="nf">inpainting_example</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Region editing (Inpainting)&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionInpaintPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-inpainting&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Original image and mask</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;original.jpg&quot;</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;mask.png&quot;</span><span class="p">)</span>  <span class="c1"># White = region to edit</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A cat sitting on the couch&quot;</span><span class="p">,</span>
        <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
        <span class="n">mask_image</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">outpainting_example</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Image extension (Outpainting)&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionInpaintPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-inpainting&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Place original image on canvas</span>
    <span class="n">original</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;original.jpg&quot;</span><span class="p">)</span>
    <span class="n">canvas_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="n">canvas</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="n">canvas_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>

    <span class="c1"># Center placement</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="p">((</span><span class="n">canvas_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">original</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
              <span class="p">(</span><span class="n">canvas_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">original</span><span class="o">.</span><span class="n">height</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">canvas</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>

    <span class="c1"># Mask: white outside original region</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;L&quot;</span><span class="p">,</span> <span class="n">canvas_size</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">mask</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="p">(</span><span class="n">offset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">original</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">offset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">original</span><span class="o">.</span><span class="n">height</span><span class="p">))</span>

    <span class="c1"># Extend</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;A beautiful landscape extending the scene&quot;</span><span class="p">,</span>
        <span class="n">image</span><span class="o">=</span><span class="n">canvas</span><span class="p">,</span>
        <span class="n">mask_image</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>

<h3 id="52-image-to-image-translation">5.2 Image-to-Image Translation<a class="header-link" href="#52-image-to-image-translation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionImg2ImgPipeline</span>

<span class="k">def</span><span class="w"> </span><span class="nf">style_transfer</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Style transformation&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionImg2ImgPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Input image</span>
    <span class="n">init_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;photo.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

    <span class="c1"># Style transformation</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;oil painting, impressionist style, vibrant colors&quot;</span><span class="p">,</span>
        <span class="n">image</span><span class="o">=</span><span class="n">init_image</span><span class="p">,</span>
        <span class="n">strength</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>  <span class="c1"># 0~1, higher = more change</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>

<h3 id="53-text-embedding-manipulation">5.3 Text Embedding Manipulation<a class="header-link" href="#53-text-embedding-manipulation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">prompt_weighting</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prompt weight adjustment&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">compel</span><span class="w"> </span><span class="kn">import</span> <span class="n">Compel</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">compel</span> <span class="o">=</span> <span class="n">Compel</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">pipe</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">text_encoder</span><span class="o">=</span><span class="n">pipe</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">)</span>

    <span class="c1"># Weight syntax</span>
    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;a (beautiful)++ sunset&quot;</span><span class="p">,</span>           <span class="c1"># ++ = 1.21x</span>
        <span class="s2">&quot;a (beautiful)+++ sunset&quot;</span><span class="p">,</span>          <span class="c1"># +++ = 1.33x</span>
        <span class="s2">&quot;a (ugly)-- sunset&quot;</span><span class="p">,</span>                <span class="c1"># -- = 0.83x</span>
        <span class="s2">&quot;a (red:1.5) and (blue:0.5) sunset&quot;</span> <span class="c1"># Explicit weights</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompts</span><span class="p">:</span>
        <span class="n">conditioning</span> <span class="o">=</span> <span class="n">compel</span><span class="o">.</span><span class="n">build_conditioning_tensor</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">conditioning</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">prompt_blending</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prompt blending&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">compel</span><span class="w"> </span><span class="kn">import</span> <span class="n">Compel</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">compel</span> <span class="o">=</span> <span class="n">Compel</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">pipe</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">text_encoder</span><span class="o">=</span><span class="n">pipe</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">)</span>

    <span class="c1"># Blend two prompts</span>
    <span class="n">prompt1</span> <span class="o">=</span> <span class="s2">&quot;a photo of a cat&quot;</span>
    <span class="n">prompt2</span> <span class="o">=</span> <span class="s2">&quot;a photo of a dog&quot;</span>

    <span class="n">cond1</span> <span class="o">=</span> <span class="n">compel</span><span class="o">.</span><span class="n">build_conditioning_tensor</span><span class="p">(</span><span class="n">prompt1</span><span class="p">)</span>
    <span class="n">cond2</span> <span class="o">=</span> <span class="n">compel</span><span class="o">.</span><span class="n">build_conditioning_tensor</span><span class="p">(</span><span class="n">prompt2</span><span class="p">)</span>

    <span class="c1"># 50:50 blending</span>
    <span class="n">blended</span> <span class="o">=</span> <span class="p">(</span><span class="n">cond1</span> <span class="o">+</span> <span class="n">cond2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">blended</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">image</span>
</code></pre></div>

<hr />
<h2 id="6-optimization-techniques">6. Optimization Techniques<a class="header-link" href="#6-optimization-techniques" title="Permanent link">&para;</a></h2>
<h3 id="61-memory-optimization">6.1 Memory Optimization<a class="header-link" href="#61-memory-optimization" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">optimize_memory</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Memory optimization techniques&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionXLPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span>

    <span class="c1"># 1. CPU Offload</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_model_cpu_offload</span><span class="p">()</span>

    <span class="c1"># 2. Sequential CPU Offload (slower but saves more memory)</span>
    <span class="c1"># pipe.enable_sequential_cpu_offload()</span>

    <span class="c1"># 3. VAE Slicing (for large images)</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_vae_slicing</span><span class="p">()</span>

    <span class="c1"># 4. VAE Tiling (for very large images)</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_vae_tiling</span><span class="p">()</span>

    <span class="c1"># 5. Attention Slicing</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_attention_slicing</span><span class="p">(</span><span class="n">slice_size</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

    <span class="c1"># 6. xFormers</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">enable_xformers_memory_efficient_attention</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">pipe</span>


<span class="k">def</span><span class="w"> </span><span class="nf">batch_generation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch generation optimization&quot;&quot;&quot;</span>

    <span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;runwayml/stable-diffusion-v1-5&quot;</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;A red apple&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A blue car&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A green tree&quot;</span><span class="p">,</span>
        <span class="s2">&quot;A yellow sun&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c1"># Batch generation (more efficient)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">images</span>

    <span class="k">return</span> <span class="n">images</span>
</code></pre></div>

<hr />
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="papers">Papers<a class="header-link" href="#papers" title="Permanent link">&para;</a></h3>
<ul>
<li>Podell et al. (2023). "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"</li>
<li>Zhang et al. (2023). "Adding Conditional Control to Text-to-Image Diffusion Models" (ControlNet)</li>
<li>Ye et al. (2023). "IP-Adapter: Text Compatible Image Prompt Adapter"</li>
<li>Luo et al. (2023). "Latent Consistency Models"</li>
</ul>
<h3 id="models">Models<a class="header-link" href="#models" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0">SDXL</a></li>
<li><a href="https://huggingface.co/lllyasviel/ControlNet">ControlNet</a></li>
<li><a href="https://huggingface.co/h94/IP-Adapter">IP-Adapter</a></li>
<li><a href="https://huggingface.co/latent-consistency/lcm-lora-sdxl">LCM-LoRA</a></li>
</ul>
<h3 id="related-lessons">Related Lessons<a class="header-link" href="#related-lessons" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../Deep_Learning/17_Diffusion_Models.md">../Deep_Learning/17_Diffusion_Models.md</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Foundation_Models/14_Unified_Vision_Models.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">14. Unified Vision Models</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Foundation_Models/16_Vision_Language_Advanced.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">16. Advanced Vision-Language</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}