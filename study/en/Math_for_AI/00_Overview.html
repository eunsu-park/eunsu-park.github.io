{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mathematics for AI/ML/DL - Overview - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">üè†</span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">üíª</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        ÌïúÍµ≠Ïñ¥
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">‚òÄÔ∏è</span>
                    <span class="theme-icon dark">üåô</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Math_for_AI/">Math for AI</a>
    <span class="separator">/</span>
    <span class="current">Mathematics for AI/ML/DL - Overview</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>Mathematics for AI/ML/DL - Overview</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <span class="nav-placeholder"></span>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Math_for_AI/01_Vectors_and_Matrices.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">01. Vectors and Matrices</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#file-list">File List</a></li>
<li><a href="#required-libraries">Required Libraries</a></li>
<li><a href="#recommended-learning-path">Recommended Learning Path</a><ul>
<li><a href="#phase-1-linear-algebra-fundamentals-01-05-2-3-weeks">Phase 1: Linear Algebra Fundamentals (01-05) - 2-3 weeks</a></li>
<li><a href="#phase-2-optimization-theory-06-07-1-2-weeks">Phase 2: Optimization Theory (06-07) - 1-2 weeks</a></li>
<li><a href="#phase-3-probability-theory-and-information-theory-08-12-2-3-weeks">Phase 3: Probability Theory and Information Theory (08-12) - 2-3 weeks</a></li>
<li><a href="#phase-4-advanced-topics-13-18-2-3-weeks">Phase 4: Advanced Topics (13-18) - 2-3 weeks</a></li>
</ul>
</li>
<li><a href="#prerequisites">Prerequisites</a><ul>
<li><a href="#required">Required</a></li>
<li><a href="#recommended">Recommended</a></li>
<li><a href="#prerequisite-courses">Prerequisite Courses</a></li>
</ul>
</li>
<li><a href="#learning-objectives">Learning Objectives</a></li>
<li><a href="#course-features">Course Features</a><ul>
<li><a href="#balance-between-theory-and-practice">Balance Between Theory and Practice</a></li>
<li><a href="#mldl-centric-approach">ML/DL-Centric Approach</a></li>
<li><a href="#modern-topics-included">Modern Topics Included</a></li>
<li><a href="#emphasis-on-visualization">Emphasis on Visualization</a></li>
</ul>
</li>
<li><a href="#learning-strategies">Learning Strategies</a><ul>
<li><a href="#1-derive-formulas-by-hand">1. Derive Formulas by Hand</a></li>
<li><a href="#2-validate-with-code">2. Validate with Code</a></li>
<li><a href="#3-build-intuition-through-visualization">3. Build Intuition Through Visualization</a></li>
<li><a href="#4-practice-problems-are-essential">4. Practice Problems Are Essential</a></li>
<li><a href="#5-practice-reading-papers">5. Practice Reading Papers</a></li>
</ul>
</li>
<li><a href="#learning-paths-by-difficulty-level">Learning Paths by Difficulty Level</a><ul>
<li><a href="#beginners-weak-math-background">Beginners (Weak math background)</a></li>
<li><a href="#intermediate-math-background-available">Intermediate (Math background available)</a></li>
<li><a href="#advanced-strong-math-background">Advanced (Strong math background)</a></li>
</ul>
</li>
<li><a href="#project-ideas">Project Ideas</a></li>
<li><a href="#references">References</a><ul>
<li><a href="#textbooks">Textbooks</a></li>
<li><a href="#online-courses">Online Courses</a></li>
<li><a href="#papers-and-blogs">Papers and Blogs</a></li>
<li><a href="#tools">Tools</a></li>
</ul>
</li>
<li><a href="#version-information">Version Information</a></li>
<li><a href="#license">License</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="mathematics-for-aimldl-overview">Mathematics for AI/ML/DL - Overview<a class="header-link" href="#mathematics-for-aimldl-overview" title="Permanent link">&para;</a></h1>
<h2 id="introduction">Introduction<a class="header-link" href="#introduction" title="Permanent link">&para;</a></h2>
<p>A solid mathematical foundation is essential for deeply understanding and effectively utilizing artificial intelligence, machine learning, and deep learning. This course systematically presents the core mathematical concepts required for AI/ML/DL.</p>
<p>This course covers mathematical fields that form the theoretical foundation of AI, including linear algebra, calculus, probability theory, optimization theory, and information theory. Each lesson is designed with theoretical explanations alongside Python code examples, allowing you to implement and visualize mathematical concepts in practice.</p>
<p>The goal is not simply to memorize formulas, but to understand why this mathematics is necessary and how it applies to ML algorithms.</p>
<h2 id="file-list">File List<a class="header-link" href="#file-list" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>No.</th>
<th>Filename</th>
<th>Topic</th>
<th>Main Content</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>00_Overview.md</td>
<td>Overview</td>
<td>Course introduction and learning guide</td>
</tr>
<tr>
<td>01</td>
<td>01_Vectors_and_Matrices.md</td>
<td>Vectors and Matrices</td>
<td>Vector spaces, basis, matrix operations, linear transformations</td>
</tr>
<tr>
<td>02</td>
<td>02_Matrix_Decompositions.md</td>
<td>Matrix Decompositions</td>
<td>Eigendecomposition, SVD, PCA, LU/QR decomposition</td>
</tr>
<tr>
<td>03</td>
<td>03_Matrix_Calculus.md</td>
<td>Matrix Calculus</td>
<td>Jacobian, Hessian, backpropagation mathematics</td>
</tr>
<tr>
<td>04</td>
<td>04_Norms_and_Distances.md</td>
<td>Norms and Distances</td>
<td>Lp norms, cosine similarity, distance metrics</td>
</tr>
<tr>
<td>05</td>
<td>05_Multivariate_Calculus.md</td>
<td>Multivariate Calculus</td>
<td>Partial derivatives, gradients, directional derivatives, Taylor series</td>
</tr>
<tr>
<td>06</td>
<td>06_Optimization_Fundamentals.md</td>
<td>Optimization Fundamentals</td>
<td>Convex functions, Lagrange multipliers, KKT conditions</td>
</tr>
<tr>
<td>07</td>
<td>07_Gradient_Descent_Theory.md</td>
<td>Gradient Descent Theory</td>
<td>GD convergence analysis, SGD, momentum, Adam</td>
</tr>
<tr>
<td>08</td>
<td>08_Probability_for_ML.md</td>
<td>Probability for ML</td>
<td>Random variables, expectation, variance, Bayes' theorem</td>
</tr>
<tr>
<td>09</td>
<td>09_Maximum_Likelihood_and_MAP.md</td>
<td>MLE and MAP</td>
<td>MLE, MAP, relationship with regularization</td>
</tr>
<tr>
<td>10</td>
<td>10_Information_Theory.md</td>
<td>Information Theory</td>
<td>Entropy, cross-entropy, KL divergence, mutual information</td>
</tr>
<tr>
<td>11</td>
<td>11_Probability_Distributions_Advanced.md</td>
<td>Advanced Distributions</td>
<td>Exponential family, multivariate Gaussian, conjugate priors</td>
</tr>
<tr>
<td>12</td>
<td>12_Sampling_and_Monte_Carlo.md</td>
<td>Sampling and Monte Carlo</td>
<td>MCMC, Gibbs sampling, reparameterization trick</td>
</tr>
<tr>
<td>13</td>
<td>13_Linear_Algebra_for_Deep_Learning.md</td>
<td>Linear Algebra for DL</td>
<td>Tensors, einsum, broadcasting, numerical stability</td>
</tr>
<tr>
<td>14</td>
<td>14_Convexity_and_Duality.md</td>
<td>Convexity and Duality</td>
<td>Convex optimization, Lagrange duality, proximal operators</td>
</tr>
<tr>
<td>15</td>
<td>15_Graph_Theory_and_Spectral_Methods.md</td>
<td>Graph Theory and Spectral</td>
<td>Graph Laplacian, spectral clustering, GNN mathematics</td>
</tr>
<tr>
<td>16</td>
<td>16_Manifold_and_Representation_Learning.md</td>
<td>Manifold Learning</td>
<td>Manifold hypothesis, geodesics, t-SNE/UMAP mathematics</td>
</tr>
<tr>
<td>17</td>
<td>17_Math_of_Attention_and_Transformers.md</td>
<td>Mathematics of Attention</td>
<td>Self-attention, positional encoding, multi-head attention</td>
</tr>
<tr>
<td>18</td>
<td>18_Math_of_Generative_Models.md</td>
<td>Mathematics of Generative Models</td>
<td>VAE ELBO, GAN objective, diffusion model mathematics</td>
</tr>
</tbody>
</table>
<h2 id="required-libraries">Required Libraries<a class="header-link" href="#required-libraries" title="Permanent link">&para;</a></h2>
<p>To run the code examples in this course, the following libraries are required:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>scipy<span class="w"> </span>matplotlib<span class="w"> </span>sympy<span class="w"> </span>torch
</code></pre></div>

<ul>
<li><strong>NumPy</strong>: Vector and matrix operations, linear algebra</li>
<li><strong>SciPy</strong>: Optimization, probability distributions, special functions</li>
<li><strong>Matplotlib</strong>: Visualization of mathematical concepts</li>
<li><strong>SymPy</strong>: Symbolic calculus, formula expansion</li>
<li><strong>PyTorch</strong>: Automatic differentiation, deep learning math implementation</li>
</ul>
<h2 id="recommended-learning-path">Recommended Learning Path<a class="header-link" href="#recommended-learning-path" title="Permanent link">&para;</a></h2>
<h3 id="phase-1-linear-algebra-fundamentals-01-05-2-3-weeks">Phase 1: Linear Algebra Fundamentals (01-05) - 2-3 weeks<a class="header-link" href="#phase-1-linear-algebra-fundamentals-01-05-2-3-weeks" title="Permanent link">&para;</a></h3>
<ul>
<li>Basic concepts of vectors and matrices</li>
<li>Matrix decompositions and PCA</li>
<li>Matrix calculus</li>
<li>Norms and distance metrics</li>
<li>Multivariate calculus</li>
</ul>
<p><strong>Goal</strong>: Establish linear algebra fundamentals to understand the mathematical representation of deep learning models</p>
<h3 id="phase-2-optimization-theory-06-07-1-2-weeks">Phase 2: Optimization Theory (06-07) - 1-2 weeks<a class="header-link" href="#phase-2-optimization-theory-06-07-1-2-weeks" title="Permanent link">&para;</a></h3>
<ul>
<li>Formulation of optimization problems</li>
<li>Convex optimization</li>
<li>Gradient descent and variants</li>
</ul>
<p><strong>Goal</strong>: Understand the working principles and convergence conditions of learning algorithms</p>
<h3 id="phase-3-probability-theory-and-information-theory-08-12-2-3-weeks">Phase 3: Probability Theory and Information Theory (08-12) - 2-3 weeks<a class="header-link" href="#phase-3-probability-theory-and-information-theory-08-12-2-3-weeks" title="Permanent link">&para;</a></h3>
<ul>
<li>Probability fundamentals</li>
<li>Maximum likelihood estimation and MAP</li>
<li>Core concepts of information theory</li>
<li>Advanced probability distributions</li>
<li>Sampling techniques</li>
</ul>
<p><strong>Goal</strong>: Acquire probabilistic modeling and uncertainty quantification capabilities</p>
<h3 id="phase-4-advanced-topics-13-18-2-3-weeks">Phase 4: Advanced Topics (13-18) - 2-3 weeks<a class="header-link" href="#phase-4-advanced-topics-13-18-2-3-weeks" title="Permanent link">&para;</a></h3>
<ul>
<li>Deep learning-specialized linear algebra</li>
<li>Convex duality</li>
<li>Graph neural network mathematics</li>
<li>Manifold learning</li>
<li>Transformer and generative model mathematics</li>
</ul>
<p><strong>Goal</strong>: Understand the theoretical foundations of modern AI models</p>
<h2 id="prerequisites">Prerequisites<a class="header-link" href="#prerequisites" title="Permanent link">&para;</a></h2>
<h3 id="required">Required<a class="header-link" href="#required" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>High school mathematics</strong>: Calculus basics (limits, derivatives, integrals), matrix basics</li>
<li><strong>Python programming</strong>: Basic syntax, functions, lists/dictionaries</li>
<li><strong>Mathematical thinking</strong>: Logical reasoning, reading and interpreting formulas</li>
</ul>
<h3 id="recommended">Recommended<a class="header-link" href="#recommended" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>NumPy basics</strong>: Array creation, indexing, basic operations</li>
<li><strong>Calculus</strong>: Partial derivatives, chain rule</li>
<li><strong>Linear algebra</strong>: Concepts of vectors, matrices, determinants</li>
</ul>
<h3 id="prerequisite-courses">Prerequisite Courses<a class="header-link" href="#prerequisite-courses" title="Permanent link">&para;</a></h3>
<ul>
<li>Python basics course</li>
<li>NumPy introduction</li>
</ul>
<h2 id="learning-objectives">Learning Objectives<a class="header-link" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<p>Upon completing this course, you will be able to:</p>
<ol>
<li><strong>Master linear algebra</strong>: Understand vector spaces, matrix decompositions, linear transformations and apply them to ML problems</li>
<li><strong>Understand optimization theory</strong>: Grasp the mathematical principles and convergence conditions of gradient descent</li>
<li><strong>Think probabilistically</strong>: Mathematically model uncertainty and perform Bayesian inference</li>
<li><strong>Apply information theory</strong>: Design loss functions using entropy and KL divergence</li>
<li><strong>Implement backpropagation</strong>: Derive gradient computation formulas using matrix calculus</li>
<li><strong>Understand dimensionality reduction</strong>: Understand the mathematical principles and implementation of PCA and SVD</li>
<li><strong>Numerical stability</strong>: Recognize and resolve numerical issues that arise during computation</li>
<li><strong>Transformer mathematics</strong>: Understand the mathematical foundations of self-attention and positional encoding</li>
<li><strong>Generative model theory</strong>: Derive VAE ELBO and diffusion model objective functions</li>
<li><strong>Read papers</strong>: Independently understand formulas and proofs in AI papers</li>
</ol>
<h2 id="course-features">Course Features<a class="header-link" href="#course-features" title="Permanent link">&para;</a></h2>
<h3 id="balance-between-theory-and-practice">Balance Between Theory and Practice<a class="header-link" href="#balance-between-theory-and-practice" title="Permanent link">&para;</a></h3>
<p>Each lesson provides mathematical proofs along with Python implementations. You can build intuition by not just looking at formulas but implementing and visualizing them in code.</p>
<h3 id="mldl-centric-approach">ML/DL-Centric Approach<a class="header-link" href="#mldl-centric-approach" title="Permanent link">&para;</a></h3>
<p>The focus is on how mathematics is actually used in machine learning and deep learning, not abstract mathematics. For example, when learning eigenvalue decomposition, we also cover applications like PCA and spectral clustering.</p>
<h3 id="modern-topics-included">Modern Topics Included<a class="header-link" href="#modern-topics-included" title="Permanent link">&para;</a></h3>
<p>Beyond traditional mathematics courses, we cover the mathematical foundations of cutting-edge AI models like Transformers, diffusion models, and graph neural networks.</p>
<h3 id="emphasis-on-visualization">Emphasis on Visualization<a class="header-link" href="#emphasis-on-visualization" title="Permanent link">&para;</a></h3>
<p>Rich visualizations using Matplotlib are provided to understand abstract concepts. Even high-dimensional space concepts can be intuitively understood through 2D/3D visualization.</p>
<h2 id="learning-strategies">Learning Strategies<a class="header-link" href="#learning-strategies" title="Permanent link">&para;</a></h2>
<h3 id="1-derive-formulas-by-hand">1. Derive Formulas by Hand<a class="header-link" href="#1-derive-formulas-by-hand" title="Permanent link">&para;</a></h3>
<p>Don't just read formulas in papers or textbooks‚Äîwrite them down on paper and derive them step by step. Where you get stuck is exactly your learning point.</p>
<h3 id="2-validate-with-code">2. Validate with Code<a class="header-link" href="#2-validate-with-code" title="Permanent link">&para;</a></h3>
<p>After deriving a formula, always implement it in code to verify the results. You can confirm the meaning of the formula through numerical examples.</p>
<h3 id="3-build-intuition-through-visualization">3. Build Intuition Through Visualization<a class="header-link" href="#3-build-intuition-through-visualization" title="Permanent link">&para;</a></h3>
<p>Even high-dimensional data or complex functions can be visualized through appropriate cross-sections or projections. Understand the geometric meaning of mathematical concepts while creating graphs.</p>
<h3 id="4-practice-problems-are-essential">4. Practice Problems Are Essential<a class="header-link" href="#4-practice-problems-are-essential" title="Permanent link">&para;</a></h3>
<p>Don't skip the practice problems in each lesson. Even if you think you understand the concept, you can only verify true understanding by solving problems.</p>
<h3 id="5-practice-reading-papers">5. Practice Reading Papers<a class="header-link" href="#5-practice-reading-papers" title="Permanent link">&para;</a></h3>
<p>When you reach Phase 4, select an AI paper of interest and intensively analyze the formula sections. This is good practice for applying learned mathematics in real situations.</p>
<h2 id="learning-paths-by-difficulty-level">Learning Paths by Difficulty Level<a class="header-link" href="#learning-paths-by-difficulty-level" title="Permanent link">&para;</a></h2>
<h3 id="beginners-weak-math-background">Beginners (Weak math background)<a class="header-link" href="#beginners-weak-math-background" title="Permanent link">&para;</a></h3>
<ol>
<li>Study introductory linear algebra textbook (Gilbert Strang) in parallel</li>
<li>Focus on lessons 01-02 (2-3 weeks)</li>
<li>Study lessons 05, 08-09</li>
<li>Refer to remaining lessons as needed</li>
</ol>
<h3 id="intermediate-math-background-available">Intermediate (Math background available)<a class="header-link" href="#intermediate-math-background-available" title="Permanent link">&para;</a></h3>
<ol>
<li>Complete Phase 1-3 in normal order</li>
<li>Selectively study Phase 4 based on areas of interest</li>
<li>Complete entire course in 6-8 weeks</li>
</ol>
<h3 id="advanced-strong-math-background">Advanced (Strong math background)<a class="header-link" href="#advanced-strong-math-background" title="Permanent link">&para;</a></h3>
<ol>
<li>Quick review of 01-05</li>
<li>Focus on 06-07, 10, 14</li>
<li>Advanced study of 13, 15-18</li>
<li>Parallel paper formula derivation project</li>
</ol>
<h2 id="project-ideas">Project Ideas<a class="header-link" href="#project-ideas" title="Permanent link">&para;</a></h2>
<p>Project suggestions to apply what you've learned:</p>
<ol>
<li><strong>PCA-based face recognition</strong>: Eigenface implementation using SVD</li>
<li><strong>Gradient descent visualization tool</strong>: Compare various optimization algorithms</li>
<li><strong>Bayesian linear regression</strong>: Visualize prior/posterior distributions</li>
<li><strong>Information theory-based feature selection</strong>: Variable selection based on mutual information</li>
<li><strong>Transformer from scratch</strong>: Mathematical implementation of attention mechanism</li>
<li><strong>Simple diffusion model</strong>: Mathematical derivation and implementation of DDPM</li>
</ol>
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="textbooks">Textbooks<a class="header-link" href="#textbooks" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A.</strong> (2016). <em>Deep Learning</em>. MIT Press. (especially Ch 2-4)</li>
<li>Concise summary of essential deep learning mathematics</li>
<li><strong>Boyd, S., &amp; Vandenberghe, L.</strong> (2004). <em>Convex Optimization</em>. Cambridge University Press.</li>
<li>The bible of optimization theory</li>
<li><strong>Bishop, C. M.</strong> (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>Probabilistic perspective on machine learning</li>
<li><strong>Strang, G.</strong> (2016). <em>Introduction to Linear Algebra</em>. Wellesley-Cambridge Press.</li>
<li>Classic linear algebra introduction</li>
<li><strong>Murphy, K. P.</strong> (2022). <em>Probabilistic Machine Learning: An Introduction</em>. MIT Press.</li>
<li>ML mathematics from a modern perspective</li>
</ol>
<h3 id="online-courses">Online Courses<a class="header-link" href="#online-courses" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>3Blue1Brown - Essence of Linear Algebra</strong>: The pinnacle of linear algebra visualization</li>
<li><strong>Gilbert Strang - MIT 18.06</strong>: Legendary linear algebra lectures</li>
<li><strong>Stanford CS229</strong>: Andrew Ng's machine learning math materials</li>
<li><strong>Fast.ai - Computational Linear Algebra</strong>: Practice-oriented approach</li>
</ol>
<h3 id="papers-and-blogs">Papers and Blogs<a class="header-link" href="#papers-and-blogs" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Distill.pub</strong>: ML math explained with interactive visualizations</li>
<li><strong>The Matrix Calculus You Need For Deep Learning</strong> (Parr &amp; Howard, 2018)</li>
<li><strong>Understanding the difficulty of training deep feedforward neural networks</strong> (Glorot &amp; Bengio, 2010)</li>
</ol>
<h3 id="tools">Tools<a class="header-link" href="#tools" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Wolfram Alpha</strong>: Formula calculation and verification</li>
<li><strong>Desmos</strong>: Function visualization</li>
<li><strong>GeoGebra</strong>: Geometric intuition development</li>
<li><strong>Jupyter Notebook</strong>: Interactive math notebooks</li>
</ol>
<h2 id="version-information">Version Information<a class="header-link" href="#version-information" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>First written</strong>: 2026-02-07</li>
<li><strong>Author</strong>: Claude (Anthropic)</li>
<li><strong>Python version</strong>: 3.8+</li>
<li><strong>Major library versions</strong>:</li>
<li>NumPy &gt;= 1.20</li>
<li>SciPy &gt;= 1.7</li>
<li>Matplotlib &gt;= 3.4</li>
<li>SymPy &gt;= 1.9</li>
<li>PyTorch &gt;= 1.10</li>
</ul>
<h2 id="license">License<a class="header-link" href="#license" title="Permanent link">&para;</a></h2>
<p>This material is freely available for educational purposes. Please cite the source for commercial use.</p>
<hr />
<p><strong>Next step</strong>: Start with <a href="01_Vectors_and_Matrices.md">01. Vectors and Matrices</a>.</p>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <span class="nav-placeholder"></span>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Math_for_AI/01_Vectors_and_Matrices.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">01. Vectors and Matrices</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">‚Üë</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}