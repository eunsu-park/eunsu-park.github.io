{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Overview - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Reinforcement_Learning/">Reinforcement Learning</a>
    <span class="separator">/</span>
    <span class="current">Reinforcement Learning Overview</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>Reinforcement Learning Overview</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <span class="nav-placeholder"></span>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Reinforcement_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Reinforcement_Learning/01_RL_Introduction.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">01. Introduction to Reinforcement Learning</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#target-audience">Target Audience</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
</ul>
</li>
<li><a href="#learning-roadmap">Learning Roadmap</a></li>
<li><a href="#file-list">File List</a></li>
<li><a href="#difficulty-guide">Difficulty Guide</a></li>
<li><a href="#environment-setup">Environment Setup</a><ul>
<li><a href="#installing-required-packages">Installing Required Packages</a></li>
<li><a href="#environment-testing">Environment Testing</a></li>
<li><a href="#recommended-development-environment">Recommended Development Environment</a></li>
</ul>
</li>
<li><a href="#recommended-learning-order">Recommended Learning Order</a><ul>
<li><a href="#stage-1-building-foundations-1-2-weeks">Stage 1: Building Foundations (1-2 weeks)</a></li>
<li><a href="#stage-2-value-based-methods-2-3-weeks">Stage 2: Value-based Methods (2-3 weeks)</a></li>
<li><a href="#stage-3-policy-based-methods-2-3-weeks">Stage 3: Policy-based Methods (2-3 weeks)</a></li>
<li><a href="#stage-4-advanced-topics-3-weeks">Stage 4: Advanced Topics (3 weeks)</a></li>
</ul>
</li>
<li><a href="#algorithm-comparison">Algorithm Comparison</a></li>
<li><a href="#references">References</a><ul>
<li><a href="#textbooks">Textbooks</a></li>
<li><a href="#online-courses">Online Courses</a></li>
<li><a href="#libraries">Libraries</a></li>
</ul>
</li>
<li><a href="#key-terms">Key Terms</a></li>
<li><a href="#related-folders">Related Folders</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="reinforcement-learning-overview">Reinforcement Learning Overview<a class="header-link" href="#reinforcement-learning-overview" title="Permanent link">&para;</a></h1>
<h2 id="introduction">Introduction<a class="header-link" href="#introduction" title="Permanent link">&para;</a></h2>
<p>This folder contains materials for systematically learning <strong>Reinforcement Learning (RL)</strong> from basics to advanced topics. It covers core concepts and algorithms of RL, where agents learn to maximize rewards through interaction with environments.</p>
<h3 id="target-audience">Target Audience<a class="header-link" href="#target-audience" title="Permanent link">&para;</a></h3>
<ul>
<li>Learners with foundational knowledge in machine learning/deep learning</li>
<li>Developers interested in game AI, robotics, autonomous driving, etc.</li>
<li>Those who want to understand the technical principles behind AlphaGo, ChatGPT(RLHF), etc.</li>
</ul>
<h3 id="prerequisites">Prerequisites<a class="header-link" href="#prerequisites" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Required</strong>: Python programming, basic probability/statistics</li>
<li><strong>Recommended</strong>: Completed Deep_Learning folder lessons, PyTorch basics</li>
</ul>
<hr />
<h2 id="learning-roadmap">Learning Roadmap<a class="header-link" href="#learning-roadmap" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     RL Foundations (01-04)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚                           â”‚
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RL Intro    â”‚         â”‚  MDP &amp; Bellman  â”‚         â”‚  Dynamic        â”‚
â”‚   (01)        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (02)           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Programming    â”‚
â”‚               â”‚         â”‚                 â”‚         â”‚  (03)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                               â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Monte Carlo Methods (04)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                               â”‚
                    â–¼                               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           Value-based Methods (05-07)                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                           â”‚
        â–¼                       â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TD Learning  â”‚â”€â”€â”€â”€â–¶â”‚  Q-Learning &amp;   â”‚â”€â”€â”€â”€â–¶â”‚  Deep Q-Network â”‚
â”‚  (05)         â”‚     â”‚  SARSA (06)     â”‚     â”‚  (07)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          Policy-based Methods (08-10)                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                           â”‚
        â–¼                       â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Policy        â”‚â”€â”€â”€â”€â–¶â”‚  Actor-Critic   â”‚â”€â”€â”€â”€â–¶â”‚  PPO &amp; TRPO     â”‚
â”‚ Gradient (08) â”‚     â”‚  A2C/A3C (09)   â”‚     â”‚  (10)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               Advanced Topics (11-12)                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                               â”‚
                â–¼                               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Multi-Agent RL â”‚             â”‚  Practical      â”‚
      â”‚  (11)           â”‚             â”‚  Project (12)   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<hr />
<h2 id="file-list">File List<a class="header-link" href="#file-list" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>Filename</th>
<th>Topic</th>
<th style="text-align: center;">Difficulty</th>
<th>Key Content</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">00</td>
<td>Overview.md</td>
<td>Overview</td>
<td style="text-align: center;">-</td>
<td>Learning guide, roadmap, environment setup</td>
</tr>
<tr>
<td style="text-align: center;">01</td>
<td>RL_Introduction.md</td>
<td>RL Intro</td>
<td style="text-align: center;">â­</td>
<td>Agent-environment, rewards, episodic/continuous tasks</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td>MDP_Basics.md</td>
<td>MDP Basics</td>
<td style="text-align: center;">â­â­</td>
<td>Markov Decision Process, Bellman equations, V/Q functions</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td>Dynamic_Programming.md</td>
<td>Dynamic Programming</td>
<td style="text-align: center;">â­â­</td>
<td>Policy iteration, value iteration, DP limitations</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td>Monte_Carlo_Methods.md</td>
<td>Monte Carlo Methods</td>
<td style="text-align: center;">â­â­</td>
<td>Sample-based learning, First-visit/Every-visit MC</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td>TD_Learning.md</td>
<td>TD Learning</td>
<td style="text-align: center;">â­â­â­</td>
<td>TD(0), TD Target, Bootstrapping, TD vs MC</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td>Q_Learning_SARSA.md</td>
<td>Q-Learning &amp; SARSA</td>
<td style="text-align: center;">â­â­â­</td>
<td>Off-policy, On-policy, Epsilon-greedy</td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td>Deep_Q_Network.md</td>
<td>DQN</td>
<td style="text-align: center;">â­â­â­</td>
<td>Experience Replay, Target Network, Double/Dueling DQN</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td>Policy_Gradient.md</td>
<td>Policy Gradient</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>REINFORCE, Baseline, policy gradient theorem</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td>Actor_Critic.md</td>
<td>Actor-Critic</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>A2C, A3C, Advantage function, GAE</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td>PPO_TRPO.md</td>
<td>PPO &amp; TRPO</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>Clipping, KL Divergence, Proximal Policy Optimization</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td>Multi_Agent_RL.md</td>
<td>Multi-Agent RL</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>Cooperation/Competition, Self-Play, MARL algorithms</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td>Practical_RL_Project.md</td>
<td>Practical Projects</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>Gymnasium environments, Atari games, comprehensive projects</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td>Model_Based_RL.md</td>
<td>Model-Based RL</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>Dyna architecture, world models, MBPO, MuZero, Dreamer</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td>Soft_Actor_Critic.md</td>
<td>SAC</td>
<td style="text-align: center;">â­â­â­â­</td>
<td>Maximum entropy RL, auto temperature, continuous control</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="difficulty-guide">Difficulty Guide<a class="header-link" href="#difficulty-guide" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Difficulty</th>
<th>Description</th>
<th style="text-align: center;">Expected Study Time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">â­</td>
<td>Beginner - Focus on concepts</td>
<td style="text-align: center;">1-2 hours</td>
</tr>
<tr>
<td style="text-align: center;">â­â­</td>
<td>Basics - Mathematical foundations and basic algorithms</td>
<td style="text-align: center;">2-3 hours</td>
</tr>
<tr>
<td style="text-align: center;">â­â­â­</td>
<td>Intermediate - Core algorithm implementation</td>
<td style="text-align: center;">3-4 hours</td>
</tr>
<tr>
<td style="text-align: center;">â­â­â­â­</td>
<td>Advanced - Latest algorithms and practical applications</td>
<td style="text-align: center;">4-6 hours</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="environment-setup">Environment Setup<a class="header-link" href="#environment-setup" title="Permanent link">&para;</a></h2>
<h3 id="installing-required-packages">Installing Required Packages<a class="header-link" href="#installing-required-packages" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Basic environment</span>
pip<span class="w"> </span>install<span class="w"> </span>gymnasium
pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision
pip<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>matplotlib

<span class="c1"># Additional environments (Atari games, etc.)</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;gymnasium[atari]&quot;</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;gymnasium[accept-rom-license]&quot;</span>

<span class="c1"># Multi-agent RL</span>
pip<span class="w"> </span>install<span class="w"> </span>pettingzoo

<span class="c1"># Visualization and logging</span>
pip<span class="w"> </span>install<span class="w"> </span>tensorboard
pip<span class="w"> </span>install<span class="w"> </span>wandb<span class="w">  </span><span class="c1"># optional</span>
</code></pre></div>

<h3 id="environment-testing">Environment Testing<a class="header-link" href="#environment-testing" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Gymnasium test</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
<span class="n">observation</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># PyTorch test</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="recommended-development-environment">Recommended Development Environment<a class="header-link" href="#recommended-development-environment" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Purpose</th>
<th>Installation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Jupyter Notebook</td>
<td>Experimentation and visualization</td>
<td><code>pip install jupyter</code></td>
</tr>
<tr>
<td>VS Code</td>
<td>Code editing</td>
<td><a href="https://code.visualstudio.com/">Official Website</a></td>
</tr>
<tr>
<td>TensorBoard</td>
<td>Training monitoring</td>
<td><code>pip install tensorboard</code></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="recommended-learning-order">Recommended Learning Order<a class="header-link" href="#recommended-learning-order" title="Permanent link">&para;</a></h2>
<h3 id="stage-1-building-foundations-1-2-weeks">Stage 1: Building Foundations (1-2 weeks)<a class="header-link" href="#stage-1-building-foundations-1-2-weeks" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>01_RL_Introduction.md</strong> - Understanding basic RL concepts</li>
<li><strong>02_MDP_Basics.md</strong> - Learning MDP and Bellman equations</li>
<li><strong>03_Dynamic_Programming.md</strong> - Understanding policy/value iteration</li>
<li><strong>04_Monte_Carlo_Methods.md</strong> - Introduction to sample-based learning</li>
</ol>
<h3 id="stage-2-value-based-methods-2-3-weeks">Stage 2: Value-based Methods (2-3 weeks)<a class="header-link" href="#stage-2-value-based-methods-2-3-weeks" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>05_TD_Learning.md</strong> - Core principles of TD learning</li>
<li><strong>06_Q_Learning_SARSA.md</strong> - Table-based Q-Learning</li>
<li><strong>07_Deep_Q_Network.md</strong> - Combining deep learning with RL</li>
</ol>
<h3 id="stage-3-policy-based-methods-2-3-weeks">Stage 3: Policy-based Methods (2-3 weeks)<a class="header-link" href="#stage-3-policy-based-methods-2-3-weeks" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>08_Policy_Gradient.md</strong> - Direct policy optimization</li>
<li><strong>09_Actor_Critic.md</strong> - Combining value and policy</li>
<li><strong>10_PPO_TRPO.md</strong> - Stable policy learning</li>
</ol>
<h3 id="stage-4-advanced-topics-3-weeks">Stage 4: Advanced Topics (3 weeks)<a class="header-link" href="#stage-4-advanced-topics-3-weeks" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>11_Multi_Agent_RL.md</strong> - Multi-agent environments</li>
<li><strong>12_Practical_RL_Project.md</strong> - Comprehensive project execution</li>
<li><strong>13_Model_Based_RL.md</strong> - Planning with learned models</li>
<li><strong>14_Soft_Actor_Critic.md</strong> - Maximum entropy for continuous control</li>
</ol>
<hr />
<h2 id="algorithm-comparison">Algorithm Comparison<a class="header-link" href="#algorithm-comparison" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Type</th>
<th style="text-align: center;">On/Off Policy</th>
<th style="text-align: center;">Continuous Actions</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q-Learning</td>
<td>Value-based</td>
<td style="text-align: center;">Off</td>
<td style="text-align: center;">X</td>
<td>Simple, table-based</td>
</tr>
<tr>
<td>SARSA</td>
<td>Value-based</td>
<td style="text-align: center;">On</td>
<td style="text-align: center;">X</td>
<td>Safe learning</td>
</tr>
<tr>
<td>DQN</td>
<td>Value-based</td>
<td style="text-align: center;">Off</td>
<td style="text-align: center;">X</td>
<td>Deep learning integration</td>
</tr>
<tr>
<td>REINFORCE</td>
<td>Policy-based</td>
<td style="text-align: center;">On</td>
<td style="text-align: center;">O</td>
<td>Direct policy optimization</td>
</tr>
<tr>
<td>A2C/A3C</td>
<td>Actor-Critic</td>
<td style="text-align: center;">On</td>
<td style="text-align: center;">O</td>
<td>Distributed learning</td>
</tr>
<tr>
<td>PPO</td>
<td>Actor-Critic</td>
<td style="text-align: center;">On</td>
<td style="text-align: center;">O</td>
<td>Stable, versatile</td>
</tr>
<tr>
<td>TRPO</td>
<td>Actor-Critic</td>
<td style="text-align: center;">On</td>
<td style="text-align: center;">O</td>
<td>Theoretical guarantees</td>
</tr>
<tr>
<td>SAC</td>
<td>Actor-Critic</td>
<td style="text-align: center;">Off</td>
<td style="text-align: center;">O</td>
<td>Maximum entropy RL</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="textbooks">Textbooks<a class="header-link" href="#textbooks" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Sutton &amp; Barto</strong>: "Reinforcement Learning: An Introduction" (2nd Edition) - <a href="http://incompleteideas.net/book/the-book-2nd.html">Free PDF</a></li>
<li><strong>Deep RL</strong>: "Spinning Up in Deep RL" by OpenAI - <a href="https://spinningup.openai.com/">Link</a></li>
</ul>
<h3 id="online-courses">Online Courses<a class="header-link" href="#online-courses" title="Permanent link">&para;</a></h3>
<ul>
<li>David Silver's RL Course (DeepMind/UCL)</li>
<li>CS285: Deep Reinforcement Learning (UC Berkeley)</li>
<li>Hugging Face Deep RL Course</li>
</ul>
<h3 id="libraries">Libraries<a class="header-link" href="#libraries" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://gymnasium.farama.org/">Gymnasium</a> - RL environment standard</li>
<li><a href="https://stable-baselines3.readthedocs.io/">Stable-Baselines3</a> - RL algorithm implementations</li>
<li><a href="https://pettingzoo.farama.org/">PettingZoo</a> - Multi-agent environments</li>
<li><a href="https://docs.ray.io/en/latest/rllib/">RLlib</a> - Distributed RL framework</li>
</ul>
<hr />
<h2 id="key-terms">Key Terms<a class="header-link" href="#key-terms" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Term</th>
<th>English</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Agent</td>
<td>Agent</td>
<td>Entity that learns through interaction with environment</td>
</tr>
<tr>
<td>Environment</td>
<td>Environment</td>
<td>World where the agent acts</td>
</tr>
<tr>
<td>State</td>
<td>State</td>
<td>Current situation of the environment</td>
</tr>
<tr>
<td>Action</td>
<td>Action</td>
<td>Decision made by the agent</td>
</tr>
<tr>
<td>Reward</td>
<td>Reward</td>
<td>Immediate feedback for an action</td>
</tr>
<tr>
<td>Policy</td>
<td>Policy</td>
<td>Strategy for selecting actions in states</td>
</tr>
<tr>
<td>Value Function</td>
<td>Value Function</td>
<td>Long-term value of states/actions</td>
</tr>
<tr>
<td>Discount Factor</td>
<td>Discount Factor (Î³)</td>
<td>Present value ratio of future rewards</td>
</tr>
<tr>
<td>Episode</td>
<td>Episode</td>
<td>Interaction from start to termination</td>
</tr>
<tr>
<td>Exploration/Exploitation</td>
<td>Exploration/Exploitation</td>
<td>Trying new vs known good actions</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="related-folders">Related Folders<a class="header-link" href="#related-folders" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Deep_Learning/</strong>: Deep learning basics (neural networks, CNN, RNN)</li>
<li><strong>Machine_Learning/</strong>: Machine learning basics (supervised/unsupervised learning)</li>
<li><strong>Python/</strong>: Advanced Python syntax</li>
<li><strong>Statistics/</strong>: Probability and statistics</li>
</ul>
<hr />
<p><em>Last updated: 2026-02</em></p>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <span class="nav-placeholder"></span>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Reinforcement_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Reinforcement_Learning/01_RL_Introduction.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">01. Introduction to Reinforcement Learning</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}