{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>13. Model-Based Reinforcement Learning - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Reinforcement_Learning/">Reinforcement Learning</a>
    <span class="separator">/</span>
    <span class="current">13. Model-Based Reinforcement Learning</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>13. Model-Based Reinforcement Learning</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Reinforcement_Learning/12_Practical_RL_Project.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">12. Practical RL Project</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Reinforcement_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Reinforcement_Learning/14_Soft_Actor_Critic.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">14. Soft Actor-Critic (SAC)</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#learning-objectives">Learning Objectives</a></li>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#1-model-free-vs-model-based-rl">1. Model-Free vs Model-Based RL</a><ul>
<li><a href="#11-comparison">1.1 Comparison</a></li>
<li><a href="#12-trade-offs">1.2 Trade-offs</a></li>
</ul>
</li>
<li><a href="#2-dyna-architecture">2. Dyna Architecture</a><ul>
<li><a href="#21-dyna-q-algorithm">2.1 Dyna-Q Algorithm</a></li>
<li><a href="#22-dyna-q-implementation">2.2 Dyna-Q Implementation</a></li>
<li><a href="#23-dyna-q-exploration-bonus">2.3 Dyna-Q+ (Exploration Bonus)</a></li>
</ul>
</li>
<li><a href="#3-learning-world-models">3. Learning World Models</a><ul>
<li><a href="#31-neural-network-dynamics-model">3.1 Neural Network Dynamics Model</a></li>
<li><a href="#32-training-the-model">3.2 Training the Model</a></li>
<li><a href="#33-model-error-and-compounding">3.3 Model Error and Compounding</a></li>
</ul>
</li>
<li><a href="#4-model-based-policy-optimization-mbpo">4. Model-Based Policy Optimization (MBPO)</a><ul>
<li><a href="#41-mbpo-algorithm">4.1 MBPO Algorithm</a></li>
<li><a href="#42-simplified-mbpo-implementation">4.2 Simplified MBPO Implementation</a></li>
</ul>
</li>
<li><a href="#5-muzero-planning-without-a-known-model">5. MuZero: Planning without a Known Model</a><ul>
<li><a href="#51-muzero-architecture">5.1 MuZero Architecture</a></li>
<li><a href="#52-muzero-planning-mcts">5.2 MuZero Planning (MCTS)</a></li>
</ul>
</li>
<li><a href="#6-dreamer-world-models-for-continuous-control">6. Dreamer: World Models for Continuous Control</a><ul>
<li><a href="#61-dreamer-architecture">6.1 Dreamer Architecture</a></li>
<li><a href="#62-imagination-based-policy-learning">6.2 Imagination-Based Policy Learning</a></li>
</ul>
</li>
<li><a href="#7-practice-problems">7. Practice Problems</a><ul>
<li><a href="#exercise-1-dyna-q-on-gridworld">Exercise 1: Dyna-Q on GridWorld</a></li>
<li><a href="#exercise-2-neural-dynamics-model">Exercise 2: Neural Dynamics Model</a></li>
<li><a href="#exercise-3-compare-sample-efficiency">Exercise 3: Compare Sample Efficiency</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="13-model-based-reinforcement-learning">13. Model-Based Reinforcement Learning<a class="header-link" href="#13-model-based-reinforcement-learning" title="Permanent link">&para;</a></h1>
<p><strong>Difficulty: â­â­â­â­ (Advanced)</strong></p>
<h2 id="learning-objectives">Learning Objectives<a class="header-link" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<ul>
<li>Understand the distinction between model-free and model-based RL</li>
<li>Implement the Dyna architecture for planning with learned models</li>
<li>Learn world model approaches (Dreamer, MuZero)</li>
<li>Apply Model-Based Policy Optimization (MBPO)</li>
<li>Understand when model-based methods outperform model-free ones</li>
</ul>
<hr />
<h2 id="table-of-contents">Table of Contents<a class="header-link" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="#1-model-free-vs-model-based-rl">Model-Free vs Model-Based RL</a></li>
<li><a href="#2-dyna-architecture">Dyna Architecture</a></li>
<li><a href="#3-learning-world-models">Learning World Models</a></li>
<li><a href="#4-model-based-policy-optimization-mbpo">Model-Based Policy Optimization (MBPO)</a></li>
<li><a href="#5-muzero-planning-without-a-known-model">MuZero: Planning without a Known Model</a></li>
<li><a href="#6-dreamer-world-models-for-continuous-control">Dreamer: World Models for Continuous Control</a></li>
<li><a href="#7-practice-problems">Practice Problems</a></li>
</ol>
<hr />
<h2 id="1-model-free-vs-model-based-rl">1. Model-Free vs Model-Based RL<a class="header-link" href="#1-model-free-vs-model-based-rl" title="Permanent link">&para;</a></h2>
<h3 id="11-comparison">1.1 Comparison<a class="header-link" href="#11-comparison" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">              </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Free</span><span class="w"> </span><span class="nx">vs</span><span class="w"> </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Based</span><span class="w"> </span><span class="nx">RL</span><span class="w">                        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Free</span><span class="p">:</span><span class="w">                                                    </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Agent</span><span class="w"> </span><span class="err">â”€â”€</span><span class="p">(</span><span class="nx">action</span><span class="p">)</span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">Environment</span><span class="w"> </span><span class="err">â”€â”€</span><span class="p">(</span><span class="nx">s</span><span class="err">&#39;</span><span class="p">,</span><span class="nx">r</span><span class="p">)</span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">Agent</span><span class="w">           </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">                                                </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Learn</span><span class="w"> </span><span class="nx">value</span><span class="o">/</span><span class="nx">policy</span><span class="w"> </span><span class="nx">directly</span><span class="w"> </span><span class="nx">from</span><span class="w"> </span><span class="nx">experience</span><span class="w">  </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">No</span><span class="w"> </span><span class="nx">explicit</span><span class="w"> </span><span class="nx">model</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">dynamics</span><span class="w">                </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Examples</span><span class="p">:</span><span class="w"> </span><span class="nx">DQN</span><span class="p">,</span><span class="w"> </span><span class="nx">PPO</span><span class="p">,</span><span class="w"> </span><span class="nx">SAC</span><span class="w">                      </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Simple</span><span class="w"> </span><span class="nx">but</span><span class="w"> </span><span class="nx">sample</span><span class="o">-</span><span class="nx">inefficient</span><span class="w">                </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Based</span><span class="p">:</span><span class="w">                                                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Agent</span><span class="w"> </span><span class="err">â”€â”€</span><span class="p">(</span><span class="nx">action</span><span class="p">)</span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">Environment</span><span class="w"> </span><span class="err">â”€â”€</span><span class="p">(</span><span class="nx">s</span><span class="err">&#39;</span><span class="p">,</span><span class="nx">r</span><span class="p">)</span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">Agent</span><span class="w">           </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">   </span><span class="err">â”‚</span><span class="w">                                      </span><span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">   </span><span class="err">â”‚</span><span class="w">         </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">         </span><span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">   </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚</span><span class="w">  </span><span class="nx">Learned</span><span class="w"> </span><span class="nx">Model</span><span class="w">   </span><span class="err">â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">     </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span><span class="w">  </span><span class="nx">Å</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="err">Ì‚</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">f</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="nx">a</span><span class="p">)</span><span class="w"> </span><span class="err">â”‚</span><span class="w">               </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">               </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">                      </span><span class="err">â”‚</span><span class="w">                         </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">                 </span><span class="nx">Planning</span><span class="w">                        </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">            </span><span class="p">(</span><span class="nx">simulated</span><span class="w"> </span><span class="nx">rollouts</span><span class="p">)</span><span class="w">                 </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">                                                </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Learn</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">model</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">environment</span><span class="w"> </span><span class="nx">dynamics</span><span class="w">         </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Plan</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">learned</span><span class="w"> </span><span class="nx">model</span><span class="w">                  </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Examples</span><span class="p">:</span><span class="w"> </span><span class="nx">Dyna</span><span class="p">,</span><span class="w"> </span><span class="nx">MBPO</span><span class="p">,</span><span class="w"> </span><span class="nx">MuZero</span><span class="p">,</span><span class="w"> </span><span class="nx">Dreamer</span><span class="w">        </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Sample</span><span class="o">-</span><span class="nx">efficient</span><span class="w"> </span><span class="nx">but</span><span class="w"> </span><span class="nx">model</span><span class="w"> </span><span class="nx">errors</span><span class="w"> </span><span class="nx">accumulate</span><span class="w">  </span><span class="err">â”‚</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<h3 id="12-trade-offs">1.2 Trade-offs<a class="header-link" href="#12-trade-offs" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">                      </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Free</span><span class="w">       </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Based</span><span class="w">           </span><span class="err">â”‚</span>
<span class="err">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Sample</span><span class="w"> </span><span class="nx">efficiency</span><span class="w">    </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Low</span><span class="w">              </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">High</span><span class="w"> </span><span class="p">(</span><span class="mi">10</span><span class="o">-</span><span class="mi">100</span><span class="nx">x</span><span class="w"> </span><span class="nx">fewer</span><span class="p">)</span><span class="w">  </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Asymptotic</span><span class="w"> </span><span class="nx">perf</span><span class="p">.</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">High</span><span class="w">             </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Limited</span><span class="w"> </span><span class="nx">by</span><span class="w"> </span><span class="nx">model</span><span class="w"> </span><span class="nx">err</span><span class="w">  </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Computation</span><span class="w">          </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Low</span><span class="w"> </span><span class="nx">per</span><span class="w"> </span><span class="nx">step</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">High</span><span class="w"> </span><span class="p">(</span><span class="nx">planning</span><span class="p">)</span><span class="w">       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Implementation</span><span class="w">       </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Simpler</span><span class="w">          </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">More</span><span class="w"> </span><span class="nx">complex</span><span class="w">          </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Robustness</span><span class="w">           </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">More</span><span class="w"> </span><span class="nx">robust</span><span class="w">      </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Sensitive</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">model</span><span class="w">    </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w"> </span><span class="nx">Best</span><span class="w"> </span><span class="k">for</span><span class="w">             </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Simulation</span><span class="o">-</span><span class="nx">heavy</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Real</span><span class="o">-</span><span class="nx">world</span><span class="p">,</span><span class="w"> </span><span class="nx">expensive</span><span class="w"> </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                      </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">environments</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">interactions</span><span class="w">          </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<hr />
<h2 id="2-dyna-architecture">2. Dyna Architecture<a class="header-link" href="#2-dyna-architecture" title="Permanent link">&para;</a></h2>
<h3 id="21-dyna-q-algorithm">2.1 Dyna-Q Algorithm<a class="header-link" href="#21-dyna-q-algorithm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">              </span><span class="nx">Dyna</span><span class="o">-</span><span class="nx">Q</span><span class="w"> </span><span class="nx">Architecture</span><span class="w">                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">          </span><span class="nx">Real</span><span class="w"> </span><span class="nx">Experience</span><span class="w">                    </span><span class="err">â”‚</span><span class="w">                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w">  </span><span class="nx">s</span><span class="w"> </span><span class="err">â”€â”€</span><span class="p">(</span><span class="nx">a</span><span class="p">)</span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">Environment</span><span class="w"> </span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="nx">s</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="w">          </span><span class="err">â”‚</span><span class="w">                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                    </span><span class="err">â”‚</span><span class="w">                                            </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">           </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">           </span><span class="err">â–¼</span><span class="w">        </span><span class="err">â–¼</span><span class="w">        </span><span class="err">â–¼</span><span class="w">                                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w"> </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”</span><span class="w"> </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Direct</span><span class="w">   </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="nx">Model</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Planning</span><span class="w"> </span><span class="err">â”‚</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">RL</span><span class="w">       </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="nx">Learn</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="p">(</span><span class="nx">n</span><span class="w"> </span><span class="nx">steps</span><span class="p">)</span><span class="err">â”‚</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Q</span><span class="o">-</span><span class="nx">update</span><span class="w"> </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="w">      </span><span class="err">â”‚</span><span class="w"> </span><span class="err">â”‚</span><span class="w">          </span><span class="err">â”‚</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w"> </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”˜</span><span class="w"> </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">           </span><span class="err">â”‚</span><span class="w">                     </span><span class="err">â”‚</span><span class="w">                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">           </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                      </span><span class="err">â–¼</span><span class="w">                                          </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">               </span><span class="nx">Q</span><span class="o">-</span><span class="nx">value</span><span class="w"> </span><span class="nx">Table</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">Network</span><span class="w">                           </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Loop</span><span class="p">:</span><span class="w">                                                          </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="nx">Act</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">real</span><span class="w"> </span><span class="nx">environment</span><span class="p">,</span><span class="w"> </span><span class="k">observe</span><span class="w"> </span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="p">,</span><span class="w"> </span><span class="nx">s</span><span class="err">&#39;</span><span class="p">)</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="nx">Direct</span><span class="w"> </span><span class="nx">RL</span><span class="p">:</span><span class="w"> </span><span class="nx">Update</span><span class="w"> </span><span class="nx">Q</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="nx">a</span><span class="p">)</span><span class="w">                                    </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mi">3</span><span class="p">.</span><span class="w"> </span><span class="nx">Model</span><span class="w"> </span><span class="nx">learning</span><span class="p">:</span><span class="w"> </span><span class="nx">Update</span><span class="w"> </span><span class="nx">model</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="nx">a</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="p">(</span><span class="nx">r</span><span class="err">Ì‚</span><span class="p">,</span><span class="w"> </span><span class="nx">Å</span><span class="err">&#39;</span><span class="p">)</span><span class="w">               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mi">4</span><span class="p">.</span><span class="w"> </span><span class="nx">Planning</span><span class="p">:</span><span class="w"> </span><span class="nx">Repeat</span><span class="w"> </span><span class="nx">n</span><span class="w"> </span><span class="nx">times</span><span class="p">:</span><span class="w">                                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="o">-</span><span class="w"> </span><span class="nx">Sample</span><span class="w"> </span><span class="nx">random</span><span class="w"> </span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="p">)</span><span class="w"> </span><span class="nx">from</span><span class="w"> </span><span class="nx">experience</span><span class="w">                      </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="o">-</span><span class="w"> </span><span class="nx">Simulate</span><span class="p">:</span><span class="w"> </span><span class="nx">r</span><span class="err">Ì‚</span><span class="p">,</span><span class="w"> </span><span class="nx">Å</span><span class="err">&#39;</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">model</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="p">)</span><span class="w">                            </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="o">-</span><span class="w"> </span><span class="nx">Update</span><span class="w"> </span><span class="nx">Q</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span><span class="w"> </span><span class="nx">a</span><span class="p">)</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">simulated</span><span class="w"> </span><span class="nx">experience</span><span class="w">                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<h3 id="22-dyna-q-implementation">2.2 Dyna-Q Implementation<a class="header-link" href="#22-dyna-q-implementation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DynaQ</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
                 <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_planning</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># (s, a) â†’ (r, s&#39;)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_planning</span> <span class="o">=</span> <span class="n">n_planning</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">visited</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># track visited (s, a) pairs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">state</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s_next</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="c1"># Step 1: Direct RL update</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">r</span> <span class="k">if</span> <span class="n">done</span> <span class="k">else</span> <span class="n">r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s_next</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>

        <span class="c1"># Step 2: Model learning</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s_next</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">))</span>

        <span class="c1"># Step 3: Planning (n simulated updates)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_planning</span><span class="p">):</span>
            <span class="c1"># Sample random previously visited (s, a)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">))</span>
            <span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">sim_r</span><span class="p">,</span> <span class="n">sim_s_next</span><span class="p">,</span> <span class="n">sim_done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[(</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">)]</span>

            <span class="c1"># Q-learning update with simulated experience</span>
            <span class="n">sim_target</span> <span class="o">=</span> <span class="n">sim_r</span> <span class="k">if</span> <span class="n">sim_done</span> <span class="k">else</span> <span class="n">sim_r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s_next</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">sim_target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">])</span>
</code></pre></div>

<h3 id="23-dyna-q-exploration-bonus">2.3 Dyna-Q+ (Exploration Bonus)<a class="header-link" href="#23-dyna-q-exploration-bonus" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DynaQPlus</span><span class="p">(</span><span class="n">DynaQ</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dyna-Q+ adds exploration bonus for states not visited recently.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span> <span class="o">=</span> <span class="n">kappa</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_visit</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># (s, a) â†’ last time step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_step</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">s_next</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_visit</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_step</span>

        <span class="c1"># Direct RL update (same as Dyna-Q)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">r</span> <span class="k">if</span> <span class="n">done</span> <span class="k">else</span> <span class="n">r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s_next</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>

        <span class="c1"># Model learning</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s_next</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">))</span>

        <span class="c1"># Planning with exploration bonus</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_planning</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">))</span>
            <span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">sim_r</span><span class="p">,</span> <span class="n">sim_s_next</span><span class="p">,</span> <span class="n">sim_done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[(</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">)]</span>

            <span class="c1"># Add bonus for unvisited time</span>
            <span class="n">tau</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_visit</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">bonus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kappa</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>

            <span class="n">sim_target</span> <span class="o">=</span> <span class="p">(</span><span class="n">sim_r</span> <span class="o">+</span> <span class="n">bonus</span><span class="p">)</span> <span class="k">if</span> <span class="n">sim_done</span> <span class="k">else</span> \
                         <span class="p">(</span><span class="n">sim_r</span> <span class="o">+</span> <span class="n">bonus</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s_next</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">sim_target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[</span><span class="n">sim_s</span><span class="p">,</span> <span class="n">sim_a</span><span class="p">])</span>
</code></pre></div>

<hr />
<h2 id="3-learning-world-models">3. Learning World Models<a class="header-link" href="#3-learning-world-models" title="Permanent link">&para;</a></h2>
<h3 id="31-neural-network-dynamics-model">3.1 Neural Network Dynamics Model<a class="header-link" href="#31-neural-network-dynamics-model" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predicts next state and reward given current state and action.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">state_dim</span> <span class="o">+</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>  <span class="c1"># predict residual</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">EnsembleDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ensemble of dynamics models for uncertainty estimation.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">n_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">DynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>
        <span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">]</span>
        <span class="n">next_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>

        <span class="c1"># Mean prediction</span>
        <span class="n">mean_next_state</span> <span class="o">=</span> <span class="n">next_states</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mean_reward</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Uncertainty (disagreement between models)</span>
        <span class="n">uncertainty</span> <span class="o">=</span> <span class="n">next_states</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_next_state</span><span class="p">,</span> <span class="n">mean_reward</span><span class="p">,</span> <span class="n">uncertainty</span>
</code></pre></div>

<h3 id="32-training-the-model">3.2 Training the Model<a class="header-link" href="#32-training-the-model" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ModelTrainer</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ensemble</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span> <span class="o">=</span> <span class="n">ensemble</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">models</span>
        <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">replay_buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># Each model trained on different bootstrap sample</span>
                <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> \
                    <span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

                <span class="n">pred_next_states</span><span class="p">,</span> <span class="n">pred_rewards</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>

                <span class="n">state_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">pred_next_states</span><span class="p">,</span> <span class="n">next_states</span><span class="p">)</span>
                <span class="n">reward_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">pred_rewards</span><span class="p">,</span> <span class="n">rewards</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">state_loss</span> <span class="o">+</span> <span class="n">reward_loss</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>

<h3 id="33-model-error-and-compounding">3.3 Model Error and Compounding<a class="header-link" href="#33-model-error-and-compounding" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Model Error Compounding                             â”‚
â”‚                                                                 â”‚
â”‚  Real trajectory:     sâ‚€ â†’ sâ‚ â†’ sâ‚‚ â†’ sâ‚ƒ â†’ ...                â”‚
â”‚                                                                 â”‚
â”‚  Model rollout:       sâ‚€ â†’ Åâ‚ â†’ Åâ‚‚ â†’ Åâ‚ƒ â†’ ...               â”‚
â”‚                            â†‘     â†‘     â†‘                       â”‚
â”‚                          small  medium  LARGE error             â”‚
â”‚                                                                 â”‚
â”‚  Error grows exponentially with rollout length!                 â”‚
â”‚                                                                 â”‚
â”‚  Mitigation strategies:                                         â”‚
â”‚  1. Short rollouts (H = 1-5 steps)                              â”‚
â”‚  2. Ensemble disagreement as uncertainty                        â”‚
â”‚  3. Truncate when uncertainty is high                           â”‚
â”‚  4. Mix real and simulated data                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<hr />
<h2 id="4-model-based-policy-optimization-mbpo">4. Model-Based Policy Optimization (MBPO)<a class="header-link" href="#4-model-based-policy-optimization-mbpo" title="Permanent link">&para;</a></h2>
<h3 id="41-mbpo-algorithm">4.1 MBPO Algorithm<a class="header-link" href="#41-mbpo-algorithm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MBPO: Model-Based Policy Optimization               â”‚
â”‚                                                                 â”‚
â”‚  Key idea: Use learned model for SHORT rollouts only            â”‚
â”‚            (branched from real states)                           â”‚
â”‚                                                                 â”‚
â”‚  Algorithm:                                                     â”‚
â”‚  1. Collect real data D_env from environment                    â”‚
â”‚  2. Train ensemble dynamics model on D_env                      â”‚
â”‚  3. For each real state s in D_env:                             â”‚
â”‚     - Generate k-step model rollout (k = 1~5)                  â”‚
â”‚     - Add simulated transitions to D_model                      â”‚
â”‚  4. Train SAC policy on D_env âˆª D_model                        â”‚
â”‚  5. Repeat                                                      â”‚
â”‚                                                                 â”‚
â”‚  Benefits:                                                      â”‚
â”‚  â€¢ 10-100x more sample efficient than SAC alone                 â”‚
â”‚  â€¢ Model only used for short rollouts â†’ less error              â”‚
â”‚  â€¢ Guaranteed monotonic improvement (under assumptions)         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="42-simplified-mbpo-implementation">4.2 Simplified MBPO Implementation<a class="header-link" href="#42-simplified-mbpo-implementation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MBPO</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span>
                 <span class="n">model_rollout_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rollouts_per_step</span><span class="o">=</span><span class="mi">400</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span> <span class="o">=</span> <span class="n">EnsembleDynamicsModel</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_trainer</span> <span class="o">=</span> <span class="n">ModelTrainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">)</span>

        <span class="c1"># SAC as the model-free backbone</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">capacity</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">capacity</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_length</span> <span class="o">=</span> <span class="n">model_rollout_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rollouts_per_step</span> <span class="o">=</span> <span class="n">rollouts_per_step</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_steps</span><span class="o">=</span><span class="mi">100_000</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
            <span class="c1"># 1. Real environment interaction</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">done</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># 2. Train dynamics model periodically</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">250</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

            <span class="c1"># 3. Generate model rollouts</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_generate_model_rollouts</span><span class="p">()</span>

            <span class="c1"># 4. Train policy on mixed data</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="c1"># Sample from both buffers</span>
                <span class="n">real_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
                <span class="n">model_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_buffer</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">128</span> <span class="k">else</span> <span class="n">real_batch</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">real_batch</span><span class="p">,</span> <span class="n">model_batch</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_model_rollouts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Branch short rollouts from real states.&quot;&quot;&quot;</span>
        <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_buffer</span><span class="o">.</span><span class="n">sample_states</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollouts_per_step</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_length</span><span class="p">):</span>
                <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                <span class="n">s_next</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble</span><span class="p">(</span>
                    <span class="n">s</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="p">)</span>

                <span class="c1"># Stop rollout if model is uncertain</span>
                <span class="k">if</span> <span class="n">uncertainty</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                    <span class="k">break</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                    <span class="n">s</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">r</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                    <span class="n">s_next</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="kc">False</span>
                <span class="p">)</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s_next</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="5-muzero-planning-without-a-known-model">5. MuZero: Planning without a Known Model<a class="header-link" href="#5-muzero-planning-without-a-known-model" title="Permanent link">&para;</a></h2>
<h3 id="51-muzero-architecture">5.1 MuZero Architecture<a class="header-link" href="#51-muzero-architecture" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">              </span><span class="nl">MuZero</span><span class="p">:</span><span class="w"> </span><span class="n">Three</span><span class="w"> </span><span class="n">Learned</span><span class="w"> </span><span class="n">Functions</span><span class="w">                     </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mf">1.</span><span class="w"> </span><span class="nl">Representation</span><span class="p">:</span><span class="w"> </span><span class="n">h</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">hidden</span><span class="w"> </span><span class="k">state</span><span class="w">               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="n">obs</span><span class="w"> </span><span class="p">(</span><span class="n">o_t</span><span class="p">)</span><span class="w"> </span><span class="err">â”‚â”€â”€â–¶</span><span class="w"> </span><span class="n">h_Î¸</span><span class="w"> </span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="n">s_0</span><span class="w"> </span><span class="p">(</span><span class="n">hidden</span><span class="w"> </span><span class="k">state</span><span class="p">)</span><span class="w">               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mf">2.</span><span class="w"> </span><span class="nl">Dynamics</span><span class="p">:</span><span class="w"> </span><span class="n">g</span><span class="p">(</span><span class="n">s_k</span><span class="p">,</span><span class="w"> </span><span class="n">a_k</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">s_</span><span class="err">{</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="n">r_k</span><span class="w">                      </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                                        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w"> </span><span class="n">s_k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="k">action</span><span class="w"> </span><span class="n">a_k</span><span class="w"> </span><span class="err">â”‚â”€â”€â–¶</span><span class="w"> </span><span class="n">g_Î¸</span><span class="w"> </span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="n">s_</span><span class="err">{</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="n">r</span><span class="err">Ì‚</span><span class="n">_k</span><span class="w">             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                                        </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="mf">3.</span><span class="w"> </span><span class="nl">Prediction</span><span class="p">:</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">s_k</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">policy</span><span class="p">,</span><span class="w"> </span><span class="k">value</span><span class="w">                          </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><span class="w">                                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="w">   </span><span class="n">s_k</span><span class="w">     </span><span class="err">â”‚â”€â”€â–¶</span><span class="w"> </span><span class="n">f_Î¸</span><span class="w"> </span><span class="err">â”€â”€â–¶</span><span class="w"> </span><span class="n">Ï€_k</span><span class="p">,</span><span class="w"> </span><span class="n">v_k</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">     </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">                                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="k">Key</span><span class="w"> </span><span class="nl">insight</span><span class="p">:</span><span class="w"> </span><span class="n">Model</span><span class="w"> </span><span class="n">operates</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">LEARNED</span><span class="w"> </span><span class="n">hidden</span><span class="w"> </span><span class="k">state</span><span class="w"> </span><span class="nf">space</span><span class="p">,</span><span class="w">     </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="ow">not</span><span class="w"> </span><span class="n">observation</span><span class="w"> </span><span class="nf">space</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="k">no</span><span class="w"> </span><span class="n">need</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">predict</span><span class="w"> </span><span class="n">pixels</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nl">Planning</span><span class="p">:</span><span class="w"> </span><span class="n">MCTS</span><span class="w"> </span><span class="p">(</span><span class="n">Monte</span><span class="w"> </span><span class="n">Carlo</span><span class="w"> </span><span class="n">Tree</span><span class="w"> </span><span class="k">Search</span><span class="p">)</span><span class="w"> </span><span class="k">using</span><span class="w"> </span><span class="n">learned</span><span class="w"> </span><span class="n">model</span><span class="w">   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nl">Results</span><span class="p">:</span><span class="w">                                                       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nl">Atari</span><span class="p">:</span><span class="w"> </span><span class="n">superhuman</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="mi">57</span><span class="w"> </span><span class="n">games</span><span class="w">                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="k">Go</span><span class="o">/</span><span class="n">Chess</span><span class="o">/</span><span class="nl">Shogi</span><span class="p">:</span><span class="w"> </span><span class="n">matches</span><span class="w"> </span><span class="n">AlphaZero</span><span class="w"> </span><span class="k">without</span><span class="w"> </span><span class="n">rules</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<h3 id="52-muzero-planning-mcts">5.2 MuZero Planning (MCTS)<a class="header-link" href="#52-muzero-planning-mcts" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="w">              </span><span class="nv">MCTS</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">MuZero</span><span class="w">                                      </span>â”‚
â”‚<span class="w">                                                                 </span>â”‚
â”‚<span class="w">  </span><span class="k">For</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">action</span><span class="w"> </span><span class="nv">decision</span>:<span class="w">                                      </span>â”‚
â”‚<span class="w">  </span><span class="mi">1</span>.<span class="w"> </span><span class="nv">Run</span><span class="w"> </span><span class="nv">N</span><span class="w"> </span><span class="nv">simulations</span><span class="w"> </span><span class="nv">through</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">learned</span><span class="w"> </span><span class="nv">model</span><span class="w">                 </span>â”‚
â”‚<span class="w">  </span><span class="mi">2</span>.<span class="w"> </span><span class="nv">Each</span><span class="w"> </span><span class="nv">simulation</span>:<span class="w">                                            </span>â”‚
â”‚<span class="w">     </span><span class="nv">a</span>.<span class="w"> </span><span class="nv">SELECT</span>:<span class="w"> </span><span class="nv">traverse</span><span class="w"> </span><span class="nv">tree</span><span class="w"> </span><span class="nv">using</span><span class="w"> </span><span class="nv">UCB</span><span class="w">                          </span>â”‚
â”‚<span class="w">     </span><span class="nv">b</span>.<span class="w"> </span><span class="nv">EXPAND</span>:<span class="w"> </span><span class="nv">use</span><span class="w"> </span><span class="nv">dynamics</span><span class="w"> </span><span class="nv">model</span><span class="w"> </span><span class="nv">g</span><span class="ss">(</span><span class="nv">s</span>,<span class="nv">a</span><span class="ss">)</span><span class="w"> </span>â†’<span class="w"> </span><span class="nv">s</span><span class="err">&#39;, rÌ‚              â”‚</span>
â”‚<span class="w">     </span><span class="nv">c</span>.<span class="w"> </span><span class="nv">EVALUATE</span>:<span class="w"> </span><span class="nv">use</span><span class="w"> </span><span class="nv">prediction</span><span class="w"> </span><span class="nv">model</span><span class="w"> </span><span class="nv">f</span><span class="ss">(</span><span class="nv">s</span><span class="err">&#39;) â†’ Ï€, v             â”‚</span>
<span class="err">â”‚     d. BACKUP: update visit counts and values                   â”‚</span>
<span class="err">â”‚                                                                 â”‚</span>
<span class="err">â”‚  Tree after 50 simulations:                                     â”‚</span>
<span class="err">â”‚                                                                 â”‚</span>
<span class="err">â”‚             sâ‚€ (root = current state)                           â”‚</span>
<span class="err">â”‚            / | \                                                â”‚</span>
<span class="err">â”‚          aâ‚€  aâ‚  aâ‚‚                                            â”‚</span>
<span class="err">â”‚         /    |     \                                            â”‚</span>
<span class="err">â”‚       sâ‚    sâ‚‚    sâ‚ƒ        N(aâ‚€)=20, N(aâ‚)=25, N(aâ‚‚)=5     â”‚</span>
<span class="err">â”‚      / \    / \    |                                            â”‚</span>
<span class="err">â”‚    aâ‚€  aâ‚ aâ‚€  aâ‚‚  aâ‚       Q(aâ‚) highest â†’ select aâ‚        â”‚</span>
<span class="err">â”‚    ...                                                          â”‚</span>
<span class="err">â”‚                                                                 â”‚</span>
<span class="err">â”‚  Final action: proportional to visit count N(a) at root         â”‚</span>
<span class="err">â”‚                                                                 â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<hr />
<h2 id="6-dreamer-world-models-for-continuous-control">6. Dreamer: World Models for Continuous Control<a class="header-link" href="#6-dreamer-world-models-for-continuous-control" title="Permanent link">&para;</a></h2>
<h3 id="61-dreamer-architecture">6.1 Dreamer Architecture<a class="header-link" href="#61-dreamer-architecture" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DreamerV3 Architecture                               â”‚
â”‚                                                                 â”‚
â”‚  World Model (RSSM â€” Recurrent State-Space Model):              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Deterministic path:                              â”‚           â”‚
â”‚  â”‚  h_t = f_Î¸(h_{t-1}, z_{t-1}, a_{t-1})           â”‚           â”‚
â”‚  â”‚                                                   â”‚           â”‚
â”‚  â”‚  Stochastic path:                                 â”‚           â”‚
â”‚  â”‚  Prior:     áº‘_t ~ p_Î¸(áº‘_t | h_t)                â”‚           â”‚
â”‚  â”‚  Posterior: z_t ~ q_Î¸(z_t | h_t, o_t)            â”‚           â”‚
â”‚  â”‚                                                   â”‚           â”‚
â”‚  â”‚  Decoder:   Ã´_t = dec_Î¸(h_t, z_t)                â”‚           â”‚
â”‚  â”‚  Reward:    rÌ‚_t = rew_Î¸(h_t, z_t)                â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                 â”‚
â”‚  Actor-Critic (trained entirely in imagination):                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Imagine trajectories using world model only      â”‚           â”‚
â”‚  â”‚  Actor:  a_t ~ Ï€_Î¸(a_t | h_t, z_t)              â”‚           â”‚
â”‚  â”‚  Critic: v_Î¸(h_t, z_t)                           â”‚           â”‚
â”‚  â”‚  No real environment interaction during policy    â”‚           â”‚
â”‚  â”‚  training!                                        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                 â”‚
â”‚  Results:                                                       â”‚
â”‚  â€¢ First single algorithm to master 150+ diverse tasks          â”‚
â”‚  â€¢ Atari, DMControl, Minecraft diamond without task-specific    â”‚
â”‚    tuning                                                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="62-imagination-based-policy-learning">6.2 Imagination-Based Policy Learning<a class="header-link" href="#62-imagination-based-policy-learning" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Dreamer Training Loop                               â”‚
â”‚                                                                 â”‚
â”‚  Outer loop (real environment):                                 â”‚
â”‚  1. Collect experience with current policy â†’ replay buffer      â”‚
â”‚  2. Train world model on replay buffer                          â”‚
â”‚                                                                 â”‚
â”‚  Inner loop (imagination):                                      â”‚
â”‚  3. Sample starting states from replay buffer                   â”‚
â”‚  4. &quot;Dream&quot; H-step trajectories using world model:              â”‚
â”‚     sâ‚€ â†’ sâ‚ â†’ sâ‚‚ â†’ ... â†’ s_H  (all in latent space)          â”‚
â”‚  5. Compute imagined rewards and values                         â”‚
â”‚  6. Update actor and critic on imagined trajectories            â”‚
â”‚                                                                 â”‚
â”‚  Key advantage: Can train policy on 10000s of imagined          â”‚
â”‚  trajectories per real environment step                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<hr />
<h2 id="7-practice-problems">7. Practice Problems<a class="header-link" href="#7-practice-problems" title="Permanent link">&para;</a></h2>
<h3 id="exercise-1-dyna-q-on-gridworld">Exercise 1: Dyna-Q on GridWorld<a class="header-link" href="#exercise-1-dyna-q-on-gridworld" title="Permanent link">&para;</a></h3>
<p>Implement Dyna-Q and compare performance with different planning steps (n=0, 5, 50).</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Starter code</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Simple GridWorld (or use FrozenLake)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;FrozenLake-v1&quot;</span><span class="p">,</span> <span class="n">is_slippery</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">n_planning</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">]:</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">DynaQ</span><span class="p">(</span>
        <span class="n">n_states</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
        <span class="n">n_actions</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
        <span class="n">n_planning</span><span class="o">=</span><span class="n">n_planning</span>
    <span class="p">)</span>

    <span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="n">episode_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="n">n_planning</span><span class="p">]</span> <span class="o">=</span> <span class="n">episode_rewards</span>

<span class="c1"># Plot: more planning steps â†’ faster learning</span>
<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">rewards</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="c1"># Smooth with moving average</span>
    <span class="n">smoothed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span><span class="o">/</span><span class="mi">20</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">smoothed</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;n_planning=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Episode&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Reward (smoothed)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Dyna-Q: Effect of Planning Steps&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<h3 id="exercise-2-neural-dynamics-model">Exercise 2: Neural Dynamics Model<a class="header-link" href="#exercise-2-neural-dynamics-model" title="Permanent link">&para;</a></h3>
<p>Train a neural network dynamics model on CartPole and evaluate prediction accuracy.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Collect data from random policy</span>
<span class="c1"># Train DynamicsModel to predict next state</span>
<span class="c1"># Evaluate: 1-step prediction error vs multi-step rollout error</span>
<span class="c1"># Show that error grows with rollout length</span>

<span class="c1"># Key metrics to plot:</span>
<span class="c1"># - 1-step prediction MSE</span>
<span class="c1"># - k-step rollout MSE for k = 1, 5, 10, 20</span>
<span class="c1"># - Ensemble disagreement correlation with actual error</span>
</code></pre></div>

<h3 id="exercise-3-compare-sample-efficiency">Exercise 3: Compare Sample Efficiency<a class="header-link" href="#exercise-3-compare-sample-efficiency" title="Permanent link">&para;</a></h3>
<p>Compare model-free SAC vs MBPO on a continuous control task.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Use HalfCheetah-v4 or Pendulum-v1</span>
<span class="c1"># Plot: reward vs environment steps</span>
<span class="c1"># Expected: MBPO reaches good performance in ~10x fewer steps</span>
<span class="c1"># But: MBPO has higher wall-clock time per step (model training + planning)</span>
</code></pre></div>

<hr />
<h2 id="summary">Summary<a class="header-link" href="#summary" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">              </span><span class="nx">Model</span><span class="o">-</span><span class="nx">Based</span><span class="w"> </span><span class="nx">RL</span><span class="w"> </span><span class="nx">Landscape</span><span class="w">                            </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Simple</span><span class="w">                                                 </span><span class="nx">Complex</span><span class="w"> </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’</span><span class="w">   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Dyna</span><span class="o">-</span><span class="nx">Q</span><span class="w">       </span><span class="nx">MBPO</span><span class="w">          </span><span class="nx">MuZero</span><span class="w">         </span><span class="nx">DreamerV3</span><span class="w">            </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="p">(</span><span class="nx">tabular</span><span class="p">)</span><span class="w">    </span><span class="p">(</span><span class="nx">ensemble</span><span class="w"> </span><span class="o">+</span><span class="w">   </span><span class="p">(</span><span class="nx">MCTS</span><span class="w"> </span><span class="o">+</span><span class="w">        </span><span class="p">(</span><span class="nx">RSSM</span><span class="w"> </span><span class="o">+</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">               </span><span class="nx">short</span><span class="w">         </span><span class="nx">learned</span><span class="w">        </span><span class="nx">imagination</span><span class="p">)</span><span class="w">         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">               </span><span class="nx">rollouts</span><span class="p">)</span><span class="w">     </span><span class="nx">hidden</span><span class="w"> </span><span class="nx">space</span><span class="p">)</span><span class="w">                       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”</span><span class="w">    </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”</span><span class="w">     </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”</span><span class="w">       </span><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="nx">Sample</span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span><span class="nx">Sample</span><span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="nx">Sample</span><span class="err">â”‚</span><span class="w">       </span><span class="err">â”‚</span><span class="nx">Sample</span><span class="err">â”‚</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="nx">eff</span><span class="p">:</span><span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span><span class="nx">eff</span><span class="p">:</span><span class="w">  </span><span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="nx">eff</span><span class="p">:</span><span class="w">  </span><span class="err">â”‚</span><span class="w">       </span><span class="err">â”‚</span><span class="nx">eff</span><span class="p">:</span><span class="w">  </span><span class="err">â”‚</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">Med</span><span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span><span class="w"> </span><span class="nx">High</span><span class="w"> </span><span class="err">â”‚</span><span class="w">     </span><span class="err">â”‚</span><span class="nx">V</span><span class="p">.</span><span class="nx">High</span><span class="err">â”‚</span><span class="w">       </span><span class="err">â”‚</span><span class="nx">V</span><span class="p">.</span><span class="nx">High</span><span class="err">â”‚</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">    </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">     </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">       </span><span class="err">â””â”€â”€â”€â”€â”€â”€â”˜</span><span class="w">              </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<p><strong>Key Takeaways:</strong>
- Model-based RL trades computation for sample efficiency
- Ensemble models provide uncertainty estimates
- Short rollouts mitigate compounding model errors
- MuZero: planning in learned latent space (no observation prediction)
- Dreamer: entire policy training in imagination</p>
<hr />
<h2 id="references">References<a class="header-link" href="#references" title="Permanent link">&para;</a></h2>
<ul>
<li>Sutton &amp; Barto Ch. 8: "Planning and Learning with Tabular Methods"</li>
<li><a href="https://arxiv.org/abs/1906.08253">MBPO Paper</a> â€” Janner et al. 2019</li>
<li><a href="https://arxiv.org/abs/1911.08265">MuZero Paper</a> â€” Schrittwieser et al. 2020</li>
<li><a href="https://arxiv.org/abs/2301.04104">DreamerV3 Paper</a> â€” Hafner et al. 2023</li>
<li><a href="https://spinningup.openai.com/">Spinning Up: Model-Based Methods</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Reinforcement_Learning/12_Practical_RL_Project.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">12. Practical RL Project</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Reinforcement_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Reinforcement_Learning/14_Soft_Actor_Critic.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">14. Soft Actor-Critic (SAC)</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}