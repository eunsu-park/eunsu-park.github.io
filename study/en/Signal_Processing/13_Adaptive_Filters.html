{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>13. Adaptive Filters - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">üè†</span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">üíª</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        ÌïúÍµ≠Ïñ¥
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">‚òÄÔ∏è</span>
                    <span class="theme-icon dark">üåô</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/en/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/en/Signal_Processing/">Signal Processing</a>
    <span class="separator">/</span>
    <span class="current">13. Adaptive Filters</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>13. Adaptive Filters</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Signal_Processing/12_Spectral_Analysis.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Spectral Analysis</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Signal_Processing/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Signal_Processing/14_Time_Frequency_Analysis.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">14. Time-Frequency Analysis</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#1-why-adaptive-filtering">1. Why Adaptive Filtering?</a><ul>
<li><a href="#11-limitations-of-fixed-filters">1.1 Limitations of Fixed Filters</a></li>
<li><a href="#12-the-adaptive-filtering-framework">1.2 The Adaptive Filtering Framework</a></li>
<li><a href="#13-common-configurations">1.3 Common Configurations</a></li>
</ul>
</li>
<li><a href="#2-the-wiener-filter-optimal-mmse-solution">2. The Wiener Filter: Optimal MMSE Solution</a><ul>
<li><a href="#21-cost-function">2.1 Cost Function</a></li>
<li><a href="#22-the-wiener-hopf-equation">2.2 The Wiener-Hopf Equation</a></li>
<li><a href="#23-performance-surface">2.3 Performance Surface</a></li>
<li><a href="#24-limitations-of-the-wiener-solution">2.4 Limitations of the Wiener Solution</a></li>
</ul>
</li>
<li><a href="#3-method-of-steepest-descent">3. Method of Steepest Descent</a><ul>
<li><a href="#31-gradient-descent-on-the-mse-surface">3.1 Gradient Descent on the MSE Surface</a></li>
<li><a href="#32-convergence-analysis">3.2 Convergence Analysis</a></li>
<li><a href="#33-convergence-speed-and-eigenvalue-spread">3.3 Convergence Speed and Eigenvalue Spread</a></li>
<li><a href="#34-learning-curve">3.4 Learning Curve</a></li>
</ul>
</li>
<li><a href="#4-the-lms-algorithm">4. The LMS Algorithm</a><ul>
<li><a href="#41-derivation">4.1 Derivation</a></li>
<li><a href="#42-algorithm-summary">4.2 Algorithm Summary</a></li>
<li><a href="#43-properties-of-lms">4.3 Properties of LMS</a></li>
</ul>
</li>
<li><a href="#5-lms-convergence-analysis">5. LMS Convergence Analysis</a><ul>
<li><a href="#51-mean-convergence">5.1 Mean Convergence</a></li>
<li><a href="#52-mean-square-convergence">5.2 Mean-Square Convergence</a></li>
<li><a href="#53-excess-mse-and-misadjustment">5.3 Excess MSE and Misadjustment</a></li>
<li><a href="#54-step-size-selection-guidelines">5.4 Step Size Selection Guidelines</a></li>
<li><a href="#55-convergence-time">5.5 Convergence Time</a></li>
</ul>
</li>
<li><a href="#6-normalized-lms-nlms">6. Normalized LMS (NLMS)</a><ul>
<li><a href="#61-motivation">6.1 Motivation</a></li>
<li><a href="#62-derivation">6.2 Derivation</a></li>
<li><a href="#63-derivation-from-constrained-optimization">6.3 Derivation from Constrained Optimization</a></li>
<li><a href="#64-advantages-of-nlms">6.4 Advantages of NLMS</a></li>
<li><a href="#65-nlms-convergence">6.5 NLMS Convergence</a></li>
</ul>
</li>
<li><a href="#7-the-rls-algorithm">7. The RLS Algorithm</a><ul>
<li><a href="#71-motivation">7.1 Motivation</a></li>
<li><a href="#72-the-normal-equations-for-weighted-ls">7.2 The Normal Equations for Weighted LS</a></li>
<li><a href="#73-matrix-inversion-lemma">7.3 Matrix Inversion Lemma</a></li>
<li><a href="#74-rls-algorithm-summary">7.4 RLS Algorithm Summary</a></li>
<li><a href="#75-forgetting-factor">7.5 Forgetting Factor</a></li>
<li><a href="#76-properties-of-rls">7.6 Properties of RLS</a></li>
</ul>
</li>
<li><a href="#8-comparison-lms-vs-rls">8. Comparison: LMS vs RLS</a></li>
<li><a href="#9-application-system-identification">9. Application: System Identification</a><ul>
<li><a href="#91-problem-statement">9.1 Problem Statement</a></li>
<li><a href="#92-when-to-use">9.2 When to Use</a></li>
</ul>
</li>
<li><a href="#10-application-noise-cancellation">10. Application: Noise Cancellation</a><ul>
<li><a href="#101-the-adaptive-noise-canceller-anc">10.1 The Adaptive Noise Canceller (ANC)</a></li>
<li><a href="#102-mathematical-justification">10.2 Mathematical Justification</a></li>
</ul>
</li>
<li><a href="#11-application-echo-cancellation">11. Application: Echo Cancellation</a><ul>
<li><a href="#111-acoustic-echo-cancellation-aec">11.1 Acoustic Echo Cancellation (AEC)</a></li>
<li><a href="#112-network-echo-cancellation">11.2 Network Echo Cancellation</a></li>
</ul>
</li>
<li><a href="#12-application-channel-equalization">12. Application: Channel Equalization</a><ul>
<li><a href="#121-problem">12.1 Problem</a></li>
<li><a href="#122-training-and-decision-directed-modes">12.2 Training and Decision-Directed Modes</a></li>
</ul>
</li>
<li><a href="#13-application-adaptive-beamforming">13. Application: Adaptive Beamforming</a><ul>
<li><a href="#131-problem">13.1 Problem</a></li>
<li><a href="#132-minimum-variance-distortionless-response-mvdr">13.2 Minimum Variance Distortionless Response (MVDR)</a></li>
</ul>
</li>
<li><a href="#14-python-implementation-complete-adaptive-filtering-toolkit">14. Python Implementation: Complete Adaptive Filtering Toolkit</a><ul>
<li><a href="#141-lms-nlms-and-rls-implementations">14.1 LMS, NLMS, and RLS Implementations</a></li>
<li><a href="#142-system-identification-example">14.2 System Identification Example</a></li>
<li><a href="#143-noise-cancellation-demo">14.3 Noise Cancellation Demo</a></li>
<li><a href="#144-tracking-a-time-varying-system">14.4 Tracking a Time-Varying System</a></li>
</ul>
</li>
<li><a href="#15-exercises">15. Exercises</a><ul>
<li><a href="#exercise-1-wiener-filter">Exercise 1: Wiener Filter</a></li>
<li><a href="#exercise-2-lms-convergence">Exercise 2: LMS Convergence</a></li>
<li><a href="#exercise-3-nlms-vs-lms">Exercise 3: NLMS vs LMS</a></li>
<li><a href="#exercise-4-rls-implementation">Exercise 4: RLS Implementation</a></li>
<li><a href="#exercise-5-echo-cancellation-simulation">Exercise 5: Echo Cancellation Simulation</a></li>
<li><a href="#exercise-6-adaptive-equalization">Exercise 6: Adaptive Equalization</a></li>
<li><a href="#exercise-7-effect-of-filter-order">Exercise 7: Effect of Filter Order</a></li>
</ul>
</li>
<li><a href="#16-summary">16. Summary</a></li>
<li><a href="#17-references">17. References</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="13-adaptive-filters">13. Adaptive Filters<a class="header-link" href="#13-adaptive-filters" title="Permanent link">&para;</a></h1>
<p><strong>Previous</strong>: <a href="./12_Multirate_Signal_Processing.md">12. Multirate Signal Processing</a> | <strong>Next</strong>: <a href="./14_Time_Frequency_Analysis.md">14. Time-Frequency Analysis</a></p>
<hr />
<p>Adaptive filters are filters whose coefficients are adjusted automatically according to an optimization algorithm. Unlike fixed filters designed with complete a priori knowledge of signal and noise statistics, adaptive filters can operate in unknown or time-varying environments by continuously updating their parameters from data. They are the workhorses behind noise cancellation headphones, echo cancellation in phones, channel equalization in modems, and many other real-world systems.</p>
<p><strong>Difficulty</strong>: ‚≠ê‚≠ê‚≠ê‚≠ê</p>
<p><strong>Prerequisites</strong>: FIR/IIR filter design, linear algebra, basic optimization concepts</p>
<p><strong>Learning Objectives</strong>:
- Derive the Wiener filter as the optimal MMSE linear filter
- Understand the method of steepest descent and its convergence properties
- Derive and implement the LMS algorithm and analyze its convergence behavior
- Implement the Normalized LMS (NLMS) algorithm for improved convergence
- Derive and implement the RLS algorithm using the matrix inversion lemma
- Compare LMS and RLS in terms of complexity, convergence, and tracking
- Apply adaptive filters to system identification, noise cancellation, echo cancellation, and equalization</p>
<hr />
<h2 id="table-of-contents">Table of Contents<a class="header-link" href="#table-of-contents" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="#1-why-adaptive-filtering">Why Adaptive Filtering?</a></li>
<li><a href="#2-the-wiener-filter-optimal-mmse-solution">The Wiener Filter: Optimal MMSE Solution</a></li>
<li><a href="#3-method-of-steepest-descent">Method of Steepest Descent</a></li>
<li><a href="#4-the-lms-algorithm">The LMS Algorithm</a></li>
<li><a href="#5-lms-convergence-analysis">LMS Convergence Analysis</a></li>
<li><a href="#6-normalized-lms-nlms">Normalized LMS (NLMS)</a></li>
<li><a href="#7-the-rls-algorithm">The RLS Algorithm</a></li>
<li><a href="#8-comparison-lms-vs-rls">Comparison: LMS vs RLS</a></li>
<li><a href="#9-application-system-identification">Application: System Identification</a></li>
<li><a href="#10-application-noise-cancellation">Application: Noise Cancellation</a></li>
<li><a href="#11-application-echo-cancellation">Application: Echo Cancellation</a></li>
<li><a href="#12-application-channel-equalization">Application: Channel Equalization</a></li>
<li><a href="#13-application-adaptive-beamforming">Application: Adaptive Beamforming</a></li>
<li><a href="#14-python-implementation-complete-adaptive-filtering-toolkit">Python Implementation: Complete Adaptive Filtering Toolkit</a></li>
<li><a href="#15-exercises">Exercises</a></li>
<li><a href="#16-summary">Summary</a></li>
<li><a href="#17-references">References</a></li>
</ol>
<hr />
<h2 id="1-why-adaptive-filtering">1. Why Adaptive Filtering?<a class="header-link" href="#1-why-adaptive-filtering" title="Permanent link">&para;</a></h2>
<h3 id="11-limitations-of-fixed-filters">1.1 Limitations of Fixed Filters<a class="header-link" href="#11-limitations-of-fixed-filters" title="Permanent link">&para;</a></h3>
<p>Conventional FIR and IIR filters require complete knowledge of the signal and noise characteristics at design time. Consider the challenges when:</p>
<ul>
<li><strong>Statistics are unknown</strong>: You cannot design an optimal filter if you don't know the spectral characteristics of the noise.</li>
<li><strong>Statistics are time-varying</strong>: A wireless channel changes as the transmitter or receiver moves. A filter designed for one channel realization becomes suboptimal moments later.</li>
<li><strong>Real-time operation is required</strong>: Some environments demand continuous adaptation without offline design phases.</li>
</ul>
<h3 id="12-the-adaptive-filtering-framework">1.2 The Adaptive Filtering Framework<a class="header-link" href="#12-the-adaptive-filtering-framework" title="Permanent link">&para;</a></h3>
<p>An adaptive filter consists of two parts:</p>
<ol>
<li><strong>A parameterized filter structure</strong> (usually FIR): computes the output $y(n)$ from the input $x(n)$.</li>
<li><strong>An adaptation algorithm</strong>: adjusts the filter coefficients $\mathbf{w}(n)$ to minimize some cost function.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="w">                    </span><span class="err">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</span>
<span class="w">     </span><span class="n">x</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="err">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ</span><span class="w">   </span><span class="n">Adaptive</span><span class="w"> </span><span class="n">Filter</span><span class="w">    </span><span class="err">‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂</span><span class="w"> </span><span class="n">y</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="w">                    </span><span class="err">‚îÇ</span><span class="w">   </span><span class="n">w</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w">               </span><span class="err">‚îÇ</span>
<span class="w">                    </span><span class="err">‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</span>
<span class="w">                               </span><span class="err">‚îÇ</span>
<span class="w">                               </span><span class="err">‚îÇ</span><span class="w">  </span><span class="n">e</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="w">                               </span><span class="err">‚îÇ</span>
<span class="w">     </span><span class="n">d</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="err">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂</span><span class="w"> </span><span class="n">Error</span>
<span class="w">     </span><span class="p">(</span><span class="n">desired</span><span class="w"> </span><span class="k">signal</span><span class="p">)</span><span class="w">                      </span><span class="n">Computation</span>
<span class="w">                                              </span><span class="err">‚îÇ</span>
<span class="w">                                              </span><span class="err">‚ñº</span>
<span class="w">                                     </span><span class="n">Adaptation</span><span class="w"> </span><span class="n">Algorithm</span>
<span class="w">                                     </span><span class="p">(</span><span class="n">update</span><span class="w"> </span><span class="n">w</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div>

<p>The <strong>error signal</strong> is:</p>
<p>$$e(n) = d(n) - y(n) = d(n) - \mathbf{w}^T(n) \mathbf{x}(n)$$</p>
<p>where:
- $d(n)$ is the <strong>desired (reference) signal</strong>
- $\mathbf{x}(n) = [x(n), x(n-1), \ldots, x(n-M+1)]^T$ is the input vector
- $\mathbf{w}(n) = [w_0(n), w_1(n), \ldots, w_{M-1}(n)]^T$ is the filter weight vector
- $M$ is the filter order</p>
<h3 id="13-common-configurations">1.3 Common Configurations<a class="header-link" href="#13-common-configurations" title="Permanent link">&para;</a></h3>
<p>Adaptive filters are used in four primary configurations:</p>
<table>
<thead>
<tr>
<th>Configuration</th>
<th>Input $x(n)$</th>
<th>Desired $d(n)$</th>
<th>Objective</th>
</tr>
</thead>
<tbody>
<tr>
<td>System identification</td>
<td>Input to unknown system</td>
<td>Output of unknown system</td>
<td>Model the unknown system</td>
</tr>
<tr>
<td>Inverse modeling</td>
<td>Output of unknown system</td>
<td>Delayed input</td>
<td>Equalize the channel</td>
</tr>
<tr>
<td>Noise cancellation</td>
<td>Correlated noise reference</td>
<td>Signal + noise</td>
<td>Extract the signal</td>
</tr>
<tr>
<td>Prediction</td>
<td>Delayed version of signal</td>
<td>Current signal</td>
<td>Predict future values</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-the-wiener-filter-optimal-mmse-solution">2. The Wiener Filter: Optimal MMSE Solution<a class="header-link" href="#2-the-wiener-filter-optimal-mmse-solution" title="Permanent link">&para;</a></h2>
<h3 id="21-cost-function">2.1 Cost Function<a class="header-link" href="#21-cost-function" title="Permanent link">&para;</a></h3>
<p>The <strong>minimum mean square error (MMSE)</strong> criterion minimizes the expected squared error:</p>
<p>$$J(\mathbf{w}) = E\left[|e(n)|^2\right] = E\left[|d(n) - \mathbf{w}^T \mathbf{x}(n)|^2\right]$$</p>
<p>Expanding:</p>
<p>$$J(\mathbf{w}) = E[d^2(n)] - 2\mathbf{w}^T E[d(n)\mathbf{x}(n)] + \mathbf{w}^T E[\mathbf{x}(n)\mathbf{x}^T(n)] \mathbf{w}$$</p>
<p>Define:
- <strong>Autocorrelation matrix</strong>: $\mathbf{R} = E[\mathbf{x}(n)\mathbf{x}^T(n)]$ (an $M \times M$ positive-definite matrix)
- <strong>Cross-correlation vector</strong>: $\mathbf{p} = E[d(n)\mathbf{x}(n)]$ (an $M \times 1$ vector)
- $\sigma_d^2 = E[d^2(n)]$</p>
<p>The cost function becomes a <strong>quadratic bowl</strong>:</p>
<p>$$J(\mathbf{w}) = \sigma_d^2 - 2\mathbf{w}^T \mathbf{p} + \mathbf{w}^T \mathbf{R} \mathbf{w}$$</p>
<h3 id="22-the-wiener-hopf-equation">2.2 The Wiener-Hopf Equation<a class="header-link" href="#22-the-wiener-hopf-equation" title="Permanent link">&para;</a></h3>
<p>Taking the gradient and setting it to zero:</p>
<p>$$\nabla_{\mathbf{w}} J = -2\mathbf{p} + 2\mathbf{R}\mathbf{w} = \mathbf{0}$$</p>
<p>This yields the <strong>Wiener-Hopf equation</strong> (normal equation):</p>
<p>$$\boxed{\mathbf{R}\mathbf{w}_{opt} = \mathbf{p}}$$</p>
<p>The optimal (Wiener) filter is:</p>
<p>$$\mathbf{w}_{opt} = \mathbf{R}^{-1}\mathbf{p}$$</p>
<p>The <strong>minimum MSE</strong> at the optimal solution is:</p>
<p>$$J_{min} = \sigma_d^2 - \mathbf{p}^T \mathbf{R}^{-1} \mathbf{p}$$</p>
<h3 id="23-performance-surface">2.3 Performance Surface<a class="header-link" href="#23-performance-surface" title="Permanent link">&para;</a></h3>
<p>Since $\mathbf{R}$ is positive-definite, the cost function $J(\mathbf{w})$ is a convex quadratic -- a bowl-shaped surface (an elliptic paraboloid in the $M$-dimensional weight space). Any descent algorithm will converge to the unique global minimum.</p>
<p>Using the eigendecomposition $\mathbf{R} = \mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^T$, the cost function in the rotated coordinate system $\mathbf{v} = \mathbf{Q}^T(\mathbf{w} - \mathbf{w}_{opt})$ becomes:</p>
<p>$$J(\mathbf{v}) = J_{min} + \sum_{k=0}^{M-1} \lambda_k v_k^2$$</p>
<p>where $\lambda_k$ are the eigenvalues of $\mathbf{R}$. The contours of $J$ are ellipses whose axes are aligned with the eigenvectors and whose extents are determined by the eigenvalues.</p>
<h3 id="24-limitations-of-the-wiener-solution">2.4 Limitations of the Wiener Solution<a class="header-link" href="#24-limitations-of-the-wiener-solution" title="Permanent link">&para;</a></h3>
<p>The Wiener filter requires:
1. Knowledge of $\mathbf{R}$ and $\mathbf{p}$ (second-order statistics)
2. Stationarity of the signals
3. Computation of $\mathbf{R}^{-1}$ ($O(M^3)$ operations)</p>
<p>In practice, these are rarely available exactly, motivating iterative and adaptive approaches.</p>
<hr />
<h2 id="3-method-of-steepest-descent">3. Method of Steepest Descent<a class="header-link" href="#3-method-of-steepest-descent" title="Permanent link">&para;</a></h2>
<h3 id="31-gradient-descent-on-the-mse-surface">3.1 Gradient Descent on the MSE Surface<a class="header-link" href="#31-gradient-descent-on-the-mse-surface" title="Permanent link">&para;</a></h3>
<p>Instead of solving the Wiener-Hopf equation directly, we can reach $\mathbf{w}_{opt}$ iteratively using gradient descent:</p>
<p>$$\mathbf{w}(n+1) = \mathbf{w}(n) - \mu \nabla_{\mathbf{w}} J(n)$$</p>
<p>The true gradient of the MSE cost function is:</p>
<p>$$\nabla_{\mathbf{w}} J = -2\mathbf{p} + 2\mathbf{R}\mathbf{w}(n)$$</p>
<p>So the update rule is:</p>
<p>$$\boxed{\mathbf{w}(n+1) = \mathbf{w}(n) + 2\mu\left(\mathbf{p} - \mathbf{R}\mathbf{w}(n)\right)}$$</p>
<p>This is the <strong>steepest descent</strong> algorithm. Note it still requires knowledge of $\mathbf{R}$ and $\mathbf{p}$, so it is not truly adaptive yet.</p>
<h3 id="32-convergence-analysis">3.2 Convergence Analysis<a class="header-link" href="#32-convergence-analysis" title="Permanent link">&para;</a></h3>
<p>Define the weight error vector: $\boldsymbol{\epsilon}(n) = \mathbf{w}(n) - \mathbf{w}_{opt}$</p>
<p>Substituting into the update:</p>
<p>$$\boldsymbol{\epsilon}(n+1) = (\mathbf{I} - 2\mu\mathbf{R})\boldsymbol{\epsilon}(n)$$</p>
<p>Using the eigendecomposition $\mathbf{R} = \mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^T$, in the rotated coordinates $\mathbf{v}(n) = \mathbf{Q}^T \boldsymbol{\epsilon}(n)$:</p>
<p>$$v_k(n+1) = (1 - 2\mu\lambda_k) v_k(n)$$</p>
<p>For convergence, we need $|1 - 2\mu\lambda_k| < 1$ for all $k$, which gives:</p>
<p>$$\boxed{0 < \mu < \frac{1}{\lambda_{max}}}$$</p>
<p>where $\lambda_{max}$ is the largest eigenvalue of $\mathbf{R}$.</p>
<h3 id="33-convergence-speed-and-eigenvalue-spread">3.3 Convergence Speed and Eigenvalue Spread<a class="header-link" href="#33-convergence-speed-and-eigenvalue-spread" title="Permanent link">&para;</a></h3>
<p>The rate of convergence of each mode $v_k$ is determined by $|1 - 2\mu\lambda_k|$. The optimal step size for each mode would be $\mu_k = 1/(2\lambda_k)$, but since we use a single $\mu$:</p>
<ul>
<li>The fastest-converging mode corresponds to $\lambda_{max}$</li>
<li>The slowest-converging mode corresponds to $\lambda_{min}$</li>
</ul>
<p>The <strong>eigenvalue spread</strong> (condition number):</p>
<p>$$\chi(\mathbf{R}) = \frac{\lambda_{max}}{\lambda_{min}}$$</p>
<p>governs the overall convergence rate. A large eigenvalue spread means slow convergence -- the algorithm "zig-zags" across the narrow valley of the performance surface.</p>
<h3 id="34-learning-curve">3.4 Learning Curve<a class="header-link" href="#34-learning-curve" title="Permanent link">&para;</a></h3>
<p>The MSE as a function of iteration is the <strong>learning curve</strong>:</p>
<p>$$J(n) = J_{min} + \sum_{k=0}^{M-1} \lambda_k v_k^2(0)(1 - 2\mu\lambda_k)^{2n}$$</p>
<p>Each mode decays geometrically with time constant:</p>
<p>$$\tau_k = \frac{-1}{2\ln|1 - 2\mu\lambda_k|} \approx \frac{1}{4\mu\lambda_k} \quad \text{for small } \mu$$</p>
<p>The slowest mode has time constant $\tau_{max} \approx 1/(4\mu\lambda_{min})$.</p>
<hr />
<h2 id="4-the-lms-algorithm">4. The LMS Algorithm<a class="header-link" href="#4-the-lms-algorithm" title="Permanent link">&para;</a></h2>
<h3 id="41-derivation">4.1 Derivation<a class="header-link" href="#41-derivation" title="Permanent link">&para;</a></h3>
<p>The steepest descent algorithm requires the true gradient $\nabla J = -2\mathbf{p} + 2\mathbf{R}\mathbf{w}(n)$. The key insight of Widrow and Hoff (1960) is to replace the true gradient with an <strong>instantaneous estimate</strong>:</p>
<p>$$\hat{\nabla} J(n) = -2e(n)\mathbf{x}(n)$$</p>
<p>This is obtained by replacing the expectation with the instantaneous sample:
- $\mathbf{R}\mathbf{w}(n) \approx \mathbf{x}(n)\mathbf{x}^T(n)\mathbf{w}(n) = \mathbf{x}(n)y(n)$
- $\mathbf{p} \approx d(n)\mathbf{x}(n)$</p>
<p>The <strong>LMS algorithm</strong> is:</p>
<p>$$\boxed{\mathbf{w}(n+1) = \mathbf{w}(n) + \mu \, e(n) \, \mathbf{x}(n)}$$</p>
<p>where $e(n) = d(n) - \mathbf{w}^T(n)\mathbf{x}(n)$.</p>
<h3 id="42-algorithm-summary">4.2 Algorithm Summary<a class="header-link" href="#42-algorithm-summary" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="nv">LMS</span><span class="w"> </span><span class="nv">Algorithm</span>
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span class="nv">Initialize</span>:<span class="w"> </span><span class="nv">w</span><span class="ss">(</span><span class="mi">0</span><span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ss">(</span><span class="nv">or</span><span class="w"> </span><span class="nv">small</span><span class="w"> </span><span class="k">random</span><span class="w"> </span><span class="nv">values</span><span class="ss">)</span>
<span class="nv">Parameters</span>:<span class="w"> </span><span class="nv">step</span><span class="w"> </span><span class="nv">size</span><span class="w"> </span>Œº,<span class="w"> </span><span class="nv">filter</span><span class="w"> </span><span class="nv">order</span><span class="w"> </span><span class="nv">M</span>

<span class="k">For</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">sample</span><span class="w"> </span><span class="nv">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>,<span class="w"> </span><span class="mi">1</span>,<span class="w"> </span><span class="mi">2</span>,<span class="w"> </span>...
<span class="w">  </span><span class="mi">1</span>.<span class="w"> </span><span class="nv">Form</span><span class="w"> </span><span class="nv">input</span><span class="w"> </span><span class="nv">vector</span>:<span class="w"> </span><span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[<span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span>,<span class="w"> </span><span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="o">-</span><span class="mi">1</span><span class="ss">)</span>,<span class="w"> </span>...,<span class="w"> </span><span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="o">-</span><span class="nv">M</span><span class="o">+</span><span class="mi">1</span><span class="ss">)</span>]<span class="o">^</span><span class="nv">T</span>
<span class="w">  </span><span class="mi">2</span>.<span class="w"> </span><span class="nv">Compute</span><span class="w"> </span><span class="nv">output</span>:<span class="w">    </span><span class="nv">y</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">w</span><span class="o">^</span><span class="nv">T</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span>
<span class="w">  </span><span class="mi">3</span>.<span class="w"> </span><span class="nv">Compute</span><span class="w"> </span><span class="nv">error</span>:<span class="w">     </span><span class="nv">e</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">d</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">y</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span>
<span class="w">  </span><span class="mi">4</span>.<span class="w"> </span><span class="nv">Update</span><span class="w"> </span><span class="nv">weights</span>:<span class="w">    </span><span class="nv">w</span><span class="ss">(</span><span class="nv">n</span><span class="o">+</span><span class="mi">1</span><span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">w</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>Œº<span class="w"> </span><span class="nv">e</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span><span class="nv">x</span><span class="ss">(</span><span class="nv">n</span><span class="ss">)</span>
</code></pre></div>

<p><strong>Computational complexity</strong>: $O(M)$ multiplications and additions per sample -- remarkably efficient.</p>
<h3 id="43-properties-of-lms">4.3 Properties of LMS<a class="header-link" href="#43-properties-of-lms" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Simplicity</strong>: No matrix inversions, no autocorrelation estimation</li>
<li><strong>Low complexity</strong>: $2M$ multiplications per iteration</li>
<li><strong>Stochastic gradient</strong>: The gradient estimate is noisy but unbiased: $E[\hat{\nabla}J] = \nabla J$</li>
<li><strong>Self-tuning</strong>: Automatically adjusts to track slow changes in signal statistics</li>
</ol>
<hr />
<h2 id="5-lms-convergence-analysis">5. LMS Convergence Analysis<a class="header-link" href="#5-lms-convergence-analysis" title="Permanent link">&para;</a></h2>
<h3 id="51-mean-convergence">5.1 Mean Convergence<a class="header-link" href="#51-mean-convergence" title="Permanent link">&para;</a></h3>
<p>Taking expectations of the LMS update (under the <strong>independence assumption</strong> -- $\mathbf{x}(n)$ is independent of $\mathbf{w}(n)$):</p>
<p>$$E[\mathbf{w}(n+1)] = E[\mathbf{w}(n)] + \mu E[e(n)\mathbf{x}(n)]$$</p>
<p>After some algebra:</p>
<p>$$E[\boldsymbol{\epsilon}(n+1)] = (\mathbf{I} - 2\mu\mathbf{R}) E[\boldsymbol{\epsilon}(n)]$$</p>
<p>This is the same recurrence as steepest descent, so the <strong>mean convergence</strong> condition is:</p>
<p>$$0 < \mu < \frac{1}{\lambda_{max}}$$</p>
<p>In practice, we use:</p>
<p>$$0 < \mu < \frac{1}{\text{tr}(\mathbf{R})} = \frac{1}{M \cdot \sigma_x^2}$$</p>
<p>since $\text{tr}(\mathbf{R}) = \sum_k \lambda_k \geq \lambda_{max}$, and $\text{tr}(\mathbf{R}) = M\sigma_x^2$ for stationary inputs.</p>
<h3 id="52-mean-square-convergence">5.2 Mean-Square Convergence<a class="header-link" href="#52-mean-square-convergence" title="Permanent link">&para;</a></h3>
<p>The condition for the MSE to converge (mean-square stability) is more restrictive:</p>
<p>$$0 < \mu < \frac{2}{\lambda_{max} + \text{tr}(\mathbf{R})}$$</p>
<p>For practical purposes, a safe choice is:</p>
<p>$$\mu < \frac{1}{3 \, \text{tr}(\mathbf{R})} = \frac{1}{3M\sigma_x^2}$$</p>
<h3 id="53-excess-mse-and-misadjustment">5.3 Excess MSE and Misadjustment<a class="header-link" href="#53-excess-mse-and-misadjustment" title="Permanent link">&para;</a></h3>
<p>Even after convergence, the LMS algorithm does not reach $J_{min}$ because the stochastic gradient introduces noise into the weight updates. The <strong>excess MSE</strong> is:</p>
<p>$$J_{excess} = J_{steady-state} - J_{min}$$</p>
<p>The <strong>misadjustment</strong> is:</p>
<p>$$\mathcal{M} = \frac{J_{excess}}{J_{min}} \approx \mu \, \text{tr}(\mathbf{R}) = \mu M \sigma_x^2$$</p>
<p>This reveals a fundamental <strong>tradeoff</strong>:
- <strong>Large $\mu$</strong>: Fast convergence but large misadjustment (noisy steady state)
- <strong>Small $\mu$</strong>: Slow convergence but small misadjustment (accurate steady state)</p>
<h3 id="54-step-size-selection-guidelines">5.4 Step Size Selection Guidelines<a class="header-link" href="#54-step-size-selection-guidelines" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Criterion</th>
<th>Step Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stability (mean)</td>
<td>$\mu < 1/\lambda_{max}$</td>
</tr>
<tr>
<td>Stability (mean-square)</td>
<td>$\mu < 2/(\lambda_{max} + \text{tr}(\mathbf{R}))$</td>
</tr>
<tr>
<td>Practical rule</td>
<td>$\mu \in [0.01, 0.1] / (M \sigma_x^2)$</td>
</tr>
<tr>
<td>Misadjustment $\leq$ 10%</td>
<td>$\mu \leq 0.1 / (M \sigma_x^2)$</td>
</tr>
</tbody>
</table>
<h3 id="55-convergence-time">5.5 Convergence Time<a class="header-link" href="#55-convergence-time" title="Permanent link">&para;</a></h3>
<p>The approximate time constant for the slowest mode is:</p>
<p>$$\tau_{mse} \approx \frac{1}{4\mu\lambda_{min}}$$</p>
<p>Combined with the misadjustment constraint $\mathcal{M} = \mu M \sigma_x^2$:</p>
<p>$$\tau_{mse} \approx \frac{M \sigma_x^2}{4\mathcal{M}\lambda_{min}} = \frac{\chi(\mathbf{R})}{4\mathcal{M}} \cdot \frac{M\sigma_x^2}{\lambda_{max}}$$</p>
<p>Large eigenvalue spread $\chi(\mathbf{R})$ requires many iterations for convergence at a given misadjustment.</p>
<hr />
<h2 id="6-normalized-lms-nlms">6. Normalized LMS (NLMS)<a class="header-link" href="#6-normalized-lms-nlms" title="Permanent link">&para;</a></h2>
<h3 id="61-motivation">6.1 Motivation<a class="header-link" href="#61-motivation" title="Permanent link">&para;</a></h3>
<p>The standard LMS has a fixed step size $\mu$, which means the effective adaptation rate depends on the input power $\|\mathbf{x}(n)\|^2$. When the input power varies, LMS can become unstable or converge too slowly.</p>
<h3 id="62-derivation">6.2 Derivation<a class="header-link" href="#62-derivation" title="Permanent link">&para;</a></h3>
<p>The NLMS algorithm is obtained by normalizing the step size by the input power:</p>
<p>$$\boxed{\mathbf{w}(n+1) = \mathbf{w}(n) + \frac{\tilde{\mu}}{\|\mathbf{x}(n)\|^2 + \delta} \, e(n) \, \mathbf{x}(n)}$$</p>
<p>where:
- $\tilde{\mu} \in (0, 2)$ is the normalized step size
- $\delta > 0$ is a small regularization constant to prevent division by zero</p>
<h3 id="63-derivation-from-constrained-optimization">6.3 Derivation from Constrained Optimization<a class="header-link" href="#63-derivation-from-constrained-optimization" title="Permanent link">&para;</a></h3>
<p>NLMS can be derived by solving the constrained optimization problem:</p>
<p>$$\min_{\mathbf{w}(n+1)} \|\mathbf{w}(n+1) - \mathbf{w}(n)\|^2 \quad \text{subject to} \quad \mathbf{w}^T(n+1)\mathbf{x}(n) = d(n)$$</p>
<p>That is: find the closest weight vector to the current one that perfectly fits the latest data point. Using Lagrange multipliers, one obtains the NLMS update with $\tilde{\mu} = 1$.</p>
<h3 id="64-advantages-of-nlms">6.4 Advantages of NLMS<a class="header-link" href="#64-advantages-of-nlms" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Robust convergence</strong>: Step size automatically adapts to input power</li>
<li><strong>Simpler tuning</strong>: Only one parameter $\tilde{\mu} \in (0, 2)$ to set</li>
<li><strong>Better for non-stationary inputs</strong>: Works well with varying signal levels</li>
<li><strong>Minimal extra cost</strong>: One additional inner product per iteration</li>
</ol>
<h3 id="65-nlms-convergence">6.5 NLMS Convergence<a class="header-link" href="#65-nlms-convergence" title="Permanent link">&para;</a></h3>
<p>The convergence condition for NLMS is simply:</p>
<p>$$0 < \tilde{\mu} < 2$$</p>
<p>The misadjustment is approximately:</p>
<p>$$\mathcal{M}_{NLMS} \approx \frac{\tilde{\mu}}{2 - \tilde{\mu}} \cdot \frac{1}{M}$$</p>
<p>A typical choice is $\tilde{\mu} \in [0.1, 1.0]$.</p>
<hr />
<h2 id="7-the-rls-algorithm">7. The RLS Algorithm<a class="header-link" href="#7-the-rls-algorithm" title="Permanent link">&para;</a></h2>
<h3 id="71-motivation">7.1 Motivation<a class="header-link" href="#71-motivation" title="Permanent link">&para;</a></h3>
<p>While LMS estimates the gradient stochastically (one sample at a time), the <strong>Recursive Least Squares (RLS)</strong> algorithm minimizes a deterministic cost function over all past data:</p>
<p>$$J_{RLS}(n) = \sum_{i=0}^{n} \lambda^{n-i} |e(i)|^2$$</p>
<p>where $\lambda \in (0, 1]$ is the <strong>forgetting factor</strong> (typically $0.95 \leq \lambda \leq 1.0$). Recent samples are weighted more heavily than older ones, providing tracking capability for non-stationary environments.</p>
<h3 id="72-the-normal-equations-for-weighted-ls">7.2 The Normal Equations for Weighted LS<a class="header-link" href="#72-the-normal-equations-for-weighted-ls" title="Permanent link">&para;</a></h3>
<p>The cost function is minimized by:</p>
<p>$$\mathbf{w}(n) = \boldsymbol{\Phi}^{-1}(n) \boldsymbol{\theta}(n)$$</p>
<p>where:
- $\boldsymbol{\Phi}(n) = \sum_{i=0}^{n} \lambda^{n-i} \mathbf{x}(i)\mathbf{x}^T(i)$ is the weighted sample correlation matrix
- $\boldsymbol{\theta}(n) = \sum_{i=0}^{n} \lambda^{n-i} d(i)\mathbf{x}(i)$ is the weighted cross-correlation vector</p>
<p>Both have recursive updates:</p>
<p>$$\boldsymbol{\Phi}(n) = \lambda \boldsymbol{\Phi}(n-1) + \mathbf{x}(n)\mathbf{x}^T(n)$$</p>
<p>$$\boldsymbol{\theta}(n) = \lambda \boldsymbol{\theta}(n-1) + d(n)\mathbf{x}(n)$$</p>
<h3 id="73-matrix-inversion-lemma">7.3 Matrix Inversion Lemma<a class="header-link" href="#73-matrix-inversion-lemma" title="Permanent link">&para;</a></h3>
<p>To avoid recomputing $\boldsymbol{\Phi}^{-1}(n)$ at each step ($O(M^3)$), we use the <strong>matrix inversion lemma</strong> (Woodbury identity):</p>
<p>$$(\mathbf{A} + \mathbf{u}\mathbf{v}^T)^{-1} = \mathbf{A}^{-1} - \frac{\mathbf{A}^{-1}\mathbf{u}\mathbf{v}^T\mathbf{A}^{-1}}{1 + \mathbf{v}^T\mathbf{A}^{-1}\mathbf{u}}$$</p>
<p>Define $\mathbf{P}(n) = \boldsymbol{\Phi}^{-1}(n)$. Then:</p>
<p>$$\mathbf{P}(n) = \lambda^{-1}\mathbf{P}(n-1) - \lambda^{-1}\mathbf{k}(n)\mathbf{x}^T(n)\mathbf{P}(n-1)$$</p>
<p>where the <strong>gain vector</strong> is:</p>
<p>$$\mathbf{k}(n) = \frac{\lambda^{-1}\mathbf{P}(n-1)\mathbf{x}(n)}{1 + \lambda^{-1}\mathbf{x}^T(n)\mathbf{P}(n-1)\mathbf{x}(n)}$$</p>
<h3 id="74-rls-algorithm-summary">7.4 RLS Algorithm Summary<a class="header-link" href="#74-rls-algorithm-summary" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">RLS</span><span class="w"> </span><span class="n">Algorithm</span>
<span class="err">‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span class="nl">Initialize:</span><span class="w"> </span><span class="n">w</span><span class="p">(</span><span class="mh">0</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0</span><span class="p">,</span><span class="w"> </span><span class="n">P</span><span class="p">(</span><span class="mh">0</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">Œ¥</span><span class="o">^</span><span class="p">{</span><span class="o">-</span><span class="mh">1</span><span class="p">}</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="p">(</span><span class="err">Œ¥</span><span class="w"> </span><span class="k">small</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">)</span>
<span class="nl">Parameters:</span><span class="w"> </span><span class="n">forgetting</span><span class="w"> </span><span class="n">factor</span><span class="w"> </span><span class="err">Œª</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.,</span><span class="w"> </span><span class="mf">0.99</span><span class="p">),</span><span class="w"> </span><span class="n">regularization</span><span class="w"> </span><span class="err">Œ¥</span>

<span class="n">For</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">1</span><span class="p">,</span><span class="w"> </span><span class="mh">2</span><span class="p">,</span><span class="w"> </span><span class="p">...</span>
<span class="w">  </span><span class="mf">1.</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">gain</span><span class="w"> </span><span class="nl">vector:</span>
<span class="w">     </span><span class="n">k</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">P</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)</span><span class="w"> </span><span class="n">x</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">[</span><span class="err">Œª</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="o">^</span><span class="n">T</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">P</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)</span><span class="w"> </span><span class="n">x</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>

<span class="w">  </span><span class="mf">2.</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">priori</span><span class="w"> </span><span class="nl">error:</span>
<span class="w">     </span><span class="n">e</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="o">^</span><span class="n">T</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)</span><span class="w"> </span><span class="n">x</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="w">  </span><span class="mf">3.</span><span class="w"> </span><span class="n">Update</span><span class="w"> </span><span class="nl">weights:</span>
<span class="w">     </span><span class="n">w</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">e</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="w">  </span><span class="mf">4.</span><span class="w"> </span><span class="n">Update</span><span class="w"> </span><span class="n">inverse</span><span class="w"> </span><span class="n">correlation</span><span class="w"> </span><span class="nl">matrix:</span>
<span class="w">     </span><span class="n">P</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">Œª</span><span class="o">^</span><span class="p">{</span><span class="o">-</span><span class="mh">1</span><span class="p">}</span><span class="w"> </span><span class="p">[</span><span class="n">P</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">k</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">x</span><span class="o">^</span><span class="n">T</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">P</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mh">1</span><span class="p">)]</span>
</code></pre></div>

<p><strong>Computational complexity</strong>: $O(M^2)$ per sample (due to the $\mathbf{P}$ matrix update).</p>
<h3 id="75-forgetting-factor">7.5 Forgetting Factor<a class="header-link" href="#75-forgetting-factor" title="Permanent link">&para;</a></h3>
<p>The forgetting factor $\lambda$ determines the <strong>effective memory</strong> of the algorithm:</p>
<p>$$N_{eff} = \frac{1}{1 - \lambda}$$</p>
<table>
<thead>
<tr>
<th>$\lambda$</th>
<th>$N_{eff}$</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.0</td>
<td>$\infty$</td>
<td>Growing window (stationary environments)</td>
</tr>
<tr>
<td>0.99</td>
<td>100</td>
<td>Good for slowly varying statistics</td>
</tr>
<tr>
<td>0.95</td>
<td>20</td>
<td>Good for rapidly varying statistics</td>
</tr>
<tr>
<td>0.9</td>
<td>10</td>
<td>Very fast tracking, but noisy</td>
</tr>
</tbody>
</table>
<h3 id="76-properties-of-rls">7.6 Properties of RLS<a class="header-link" href="#76-properties-of-rls" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Fast convergence</strong>: Converges in approximately $2M$ iterations (independent of eigenvalue spread)</li>
<li><strong>No eigenvalue spread problem</strong>: The $\mathbf{P}$ matrix whitens the input</li>
<li><strong>Higher complexity</strong>: $O(M^2)$ vs $O(M)$ for LMS</li>
<li><strong>Numerical sensitivity</strong>: The $\mathbf{P}$ matrix can lose positive-definiteness; stabilized versions exist (e.g., QR-RLS, lattice RLS)</li>
</ol>
<hr />
<h2 id="8-comparison-lms-vs-rls">8. Comparison: LMS vs RLS<a class="header-link" href="#8-comparison-lms-vs-rls" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>LMS</th>
<th>NLMS</th>
<th>RLS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Complexity per sample</td>
<td>$O(M)$</td>
<td>$O(M)$</td>
<td>$O(M^2)$</td>
</tr>
<tr>
<td>Memory</td>
<td>$O(M)$</td>
<td>$O(M)$</td>
<td>$O(M^2)$</td>
</tr>
<tr>
<td>Convergence speed</td>
<td>Slow (depends on $\chi$)</td>
<td>Moderate</td>
<td>Fast ($\sim 2M$ iterations)</td>
</tr>
<tr>
<td>Misadjustment</td>
<td>Higher</td>
<td>Moderate</td>
<td>Lower</td>
</tr>
<tr>
<td>Tracking ability</td>
<td>Moderate</td>
<td>Moderate</td>
<td>Good</td>
</tr>
<tr>
<td>Numerical stability</td>
<td>Excellent</td>
<td>Excellent</td>
<td>Can be poor</td>
</tr>
<tr>
<td>Eigenvalue spread sensitivity</td>
<td>High</td>
<td>Moderate</td>
<td>None</td>
</tr>
<tr>
<td>Step size parameter</td>
<td>$\mu$ (tricky to set)</td>
<td>$\tilde{\mu} \in (0,2)$</td>
<td>$\lambda$ (easier to set)</td>
</tr>
</tbody>
</table>
<p><strong>Rule of thumb</strong>: Use LMS/NLMS when computational cost is paramount or the filter is long. Use RLS when fast convergence is essential and the filter order is moderate.</p>
<hr />
<h2 id="9-application-system-identification">9. Application: System Identification<a class="header-link" href="#9-application-system-identification" title="Permanent link">&para;</a></h2>
<h3 id="91-problem-statement">9.1 Problem Statement<a class="header-link" href="#91-problem-statement" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     x(n) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Unknown System     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ d(n) = h*x(n) + v(n)
         ‚îÇ          ‚îÇ  h = [h0, h1, ...]  ‚îÇ
         ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Adaptive Filter   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ y(n) = w^T x(n)
                    ‚îÇ  w(n)              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    e(n) = d(n) - y(n) ‚Üí 0
</code></pre></div>

<p>The adaptive filter learns the impulse response of the unknown system. When the algorithm converges, $\mathbf{w}_{opt} \approx \mathbf{h}$.</p>
<h3 id="92-when-to-use">9.2 When to Use<a class="header-link" href="#92-when-to-use" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Plant modeling</strong>: Control systems need a model of the system</li>
<li><strong>Acoustic path identification</strong>: Know the room impulse response</li>
<li><strong>Adaptive inverse control</strong>: Once you identify the forward model, invert it</li>
</ul>
<hr />
<h2 id="10-application-noise-cancellation">10. Application: Noise Cancellation<a class="header-link" href="#10-application-noise-cancellation" title="Permanent link">&para;</a></h2>
<h3 id="101-the-adaptive-noise-canceller-anc">10.1 The Adaptive Noise Canceller (ANC)<a class="header-link" href="#101-the-adaptive-noise-canceller-anc" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>     Signal s(n) + Noise n0(n) = d(n)    (primary input)

     Noise reference n1(n)               (reference input, correlated with n0)
              ‚îÇ
              ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  Adaptive Filter   ‚îÇ ‚îÄ‚îÄ‚ñ∂ ≈∑(n) ‚âà n0(n)
     ‚îÇ  w(n)              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                         e(n) = d(n) - ≈∑(n) ‚âà s(n)
</code></pre></div>

<p><strong>Key insight</strong>: The reference input $n_1(n)$ is correlated with the noise $n_0(n)$ but uncorrelated with the signal $s(n)$. The adaptive filter transforms $n_1(n)$ into an estimate of $n_0(n)$. The error signal is then an estimate of the clean signal $s(n)$.</p>
<h3 id="102-mathematical-justification">10.2 Mathematical Justification<a class="header-link" href="#102-mathematical-justification" title="Permanent link">&para;</a></h3>
<p>The MSE is:</p>
<p>$$E[e^2(n)] = E[(s(n) + n_0(n) - \hat{y}(n))^2]$$</p>
<p>Since $s(n)$ is uncorrelated with both $n_0(n)$ and $n_1(n)$:</p>
<p>$$E[e^2(n)] = E[s^2(n)] + E[(n_0(n) - \hat{y}(n))^2]$$</p>
<p>Minimizing $E[e^2(n)]$ with respect to $\mathbf{w}$ minimizes $E[(n_0(n) - \hat{y}(n))^2]$, which means $\hat{y}(n) \to n_0(n)$ and $e(n) \to s(n)$.</p>
<p><strong>The signal is extracted as a byproduct of the noise estimation.</strong></p>
<hr />
<h2 id="11-application-echo-cancellation">11. Application: Echo Cancellation<a class="header-link" href="#11-application-echo-cancellation" title="Permanent link">&para;</a></h2>
<h3 id="111-acoustic-echo-cancellation-aec">11.1 Acoustic Echo Cancellation (AEC)<a class="header-link" href="#111-acoustic-echo-cancellation-aec" title="Permanent link">&para;</a></h3>
<p>In speakerphone systems, the far-end speech is played through a loudspeaker, bounces around the room, and is picked up by the microphone. The adaptive filter models the acoustic path from loudspeaker to microphone.</p>
<div class="highlight"><pre><span></span><code>Far-end ‚îÄ‚îÄ‚ñ∂ Loudspeaker ‚îÄ‚îÄ‚ñ∂ Room ‚îÄ‚îÄ‚ñ∂ Microphone ‚îÄ‚îÄ‚ñ∂ Near-end + Echo
  x(n)                   h(n)                        d(n) = s(n) + h*x(n)
    ‚îÇ
    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Adaptive Filter ‚îÇ‚îÄ‚îÄ‚ñ∂ ≈∑(n) ‚âà h*x(n)
              ‚îÇ  w(n) ‚âà h        ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       e(n) = d(n) - ≈∑(n) ‚âà s(n)
</code></pre></div>

<p><strong>Challenges</strong>:
- The acoustic impulse response can be very long (100-500 ms at 8 kHz = 800-4000 taps)
- Double-talk: both speakers active simultaneously
- Non-stationarity: people move, doors open</p>
<h3 id="112-network-echo-cancellation">11.2 Network Echo Cancellation<a class="header-link" href="#112-network-echo-cancellation" title="Permanent link">&para;</a></h3>
<p>In telephone networks, impedance mismatches at the hybrid (2-wire to 4-wire conversion) create electrical echoes. The echo path is shorter but the requirements are strict (&gt;40 dB echo return loss enhancement).</p>
<hr />
<h2 id="12-application-channel-equalization">12. Application: Channel Equalization<a class="header-link" href="#12-application-channel-equalization" title="Permanent link">&para;</a></h2>
<h3 id="121-problem">12.1 Problem<a class="header-link" href="#121-problem" title="Permanent link">&para;</a></h3>
<p>A transmitted signal $a(n)$ passes through a dispersive channel $c(n)$, producing inter-symbol interference (ISI):</p>
<p>$$x(n) = \sum_k c(k) a(n-k) + v(n)$$</p>
<p>The equalizer is an adaptive filter that undoes the channel distortion:</p>
<p>$$\hat{a}(n - \Delta) = \mathbf{w}^T(n) \mathbf{x}(n)$$</p>
<p>where $\Delta$ is a decision delay chosen so that $w(n) * c(n) \approx \delta(n - \Delta)$.</p>
<h3 id="122-training-and-decision-directed-modes">12.2 Training and Decision-Directed Modes<a class="header-link" href="#122-training-and-decision-directed-modes" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Training mode</strong>: A known sequence is transmitted; $d(n) = a(n-\Delta)$</li>
<li><strong>Decision-directed mode</strong>: After initial convergence, use the slicer output $\hat{a}(n-\Delta)$ as $d(n)$</li>
</ul>
<hr />
<h2 id="13-application-adaptive-beamforming">13. Application: Adaptive Beamforming<a class="header-link" href="#13-application-adaptive-beamforming" title="Permanent link">&para;</a></h2>
<h3 id="131-problem">13.1 Problem<a class="header-link" href="#131-problem" title="Permanent link">&para;</a></h3>
<p>An array of $M$ sensors receives signals from multiple directions. The goal is to steer a beam toward the desired signal while nulling interferers.</p>
<p>The received signal at the array is:</p>
<p>$$\mathbf{x}(n) = s(n)\mathbf{a}(\theta_s) + \sum_{k=1}^{K} i_k(n)\mathbf{a}(\theta_k) + \mathbf{v}(n)$$</p>
<p>where $\mathbf{a}(\theta)$ is the <strong>steering vector</strong> for direction $\theta$.</p>
<h3 id="132-minimum-variance-distortionless-response-mvdr">13.2 Minimum Variance Distortionless Response (MVDR)<a class="header-link" href="#132-minimum-variance-distortionless-response-mvdr" title="Permanent link">&para;</a></h3>
<p>The Capon beamformer solves:</p>
<p>$$\min_{\mathbf{w}} \mathbf{w}^H \mathbf{R} \mathbf{w} \quad \text{subject to} \quad \mathbf{w}^H \mathbf{a}(\theta_s) = 1$$</p>
<p>Solution:</p>
<p>$$\mathbf{w}_{MVDR} = \frac{\mathbf{R}^{-1}\mathbf{a}(\theta_s)}{\mathbf{a}^H(\theta_s)\mathbf{R}^{-1}\mathbf{a}(\theta_s)}$$</p>
<p>Adaptive variants estimate $\mathbf{R}$ recursively using RLS-like updates.</p>
<hr />
<h2 id="14-python-implementation-complete-adaptive-filtering-toolkit">14. Python Implementation: Complete Adaptive Filtering Toolkit<a class="header-link" href="#14-python-implementation-complete-adaptive-filtering-toolkit" title="Permanent link">&para;</a></h2>
<h3 id="141-lms-nlms-and-rls-implementations">14.1 LMS, NLMS, and RLS Implementations<a class="header-link" href="#141-lms-nlms-and-rls-implementations" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>


<span class="k">def</span><span class="w"> </span><span class="nf">lms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    LMS adaptive filter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : ndarray</span>
<span class="sd">        Input signal</span>
<span class="sd">    d : ndarray</span>
<span class="sd">        Desired (reference) signal</span>
<span class="sd">    M : int</span>
<span class="sd">        Filter order (number of taps)</span>
<span class="sd">    mu : float</span>
<span class="sd">        Step size</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y : ndarray</span>
<span class="sd">        Filter output</span>
<span class="sd">    e : ndarray</span>
<span class="sd">        Error signal</span>
<span class="sd">    w_history : ndarray</span>
<span class="sd">        Weight history (N x M)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">w_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">:</span><span class="n">n</span><span class="o">-</span><span class="n">M</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">M</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">]])</span>
        <span class="c1"># Proper construction of input vector</span>
        <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="n">M</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span>
        <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_vec</span>
        <span class="n">w_history</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">w_history</span>


<span class="k">def</span><span class="w"> </span><span class="nf">nlms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu_tilde</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalized LMS adaptive filter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : ndarray</span>
<span class="sd">        Input signal</span>
<span class="sd">    d : ndarray</span>
<span class="sd">        Desired (reference) signal</span>
<span class="sd">    M : int</span>
<span class="sd">        Filter order</span>
<span class="sd">    mu_tilde : float</span>
<span class="sd">        Normalized step size (0 &lt; mu_tilde &lt; 2)</span>
<span class="sd">    delta : float</span>
<span class="sd">        Regularization constant</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y, e, w_history : ndarrays</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">w_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="n">M</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span>
        <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>

        <span class="n">norm_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="p">(</span><span class="n">mu_tilde</span> <span class="o">/</span> <span class="n">norm_sq</span><span class="p">)</span> <span class="o">*</span> <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_vec</span>
        <span class="n">w_history</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">w_history</span>


<span class="k">def</span><span class="w"> </span><span class="nf">rls_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Recursive Least Squares adaptive filter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : ndarray</span>
<span class="sd">        Input signal</span>
<span class="sd">    d : ndarray</span>
<span class="sd">        Desired (reference) signal</span>
<span class="sd">    M : int</span>
<span class="sd">        Filter order</span>
<span class="sd">    lam : float</span>
<span class="sd">        Forgetting factor (0 &lt; lambda &lt;= 1)</span>
<span class="sd">    delta : float</span>
<span class="sd">        Regularization for P initialization</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y, e, w_history : ndarrays</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">w_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="n">M</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Gain vector</span>
        <span class="n">Px</span> <span class="o">=</span> <span class="n">P</span> <span class="o">@</span> <span class="n">x_vec</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">lam</span> <span class="o">+</span> <span class="n">x_vec</span> <span class="o">@</span> <span class="n">Px</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">Px</span> <span class="o">/</span> <span class="n">denom</span>

        <span class="c1"># A priori error</span>
        <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span>
        <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>

        <span class="c1"># Weight update</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="n">e</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>

        <span class="c1"># Inverse correlation matrix update</span>
        <span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">P</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x_vec</span> <span class="o">@</span> <span class="n">P</span><span class="p">))</span>

        <span class="n">w_history</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">w_history</span>
</code></pre></div>

<h3 id="142-system-identification-example">14.2 System Identification Example<a class="header-link" href="#142-system-identification-example" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># System Identification Demo</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Unknown system (FIR)</span>
<span class="n">h_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="n">M</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">h_true</span><span class="p">)</span>

<span class="c1"># Generate input signal (white noise)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># System output + measurement noise</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h_true</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># Run adaptive filters</span>
<span class="n">mu_lms</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_lms</span><span class="p">,</span> <span class="n">w_lms</span> <span class="o">=</span> <span class="n">lms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu_lms</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_nlms</span><span class="p">,</span> <span class="n">w_nlms</span> <span class="o">=</span> <span class="n">nlms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu_tilde</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_rls</span><span class="p">,</span> <span class="n">w_rls</span> <span class="o">=</span> <span class="n">rls_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>

<span class="c1"># Plot learning curves</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># MSE learning curves (smoothed)</span>
<span class="n">window</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">mse_lms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">e_lms</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="n">mse_nlms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">e_nlms</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="n">mse_rls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">e_rls</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">mse_lms</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LMS&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">mse_nlms</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;NLMS&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">mse_rls</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;RLS&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Learning Curves: System Identification&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Final weight comparison</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">-</span> <span class="mf">1.5</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="n">h_true</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="n">w_lms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LMS&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="n">w_nlms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;NLMS&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_pos</span> <span class="o">+</span> <span class="mf">1.5</span><span class="o">*</span><span class="n">width</span><span class="p">,</span> <span class="n">w_rls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;RLS&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Tap index&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Weight value&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Identified Impulse Response&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;system_identification.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Print final weights</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True system:  &quot;</span><span class="p">,</span> <span class="n">h_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LMS weights:  &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">w_lms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NLMS weights: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">w_nlms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RLS weights:  &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">w_rls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div>

<h3 id="143-noise-cancellation-demo">14.3 Noise Cancellation Demo<a class="header-link" href="#143-noise-cancellation-demo" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Adaptive Noise Cancellation Demo</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1000.0</span>  <span class="c1"># 1 kHz sampling rate</span>

<span class="c1"># Clean signal: sum of sinusoids</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">120</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="c1"># Noise source</span>
<span class="n">noise_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># Noise that corrupts the signal (filtered version of noise source)</span>
<span class="n">noise_path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="n">n0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">noise_source</span><span class="p">,</span> <span class="n">noise_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>

<span class="c1"># Primary input: signal + noise</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n0</span>

<span class="c1"># Reference input: correlated with noise but not with signal</span>
<span class="c1"># (different path from the noise source)</span>
<span class="n">ref_path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">n1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">noise_source</span><span class="p">,</span> <span class="n">ref_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>

<span class="c1"># Apply adaptive noise canceller</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># Filter order (longer than the noise path to be safe)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">y_lms</span><span class="p">,</span> <span class="n">e_lms</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">lms_filter</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<span class="n">y_nlms</span><span class="p">,</span> <span class="n">e_nlms</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nlms_filter</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu_tilde</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">y_rls</span><span class="p">,</span> <span class="n">e_rls</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rls_filter</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.995</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="n">s</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Clean signal&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Clean Signal&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="n">d</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Signal + Noise&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Noisy Signal (Primary Input)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="n">e_nlms</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;NLMS output&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="n">s</span><span class="p">[:</span><span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Clean (reference)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Recovered Signal (NLMS Noise Canceller)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># SNR improvement over time</span>
<span class="n">window</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">snr_input</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span> <span class="o">/</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">n0</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
<span class="p">)</span>
<span class="n">residual_nlms</span> <span class="o">=</span> <span class="n">e_nlms</span> <span class="o">-</span> <span class="n">s</span>
<span class="n">snr_output</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span> <span class="o">/</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">residual_nlms</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">/</span><span class="n">window</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
<span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">snr_input</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Input SNR&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">snr_output</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Output SNR (NLMS)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time (s)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;SNR (dB)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;SNR Improvement&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;noise_cancellation.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute overall SNR improvement</span>
<span class="n">snr_in</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">M</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">n0</span><span class="p">[</span><span class="n">M</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">snr_out_nlms</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">e_nlms</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span> <span class="o">-</span> <span class="n">s</span><span class="p">[</span><span class="mi">1000</span><span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input SNR:       </span><span class="si">{</span><span class="n">snr_in</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> dB&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output SNR (NLMS): </span><span class="si">{</span><span class="n">snr_out_nlms</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> dB&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SNR improvement:   </span><span class="si">{</span><span class="n">snr_out_nlms</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">snr_in</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> dB&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="144-tracking-a-time-varying-system">14.4 Tracking a Time-Varying System<a class="header-link" href="#144-tracking-a-time-varying-system" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Tracking a time-varying system</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">4000</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

<span class="c1"># Time-varying system: coefficients change at n=2000</span>
<span class="n">h1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">])</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="n">M</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2000</span><span class="p">:</span>
        <span class="n">d</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h1</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">d</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h2</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>

<span class="c1"># Compare algorithms</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_lms</span><span class="p">,</span> <span class="n">w_lms</span> <span class="o">=</span> <span class="n">lms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_nlms</span><span class="p">,</span> <span class="n">w_nlms</span> <span class="o">=</span> <span class="n">nlms_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">mu_tilde</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">e_rls</span><span class="p">,</span> <span class="n">w_rls</span> <span class="o">=</span> <span class="n">rls_filter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>

<span class="c1"># Plot weight trajectories</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LMS&#39;</span><span class="p">,</span> <span class="s1">&#39;NLMS&#39;</span><span class="p">,</span> <span class="s1">&#39;RLS&#39;</span><span class="p">]</span>
<span class="n">w_histories</span> <span class="o">=</span> <span class="p">[</span><span class="n">w_lms</span><span class="p">,</span> <span class="n">w_nlms</span><span class="p">,</span> <span class="n">w_rls</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:orange&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:green&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">w_hist</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">titles</span><span class="p">,</span> <span class="n">w_histories</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w_hist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;w[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="c1"># Plot true values</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">h1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">h1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">h1</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;System change&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s1"> Weight Tracking&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;tracking_demo.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="15-exercises">15. Exercises<a class="header-link" href="#15-exercises" title="Permanent link">&para;</a></h2>
<h3 id="exercise-1-wiener-filter">Exercise 1: Wiener Filter<a class="header-link" href="#exercise-1-wiener-filter" title="Permanent link">&para;</a></h3>
<p>Consider a system where $x(n)$ is white noise with variance $\sigma_x^2 = 1$ and the desired signal is $d(n) = 0.8x(n) + 0.5x(n-1) - 0.3x(n-2) + v(n)$, where $v(n)$ is white noise with variance $\sigma_v^2 = 0.1$, independent of $x(n)$.</p>
<p>(a) Compute the autocorrelation matrix $\mathbf{R}$ for a 3-tap Wiener filter.</p>
<p>(b) Compute the cross-correlation vector $\mathbf{p}$.</p>
<p>(c) Find the optimal Wiener filter $\mathbf{w}_{opt}$ by solving $\mathbf{R}\mathbf{w}_{opt} = \mathbf{p}$.</p>
<p>(d) Compute the minimum MSE $J_{min}$.</p>
<h3 id="exercise-2-lms-convergence">Exercise 2: LMS Convergence<a class="header-link" href="#exercise-2-lms-convergence" title="Permanent link">&para;</a></h3>
<p>An LMS filter with $M = 10$ taps is applied to an input signal with autocorrelation matrix having eigenvalues $\lambda_{max} = 5.0$ and $\lambda_{min} = 0.1$.</p>
<p>(a) What is the maximum step size for mean convergence?</p>
<p>(b) What is the condition number $\chi(\mathbf{R})$?</p>
<p>(c) If $\mu = 0.01$, compute the misadjustment $\mathcal{M}$, given $\text{tr}(\mathbf{R}) = 10$.</p>
<p>(d) Estimate the convergence time constant $\tau_{mse}$ for the slowest mode.</p>
<p>(e) Explain qualitatively how the convergence would change if you whitened the input before applying LMS.</p>
<h3 id="exercise-3-nlms-vs-lms">Exercise 3: NLMS vs LMS<a class="header-link" href="#exercise-3-nlms-vs-lms" title="Permanent link">&para;</a></h3>
<p>Implement both LMS and NLMS for noise cancellation with a non-stationary input signal whose power alternates between 0.1 and 10.0 every 500 samples. Use a filter order of $M = 16$.</p>
<p>(a) Show that LMS with a fixed step size either diverges during high-power segments or converges too slowly during low-power segments.</p>
<p>(b) Demonstrate that NLMS handles the power variation gracefully.</p>
<p>(c) Plot the MSE learning curves for both algorithms.</p>
<h3 id="exercise-4-rls-implementation">Exercise 4: RLS Implementation<a class="header-link" href="#exercise-4-rls-implementation" title="Permanent link">&para;</a></h3>
<p>Implement RLS with forgetting factor $\lambda = 0.99$ for identifying a system with impulse response $h = [1, -0.5, 0.25, -0.125]$.</p>
<p>(a) Plot the convergence of each weight to its true value. Compare with LMS and NLMS.</p>
<p>(b) Vary $\lambda$ from 0.9 to 1.0 and plot the steady-state MSE vs convergence time tradeoff.</p>
<p>(c) Introduce a system change at $n = 1000$ (change $h$ to $[0.5, 0.3, -0.2, 0.1]$). Compare the tracking performance of LMS, NLMS, and RLS.</p>
<h3 id="exercise-5-echo-cancellation-simulation">Exercise 5: Echo Cancellation Simulation<a class="header-link" href="#exercise-5-echo-cancellation-simulation" title="Permanent link">&para;</a></h3>
<p>Simulate an acoustic echo cancellation scenario:</p>
<p>(a) Generate a "far-end speech" signal as a sum of sinusoids with varying frequencies.</p>
<p>(b) Create a room impulse response (use an exponentially decaying random sequence of length 100).</p>
<p>(c) Add near-end noise.</p>
<p>(d) Apply NLMS with filter order 128. Plot the echo return loss enhancement (ERLE) over time:</p>
<p>$$\text{ERLE}(n) = 10 \log_{10} \frac{E[d^2(n)]}{E[e^2(n)]}$$</p>
<p>(e) Investigate the effect of double-talk (adding near-end speech) on the adaptive filter.</p>
<h3 id="exercise-6-adaptive-equalization">Exercise 6: Adaptive Equalization<a class="header-link" href="#exercise-6-adaptive-equalization" title="Permanent link">&para;</a></h3>
<p>A digital communication channel has impulse response $c = [0.5, 1.0, 0.5]$ (introduces ISI).</p>
<p>(a) Generate a random BPSK signal ($a(n) \in \{-1, +1\}$) and pass it through the channel. Add noise at SNR = 20 dB.</p>
<p>(b) Design an adaptive equalizer using LMS with $M = 11$ taps and decision delay $\Delta = 5$.</p>
<p>(c) Plot the bit error rate (BER) as a function of training length.</p>
<p>(d) Switch to decision-directed mode after 500 training symbols and verify that the BER remains stable.</p>
<p>(e) Compare the eye diagram before and after equalization.</p>
<h3 id="exercise-7-effect-of-filter-order">Exercise 7: Effect of Filter Order<a class="header-link" href="#exercise-7-effect-of-filter-order" title="Permanent link">&para;</a></h3>
<p>For the system identification problem with true system $h = [0.5, 1.2, -0.8, 0.3, -0.1]$:</p>
<p>(a) Run LMS with filter orders $M = 3, 5, 7, 10, 20$ and compare the steady-state MSE.</p>
<p>(b) Explain what happens when $M < 5$ (under-modeling) and $M > 5$ (over-modeling).</p>
<p>(c) Plot the identified impulse responses for each $M$.</p>
<hr />
<h2 id="16-summary">16. Summary<a class="header-link" href="#16-summary" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Key Formula / Idea</th>
</tr>
</thead>
<tbody>
<tr>
<td>Wiener filter</td>
<td>$\mathbf{w}_{opt} = \mathbf{R}^{-1}\mathbf{p}$ (optimal MMSE)</td>
</tr>
<tr>
<td>Steepest descent</td>
<td>$\mathbf{w}(n+1) = \mathbf{w}(n) + 2\mu(\mathbf{p} - \mathbf{R}\mathbf{w}(n))$</td>
</tr>
<tr>
<td>Convergence condition</td>
<td>$0 < \mu < 1/\lambda_{max}$</td>
</tr>
<tr>
<td>LMS update</td>
<td>$\mathbf{w}(n+1) = \mathbf{w}(n) + \mu \, e(n) \, \mathbf{x}(n)$</td>
</tr>
<tr>
<td>LMS misadjustment</td>
<td>$\mathcal{M} = \mu \, \text{tr}(\mathbf{R})$</td>
</tr>
<tr>
<td>NLMS update</td>
<td>$\mathbf{w}(n+1) = \mathbf{w}(n) + \frac{\tilde{\mu}}{\|\mathbf{x}\|^2+\delta} e(n)\mathbf{x}(n)$</td>
</tr>
<tr>
<td>RLS gain</td>
<td>$\mathbf{k}(n) = \frac{\mathbf{P}(n-1)\mathbf{x}(n)}{\lambda + \mathbf{x}^T(n)\mathbf{P}(n-1)\mathbf{x}(n)}$</td>
</tr>
<tr>
<td>Forgetting factor memory</td>
<td>$N_{eff} = 1/(1-\lambda)$</td>
</tr>
<tr>
<td>Noise cancellation</td>
<td>Error signal $e(n) = d(n) - \hat{y}(n) \approx s(n)$</td>
</tr>
<tr>
<td>Tradeoff</td>
<td>Fast convergence vs low misadjustment</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaways</strong>:
1. The Wiener filter provides the theoretical optimum but requires known statistics.
2. LMS approximates the gradient with instantaneous estimates -- simple, robust, $O(M)$.
3. NLMS normalizes by input power -- better stability with varying signal levels.
4. RLS uses all past data with exponential weighting -- fast convergence at $O(M^2)$ cost.
5. The misadjustment-convergence tradeoff is fundamental to all adaptive algorithms.
6. Adaptive filters power numerous applications from noise cancellation to equalization.</p>
<hr />
<h2 id="17-references">17. References<a class="header-link" href="#17-references" title="Permanent link">&para;</a></h2>
<ol>
<li>S. Haykin, <em>Adaptive Filter Theory</em>, 5th ed., Pearson, 2014.</li>
<li>A.H. Sayed, <em>Adaptive Filters</em>, Wiley-IEEE Press, 2008.</li>
<li>P.S.R. Diniz, <em>Adaptive Filtering: Algorithms and Practical Implementation</em>, 4th ed., Springer, 2013.</li>
<li>B. Widrow and S.D. Stearns, <em>Adaptive Signal Processing</em>, Pearson, 1985.</li>
<li>S. Haykin, "Adaptive filter theory," in <em>Proc. IEEE</em>, vol. 90, no. 2, pp. 211-259, 2002.</li>
<li>B. Farhang-Boroujeny, <em>Adaptive Filters: Theory and Applications</em>, 2nd ed., Wiley, 2013.</li>
</ol>
<hr />
<p><strong>Previous</strong>: <a href="./12_Multirate_Signal_Processing.md">12. Multirate Signal Processing</a> | <strong>Next</strong>: <a href="./14_Time_Frequency_Analysis.md">14. Time-Frequency Analysis</a></p>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/en/Signal_Processing/12_Spectral_Analysis.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Spectral Analysis</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">üîó</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/en/Signal_Processing/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">üìã</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/en/Signal_Processing/14_Time_Frequency_Analysis.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">14. Time-Frequency Analysis</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">‚Üë</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}