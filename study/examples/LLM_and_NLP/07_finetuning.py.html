{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>07_finetuning.py - Examples</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">π </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item active">
                    <span class="nav-icon">π’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        ν•κµ­μ–΄
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">β€οΈ</span>
                    <span class="theme-icon dark">π™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/examples/">Examples</a>
    <span class="separator">/</span>
    <a href="/study/examples/LLM_and_NLP/">LLM and NLP</a>
    <span class="separator">/</span>
    <span class="current">07_finetuning.py</span>
</nav>

            </header>

            <div class="content">
                
<article class="example-article">
    <header class="example-header">
        <h1>07_finetuning.py</h1>
        <div class="example-actions">
            <a href="07_finetuning.py" download class="btn">Download</a>
            <button class="btn" id="copy-code-btn">Copy code</button>
        </div>
    </header>

    <div class="example-meta">
        <span>python</span>
        <span>304 lines</span>
        <span>7.2 KB</span>
    </div>

    <div class="example-code markdown-body">
        <div class="highlight"><pre><span></span><code><span class="linenos">  1</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">  2</span><span class="sd">07. νμΈνλ‹ μμ </span>
<span class="linenos">  3</span>
<span class="linenos">  4</span><span class="sd">HuggingFace Trainerλ¥Ό μ‚¬μ©ν• λ¨λΈ νμΈνλ‹</span>
<span class="linenos">  5</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">  6</span>
<span class="linenos">  7</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="linenos">  8</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;νμΈνλ‹&quot;</span><span class="p">)</span>
<span class="linenos">  9</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="linenos"> 10</span>
<span class="linenos"> 11</span>
<span class="linenos"> 12</span><span class="c1"># ============================================</span>
<span class="linenos"> 13</span><span class="c1"># 1. κΈ°λ³Έ νμΈνλ‹ (μ½”λ“ μμ‹)</span>
<span class="linenos"> 14</span><span class="c1"># ============================================</span>
<span class="linenos"> 15</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[1] κΈ°λ³Έ νμΈνλ‹&quot;</span><span class="p">)</span>
<span class="linenos"> 16</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos"> 17</span>
<span class="linenos"> 18</span><span class="n">basic_finetuning</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos"> 19</span><span class="s1">from transformers import (</span>
<span class="linenos"> 20</span><span class="s1">    AutoTokenizer,</span>
<span class="linenos"> 21</span><span class="s1">    AutoModelForSequenceClassification,</span>
<span class="linenos"> 22</span><span class="s1">    TrainingArguments,</span>
<span class="linenos"> 23</span><span class="s1">    Trainer</span>
<span class="linenos"> 24</span><span class="s1">)</span>
<span class="linenos"> 25</span><span class="s1">from datasets import load_dataset</span>
<span class="linenos"> 26</span>
<span class="linenos"> 27</span><span class="s1"># λ°μ΄ν„° λ΅λ“</span>
<span class="linenos"> 28</span><span class="s1">dataset = load_dataset(&quot;imdb&quot;)</span>
<span class="linenos"> 29</span>
<span class="linenos"> 30</span><span class="s1"># ν† ν¬λ‚μ΄μ €</span>
<span class="linenos"> 31</span><span class="s1">tokenizer = AutoTokenizer.from_pretrained(&quot;bert-base-uncased&quot;)</span>
<span class="linenos"> 32</span>
<span class="linenos"> 33</span><span class="s1">def tokenize(batch):</span>
<span class="linenos"> 34</span><span class="s1">    return tokenizer(batch[&quot;text&quot;], truncation=True, padding=&quot;max_length&quot;, max_length=256)</span>
<span class="linenos"> 35</span>
<span class="linenos"> 36</span><span class="s1">tokenized = dataset.map(tokenize, batched=True)</span>
<span class="linenos"> 37</span>
<span class="linenos"> 38</span><span class="s1"># λ¨λΈ</span>
<span class="linenos"> 39</span><span class="s1">model = AutoModelForSequenceClassification.from_pretrained(&quot;bert-base-uncased&quot;, num_labels=2)</span>
<span class="linenos"> 40</span>
<span class="linenos"> 41</span><span class="s1"># ν•™μµ μ„¤μ •</span>
<span class="linenos"> 42</span><span class="s1">args = TrainingArguments(</span>
<span class="linenos"> 43</span><span class="s1">    output_dir=&quot;./results&quot;,</span>
<span class="linenos"> 44</span><span class="s1">    num_train_epochs=3,</span>
<span class="linenos"> 45</span><span class="s1">    per_device_train_batch_size=16,</span>
<span class="linenos"> 46</span><span class="s1">    learning_rate=2e-5,</span>
<span class="linenos"> 47</span><span class="s1">    evaluation_strategy=&quot;epoch&quot;,</span>
<span class="linenos"> 48</span><span class="s1">)</span>
<span class="linenos"> 49</span>
<span class="linenos"> 50</span><span class="s1"># Trainer</span>
<span class="linenos"> 51</span><span class="s1">trainer = Trainer(</span>
<span class="linenos"> 52</span><span class="s1">    model=model,</span>
<span class="linenos"> 53</span><span class="s1">    args=args,</span>
<span class="linenos"> 54</span><span class="s1">    train_dataset=tokenized[&quot;train&quot;],</span>
<span class="linenos"> 55</span><span class="s1">    eval_dataset=tokenized[&quot;test&quot;],</span>
<span class="linenos"> 56</span><span class="s1">)</span>
<span class="linenos"> 57</span>
<span class="linenos"> 58</span><span class="s1"># ν•™μµ</span>
<span class="linenos"> 59</span><span class="s1">trainer.train()</span>
<span class="linenos"> 60</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos"> 61</span><span class="nb">print</span><span class="p">(</span><span class="n">basic_finetuning</span><span class="p">)</span>
<span class="linenos"> 62</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span><span class="c1"># ============================================</span>
<span class="linenos"> 65</span><span class="c1"># 2. LoRA νμΈνλ‹</span>
<span class="linenos"> 66</span><span class="c1"># ============================================</span>
<span class="linenos"> 67</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[2] LoRA νμΈνλ‹&quot;</span><span class="p">)</span>
<span class="linenos"> 68</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos"> 69</span>
<span class="linenos"> 70</span><span class="n">lora_code</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos"> 71</span><span class="s1">from peft import LoraConfig, get_peft_model, TaskType</span>
<span class="linenos"> 72</span>
<span class="linenos"> 73</span><span class="s1"># LoRA μ„¤μ •</span>
<span class="linenos"> 74</span><span class="s1">lora_config = LoraConfig(</span>
<span class="linenos"> 75</span><span class="s1">    r=8,                           # λ­ν¬</span>
<span class="linenos"> 76</span><span class="s1">    lora_alpha=32,                 # μ¤μΌ€μΌλ§</span>
<span class="linenos"> 77</span><span class="s1">    target_modules=[&quot;query&quot;, &quot;value&quot;],  # μ μ© λ¨λ“</span>
<span class="linenos"> 78</span><span class="s1">    lora_dropout=0.1,</span>
<span class="linenos"> 79</span><span class="s1">    bias=&quot;none&quot;,</span>
<span class="linenos"> 80</span><span class="s1">    task_type=TaskType.SEQ_CLS</span>
<span class="linenos"> 81</span><span class="s1">)</span>
<span class="linenos"> 82</span>
<span class="linenos"> 83</span><span class="s1"># λ¨λΈμ— LoRA μ μ©</span>
<span class="linenos"> 84</span><span class="s1">model = AutoModelForSequenceClassification.from_pretrained(&quot;bert-base-uncased&quot;, num_labels=2)</span>
<span class="linenos"> 85</span><span class="s1">model = get_peft_model(model, lora_config)</span>
<span class="linenos"> 86</span>
<span class="linenos"> 87</span><span class="s1"># ν•™μµ κ°€λ¥ν• νλΌλ―Έν„° ν™•μΈ</span>
<span class="linenos"> 88</span><span class="s1">model.print_trainable_parameters()</span>
<span class="linenos"> 89</span><span class="s1"># trainable: 0.27% (μ•½ 300K / 110M)</span>
<span class="linenos"> 90</span>
<span class="linenos"> 91</span><span class="s1"># μΌλ° Trainerλ΅ ν•™μµ</span>
<span class="linenos"> 92</span><span class="s1">trainer = Trainer(model=model, args=args, ...)</span>
<span class="linenos"> 93</span><span class="s1">trainer.train()</span>
<span class="linenos"> 94</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos"> 95</span><span class="nb">print</span><span class="p">(</span><span class="n">lora_code</span><span class="p">)</span>
<span class="linenos"> 96</span>
<span class="linenos"> 97</span>
<span class="linenos"> 98</span><span class="c1"># ============================================</span>
<span class="linenos"> 99</span><span class="c1"># 3. QLoRA (μ–‘μν™” + LoRA)</span>
<span class="linenos">100</span><span class="c1"># ============================================</span>
<span class="linenos">101</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[3] QLoRA&quot;</span><span class="p">)</span>
<span class="linenos">102</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos">103</span>
<span class="linenos">104</span><span class="n">qlora_code</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">105</span><span class="s1">from transformers import BitsAndBytesConfig</span>
<span class="linenos">106</span><span class="s1">import torch</span>
<span class="linenos">107</span>
<span class="linenos">108</span><span class="s1"># 4λΉ„νΈ μ–‘μν™” μ„¤μ •</span>
<span class="linenos">109</span><span class="s1">bnb_config = BitsAndBytesConfig(</span>
<span class="linenos">110</span><span class="s1">    load_in_4bit=True,</span>
<span class="linenos">111</span><span class="s1">    bnb_4bit_use_double_quant=True,</span>
<span class="linenos">112</span><span class="s1">    bnb_4bit_quant_type=&quot;nf4&quot;,</span>
<span class="linenos">113</span><span class="s1">    bnb_4bit_compute_dtype=torch.bfloat16</span>
<span class="linenos">114</span><span class="s1">)</span>
<span class="linenos">115</span>
<span class="linenos">116</span><span class="s1"># μ–‘μν™”λ λ¨λΈ λ΅λ“</span>
<span class="linenos">117</span><span class="s1">model = AutoModelForCausalLM.from_pretrained(</span>
<span class="linenos">118</span><span class="s1">    &quot;meta-llama/Llama-2-7b-hf&quot;,</span>
<span class="linenos">119</span><span class="s1">    quantization_config=bnb_config,</span>
<span class="linenos">120</span><span class="s1">    device_map=&quot;auto&quot;</span>
<span class="linenos">121</span><span class="s1">)</span>
<span class="linenos">122</span>
<span class="linenos">123</span><span class="s1"># LoRA μ μ©</span>
<span class="linenos">124</span><span class="s1">model = get_peft_model(model, lora_config)</span>
<span class="linenos">125</span>
<span class="linenos">126</span><span class="s1"># ν•™μµ</span>
<span class="linenos">127</span><span class="s1">trainer = Trainer(model=model, ...)</span>
<span class="linenos">128</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">129</span><span class="nb">print</span><span class="p">(</span><span class="n">qlora_code</span><span class="p">)</span>
<span class="linenos">130</span>
<span class="linenos">131</span>
<span class="linenos">132</span><span class="c1"># ============================================</span>
<span class="linenos">133</span><span class="c1"># 4. μ»¤μ¤ν…€ λ©”νΈλ¦­</span>
<span class="linenos">134</span><span class="c1"># ============================================</span>
<span class="linenos">135</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[4] μ»¤μ¤ν…€ λ©”νΈλ¦­&quot;</span><span class="p">)</span>
<span class="linenos">136</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos">137</span>
<span class="linenos">138</span><span class="k">try</span><span class="p">:</span>
<span class="linenos">139</span>    <span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="linenos">140</span>    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="linenos">141</span>
<span class="linenos">142</span>    <span class="c1"># λ©”νΈλ¦­ λ΅λ“</span>
<span class="linenos">143</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="linenos">144</span>    <span class="n">f1</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;f1&quot;</span><span class="p">)</span>
<span class="linenos">145</span>
<span class="linenos">146</span>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
<span class="linenos">147</span>        <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
<span class="linenos">148</span>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">149</span>        <span class="k">return</span> <span class="p">{</span>
<span class="linenos">150</span>            <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
<span class="linenos">151</span>            <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)[</span><span class="s2">&quot;f1&quot;</span><span class="p">]</span>
<span class="linenos">152</span>        <span class="p">}</span>
<span class="linenos">153</span>
<span class="linenos">154</span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;μ»¤μ¤ν…€ λ©”νΈλ¦­ ν•¨μ μ •μ μ™„λ£&quot;</span><span class="p">)</span>
<span class="linenos">155</span>
<span class="linenos">156</span>    <span class="c1"># ν…μ¤νΈ</span>
<span class="linenos">157</span>    <span class="n">mock_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="linenos">158</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">mock_pred</span><span class="p">)</span>
<span class="linenos">159</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ν…μ¤νΈ κ²°κ³Ό: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">160</span>
<span class="linenos">161</span><span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
<span class="linenos">162</span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;evaluate λ―Έμ„¤μΉ (pip install evaluate)&quot;</span><span class="p">)</span>
<span class="linenos">163</span>
<span class="linenos">164</span>
<span class="linenos">165</span><span class="c1"># ============================================</span>
<span class="linenos">166</span><span class="c1"># 5. NER νμΈνλ‹</span>
<span class="linenos">167</span><span class="c1"># ============================================</span>
<span class="linenos">168</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[5] NER νμΈνλ‹&quot;</span><span class="p">)</span>
<span class="linenos">169</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos">170</span>
<span class="linenos">171</span><span class="n">ner_code</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">172</span><span class="s1">from transformers import AutoModelForTokenClassification</span>
<span class="linenos">173</span>
<span class="linenos">174</span><span class="s1"># λ μ΄λΈ”</span>
<span class="linenos">175</span><span class="s1">label_names = [&quot;O&quot;, &quot;B-PER&quot;, &quot;I-PER&quot;, &quot;B-ORG&quot;, &quot;I-ORG&quot;, &quot;B-LOC&quot;, &quot;I-LOC&quot;]</span>
<span class="linenos">176</span>
<span class="linenos">177</span><span class="s1"># λ¨λΈ</span>
<span class="linenos">178</span><span class="s1">model = AutoModelForTokenClassification.from_pretrained(</span>
<span class="linenos">179</span><span class="s1">    &quot;bert-base-uncased&quot;,</span>
<span class="linenos">180</span><span class="s1">    num_labels=len(label_names)</span>
<span class="linenos">181</span><span class="s1">)</span>
<span class="linenos">182</span>
<span class="linenos">183</span><span class="s1"># ν† ν° μ •λ ¬ (μ„λΈμ›λ“ μ²λ¦¬)</span>
<span class="linenos">184</span><span class="s1">def tokenize_and_align_labels(examples):</span>
<span class="linenos">185</span><span class="s1">    tokenized = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True)</span>
<span class="linenos">186</span>
<span class="linenos">187</span><span class="s1">    labels = []</span>
<span class="linenos">188</span><span class="s1">    for i, label in enumerate(examples[&quot;ner_tags&quot;]):</span>
<span class="linenos">189</span><span class="s1">        word_ids = tokenized.word_ids(batch_index=i)</span>
<span class="linenos">190</span><span class="s1">        label_ids = []</span>
<span class="linenos">191</span><span class="s1">        for word_idx in word_ids:</span>
<span class="linenos">192</span><span class="s1">            if word_idx is None:</span>
<span class="linenos">193</span><span class="s1">                label_ids.append(-100)  # νΉμ ν† ν°</span>
<span class="linenos">194</span><span class="s1">            else:</span>
<span class="linenos">195</span><span class="s1">                label_ids.append(label[word_idx])</span>
<span class="linenos">196</span><span class="s1">        labels.append(label_ids)</span>
<span class="linenos">197</span>
<span class="linenos">198</span><span class="s1">    tokenized[&quot;labels&quot;] = labels</span>
<span class="linenos">199</span><span class="s1">    return tokenized</span>
<span class="linenos">200</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">201</span><span class="nb">print</span><span class="p">(</span><span class="n">ner_code</span><span class="p">)</span>
<span class="linenos">202</span>
<span class="linenos">203</span>
<span class="linenos">204</span><span class="c1"># ============================================</span>
<span class="linenos">205</span><span class="c1"># 6. QA νμΈνλ‹</span>
<span class="linenos">206</span><span class="c1"># ============================================</span>
<span class="linenos">207</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[6] QA νμΈνλ‹&quot;</span><span class="p">)</span>
<span class="linenos">208</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos">209</span>
<span class="linenos">210</span><span class="n">qa_code</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">211</span><span class="s1">from transformers import AutoModelForQuestionAnswering</span>
<span class="linenos">212</span>
<span class="linenos">213</span><span class="s1"># λ¨λΈ</span>
<span class="linenos">214</span><span class="s1">model = AutoModelForQuestionAnswering.from_pretrained(&quot;bert-base-uncased&quot;)</span>
<span class="linenos">215</span>
<span class="linenos">216</span><span class="s1"># μ „μ²λ¦¬ (μ‹μ‘/λ μ„μΉ μ°ΎκΈ°)</span>
<span class="linenos">217</span><span class="s1">def prepare_train_features(examples):</span>
<span class="linenos">218</span><span class="s1">    tokenized = tokenizer(</span>
<span class="linenos">219</span><span class="s1">        examples[&quot;question&quot;],</span>
<span class="linenos">220</span><span class="s1">        examples[&quot;context&quot;],</span>
<span class="linenos">221</span><span class="s1">        truncation=&quot;only_second&quot;,</span>
<span class="linenos">222</span><span class="s1">        max_length=384,</span>
<span class="linenos">223</span><span class="s1">        stride=128,</span>
<span class="linenos">224</span><span class="s1">        return_overflowing_tokens=True,</span>
<span class="linenos">225</span><span class="s1">        return_offsets_mapping=True,</span>
<span class="linenos">226</span><span class="s1">        padding=&quot;max_length&quot;,</span>
<span class="linenos">227</span><span class="s1">    )</span>
<span class="linenos">228</span>
<span class="linenos">229</span><span class="s1">    # λ‹µλ³€ μ„μΉλ¥Ό ν† ν° μ„μΉλ΅ λ³€ν™</span>
<span class="linenos">230</span><span class="s1">    tokenized[&quot;start_positions&quot;] = []</span>
<span class="linenos">231</span><span class="s1">    tokenized[&quot;end_positions&quot;] = []</span>
<span class="linenos">232</span>
<span class="linenos">233</span><span class="s1">    for i, offsets in enumerate(tokenized[&quot;offset_mapping&quot;]):</span>
<span class="linenos">234</span><span class="s1">        # λ‹µλ³€ μ‹μ‘/λ λ¬Έμ μ„μΉ β†’ ν† ν° μ„μΉ</span>
<span class="linenos">235</span><span class="s1">        ...</span>
<span class="linenos">236</span>
<span class="linenos">237</span><span class="s1">    return tokenized</span>
<span class="linenos">238</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">239</span><span class="nb">print</span><span class="p">(</span><span class="n">qa_code</span><span class="p">)</span>
<span class="linenos">240</span>
<span class="linenos">241</span>
<span class="linenos">242</span><span class="c1"># ============================================</span>
<span class="linenos">243</span><span class="c1"># 7. ν•™μµ μµμ ν™” ν</span>
<span class="linenos">244</span><span class="c1"># ============================================</span>
<span class="linenos">245</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[7] ν•™μµ μµμ ν™” ν&quot;</span><span class="p">)</span>
<span class="linenos">246</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="linenos">247</span>
<span class="linenos">248</span><span class="n">optimization_tips</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">249</span><span class="s1"># Gradient Checkpointing (λ©”λ¨λ¦¬ μ μ•½)</span>
<span class="linenos">250</span><span class="s1">model.gradient_checkpointing_enable()</span>
<span class="linenos">251</span>
<span class="linenos">252</span><span class="s1"># Mixed Precision (μ†λ„ ν–¥μƒ)</span>
<span class="linenos">253</span><span class="s1">args = TrainingArguments(</span>
<span class="linenos">254</span><span class="s1">    ...,</span>
<span class="linenos">255</span><span class="s1">    fp16=True,  # λλ” bf16=True</span>
<span class="linenos">256</span><span class="s1">)</span>
<span class="linenos">257</span>
<span class="linenos">258</span><span class="s1"># Gradient Accumulation (ν° λ°°μΉ ν¨κ³Ό)</span>
<span class="linenos">259</span><span class="s1">args = TrainingArguments(</span>
<span class="linenos">260</span><span class="s1">    per_device_train_batch_size=4,</span>
<span class="linenos">261</span><span class="s1">    gradient_accumulation_steps=8,  # μ‹¤ν¨ λ°°μΉ = 32</span>
<span class="linenos">262</span><span class="s1">)</span>
<span class="linenos">263</span>
<span class="linenos">264</span><span class="s1"># DeepSpeed (λ¶„μ‚° ν•™μµ)</span>
<span class="linenos">265</span><span class="s1">args = TrainingArguments(</span>
<span class="linenos">266</span><span class="s1">    ...,</span>
<span class="linenos">267</span><span class="s1">    deepspeed=&quot;ds_config.json&quot;</span>
<span class="linenos">268</span><span class="s1">)</span>
<span class="linenos">269</span>
<span class="linenos">270</span><span class="s1"># Learning Rate Scheduler</span>
<span class="linenos">271</span><span class="s1">args = TrainingArguments(</span>
<span class="linenos">272</span><span class="s1">    learning_rate=2e-5,</span>
<span class="linenos">273</span><span class="s1">    warmup_ratio=0.1,</span>
<span class="linenos">274</span><span class="s1">    lr_scheduler_type=&quot;cosine&quot;,</span>
<span class="linenos">275</span><span class="s1">)</span>
<span class="linenos">276</span><span class="s1">&#39;&#39;&#39;</span>
<span class="linenos">277</span><span class="nb">print</span><span class="p">(</span><span class="n">optimization_tips</span><span class="p">)</span>
<span class="linenos">278</span>
<span class="linenos">279</span>
<span class="linenos">280</span><span class="c1"># ============================================</span>
<span class="linenos">281</span><span class="c1"># μ •λ¦¬</span>
<span class="linenos">282</span><span class="c1"># ============================================</span>
<span class="linenos">283</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="linenos">284</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;νμΈνλ‹ μ •λ¦¬&quot;</span><span class="p">)</span>
<span class="linenos">285</span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="linenos">286</span>
<span class="linenos">287</span><span class="n">summary</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="linenos">288</span><span class="s2">νμΈνλ‹ μ„ νƒ κ°€μ΄λ“:</span>
<span class="linenos">289</span><span class="s2">    - μ¶©λ¶„ν• GPU: Full Fine-tuning</span>
<span class="linenos">290</span><span class="s2">    - μ ν•λ λ©”λ¨λ¦¬: LoRA / QLoRA</span>
<span class="linenos">291</span><span class="s2">    - λ§¤μ° μ μ€ λ°μ΄ν„°: Prompt Tuning</span>
<span class="linenos">292</span>
<span class="linenos">293</span><span class="s2">ν•µμ‹¬ μ½”λ“:</span>
<span class="linenos">294</span><span class="s2">    # Trainer</span>
<span class="linenos">295</span><span class="s2">    trainer = Trainer(model=model, args=args, train_dataset=dataset)</span>
<span class="linenos">296</span><span class="s2">    trainer.train()</span>
<span class="linenos">297</span>
<span class="linenos">298</span><span class="s2">    # LoRA</span>
<span class="linenos">299</span><span class="s2">    from peft import LoraConfig, get_peft_model</span>
<span class="linenos">300</span><span class="s2">    config = LoraConfig(r=8, target_modules=[&quot;query&quot;, &quot;value&quot;])</span>
<span class="linenos">301</span><span class="s2">    model = get_peft_model(model, config)</span>
<span class="linenos">302</span><span class="s2">&quot;&quot;&quot;</span>
<span class="linenos">303</span><span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div>

    </div>
</article>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.getElementById('copy-code-btn').addEventListener('click', function() {
        var code = document.querySelector('.example-code .highlight');
        // Extract just the code text, not line numbers
        var lines = code.querySelectorAll('.code pre span.line');
        var text;
        if (lines.length > 0) {
            text = Array.from(lines).map(function(l) { return l.textContent; }).join('\n');
        } else {
            // Fallback: get all code text
            var codeEl = code.querySelector('pre code') || code.querySelector('pre');
            text = codeEl ? codeEl.textContent : code.textContent;
        }
        navigator.clipboard.writeText(text);
        this.textContent = 'Copied!';
        var btn = this;
        setTimeout(function() { btn.textContent = 'Copy code'; }, 2000);
    });
</script>

</body>
</html>
{% endraw %}