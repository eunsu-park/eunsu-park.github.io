{% raw %}
<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>academic_paper.tex - Examples</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/en/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/en/" class="nav-item ">
                    <span class="nav-icon">üè†</span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item active">
                    <span class="nav-icon">üíª</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/en/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" selected>
                        English
                    </option>
                    
                    <option value="ko" >
                        ÌïúÍµ≠Ïñ¥
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">‚òÄÔ∏è</span>
                    <span class="theme-icon dark">üåô</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/examples/">Examples</a>
    <span class="separator">/</span>
    <a href="/study/examples/LaTeX/">LaTeX</a>
    <span class="separator">/</span>
    <span class="current">academic_paper.tex</span>
</nav>

            </header>

            <div class="content">
                
<article class="example-article">
    <header class="example-header">
        <h1>academic_paper.tex</h1>
        <div class="example-actions">
            <a href="academic_paper.tex" download class="btn">Download</a>
            <button class="btn" id="copy-code-btn">Copy code</button>
        </div>
    </header>

    <div class="example-meta">
        <span>latex</span>
        <span>593 lines</span>
        <span>20.1 KB</span>
    </div>

    <div class="example-code markdown-body">
        <div class="highlight"><pre><span></span><code><span class="linenos">  1</span><span class="c">% academic_paper.tex</span>
<span class="linenos">  2</span><span class="c">% Complete academic paper template with all standard sections</span>
<span class="linenos">  3</span><span class="c">% Demonstrates bibliography, cross-references, figures, tables, and appendices</span>
<span class="linenos">  4</span>
<span class="linenos">  5</span><span class="k">\documentclass</span><span class="na">[12pt,a4paper]</span><span class="nb">{</span>article<span class="nb">}</span>
<span class="linenos">  6</span>
<span class="linenos">  7</span><span class="c">% Essential packages</span>
<span class="linenos">  8</span><span class="k">\usepackage</span><span class="na">[utf8]</span><span class="nb">{</span>inputenc<span class="nb">}</span>
<span class="linenos">  9</span><span class="k">\usepackage</span><span class="na">[T1]</span><span class="nb">{</span>fontenc<span class="nb">}</span>
<span class="linenos"> 10</span><span class="k">\usepackage</span><span class="na">[margin=1in]</span><span class="nb">{</span>geometry<span class="nb">}</span>
<span class="linenos"> 11</span><span class="k">\usepackage</span><span class="nb">{</span>setspace<span class="nb">}</span>
<span class="linenos"> 12</span><span class="k">\onehalfspacing</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="c">% Math packages</span>
<span class="linenos"> 15</span><span class="k">\usepackage</span><span class="nb">{</span>amsmath, amssymb, amsthm<span class="nb">}</span>
<span class="linenos"> 16</span>
<span class="linenos"> 17</span><span class="c">% Graphics and tables</span>
<span class="linenos"> 18</span><span class="k">\usepackage</span><span class="nb">{</span>graphicx<span class="nb">}</span>
<span class="linenos"> 19</span><span class="k">\usepackage</span><span class="nb">{</span>booktabs<span class="nb">}</span>
<span class="linenos"> 20</span><span class="k">\usepackage</span><span class="nb">{</span>multirow<span class="nb">}</span>
<span class="linenos"> 21</span><span class="k">\usepackage</span><span class="nb">{</span>array<span class="nb">}</span>
<span class="linenos"> 22</span>
<span class="linenos"> 23</span><span class="c">% Bibliography</span>
<span class="linenos"> 24</span><span class="k">\usepackage</span>[
<span class="linenos"> 25</span>    backend=biber,
<span class="linenos"> 26</span>    style=authoryear,
<span class="linenos"> 27</span>    sorting=nyt,
<span class="linenos"> 28</span>    maxbibnames=99
<span class="linenos"> 29</span>]<span class="nb">{</span>biblatex<span class="nb">}</span>
<span class="linenos"> 30</span><span class="c">% Note: In a real paper, you would have a separate .bib file</span>
<span class="linenos"> 31</span><span class="c">% For this example, we use embedded bibliography at the end</span>
<span class="linenos"> 32</span>
<span class="linenos"> 33</span><span class="c">% Hyperlinks (should be loaded last)</span>
<span class="linenos"> 34</span><span class="k">\usepackage</span><span class="nb">{</span>hyperref<span class="nb">}</span>
<span class="linenos"> 35</span><span class="k">\hypersetup</span><span class="nb">{</span>
<span class="linenos"> 36</span>    colorlinks=true,
<span class="linenos"> 37</span>    linkcolor=blue,
<span class="linenos"> 38</span>    citecolor=blue,
<span class="linenos"> 39</span>    urlcolor=blue
<span class="linenos"> 40</span><span class="nb">}</span>
<span class="linenos"> 41</span>
<span class="linenos"> 42</span><span class="c">% Cross-referencing</span>
<span class="linenos"> 43</span><span class="k">\usepackage</span><span class="nb">{</span>cleveref<span class="nb">}</span>
<span class="linenos"> 44</span>
<span class="linenos"> 45</span><span class="c">% Custom theorem environments</span>
<span class="linenos"> 46</span><span class="k">\newtheorem</span><span class="nb">{</span>theorem<span class="nb">}{</span>Theorem<span class="nb">}</span>[section]
<span class="linenos"> 47</span><span class="k">\newtheorem</span><span class="nb">{</span>lemma<span class="nb">}</span>[theorem]<span class="nb">{</span>Lemma<span class="nb">}</span>
<span class="linenos"> 48</span><span class="k">\newtheorem</span><span class="nb">{</span>proposition<span class="nb">}</span>[theorem]<span class="nb">{</span>Proposition<span class="nb">}</span>
<span class="linenos"> 49</span><span class="k">\newtheorem</span><span class="nb">{</span>corollary<span class="nb">}</span>[theorem]<span class="nb">{</span>Corollary<span class="nb">}</span>
<span class="linenos"> 50</span>
<span class="linenos"> 51</span><span class="k">\theoremstyle</span><span class="nb">{</span>definition<span class="nb">}</span>
<span class="linenos"> 52</span><span class="k">\newtheorem</span><span class="nb">{</span>definition<span class="nb">}</span>[theorem]<span class="nb">{</span>Definition<span class="nb">}</span>
<span class="linenos"> 53</span>
<span class="linenos"> 54</span><span class="k">\theoremstyle</span><span class="nb">{</span>remark<span class="nb">}</span>
<span class="linenos"> 55</span><span class="k">\newtheorem</span><span class="nb">{</span>remark<span class="nb">}</span>[theorem]<span class="nb">{</span>Remark<span class="nb">}</span>
<span class="linenos"> 56</span>
<span class="linenos"> 57</span><span class="c">% Custom commands for this paper</span>
<span class="linenos"> 58</span><span class="k">\newcommand</span><span class="nb">{</span><span class="k">\R</span><span class="nb">}{</span><span class="k">\mathbb</span><span class="nb">{</span>R<span class="nb">}}</span>
<span class="linenos"> 59</span><span class="k">\newcommand</span><span class="nb">{</span><span class="k">\E</span><span class="nb">}</span>[1]<span class="nb">{</span><span class="k">\mathbb</span><span class="nb">{</span>E<span class="nb">}</span><span class="k">\left</span><span class="na">[#1\right]</span><span class="nb">}</span>
<span class="linenos"> 60</span><span class="k">\newcommand</span><span class="nb">{</span><span class="k">\vect</span><span class="nb">}</span>[1]<span class="nb">{</span><span class="k">\mathbf</span><span class="nb">{</span>#1<span class="nb">}}</span>
<span class="linenos"> 61</span><span class="k">\newcommand</span><span class="nb">{</span><span class="k">\mat</span><span class="nb">}</span>[1]<span class="nb">{</span><span class="k">\mathbf</span><span class="nb">{</span>#1<span class="nb">}}</span>
<span class="linenos"> 62</span><span class="k">\newcommand</span><span class="nb">{</span><span class="k">\norm</span><span class="nb">}</span>[1]<span class="nb">{</span><span class="k">\left\lVert</span> #1 <span class="k">\right\rVert</span><span class="nb">}</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span><span class="c">% Title and author information</span>
<span class="linenos"> 65</span><span class="k">\title</span><span class="nb">{</span>Deep Learning for Image Classification:<span class="k">\\</span>A Comprehensive Study of Convolutional Neural Networks<span class="nb">}</span>
<span class="linenos"> 66</span>
<span class="linenos"> 67</span><span class="k">\author</span><span class="nb">{</span>
<span class="linenos"> 68</span>    Jane Smith<span class="k">\thanks</span><span class="nb">{</span>Corresponding author: jane.smith@university.edu<span class="nb">}</span><span class="k">\\</span>
<span class="linenos"> 69</span>    <span class="k">\textit</span><span class="nb">{</span>Department of Computer Science<span class="nb">}</span><span class="k">\\</span>
<span class="linenos"> 70</span>    <span class="k">\textit</span><span class="nb">{</span>University of Technology<span class="nb">}</span><span class="k">\\</span>
<span class="linenos"> 71</span>    <span class="k">\textit</span><span class="nb">{</span>City, Country<span class="nb">}</span>
<span class="linenos"> 72</span>    <span class="k">\and</span>
<span class="linenos"> 73</span>    John Doe<span class="k">\\</span>
<span class="linenos"> 74</span>    <span class="k">\textit</span><span class="nb">{</span>Department of Artificial Intelligence<span class="nb">}</span><span class="k">\\</span>
<span class="linenos"> 75</span>    <span class="k">\textit</span><span class="nb">{</span>Institute of Advanced Studies<span class="nb">}</span><span class="k">\\</span>
<span class="linenos"> 76</span>    <span class="k">\textit</span><span class="nb">{</span>City, Country<span class="nb">}</span>
<span class="linenos"> 77</span><span class="nb">}</span>
<span class="linenos"> 78</span>
<span class="linenos"> 79</span><span class="k">\date</span><span class="nb">{</span><span class="k">\today</span><span class="nb">}</span>
<span class="linenos"> 80</span>
<span class="linenos"> 81</span><span class="k">\begin</span><span class="nb">{</span>document<span class="nb">}</span>
<span class="linenos"> 82</span>
<span class="linenos"> 83</span><span class="c">% ==================== Front Matter ====================</span>
<span class="linenos"> 84</span>
<span class="linenos"> 85</span><span class="k">\maketitle</span>
<span class="linenos"> 86</span>
<span class="linenos"> 87</span><span class="k">\begin</span><span class="nb">{</span>abstract<span class="nb">}</span>
<span class="linenos"> 88</span>In this paper, we present a comprehensive study of convolutional neural networks (CNNs)
<span class="linenos"> 89</span>for image classification tasks. We investigate the impact of various architectural
<span class="linenos"> 90</span>choices, including depth, width, and skip connections, on classification performance
<span class="linenos"> 91</span>across multiple benchmark datasets. Our experiments demonstrate that deeper networks
<span class="linenos"> 92</span>with residual connections achieve superior performance on complex datasets, with our
<span class="linenos"> 93</span>best model achieving 96.8<span class="k">\%</span> accuracy on CIFAR-10 and 84.2<span class="k">\%</span> on CIFAR-100. We provide
<span class="linenos"> 94</span>detailed analysis of the trade-offs between model complexity and performance, and
<span class="linenos"> 95</span>propose guidelines for practitioners designing CNN architectures for image
<span class="linenos"> 96</span>classification. Furthermore, we investigate the role of data augmentation and
<span class="linenos"> 97</span>regularization techniques in preventing overfitting. Our findings suggest that a
<span class="linenos"> 98</span>combination of architectural improvements and proper regularization is essential for
<span class="linenos"> 99</span>achieving state-of-the-art performance.
<span class="linenos">100</span>
<span class="linenos">101</span><span class="k">\vspace</span><span class="nb">{</span>0.5cm<span class="nb">}</span>
<span class="linenos">102</span>
<span class="linenos">103</span><span class="k">\noindent\textbf</span><span class="nb">{</span>Keywords:<span class="nb">}</span> Deep Learning, Convolutional Neural Networks, Image
<span class="linenos">104</span>Classification, ResNet, Data Augmentation, Transfer Learning
<span class="linenos">105</span><span class="k">\end</span><span class="nb">{</span>abstract<span class="nb">}</span>
<span class="linenos">106</span>
<span class="linenos">107</span><span class="k">\tableofcontents</span>
<span class="linenos">108</span>
<span class="linenos">109</span><span class="c">% ==================== Introduction ====================</span>
<span class="linenos">110</span>
<span class="linenos">111</span><span class="k">\section</span><span class="nb">{</span>Introduction<span class="nb">}</span>
<span class="linenos">112</span><span class="k">\label</span><span class="nb">{</span>sec:introduction<span class="nb">}</span>
<span class="linenos">113</span>
<span class="linenos">114</span>Image classification is a fundamental task in computer vision with applications
<span class="linenos">115</span>ranging from medical diagnosis to autonomous driving. Deep learning, particularly
<span class="linenos">116</span>convolutional neural networks (CNNs), has revolutionized this field over the past
<span class="linenos">117</span>decade~<span class="k">\cite</span><span class="nb">{</span>lecun2015deep,goodfellow2016deep<span class="nb">}</span>.
<span class="linenos">118</span>
<span class="linenos">119</span>Since the breakthrough of AlexNet in 2012~<span class="k">\cite</span><span class="nb">{</span>krizhevsky2012imagenet<span class="nb">}</span>, deep
<span class="linenos">120</span>learning models have consistently achieved state-of-the-art performance on image
<span class="linenos">121</span>classification benchmarks. The success of CNNs can be attributed to their ability
<span class="linenos">122</span>to automatically learn hierarchical feature representations from raw pixel data,
<span class="linenos">123</span>eliminating the need for hand-crafted features.
<span class="linenos">124</span>
<span class="linenos">125</span><span class="k">\subsection</span><span class="nb">{</span>Motivation<span class="nb">}</span>
<span class="linenos">126</span>
<span class="linenos">127</span>Despite the success of CNNs, several important questions remain:
<span class="linenos">128</span>
<span class="linenos">129</span><span class="k">\begin</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">130</span>    <span class="k">\item</span> How do architectural choices affect classification performance?
<span class="linenos">131</span>    <span class="k">\item</span> What is the optimal balance between model complexity and generalization?
<span class="linenos">132</span>    <span class="k">\item</span> How can we effectively prevent overfitting in deep networks?
<span class="linenos">133</span>    <span class="k">\item</span> What role does data augmentation play in modern architectures?
<span class="linenos">134</span><span class="k">\end</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">135</span>
<span class="linenos">136</span>This paper addresses these questions through systematic experimentation and analysis.
<span class="linenos">137</span>
<span class="linenos">138</span><span class="k">\subsection</span><span class="nb">{</span>Contributions<span class="nb">}</span>
<span class="linenos">139</span>
<span class="linenos">140</span>Our main contributions are:
<span class="linenos">141</span>
<span class="linenos">142</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">143</span>    <span class="k">\item</span> A comprehensive empirical study of CNN architectures on multiple datasets
<span class="linenos">144</span>    <span class="k">\item</span> Analysis of the relationship between network depth and performance
<span class="linenos">145</span>    <span class="k">\item</span> Evaluation of various regularization and data augmentation techniques
<span class="linenos">146</span>    <span class="k">\item</span> Practical guidelines for designing CNN architectures
<span class="linenos">147</span>    <span class="k">\item</span> Open-source implementation of all models and experiments
<span class="linenos">148</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">149</span>
<span class="linenos">150</span><span class="k">\subsection</span><span class="nb">{</span>Organization<span class="nb">}</span>
<span class="linenos">151</span>
<span class="linenos">152</span>The remainder of this paper is organized as follows: <span class="k">\Cref</span><span class="nb">{</span>sec:related<span class="nb">}</span> reviews
<span class="linenos">153</span>related work; <span class="k">\Cref</span><span class="nb">{</span>sec:methodology<span class="nb">}</span> describes our methodology and experimental
<span class="linenos">154</span>setup; <span class="k">\Cref</span><span class="nb">{</span>sec:results<span class="nb">}</span> presents our experimental results; <span class="k">\Cref</span><span class="nb">{</span>sec:discussion<span class="nb">}</span>
<span class="linenos">155</span>discusses the implications of our findings; and <span class="k">\Cref</span><span class="nb">{</span>sec:conclusion<span class="nb">}</span> concludes
<span class="linenos">156</span>the paper with directions for future work.
<span class="linenos">157</span>
<span class="linenos">158</span><span class="c">% ==================== Related Work ====================</span>
<span class="linenos">159</span>
<span class="linenos">160</span><span class="k">\section</span><span class="nb">{</span>Related Work<span class="nb">}</span>
<span class="linenos">161</span><span class="k">\label</span><span class="nb">{</span>sec:related<span class="nb">}</span>
<span class="linenos">162</span>
<span class="linenos">163</span><span class="k">\subsection</span><span class="nb">{</span>Convolutional Neural Networks<span class="nb">}</span>
<span class="linenos">164</span>
<span class="linenos">165</span>Convolutional neural networks were pioneered by LeCun et al.~<span class="k">\cite</span><span class="nb">{</span>lecun1998gradient<span class="nb">}</span>
<span class="linenos">166</span>with LeNet-5, which achieved impressive results on digit recognition. However, CNNs
<span class="linenos">167</span>did not gain widespread adoption until the success of AlexNet~<span class="k">\cite</span><span class="nb">{</span>krizhevsky2012imagenet<span class="nb">}</span>
<span class="linenos">168</span>on the ImageNet challenge.
<span class="linenos">169</span>
<span class="linenos">170</span>Following AlexNet, several influential architectures were proposed:
<span class="linenos">171</span>
<span class="linenos">172</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">173</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>VGGNet<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>simonyan2014very<span class="nb">}</span>: Demonstrated the importance of
<span class="linenos">174</span>          depth by using small 3√ó3 filters throughout the network
<span class="linenos">175</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>GoogLeNet<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>szegedy2015going<span class="nb">}</span>: Introduced the Inception
<span class="linenos">176</span>          module for efficient computation
<span class="linenos">177</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>ResNet<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>he2016deep<span class="nb">}</span>: Enabled training of very deep networks
<span class="linenos">178</span>          using residual connections
<span class="linenos">179</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>DenseNet<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>huang2017densely<span class="nb">}</span>: Extended residual connections
<span class="linenos">180</span>          by connecting all layers directly
<span class="linenos">181</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">182</span>
<span class="linenos">183</span><span class="k">\subsection</span><span class="nb">{</span>Regularization Techniques<span class="nb">}</span>
<span class="linenos">184</span>
<span class="linenos">185</span>Preventing overfitting is crucial for deep learning. Common techniques include:
<span class="linenos">186</span>
<span class="linenos">187</span><span class="k">\textbf</span><span class="nb">{</span>Dropout<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>srivastava2014dropout<span class="nb">}</span> randomly deactivates neurons during
<span class="linenos">188</span>training, forcing the network to learn redundant representations.
<span class="linenos">189</span>
<span class="linenos">190</span><span class="k">\textbf</span><span class="nb">{</span>Batch Normalization<span class="nb">}</span>~<span class="k">\cite</span><span class="nb">{</span>ioffe2015batch<span class="nb">}</span> normalizes layer inputs,
<span class="linenos">191</span>accelerating training and providing regularization effects.
<span class="linenos">192</span>
<span class="linenos">193</span><span class="k">\textbf</span><span class="nb">{</span>Data Augmentation<span class="nb">}</span> artificially increases dataset size by applying random
<span class="linenos">194</span>transformations to training images~<span class="k">\cite</span><span class="nb">{</span>shorten2019survey<span class="nb">}</span>.
<span class="linenos">195</span>
<span class="linenos">196</span><span class="k">\subsection</span><span class="nb">{</span>Transfer Learning<span class="nb">}</span>
<span class="linenos">197</span>
<span class="linenos">198</span>Transfer learning leverages pre-trained models on large datasets to improve
<span class="linenos">199</span>performance on smaller target datasets~<span class="k">\cite</span><span class="nb">{</span>yosinski2014transferable<span class="nb">}</span>. This
<span class="linenos">200</span>approach has become standard practice in computer vision.
<span class="linenos">201</span>
<span class="linenos">202</span><span class="c">% ==================== Methodology ====================</span>
<span class="linenos">203</span>
<span class="linenos">204</span><span class="k">\section</span><span class="nb">{</span>Methodology<span class="nb">}</span>
<span class="linenos">205</span><span class="k">\label</span><span class="nb">{</span>sec:methodology<span class="nb">}</span>
<span class="linenos">206</span>
<span class="linenos">207</span><span class="k">\subsection</span><span class="nb">{</span>Datasets<span class="nb">}</span>
<span class="linenos">208</span>
<span class="linenos">209</span>We conduct experiments on three benchmark datasets:
<span class="linenos">210</span>
<span class="linenos">211</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">212</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>CIFAR-10<span class="nb">}</span>: 60,000 32√ó32 color images in 10 classes
<span class="linenos">213</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>CIFAR-100<span class="nb">}</span>: 60,000 32√ó32 color images in 100 classes
<span class="linenos">214</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>ImageNet<span class="nb">}</span>: 1.2M high-resolution images in 1000 classes (subset)
<span class="linenos">215</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">216</span>
<span class="linenos">217</span><span class="k">\Cref</span><span class="nb">{</span>tab:datasets<span class="nb">}</span> summarizes the dataset statistics.
<span class="linenos">218</span>
<span class="linenos">219</span><span class="k">\begin</span><span class="nb">{</span>table<span class="nb">}</span>[htbp]
<span class="linenos">220</span><span class="k">\centering</span>
<span class="linenos">221</span><span class="k">\caption</span><span class="nb">{</span>Dataset statistics for our experiments<span class="nb">}</span>
<span class="linenos">222</span><span class="k">\label</span><span class="nb">{</span>tab:datasets<span class="nb">}</span>
<span class="linenos">223</span><span class="k">\begin</span><span class="nb">{</span>tabular<span class="nb">}{</span>@<span class="nb">{}</span>lrrr@<span class="nb">{}}</span>
<span class="linenos">224</span><span class="k">\toprule</span>
<span class="linenos">225</span>Dataset <span class="nb">&amp;</span> Training Images <span class="nb">&amp;</span> Test Images <span class="nb">&amp;</span> Classes <span class="k">\\</span>
<span class="linenos">226</span><span class="k">\midrule</span>
<span class="linenos">227</span>CIFAR-10 <span class="nb">&amp;</span> 50,000 <span class="nb">&amp;</span> 10,000 <span class="nb">&amp;</span> 10 <span class="k">\\</span>
<span class="linenos">228</span>CIFAR-100 <span class="nb">&amp;</span> 50,000 <span class="nb">&amp;</span> 10,000 <span class="nb">&amp;</span> 100 <span class="k">\\</span>
<span class="linenos">229</span>ImageNet (subset) <span class="nb">&amp;</span> 100,000 <span class="nb">&amp;</span> 5,000 <span class="nb">&amp;</span> 100 <span class="k">\\</span>
<span class="linenos">230</span><span class="k">\bottomrule</span>
<span class="linenos">231</span><span class="k">\end</span><span class="nb">{</span>tabular<span class="nb">}</span>
<span class="linenos">232</span><span class="k">\end</span><span class="nb">{</span>table<span class="nb">}</span>
<span class="linenos">233</span>
<span class="linenos">234</span><span class="k">\subsection</span><span class="nb">{</span>Network Architectures<span class="nb">}</span>
<span class="linenos">235</span>
<span class="linenos">236</span>We implement and evaluate the following architectures:
<span class="linenos">237</span>
<span class="linenos">238</span><span class="k">\begin</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">239</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Baseline CNN<span class="nb">}</span>: Simple 6-layer convolutional network
<span class="linenos">240</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>VGG-style<span class="nb">}</span>: Deep network with small filters
<span class="linenos">241</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>ResNet-18/34/50<span class="nb">}</span>: Residual networks of varying depths
<span class="linenos">242</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Custom Hybrid<span class="nb">}</span>: Our proposed architecture combining best practices
<span class="linenos">243</span><span class="k">\end</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">244</span>
<span class="linenos">245</span>The baseline architecture is defined as:
<span class="linenos">246</span>
<span class="linenos">247</span><span class="k">\begin</span><span class="nb">{</span>equation<span class="nb">}</span>
<span class="linenos">248</span><span class="k">\begin</span><span class="nb">{</span>aligned<span class="nb">}</span>
<span class="linenos">249</span>    <span class="k">\text</span><span class="nb">{</span>Conv<span class="nb">}</span>(3 <span class="k">\times</span> 3, 64) <span class="nb">&amp;</span><span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>ReLU<span class="nb">}</span> <span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>MaxPool<span class="nb">}</span> <span class="k">\\</span>
<span class="linenos">250</span>    <span class="k">\text</span><span class="nb">{</span>Conv<span class="nb">}</span>(3 <span class="k">\times</span> 3, 128) <span class="nb">&amp;</span><span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>ReLU<span class="nb">}</span> <span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>MaxPool<span class="nb">}</span> <span class="k">\\</span>
<span class="linenos">251</span>    <span class="k">\text</span><span class="nb">{</span>Conv<span class="nb">}</span>(3 <span class="k">\times</span> 3, 256) <span class="nb">&amp;</span><span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>ReLU<span class="nb">}</span> <span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>MaxPool<span class="nb">}</span> <span class="k">\\</span>
<span class="linenos">252</span>    <span class="k">\text</span><span class="nb">{</span>FC<span class="nb">}</span>(512) <span class="nb">&amp;</span><span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>ReLU<span class="nb">}</span> <span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>Dropout<span class="nb">}</span>(0.5) <span class="k">\\</span>
<span class="linenos">253</span>    <span class="k">\text</span><span class="nb">{</span>FC<span class="nb">}</span>(<span class="k">\text</span><span class="nb">{</span>num<span class="k">\_classes</span><span class="nb">}</span>) <span class="nb">&amp;</span><span class="k">\rightarrow</span> <span class="k">\text</span><span class="nb">{</span>Softmax<span class="nb">}</span>
<span class="linenos">254</span><span class="k">\end</span><span class="nb">{</span>aligned<span class="nb">}</span>
<span class="linenos">255</span><span class="k">\end</span><span class="nb">{</span>equation<span class="nb">}</span>
<span class="linenos">256</span>
<span class="linenos">257</span><span class="k">\subsection</span><span class="nb">{</span>Training Procedure<span class="nb">}</span>
<span class="linenos">258</span>
<span class="linenos">259</span>All models are trained using the following configuration:
<span class="linenos">260</span>
<span class="linenos">261</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">262</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Optimizer<span class="nb">}</span>: SGD with momentum (0.9)
<span class="linenos">263</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Learning Rate<span class="nb">}</span>: 0.1, reduced by 10√ó at epochs 60, 120, 160
<span class="linenos">264</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Batch Size<span class="nb">}</span>: 128
<span class="linenos">265</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Weight Decay<span class="nb">}</span>: <span class="s">$</span><span class="m">5</span><span class="nb"> </span><span class="nv">\times</span><span class="nb"> </span><span class="m">10</span><span class="nb">^{</span><span class="o">-</span><span class="m">4</span><span class="nb">}</span><span class="s">$</span>
<span class="linenos">266</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Training Epochs<span class="nb">}</span>: 200
<span class="linenos">267</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">268</span>
<span class="linenos">269</span>The loss function is cross-entropy:
<span class="linenos">270</span>
<span class="linenos">271</span><span class="k">\begin</span><span class="nb">{</span>equation<span class="nb">}</span>
<span class="linenos">272</span><span class="k">\mathcal</span><span class="nb">{</span>L<span class="nb">}</span>(<span class="k">\vect</span><span class="nb">{</span><span class="k">\theta</span><span class="nb">}</span>) = -<span class="k">\frac</span><span class="nb">{</span>1<span class="nb">}{</span>N<span class="nb">}</span><span class="k">\sum_</span><span class="nb">{</span>i=1<span class="nb">}^</span>N <span class="k">\sum_</span><span class="nb">{</span>c=1<span class="nb">}^</span>C y<span class="nb">_{</span>ic<span class="nb">}</span> <span class="k">\log</span>(<span class="k">\hat</span><span class="nb">{</span>y<span class="nb">}_{</span>ic<span class="nb">}</span>)
<span class="linenos">273</span><span class="k">\end</span><span class="nb">{</span>equation<span class="nb">}</span>
<span class="linenos">274</span>
<span class="linenos">275</span>where <span class="s">$</span><span class="nb">N</span><span class="s">$</span> is batch size, <span class="s">$</span><span class="nb">C</span><span class="s">$</span> is number of classes, <span class="s">$</span><span class="nb">y_{ic}</span><span class="s">$</span> is ground truth, and
<span class="linenos">276</span><span class="s">$</span><span class="nv">\hat</span><span class="nb">{y}_{ic}</span><span class="s">$</span> is predicted probability.
<span class="linenos">277</span>
<span class="linenos">278</span><span class="k">\subsection</span><span class="nb">{</span>Data Augmentation<span class="nb">}</span>
<span class="linenos">279</span>
<span class="linenos">280</span>We apply the following augmentation techniques during training:
<span class="linenos">281</span>
<span class="linenos">282</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">283</span>    <span class="k">\item</span> Random horizontal flips (probability 0.5)
<span class="linenos">284</span>    <span class="k">\item</span> Random crops with padding of 4 pixels
<span class="linenos">285</span>    <span class="k">\item</span> Color jittering (brightness, contrast, saturation)
<span class="linenos">286</span>    <span class="k">\item</span> Random rotation (<span class="s">$</span><span class="nv">\pm</span><span class="nb"> </span><span class="m">15</span><span class="s">$</span> degrees)
<span class="linenos">287</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">288</span>
<span class="linenos">289</span><span class="k">\subsection</span><span class="nb">{</span>Evaluation Metrics<span class="nb">}</span>
<span class="linenos">290</span>
<span class="linenos">291</span>We evaluate models using:
<span class="linenos">292</span>
<span class="linenos">293</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">294</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Top-1 Accuracy<span class="nb">}</span>: Percentage of correct predictions
<span class="linenos">295</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Top-5 Accuracy<span class="nb">}</span>: Percentage where correct class is in top 5 predictions
<span class="linenos">296</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Parameters<span class="nb">}</span>: Total number of trainable parameters
<span class="linenos">297</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>FLOPs<span class="nb">}</span>: Floating-point operations per forward pass
<span class="linenos">298</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">299</span>
<span class="linenos">300</span><span class="c">% ==================== Results ====================</span>
<span class="linenos">301</span>
<span class="linenos">302</span><span class="k">\section</span><span class="nb">{</span>Results<span class="nb">}</span>
<span class="linenos">303</span><span class="k">\label</span><span class="nb">{</span>sec:results<span class="nb">}</span>
<span class="linenos">304</span>
<span class="linenos">305</span><span class="k">\subsection</span><span class="nb">{</span>Main Results<span class="nb">}</span>
<span class="linenos">306</span>
<span class="linenos">307</span><span class="k">\Cref</span><span class="nb">{</span>tab:main<span class="nb">_</span>results<span class="nb">}</span> presents the performance of different architectures on CIFAR-10
<span class="linenos">308</span>and CIFAR-100.
<span class="linenos">309</span>
<span class="linenos">310</span><span class="k">\begin</span><span class="nb">{</span>table<span class="nb">}</span>[htbp]
<span class="linenos">311</span><span class="k">\centering</span>
<span class="linenos">312</span><span class="k">\caption</span><span class="nb">{</span>Classification accuracy (<span class="k">\%</span>) on CIFAR-10 and CIFAR-100<span class="nb">}</span>
<span class="linenos">313</span><span class="k">\label</span><span class="nb">{</span>tab:main<span class="nb">_</span>results<span class="nb">}</span>
<span class="linenos">314</span><span class="k">\begin</span><span class="nb">{</span>tabular<span class="nb">}{</span>@<span class="nb">{}</span>lcccc@<span class="nb">{}}</span>
<span class="linenos">315</span><span class="k">\toprule</span>
<span class="linenos">316</span><span class="k">\multirow</span><span class="nb">{</span>2<span class="nb">}{</span>*<span class="nb">}{</span>Model<span class="nb">}</span> <span class="nb">&amp;</span> <span class="k">\multicolumn</span><span class="nb">{</span>2<span class="nb">}{</span>c<span class="nb">}{</span>CIFAR-10<span class="nb">}</span> <span class="nb">&amp;</span> <span class="k">\multicolumn</span><span class="nb">{</span>2<span class="nb">}{</span>c<span class="nb">}{</span>CIFAR-100<span class="nb">}</span> <span class="k">\\</span>
<span class="linenos">317</span><span class="k">\cmidrule</span>(lr)<span class="nb">{</span>2-3<span class="nb">}</span> <span class="k">\cmidrule</span>(lr)<span class="nb">{</span>4-5<span class="nb">}</span>
<span class="linenos">318</span> <span class="nb">&amp;</span> Top-1 <span class="nb">&amp;</span> Top-5 <span class="nb">&amp;</span> Top-1 <span class="nb">&amp;</span> Top-5 <span class="k">\\</span>
<span class="linenos">319</span><span class="k">\midrule</span>
<span class="linenos">320</span>Baseline CNN <span class="nb">&amp;</span> 89.2 <span class="nb">&amp;</span> 99.6 <span class="nb">&amp;</span> 62.4 <span class="nb">&amp;</span> 85.3 <span class="k">\\</span>
<span class="linenos">321</span>VGG-style <span class="nb">&amp;</span> 92.5 <span class="nb">&amp;</span> 99.8 <span class="nb">&amp;</span> 68.7 <span class="nb">&amp;</span> 88.9 <span class="k">\\</span>
<span class="linenos">322</span>ResNet-18 <span class="nb">&amp;</span> 94.8 <span class="nb">&amp;</span> 99.9 <span class="nb">&amp;</span> 74.2 <span class="nb">&amp;</span> 91.5 <span class="k">\\</span>
<span class="linenos">323</span>ResNet-34 <span class="nb">&amp;</span> 95.6 <span class="nb">&amp;</span> 99.9 <span class="nb">&amp;</span> 76.8 <span class="nb">&amp;</span> 92.8 <span class="k">\\</span>
<span class="linenos">324</span>ResNet-50 <span class="nb">&amp;</span> 96.1 <span class="nb">&amp;</span> 100.0 <span class="nb">&amp;</span> 78.5 <span class="nb">&amp;</span> 93.7 <span class="k">\\</span>
<span class="linenos">325</span>Custom Hybrid <span class="nb">&amp;</span> <span class="k">\textbf</span><span class="nb">{</span>96.8<span class="nb">}</span> <span class="nb">&amp;</span> <span class="k">\textbf</span><span class="nb">{</span>100.0<span class="nb">}</span> <span class="nb">&amp;</span> <span class="k">\textbf</span><span class="nb">{</span>84.2<span class="nb">}</span> <span class="nb">&amp;</span> <span class="k">\textbf</span><span class="nb">{</span>95.1<span class="nb">}</span> <span class="k">\\</span>
<span class="linenos">326</span><span class="k">\bottomrule</span>
<span class="linenos">327</span><span class="k">\end</span><span class="nb">{</span>tabular<span class="nb">}</span>
<span class="linenos">328</span><span class="k">\end</span><span class="nb">{</span>table<span class="nb">}</span>
<span class="linenos">329</span>
<span class="linenos">330</span>Our Custom Hybrid architecture achieves the best performance on both datasets,
<span class="linenos">331</span>demonstrating the effectiveness of combining architectural innovations.
<span class="linenos">332</span>
<span class="linenos">333</span><span class="k">\subsection</span><span class="nb">{</span>Impact of Network Depth<span class="nb">}</span>
<span class="linenos">334</span>
<span class="linenos">335</span>We investigate how network depth affects performance by training ResNets of varying
<span class="linenos">336</span>depths. <span class="k">\Cref</span><span class="nb">{</span>fig:depth<span class="nb">_</span>analysis<span class="nb">}</span> would show that performance improves with depth
<span class="linenos">337</span>but plateaus beyond 50 layers for CIFAR-10.
<span class="linenos">338</span>
<span class="linenos">339</span><span class="k">\begin</span><span class="nb">{</span>theorem<span class="nb">}</span>[Depth-Performance Relationship]
<span class="linenos">340</span><span class="k">\label</span><span class="nb">{</span>thm:depth<span class="nb">}</span>
<span class="linenos">341</span>For a fixed parameter budget, deeper networks with residual connections outperform
<span class="linenos">342</span>shallower networks on complex classification tasks, up to a saturation point
<span class="linenos">343</span>determined by dataset complexity.
<span class="linenos">344</span><span class="k">\end</span><span class="nb">{</span>theorem<span class="nb">}</span>
<span class="linenos">345</span>
<span class="linenos">346</span><span class="k">\subsection</span><span class="nb">{</span>Regularization Analysis<span class="nb">}</span>
<span class="linenos">347</span>
<span class="linenos">348</span><span class="k">\Cref</span><span class="nb">{</span>tab:regularization<span class="nb">}</span> shows the impact of different regularization techniques.
<span class="linenos">349</span>
<span class="linenos">350</span><span class="k">\begin</span><span class="nb">{</span>table<span class="nb">}</span>[htbp]
<span class="linenos">351</span><span class="k">\centering</span>
<span class="linenos">352</span><span class="k">\caption</span><span class="nb">{</span>Effect of regularization on ResNet-18 (CIFAR-10 accuracy)<span class="nb">}</span>
<span class="linenos">353</span><span class="k">\label</span><span class="nb">{</span>tab:regularization<span class="nb">}</span>
<span class="linenos">354</span><span class="k">\begin</span><span class="nb">{</span>tabular<span class="nb">}{</span>@<span class="nb">{}</span>lccc@<span class="nb">{}}</span>
<span class="linenos">355</span><span class="k">\toprule</span>
<span class="linenos">356</span>Technique <span class="nb">&amp;</span> Training Acc. <span class="nb">&amp;</span> Test Acc. <span class="nb">&amp;</span> Overfitting <span class="k">\\</span>
<span class="linenos">357</span><span class="k">\midrule</span>
<span class="linenos">358</span>None <span class="nb">&amp;</span> 99.8 <span class="nb">&amp;</span> 89.3 <span class="nb">&amp;</span> 10.5 <span class="k">\\</span>
<span class="linenos">359</span>Dropout only <span class="nb">&amp;</span> 98.2 <span class="nb">&amp;</span> 92.1 <span class="nb">&amp;</span> 6.1 <span class="k">\\</span>
<span class="linenos">360</span>BatchNorm only <span class="nb">&amp;</span> 99.1 <span class="nb">&amp;</span> 93.8 <span class="nb">&amp;</span> 5.3 <span class="k">\\</span>
<span class="linenos">361</span>Data Aug. only <span class="nb">&amp;</span> 97.5 <span class="nb">&amp;</span> 94.2 <span class="nb">&amp;</span> 3.3 <span class="k">\\</span>
<span class="linenos">362</span>All combined <span class="nb">&amp;</span> 96.8 <span class="nb">&amp;</span> 94.8 <span class="nb">&amp;</span> 2.0 <span class="k">\\</span>
<span class="linenos">363</span><span class="k">\bottomrule</span>
<span class="linenos">364</span><span class="k">\end</span><span class="nb">{</span>tabular<span class="nb">}</span>
<span class="linenos">365</span><span class="k">\end</span><span class="nb">{</span>table<span class="nb">}</span>
<span class="linenos">366</span>
<span class="linenos">367</span>The combination of all regularization techniques achieves the best generalization.
<span class="linenos">368</span>
<span class="linenos">369</span><span class="k">\subsection</span><span class="nb">{</span>Computational Efficiency<span class="nb">}</span>
<span class="linenos">370</span>
<span class="linenos">371</span><span class="k">\Cref</span><span class="nb">{</span>tab:efficiency<span class="nb">}</span> compares model complexity and inference time.
<span class="linenos">372</span>
<span class="linenos">373</span><span class="k">\begin</span><span class="nb">{</span>table<span class="nb">}</span>[htbp]
<span class="linenos">374</span><span class="k">\centering</span>
<span class="linenos">375</span><span class="k">\caption</span><span class="nb">{</span>Model complexity and computational requirements<span class="nb">}</span>
<span class="linenos">376</span><span class="k">\label</span><span class="nb">{</span>tab:efficiency<span class="nb">}</span>
<span class="linenos">377</span><span class="k">\begin</span><span class="nb">{</span>tabular<span class="nb">}{</span>@<span class="nb">{}</span>lrrr@<span class="nb">{}}</span>
<span class="linenos">378</span><span class="k">\toprule</span>
<span class="linenos">379</span>Model <span class="nb">&amp;</span> Parameters (M) <span class="nb">&amp;</span> FLOPs (G) <span class="nb">&amp;</span> Inference Time (ms) <span class="k">\\</span>
<span class="linenos">380</span><span class="k">\midrule</span>
<span class="linenos">381</span>Baseline CNN <span class="nb">&amp;</span> 2.4 <span class="nb">&amp;</span> 0.15 <span class="nb">&amp;</span> 3.2 <span class="k">\\</span>
<span class="linenos">382</span>VGG-style <span class="nb">&amp;</span> 14.7 <span class="nb">&amp;</span> 0.31 <span class="nb">&amp;</span> 8.5 <span class="k">\\</span>
<span class="linenos">383</span>ResNet-18 <span class="nb">&amp;</span> 11.2 <span class="nb">&amp;</span> 0.56 <span class="nb">&amp;</span> 6.8 <span class="k">\\</span>
<span class="linenos">384</span>ResNet-50 <span class="nb">&amp;</span> 23.5 <span class="nb">&amp;</span> 1.31 <span class="nb">&amp;</span> 12.3 <span class="k">\\</span>
<span class="linenos">385</span>Custom Hybrid <span class="nb">&amp;</span> 18.6 <span class="nb">&amp;</span> 0.89 <span class="nb">&amp;</span> 9.7 <span class="k">\\</span>
<span class="linenos">386</span><span class="k">\bottomrule</span>
<span class="linenos">387</span><span class="k">\end</span><span class="nb">{</span>tabular<span class="nb">}</span>
<span class="linenos">388</span><span class="k">\end</span><span class="nb">{</span>table<span class="nb">}</span>
<span class="linenos">389</span>
<span class="linenos">390</span><span class="c">% ==================== Discussion ====================</span>
<span class="linenos">391</span>
<span class="linenos">392</span><span class="k">\section</span><span class="nb">{</span>Discussion<span class="nb">}</span>
<span class="linenos">393</span><span class="k">\label</span><span class="nb">{</span>sec:discussion<span class="nb">}</span>
<span class="linenos">394</span>
<span class="linenos">395</span><span class="k">\subsection</span><span class="nb">{</span>Key Findings<span class="nb">}</span>
<span class="linenos">396</span>
<span class="linenos">397</span>Our experiments reveal several important insights:
<span class="linenos">398</span>
<span class="linenos">399</span><span class="k">\begin</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">400</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Depth matters<span class="nb">}</span>: Deeper networks consistently outperform shallow
<span class="linenos">401</span>          ones when properly regularized (see <span class="k">\Cref</span><span class="nb">{</span>thm:depth<span class="nb">}</span>)
<span class="linenos">402</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Skip connections are essential<span class="nb">}</span>: ResNets significantly outperform
<span class="linenos">403</span>          plain deep networks of similar depth
<span class="linenos">404</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Regularization is crucial<span class="nb">}</span>: The combination of multiple
<span class="linenos">405</span>          regularization techniques is more effective than any single method
<span class="linenos">406</span>    <span class="k">\item</span> <span class="k">\textbf</span><span class="nb">{</span>Data augmentation has the largest impact<span class="nb">}</span>: Among regularization
<span class="linenos">407</span>          techniques, data augmentation provides the most significant improvement
<span class="linenos">408</span><span class="k">\end</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">409</span>
<span class="linenos">410</span><span class="k">\subsection</span><span class="nb">{</span>Comparison with Prior Work<span class="nb">}</span>
<span class="linenos">411</span>
<span class="linenos">412</span>Our Custom Hybrid architecture achieves competitive performance compared to
<span class="linenos">413</span>state-of-the-art methods while maintaining reasonable computational requirements.
<span class="linenos">414</span>The 96.8<span class="k">\%</span> accuracy on CIFAR-10 is comparable to recent work, though some highly
<span class="linenos">415</span>optimized architectures achieve slightly higher accuracy at the cost of increased
<span class="linenos">416</span>complexity.
<span class="linenos">417</span>
<span class="linenos">418</span><span class="k">\subsection</span><span class="nb">{</span>Practical Guidelines<span class="nb">}</span>
<span class="linenos">419</span>
<span class="linenos">420</span>Based on our findings, we recommend the following guidelines for practitioners:
<span class="linenos">421</span>
<span class="linenos">422</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">423</span>    <span class="k">\item</span> Start with ResNet-18 or ResNet-34 as baseline architectures
<span class="linenos">424</span>    <span class="k">\item</span> Always use batch normalization and data augmentation
<span class="linenos">425</span>    <span class="k">\item</span> Prefer deeper networks over wider networks for complex datasets
<span class="linenos">426</span>    <span class="k">\item</span> Use transfer learning when dataset size is limited
<span class="linenos">427</span>    <span class="k">\item</span> Monitor both training and validation metrics to detect overfitting
<span class="linenos">428</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">429</span>
<span class="linenos">430</span><span class="k">\subsection</span><span class="nb">{</span>Limitations<span class="nb">}</span>
<span class="linenos">431</span>
<span class="linenos">432</span>Our study has several limitations:
<span class="linenos">433</span>
<span class="linenos">434</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">435</span>    <span class="k">\item</span> Experiments are limited to relatively small images (32√ó32 and 224√ó224)
<span class="linenos">436</span>    <span class="k">\item</span> Computational constraints limited hyperparameter search space
<span class="linenos">437</span>    <span class="k">\item</span> We did not explore neural architecture search methods
<span class="linenos">438</span>    <span class="k">\item</span> Analysis focuses on accuracy; other metrics (fairness, robustness) not considered
<span class="linenos">439</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">440</span>
<span class="linenos">441</span><span class="c">% ==================== Conclusion ====================</span>
<span class="linenos">442</span>
<span class="linenos">443</span><span class="k">\section</span><span class="nb">{</span>Conclusion<span class="nb">}</span>
<span class="linenos">444</span><span class="k">\label</span><span class="nb">{</span>sec:conclusion<span class="nb">}</span>
<span class="linenos">445</span>
<span class="linenos">446</span>This paper presented a comprehensive empirical study of CNN architectures for image
<span class="linenos">447</span>classification. Through systematic experiments on multiple datasets, we demonstrated
<span class="linenos">448</span>that the combination of increased depth, residual connections, and proper regularization
<span class="linenos">449</span>leads to superior performance.
<span class="linenos">450</span>
<span class="linenos">451</span>Our Custom Hybrid architecture achieves 96.8<span class="k">\%</span> accuracy on CIFAR-10 and 84.2<span class="k">\%</span> on
<span class="linenos">452</span>CIFAR-100, demonstrating the effectiveness of combining architectural best practices.
<span class="linenos">453</span>We provide practical guidelines to help practitioners design effective CNN architectures.
<span class="linenos">454</span>
<span class="linenos">455</span><span class="k">\subsection</span><span class="nb">{</span>Future Work<span class="nb">}</span>
<span class="linenos">456</span>
<span class="linenos">457</span>Several directions for future research include:
<span class="linenos">458</span>
<span class="linenos">459</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">460</span>    <span class="k">\item</span> Investigating attention mechanisms in CNNs
<span class="linenos">461</span>    <span class="k">\item</span> Exploring neural architecture search for automatic design
<span class="linenos">462</span>    <span class="k">\item</span> Extending analysis to other computer vision tasks (detection, segmentation)
<span class="linenos">463</span>    <span class="k">\item</span> Studying adversarial robustness of different architectures
<span class="linenos">464</span>    <span class="k">\item</span> Developing more efficient architectures for mobile deployment
<span class="linenos">465</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">466</span>
<span class="linenos">467</span><span class="k">\section*</span><span class="nb">{</span>Acknowledgments<span class="nb">}</span>
<span class="linenos">468</span>
<span class="linenos">469</span>We thank the anonymous reviewers for their valuable feedback. This work was supported
<span class="linenos">470</span>by the National Science Foundation under Grant No. 12345. Computational resources
<span class="linenos">471</span>were provided by the University Computing Center.
<span class="linenos">472</span>
<span class="linenos">473</span><span class="c">% ==================== Bibliography ====================</span>
<span class="linenos">474</span>
<span class="linenos">475</span><span class="k">\begin</span><span class="nb">{</span>thebibliography<span class="nb">}{</span>10<span class="nb">}</span>
<span class="linenos">476</span>
<span class="linenos">477</span><span class="k">\bibitem</span><span class="nb">{</span>lecun2015deep<span class="nb">}</span>
<span class="linenos">478</span>Y.~LeCun, Y.~Bengio, and G.~Hinton.
<span class="linenos">479</span><span class="k">\newblock</span> Deep learning.
<span class="linenos">480</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> Nature<span class="nb">}</span>, 521(7553):436--444, 2015.
<span class="linenos">481</span>
<span class="linenos">482</span><span class="k">\bibitem</span><span class="nb">{</span>goodfellow2016deep<span class="nb">}</span>
<span class="linenos">483</span>I.~Goodfellow, Y.~Bengio, and A.~Courville.
<span class="linenos">484</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> Deep Learning<span class="nb">}</span>.
<span class="linenos">485</span><span class="k">\newblock</span> MIT Press, 2016.
<span class="linenos">486</span>
<span class="linenos">487</span><span class="k">\bibitem</span><span class="nb">{</span>krizhevsky2012imagenet<span class="nb">}</span>
<span class="linenos">488</span>A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
<span class="linenos">489</span><span class="k">\newblock</span> Imagenet classification with deep convolutional neural networks.
<span class="linenos">490</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> Advances in Neural Information Processing Systems<span class="nb">}</span>, pages
<span class="linenos">491</span>  1097--1105, 2012.
<span class="linenos">492</span>
<span class="linenos">493</span><span class="k">\bibitem</span><span class="nb">{</span>lecun1998gradient<span class="nb">}</span>
<span class="linenos">494</span>Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
<span class="linenos">495</span><span class="k">\newblock</span> Gradient-based learning applied to document recognition.
<span class="linenos">496</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> Proceedings of the IEEE<span class="nb">}</span>, 86(11):2278--2324, 1998.
<span class="linenos">497</span>
<span class="linenos">498</span><span class="k">\bibitem</span><span class="nb">{</span>simonyan2014very<span class="nb">}</span>
<span class="linenos">499</span>K.~Simonyan and A.~Zisserman.
<span class="linenos">500</span><span class="k">\newblock</span> Very deep convolutional networks for large-scale image recognition.
<span class="linenos">501</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> arXiv preprint arXiv:1409.1556<span class="nb">}</span>, 2014.
<span class="linenos">502</span>
<span class="linenos">503</span><span class="k">\bibitem</span><span class="nb">{</span>szegedy2015going<span class="nb">}</span>
<span class="linenos">504</span>C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
<span class="linenos">505</span>  V.~Vanhoucke, and A.~Rabinovich.
<span class="linenos">506</span><span class="k">\newblock</span> Going deeper with convolutions.
<span class="linenos">507</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> CVPR<span class="nb">}</span>, pages 1--9, 2015.
<span class="linenos">508</span>
<span class="linenos">509</span><span class="k">\bibitem</span><span class="nb">{</span>he2016deep<span class="nb">}</span>
<span class="linenos">510</span>K.~He, X.~Zhang, S.~Ren, and J.~Sun.
<span class="linenos">511</span><span class="k">\newblock</span> Deep residual learning for image recognition.
<span class="linenos">512</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> CVPR<span class="nb">}</span>, pages 770--778, 2016.
<span class="linenos">513</span>
<span class="linenos">514</span><span class="k">\bibitem</span><span class="nb">{</span>huang2017densely<span class="nb">}</span>
<span class="linenos">515</span>G.~Huang, Z.~Liu, L.~Van Der Maaten, and K.~Q. Weinberger.
<span class="linenos">516</span><span class="k">\newblock</span> Densely connected convolutional networks.
<span class="linenos">517</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> CVPR<span class="nb">}</span>, pages 4700--4708, 2017.
<span class="linenos">518</span>
<span class="linenos">519</span><span class="k">\bibitem</span><span class="nb">{</span>srivastava2014dropout<span class="nb">}</span>
<span class="linenos">520</span>N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
<span class="linenos">521</span><span class="k">\newblock</span> Dropout: A simple way to prevent neural networks from overfitting.
<span class="linenos">522</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> The Journal of Machine Learning Research<span class="nb">}</span>, 15(1):1929--1958,
<span class="linenos">523</span>  2014.
<span class="linenos">524</span>
<span class="linenos">525</span><span class="k">\bibitem</span><span class="nb">{</span>ioffe2015batch<span class="nb">}</span>
<span class="linenos">526</span>S.~Ioffe and C.~Szegedy.
<span class="linenos">527</span><span class="k">\newblock</span> Batch normalization: Accelerating deep network training by reducing
<span class="linenos">528</span>  internal covariate shift.
<span class="linenos">529</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> ICML<span class="nb">}</span>, pages 448--456, 2015.
<span class="linenos">530</span>
<span class="linenos">531</span><span class="k">\bibitem</span><span class="nb">{</span>shorten2019survey<span class="nb">}</span>
<span class="linenos">532</span>C.~Shorten and T.~M. Khoshgoftaar.
<span class="linenos">533</span><span class="k">\newblock</span> A survey on image data augmentation for deep learning.
<span class="linenos">534</span><span class="k">\newblock</span> <span class="nb">{</span><span class="k">\em</span> Journal of Big Data<span class="nb">}</span>, 6(1):1--48, 2019.
<span class="linenos">535</span>
<span class="linenos">536</span><span class="k">\bibitem</span><span class="nb">{</span>yosinski2014transferable<span class="nb">}</span>
<span class="linenos">537</span>J.~Yosinski, J.~Clune, Y.~Bengio, and H.~Lipson.
<span class="linenos">538</span><span class="k">\newblock</span> How transferable are features in deep neural networks?
<span class="linenos">539</span><span class="k">\newblock</span> In <span class="nb">{</span><span class="k">\em</span> Advances in Neural Information Processing Systems<span class="nb">}</span>, pages
<span class="linenos">540</span>  3320--3328, 2014.
<span class="linenos">541</span>
<span class="linenos">542</span><span class="k">\end</span><span class="nb">{</span>thebibliography<span class="nb">}</span>
<span class="linenos">543</span>
<span class="linenos">544</span><span class="c">% ==================== Appendices ====================</span>
<span class="linenos">545</span>
<span class="linenos">546</span><span class="k">\appendix</span>
<span class="linenos">547</span>
<span class="linenos">548</span><span class="k">\section</span><span class="nb">{</span>Hyperparameter Search Details<span class="nb">}</span>
<span class="linenos">549</span><span class="k">\label</span><span class="nb">{</span>app:hyperparams<span class="nb">}</span>
<span class="linenos">550</span>
<span class="linenos">551</span>We conducted grid search over the following hyperparameters:
<span class="linenos">552</span>
<span class="linenos">553</span><span class="k">\begin</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">554</span>    <span class="k">\item</span> Learning rate: <span class="s">$</span><span class="nv">\{</span><span class="m">0</span><span class="nb">.</span><span class="m">01</span><span class="nb">, </span><span class="m">0</span><span class="nb">.</span><span class="m">05</span><span class="nb">, </span><span class="m">0</span><span class="nb">.</span><span class="m">1</span><span class="nb">, </span><span class="m">0</span><span class="nb">.</span><span class="m">2</span><span class="nv">\}</span><span class="s">$</span>
<span class="linenos">555</span>    <span class="k">\item</span> Weight decay: <span class="s">$</span><span class="nv">\{</span><span class="m">10</span><span class="nb">^{</span><span class="o">-</span><span class="m">4</span><span class="nb">}, </span><span class="m">5</span><span class="nb"> </span><span class="nv">\times</span><span class="nb"> </span><span class="m">10</span><span class="nb">^{</span><span class="o">-</span><span class="m">4</span><span class="nb">}, </span><span class="m">10</span><span class="nb">^{</span><span class="o">-</span><span class="m">3</span><span class="nb">}</span><span class="nv">\}</span><span class="s">$</span>
<span class="linenos">556</span>    <span class="k">\item</span> Dropout rate: <span class="s">$</span><span class="nv">\{</span><span class="m">0</span><span class="nb">.</span><span class="m">3</span><span class="nb">, </span><span class="m">0</span><span class="nb">.</span><span class="m">5</span><span class="nb">, </span><span class="m">0</span><span class="nb">.</span><span class="m">7</span><span class="nv">\}</span><span class="s">$</span>
<span class="linenos">557</span>    <span class="k">\item</span> Batch size: <span class="s">$</span><span class="nv">\{</span><span class="m">64</span><span class="nb">, </span><span class="m">128</span><span class="nb">, </span><span class="m">256</span><span class="nv">\}</span><span class="s">$</span>
<span class="linenos">558</span><span class="k">\end</span><span class="nb">{</span>itemize<span class="nb">}</span>
<span class="linenos">559</span>
<span class="linenos">560</span>The best configuration for ResNet-18 on CIFAR-10 was: learning rate = 0.1,
<span class="linenos">561</span>weight decay = <span class="s">$</span><span class="m">5</span><span class="nb"> </span><span class="nv">\times</span><span class="nb"> </span><span class="m">10</span><span class="nb">^{</span><span class="o">-</span><span class="m">4</span><span class="nb">}</span><span class="s">$</span>, dropout = 0.5, batch size = 128.
<span class="linenos">562</span>
<span class="linenos">563</span><span class="k">\section</span><span class="nb">{</span>Additional Experimental Results<span class="nb">}</span>
<span class="linenos">564</span><span class="k">\label</span><span class="nb">{</span>app:additional<span class="nb">}</span>
<span class="linenos">565</span>
<span class="linenos">566</span><span class="k">\subsection</span><span class="nb">{</span>Learning Curves<span class="nb">}</span>
<span class="linenos">567</span>
<span class="linenos">568</span>Training and validation accuracy curves for all models show consistent convergence
<span class="linenos">569</span>patterns. ResNet models converge faster than VGG-style networks due to better
<span class="linenos">570</span>gradient flow.
<span class="linenos">571</span>
<span class="linenos">572</span><span class="k">\subsection</span><span class="nb">{</span>Ablation Studies<span class="nb">}</span>
<span class="linenos">573</span>
<span class="linenos">574</span>We performed ablation studies on our Custom Hybrid architecture:
<span class="linenos">575</span>
<span class="linenos">576</span><span class="k">\begin</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">577</span>    <span class="k">\item</span> Removing skip connections: -2.3<span class="k">\%</span> accuracy
<span class="linenos">578</span>    <span class="k">\item</span> Removing batch normalization: -1.8<span class="k">\%</span> accuracy
<span class="linenos">579</span>    <span class="k">\item</span> Reducing depth by 50<span class="k">\%</span>: -1.5<span class="k">\%</span> accuracy
<span class="linenos">580</span>    <span class="k">\item</span> Removing data augmentation: -3.2<span class="k">\%</span> accuracy
<span class="linenos">581</span><span class="k">\end</span><span class="nb">{</span>enumerate<span class="nb">}</span>
<span class="linenos">582</span>
<span class="linenos">583</span><span class="k">\section</span><span class="nb">{</span>Implementation Details<span class="nb">}</span>
<span class="linenos">584</span><span class="k">\label</span><span class="nb">{</span>app:implementation<span class="nb">}</span>
<span class="linenos">585</span>
<span class="linenos">586</span>All experiments were implemented in PyTorch 1.12. Training was performed on
<span class="linenos">587</span>NVIDIA Tesla V100 GPUs. Average training time was 6 hours for ResNet-18 and
<span class="linenos">588</span>18 hours for ResNet-50 on CIFAR-10.
<span class="linenos">589</span>
<span class="linenos">590</span>Code is available at: <span class="k">\url</span><span class="nb">{</span>https://github.com/username/cnn-image-classification<span class="nb">}</span>
<span class="linenos">591</span>
<span class="linenos">592</span><span class="k">\end</span><span class="nb">{</span>document<span class="nb">}</span>
</code></pre></div>

    </div>
</article>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'en';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.getElementById('copy-code-btn').addEventListener('click', function() {
        var code = document.querySelector('.example-code .highlight');
        // Extract just the code text, not line numbers
        var lines = code.querySelectorAll('.code pre span.line');
        var text;
        if (lines.length > 0) {
            text = Array.from(lines).map(function(l) { return l.textContent; }).join('\n');
        } else {
            // Fallback: get all code text
            var codeEl = code.querySelector('pre code') || code.querySelector('pre');
            text = codeEl ? codeEl.textContent : code.textContent;
        }
        navigator.clipboard.writeText(text);
        this.textContent = 'Copied!';
        var btn = this;
        setTimeout(function() { btn.textContent = 'Copy code'; }, 2000);
    });
</script>

</body>
</html>
{% endraw %}