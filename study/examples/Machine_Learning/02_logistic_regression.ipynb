{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 로지스틱 회귀 (Logistic Regression)\n",
    "\n",
    "## 학습 목표\n",
    "- 로지스틱 회귀의 원리 이해 (이진 분류)\n",
    "- 시그모이드 함수와 확률 해석\n",
    "- 분류 평가 지표 (정확도, 정밀도, 재현율, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, roc_auc_score)\n",
    "from sklearn.datasets import make_classification, load_iris\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 시그모이드 함수 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 시그모이드 함수 시각화\n",
    "z = np.linspace(-10, 10, 100)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(z, sigmoid(z), linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('σ(z)')\n",
    "plt.title('Sigmoid Function: σ(z) = 1 / (1 + e^(-z))')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이진 분류 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 데이터 생성\n",
    "X, y = make_classification(\n",
    "    n_samples=500, \n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y classes: {np.unique(y)}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', label='Class 0', alpha=0.6, edgecolors='black')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='red', label='Class 1', alpha=0.6, edgecolors='black')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Binary Classification Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 로지스틱 회귀 모델\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # 클래스 1의 확률\n",
    "\n",
    "# 평가 지표\n",
    "print(\"=== Classification Metrics ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrue Negatives: {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives: {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ROC 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 곡선\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결정 경계 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title='Decision Boundary'):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', label='Class 0', edgecolors='black')\n",
    "    plt.scatter(X[y==1, 0], X[y==1, 1], c='red', label='Class 1', edgecolors='black')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(model, X_test, y_test, 'Logistic Regression Decision Boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 다중 클래스 분류 (Iris Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris 데이터 로드\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "print(f\"Shape: {X_iris.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 로지스틱 회귀\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "model_multi = LogisticRegression(multi_class='multinomial', max_iter=200, random_state=42)\n",
    "model_multi.fit(X_train_i, y_train_i)\n",
    "\n",
    "y_pred_i = model_multi.predict(X_test_i)\n",
    "print(f\"Accuracy: {accuracy_score(y_test_i, y_pred_i):.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_i, y_pred_i, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 혼동 행렬\n",
    "cm_multi = confusion_matrix(y_test_i, y_pred_i)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix - Iris Dataset')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "### 핵심 개념\n",
    "- **로지스틱 회귀**: 시그모이드 함수로 확률 출력 (0~1)\n",
    "- **결정 경계**: P(y=1) = 0.5인 지점\n",
    "- **평가 지표**:\n",
    "  - Accuracy: 전체 정확도\n",
    "  - Precision: 양성 예측 중 실제 양성 비율\n",
    "  - Recall: 실제 양성 중 예측 성공 비율\n",
    "  - F1 Score: Precision과 Recall의 조화 평균\n",
    "\n",
    "### 다음 단계\n",
    "- 규제 (L1/L2 Regularization)\n",
    "- 임계값 조정\n",
    "- 불균형 데이터 처리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
