{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가 (Model Evaluation)\n",
    "\n",
    "이 노트북에서는 머신러닝 모델의 성능을 평가하는 다양한 지표와 방법을 학습합니다.\n",
    "\n",
    "## 목차\n",
    "1. 분류 평가 지표\n",
    "   - 혼동 행렬 (Confusion Matrix)\n",
    "   - 정확도, 정밀도, 재현율, F1-score\n",
    "   - ROC 곡선과 AUC\n",
    "   - Precision-Recall 곡선\n",
    "2. 다중 분류 평가\n",
    "3. 회귀 평가 지표\n",
    "4. 학습 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report,\n",
    "    roc_curve, roc_auc_score, auc,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # MacOS용 한글 폰트\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 분류 평가 지표\n",
    "\n",
    "### 1.1 혼동 행렬 (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 예시 데이터\n",
    "y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 1])\n",
    "y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1])\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"혼동 행렬:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# 혼동 행렬 요소 추출\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"TN (True Negative): {tn}\")\n",
    "print(f\"FP (False Positive): {fp} - Type I Error (위양성)\")\n",
    "print(f\"FN (False Negative): {fn} - Type II Error (위음성)\")\n",
    "print(f\"TP (True Positive): {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix', fontsize=14, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 정확도, 정밀도, 재현율, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 지표 계산\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"=== 분류 평가 지표 ===\")\n",
    "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"  - (TP + TN) / (TP + TN + FP + FN)\")\n",
    "print(f\"  - 전체 예측 중 정답 비율\\n\")\n",
    "\n",
    "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
    "print(f\"  - TP / (TP + FP)\")\n",
    "print(f\"  - 양성으로 예측한 것 중 실제 양성의 비율\\n\")\n",
    "\n",
    "print(f\"재현율 (Recall/Sensitivity): {recall:.4f}\")\n",
    "print(f\"  - TP / (TP + FN)\")\n",
    "print(f\"  - 실제 양성 중 양성으로 예측한 비율\\n\")\n",
    "\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"  - 2 * (Precision * Recall) / (Precision + Recall)\")\n",
    "print(f\"  - 정밀도와 재현율의 조화평균\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동 계산으로 검증\n",
    "accuracy_manual = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision_manual = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall_manual = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_manual = 2 * precision_manual * recall_manual / (precision_manual + recall_manual) if (precision_manual + recall_manual) > 0 else 0\n",
    "\n",
    "print(\"=== 수동 계산 검증 ===\")\n",
    "print(f\"Accuracy:  {accuracy_manual:.4f}\")\n",
    "print(f\"Precision: {precision_manual:.4f}\")\n",
    "print(f\"Recall:    {recall_manual:.4f}\")\n",
    "print(f\"F1-Score:  {f1_manual:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 실제 데이터셋으로 분류 평가 - Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유방암 데이터셋 로드\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Breast Cancer Classification Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {cancer.feature_names[:5]}... (total {len(cancer.feature_names)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Malignant', 'Benign'])\n",
    "disp.plot(ax=ax, cmap='RdYlGn', values_format='d')\n",
    "plt.title('Confusion Matrix - Breast Cancer Classification', fontsize=14, pad=20)\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 리포트\n",
    "report = classification_report(y_test, y_pred, target_names=['Malignant', 'Benign'])\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(report)\n",
    "\n",
    "# 딕셔너리 형태로도 확인\n",
    "report_dict = classification_report(y_test, y_pred, target_names=['Malignant', 'Benign'], output_dict=True)\n",
    "print(f\"\\nBenign 클래스의 F1-score: {report_dict['Benign']['f1-score']:.4f}\")\n",
    "print(f\"Malignant 클래스의 Recall: {report_dict['Malignant']['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ROC 곡선과 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC 곡선 계산\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# ROC 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=12)\n",
    "plt.title('ROC Curve - Breast Cancer Classification', fontsize=14, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"AUC Score (sklearn 직접 계산): {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(\"\\nAUC 해석:\")\n",
    "print(\"  - 1.0: 완벽한 분류기\")\n",
    "print(\"  - 0.5: 랜덤 분류기\")\n",
    "print(\"  - 0.0: 최악의 분류기\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Precision-Recall 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR 곡선 계산\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "\n",
    "# PR 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, 'b-', linewidth=2, label=f'PR Curve (AP = {ap:.4f})')\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=14, pad=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Precision (AP): {ap:.4f}\")\n",
    "print(\"\\nROC vs PR 곡선:\")\n",
    "print(\"  - ROC: 불균형 데이터에서도 안정적, 전반적인 성능 평가\")\n",
    "print(\"  - PR: 불균형 데이터에서 더 민감, 양성 클래스 예측 성능에 집중\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC와 PR 곡선 동시 비교\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ROC Curve\n",
    "axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', linewidth=2)\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0].set_title('ROC Curve', fontsize=14)\n",
    "axes[0].legend(loc='lower right', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PR Curve\n",
    "axes[1].plot(recall, precision, 'g-', linewidth=2, label=f'PR (AP = {ap:.4f})')\n",
    "axes[1].set_xlabel('Recall', fontsize=12)\n",
    "axes[1].set_ylabel('Precision', fontsize=12)\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=14)\n",
    "axes[1].legend(loc='best', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다중 분류 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris 데이터셋 로드 (3개 클래스)\n",
    "iris = load_iris()\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model_iris = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_iris.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = model_iris.predict(X_test_iris)\n",
    "\n",
    "print(\"Iris Multi-class Classification\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "print(f\"Features: {iris.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 혼동 행렬\n",
    "cm_iris = confusion_matrix(y_test_iris, y_pred_iris)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_iris, display_labels=iris.target_names)\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title('Multi-class Confusion Matrix - Iris Dataset', fontsize=14, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류 지표\n",
    "print(\"=== Multi-class Classification Metrics ===\")\n",
    "print(f\"정확도: {accuracy_score(y_test_iris, y_pred_iris):.4f}\\n\")\n",
    "\n",
    "# F1-score의 다양한 평균 방법\n",
    "f1_macro = f1_score(y_test_iris, y_pred_iris, average='macro')\n",
    "f1_weighted = f1_score(y_test_iris, y_pred_iris, average='weighted')\n",
    "f1_micro = f1_score(y_test_iris, y_pred_iris, average='micro')\n",
    "\n",
    "print(f\"F1-Score (macro):    {f1_macro:.4f}  - 각 클래스의 F1을 단순 평균\")\n",
    "print(f\"F1-Score (weighted): {f1_weighted:.4f}  - 각 클래스의 샘플 수로 가중 평균\")\n",
    "print(f\"F1-Score (micro):    {f1_micro:.4f}  - 전체 TP, FP, FN을 합산하여 계산\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 리포트\n",
    "report_iris = classification_report(y_test_iris, y_pred_iris, target_names=iris.target_names)\n",
    "print(\"\\n=== Classification Report - Iris ===\")\n",
    "print(report_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 클래스 ROC 곡선\n",
    "y_test_iris_bin = label_binarize(y_test_iris, classes=[0, 1, 2])\n",
    "y_proba_iris = model_iris.predict_proba(X_test_iris)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i, (color, name) in enumerate(zip(colors, iris.target_names)):\n",
    "    fpr_i, tpr_i, _ = roc_curve(y_test_iris_bin[:, i], y_proba_iris[:, i])\n",
    "    roc_auc_i = auc(fpr_i, tpr_i)\n",
    "    plt.plot(fpr_i, tpr_i, color=color, linewidth=2,\n",
    "             label=f'{name} (AUC = {roc_auc_i:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Multi-class ROC Curves - Iris Dataset', fontsize=14, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 회귀 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 예시\n",
    "y_true_reg = np.array([3.0, -0.5, 2.0, 7.0, 4.5])\n",
    "y_pred_reg = np.array([2.5, 0.0, 2.0, 8.0, 4.0])\n",
    "\n",
    "# 회귀 지표 계산\n",
    "mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true_reg, y_pred_reg)\n",
    "\n",
    "print(\"=== 회귀 평가 지표 ===\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "print(f\"  - 평균적으로 예측이 실제값에서 {mae:.4f} 만큼 벗어남\\n\")\n",
    "\n",
    "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
    "print(f\"  - 큰 오차에 더 큰 패널티\\n\")\n",
    "\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "print(f\"  - 타겟과 같은 단위로 해석 가능\\n\")\n",
    "\n",
    "print(f\"R² (Coefficient of Determination): {r2:.4f}\")\n",
    "print(f\"  - 0~1, 1에 가까울수록 좋음\")\n",
    "print(f\"  - 모델이 분산의 {r2*100:.1f}%를 설명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동 계산으로 검증\n",
    "print(\"\\n=== 수동 계산 검증 ===\")\n",
    "mae_manual = np.mean(np.abs(y_true_reg - y_pred_reg))\n",
    "mse_manual = np.mean((y_true_reg - y_pred_reg)**2)\n",
    "rmse_manual = np.sqrt(mse_manual)\n",
    "r2_manual = 1 - np.sum((y_true_reg - y_pred_reg)**2) / np.sum((y_true_reg - np.mean(y_true_reg))**2)\n",
    "\n",
    "print(f\"MAE:  {mae_manual:.4f}\")\n",
    "print(f\"MSE:  {mse_manual:.4f}\")\n",
    "print(f\"RMSE: {rmse_manual:.4f}\")\n",
    "print(f\"R²:   {r2_manual:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터셋으로 회귀 평가 - Diabetes Dataset\n",
    "diabetes = load_diabetes()\n",
    "X_train_diab, X_test_diab, y_train_diab, y_test_diab = train_test_split(\n",
    "    diabetes.data, diabetes.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 선형 회귀 모델 학습\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_diab, y_train_diab)\n",
    "y_pred_diab = model_reg.predict(X_test_diab)\n",
    "\n",
    "# 평가\n",
    "mae_diab = mean_absolute_error(y_test_diab, y_pred_diab)\n",
    "mse_diab = mean_squared_error(y_test_diab, y_pred_diab)\n",
    "rmse_diab = np.sqrt(mse_diab)\n",
    "r2_diab = r2_score(y_test_diab, y_pred_diab)\n",
    "\n",
    "print(\"Diabetes Regression Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE:  {mae_diab:.4f}\")\n",
    "print(f\"MSE:  {mse_diab:.4f}\")\n",
    "print(f\"RMSE: {rmse_diab:.4f}\")\n",
    "print(f\"R²:   {r2_diab:.4f}\")\n",
    "print(f\"\\n해석: 모델이 타겟 분산의 {r2_diab*100:.1f}%를 설명합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제값 vs 예측값 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_diab, y_pred_diab, alpha=0.6, edgecolors='k', s=80)\n",
    "plt.plot([y_test_diab.min(), y_test_diab.max()], \n",
    "         [y_test_diab.min(), y_test_diab.max()], \n",
    "         'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('실제값 (Actual)', fontsize=12)\n",
    "plt.ylabel('예측값 (Predicted)', fontsize=12)\n",
    "plt.title(f'실제값 vs 예측값 (R² = {r2_diab:.4f})', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차 분석\n",
    "residuals = y_test_diab - y_pred_diab\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 잔차 플롯\n",
    "axes[0].scatter(y_pred_diab, residuals, alpha=0.6, edgecolors='k', s=80)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('예측값 (Predicted)', fontsize=12)\n",
    "axes[0].set_ylabel('잔차 (Residuals)', fontsize=12)\n",
    "axes[0].set_title('Residual Plot', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 잔차 분포\n",
    "axes[1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('잔차 (Residuals)', fontsize=12)\n",
    "axes[1].set_ylabel('빈도 (Frequency)', fontsize=12)\n",
    "axes[1].set_title('Residuals Distribution', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"잔차 평균: {residuals.mean():.4f} (0에 가까워야 함)\")\n",
    "print(f\"잔차 표준편차: {residuals.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 곡선 (Learning Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 계산\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    LogisticRegression(max_iter=10000, random_state=42),\n",
    "    cancer.data, cancer.target,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 평균 및 표준편차\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.2, color='blue')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, \n",
    "                 alpha=0.2, color='orange')\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', linewidth=2, \n",
    "         label='Training Score')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='orange', linewidth=2, \n",
    "         label='Validation Score')\n",
    "plt.xlabel('Training Set Size', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Learning Curve - Breast Cancer Classification', fontsize=14, pad=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"학습 곡선 해석:\")\n",
    "print(\"  - 두 곡선이 모두 낮음 → 과소적합 (더 복잡한 모델 필요)\")\n",
    "print(\"  - 훈련 곡선 높고 검증 곡선 낮음 → 과적합 (정규화 필요)\")\n",
    "print(\"  - 두 곡선이 수렴 → 적절한 적합\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 평가 지표 선택 가이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종합 평가 함수\n",
    "def evaluate_classification(y_true, y_pred, y_proba=None):\n",
    "    \"\"\"분류 모델 종합 평가\"\"\"\n",
    "    print(\"=== 분류 평가 결과 ===\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    if y_proba is not None and len(np.unique(y_true)) == 2:\n",
    "        print(f\"ROC-AUC:   {roc_auc_score(y_true, y_proba):.4f}\")\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"회귀 모델 종합 평가\"\"\"\n",
    "    print(\"=== 회귀 평가 결과 ===\")\n",
    "    print(f\"MAE:  {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"MSE:  {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.4f}\")\n",
    "    print(f\"R²:   {r2_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# 테스트\n",
    "print(\"Breast Cancer 모델 평가:\")\n",
    "evaluate_classification(y_test, y_pred, y_proba)\n",
    "\n",
    "print(\"\\nDiabetes 회귀 모델 평가:\")\n",
    "evaluate_regression(y_test_diab, y_pred_diab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 요약 표\n",
    "import pandas as pd\n",
    "\n",
    "metrics_summary = pd.DataFrame({\n",
    "    '지표': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'MAE', 'MSE', 'R²'],\n",
    "    '분류/회귀': ['분류', '분류', '분류', '분류', '분류', '회귀', '회귀', '회귀'],\n",
    "    '범위': ['0-1', '0-1', '0-1', '0-1', '0-1', '0-∞', '0-∞', '-∞-1'],\n",
    "    '설명': [\n",
    "        '전체 정답 비율',\n",
    "        '양성 예측 중 실제 양성',\n",
    "        '실제 양성 중 양성 예측',\n",
    "        'Precision/Recall 조화평균',\n",
    "        '분류기 전반적 성능',\n",
    "        '평균 절대 오차',\n",
    "        '평균 제곱 오차',\n",
    "        '설명 분산 비율'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== 평가 지표 요약 ===\")\n",
    "print(metrics_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### 분류 문제 지표 선택\n",
    "\n",
    "1. **균형 데이터**: Accuracy, F1-score\n",
    "2. **불균형 데이터**: Precision, Recall, F1-score, PR-AUC\n",
    "   - 양성 클래스가 중요: Recall 중시 (암 진단, 사기 탐지)\n",
    "   - 오탐이 비용: Precision 중시 (스팸 필터)\n",
    "3. **확률 예측 품질**: ROC-AUC, PR-AUC\n",
    "4. **다중 분류**: Macro/Weighted/Micro F1\n",
    "\n",
    "### 회귀 문제 지표 선택\n",
    "\n",
    "1. **기본**: MSE, RMSE, MAE\n",
    "2. **이상치 민감도**: MAE (robust), MSE (sensitive)\n",
    "3. **상대적 오차**: R²\n",
    "4. **모델 비교**: R² (0~1 범위로 정규화)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
