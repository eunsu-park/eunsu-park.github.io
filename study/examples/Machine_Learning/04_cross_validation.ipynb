{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증과 하이퍼파라미터 튜닝\n",
    "\n",
    "이 노트북에서는 모델의 일반화 성능을 평가하는 교차검증과 최적의 하이퍼파라미터를 찾는 방법을 학습합니다.\n",
    "\n",
    "## 목차\n",
    "1. 교차검증 (Cross-Validation)\n",
    "   - K-Fold Cross-Validation\n",
    "   - Stratified K-Fold\n",
    "   - Leave-One-Out CV\n",
    "   - Time Series Split\n",
    "2. 하이퍼파라미터 튜닝\n",
    "   - Grid Search\n",
    "   - Randomized Search\n",
    "3. 고급 기법\n",
    "   - Nested Cross-Validation\n",
    "   - Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_diabetes\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, cross_validate,\n",
    "    KFold, StratifiedKFold, LeaveOneOut, ShuffleSplit,\n",
    "    TimeSeriesSplit, RepeatedKFold,\n",
    "    GridSearchCV, RandomizedSearchCV,\n",
    "    learning_curve, validation_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # MacOS용 한글 폰트\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 교차검증 (Cross-Validation)\n",
    "\n",
    "### 1.1 K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 모델 생성\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# K-Fold 교차검증 (K=5)\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"=== K-Fold 교차검증 (K=5) ===\")\n",
    "print(f\"각 폴드 점수: {scores}\")\n",
    "print(f\"평균 정확도: {scores.mean():.4f}\")\n",
    "print(f\"표준편차: {scores.std():.4f}\")\n",
    "print(f\"95% 신뢰구간: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 수동 구현으로 이해하기\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\n=== K-Fold 분할 시각화 ===\")\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "    # 데이터 분할\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # 모델 학습 및 평가\n",
    "    model_fold = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model_fold.fit(X_train, y_train)\n",
    "    score = model_fold.score(X_val, y_val)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    print(f\"Fold {fold}: Train={len(train_idx)}, Val={len(val_idx)}, Accuracy={score:.4f}\")\n",
    "\n",
    "print(f\"\\n평균 정확도: {np.mean(fold_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K 값에 따른 성능 비교\n",
    "k_values = [3, 5, 10, 15, 20]\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    scores = cross_val_score(model, X, y, cv=k, scoring='accuracy')\n",
    "    mean_scores.append(scores.mean())\n",
    "    std_scores.append(scores.std())\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(k_values, mean_scores, yerr=std_scores, marker='o', \n",
    "             capsize=5, capthick=2, linewidth=2)\n",
    "plt.xlabel('K (Number of Folds)', fontsize=12)\n",
    "plt.ylabel('Mean Accuracy', fontsize=12)\n",
    "plt.title('K-Fold CV Performance vs K Value', fontsize=14, pad=20)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== K 값에 따른 성능 ===\")\n",
    "for k, mean, std in zip(k_values, mean_scores, std_scores):\n",
    "    print(f\"K={k:2d}: {mean:.4f} (+/- {std:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Stratified K-Fold (계층화 K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 비율 확인\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"전체 데이터 클래스 분포:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {cnt} ({cnt/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\n=== Stratified K-Fold 각 폴드의 클래스 분포 ===\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    train_classes = np.bincount(y[train_idx])\n",
    "    val_classes = np.bincount(y[val_idx])\n",
    "    \n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train: {train_classes} ({train_classes/train_classes.sum()*100})\")\n",
    "    print(f\"  Val:   {val_classes} ({val_classes/val_classes.sum()*100})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold vs Stratified K-Fold 성능 비교\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores_kf = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "scores_skf = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(\"=== K-Fold vs Stratified K-Fold ===\")\n",
    "print(f\"K-Fold:           {scores_kf.mean():.4f} (+/- {scores_kf.std():.4f})\")\n",
    "print(f\"Stratified K-Fold: {scores_skf.mean():.4f} (+/- {scores_skf.std():.4f})\")\n",
    "print(\"\\n불균형 데이터에서는 Stratified K-Fold가 더 안정적입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 다양한 교차검증 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out (LOO)\n",
    "loo = LeaveOneOut()\n",
    "print(f\"Leave-One-Out 분할 수: {loo.get_n_splits(X)} (데이터 수와 동일)\")\n",
    "print(\"LOO는 작은 데이터셋에서 유용하지만 계산 비용이 높습니다.\\n\")\n",
    "\n",
    "# Shuffle Split (랜덤 분할)\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "scores_ss = cross_val_score(model, X, y, cv=ss, scoring='accuracy')\n",
    "print(f\"Shuffle Split 평균: {scores_ss.mean():.4f} (+/- {scores_ss.std():.4f})\")\n",
    "print(\"각 분할이 독립적으로 랜덤 샘플링됩니다.\\n\")\n",
    "\n",
    "# Repeated K-Fold (반복)\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "scores_rkf = cross_val_score(model, X, y, cv=rkf, scoring='accuracy')\n",
    "print(f\"Repeated K-Fold 평균: {scores_rkf.mean():.4f} (+/- {scores_rkf.std():.4f})\")\n",
    "print(f\"총 분할 수: {len(scores_rkf)} (5 folds × 10 repeats = 50)\")\n",
    "print(\"더 안정적인 추정을 위해 여러 번 반복합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 시계열 교차검증 (Time Series Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터용 교차검증\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"=== Time Series Split ===\")\n",
    "print(\"시계열 데이터는 과거 → 미래 순서를 유지해야 합니다.\\n\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train: [{train_idx[0]:3d}:{train_idx[-1]:3d}] ({len(train_idx)} samples)\")\n",
    "    print(f\"  Test:  [{test_idx[0]:3d}:{test_idx[-1]:3d}] ({len(test_idx)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Split 시각화\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, (train, test) in enumerate(tscv.split(X)):\n",
    "    # Train set\n",
    "    ax.barh(i, len(train), left=train[0], height=0.4, \n",
    "            align='center', color='blue', alpha=0.6, label='Train' if i == 0 else '')\n",
    "    # Test set\n",
    "    ax.barh(i, len(test), left=test[0], height=0.4, \n",
    "            align='center', color='red', alpha=0.6, label='Test' if i == 0 else '')\n",
    "\n",
    "ax.set_yticks(range(tscv.n_splits))\n",
    "ax.set_yticklabels([f'Fold {i+1}' for i in range(tscv.n_splits)])\n",
    "ax.set_xlabel('Sample Index', fontsize=12)\n",
    "ax.set_title('Time Series Split Visualization', fontsize=14, pad=20)\n",
    "ax.legend(loc='upper left', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. cross_val_score vs cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate: 여러 지표 동시 평가\n",
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model, X, y,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"=== cross_validate 결과 ===\")\n",
    "for metric in scoring:\n",
    "    train_key = f'train_{metric}'\n",
    "    test_key = f'test_{metric}'\n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  Train: {cv_results[train_key].mean():.4f} (+/- {cv_results[train_key].std():.4f})\")\n",
    "    print(f\"  Test:  {cv_results[test_key].mean():.4f} (+/- {cv_results[test_key].std():.4f})\")\n",
    "\n",
    "print(f\"\\n평균 학습 시간: {cv_results['fit_time'].mean():.4f}초\")\n",
    "print(f\"평균 예측 시간: {cv_results['score_time'].mean():.4f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Train': [cv_results[f'train_{m}'].mean() for m in scoring],\n",
    "    'Test': [cv_results[f'test_{m}'].mean() for m in scoring]\n",
    "})\n",
    "\n",
    "x = np.arange(len(metrics_df))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, metrics_df['Train'], width, label='Train', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, metrics_df['Test'], width, label='Test', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Train vs Test Scores (5-Fold CV)', fontsize=14, pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_df['Metric'])\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim([0.9, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 하이퍼파라미터 튜닝\n",
    "\n",
    "### 3.1 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast Cancer 데이터셋\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cancer)\n",
    "\n",
    "# 하이퍼파라미터 그리드\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "print(\"=== Grid Search ===\")\n",
    "print(f\"파라미터 조합 수: {len(param_grid['C']) * len(param_grid['gamma']) * len(param_grid['kernel'])}\")\n",
    "print(f\"CV Folds: 5\")\n",
    "print(f\"총 fit 횟수: {32 * 5} = 160\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search 실행\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # 모든 CPU 사용\n",
    ")\n",
    "\n",
    "grid_search.fit(X_scaled, y_cancer)\n",
    "\n",
    "print(\"\\n=== Grid Search 결과 ===\")\n",
    "print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
    "print(f\"최적 점수: {grid_search.best_score_:.4f}\")\n",
    "print(f\"최적 모델: {grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 결과 확인\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# 상위 10개 조합\n",
    "top_results = results_df.nsmallest(10, 'rank_test_score')[[\n",
    "    'params', 'mean_test_score', 'std_test_score', 'rank_test_score'\n",
    "]]\n",
    "\n",
    "print(\"\\n=== 상위 10개 파라미터 조합 ===\")\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(f\"Rank {int(row['rank_test_score'])}: {row['params']}\")\n",
    "    print(f\"  Score: {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search 결과 히트맵 (C vs gamma, rbf kernel)\n",
    "rbf_results = results_df[results_df['param_kernel'] == 'rbf']\n",
    "\n",
    "# Pivot table 생성\n",
    "pivot_table = rbf_results.pivot_table(\n",
    "    values='mean_test_score',\n",
    "    index='param_gamma',\n",
    "    columns='param_C'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.4f', cmap='YlGnBu', \n",
    "            cbar_kws={'label': 'Accuracy'})\n",
    "plt.title('Grid Search Results (RBF Kernel): C vs Gamma', fontsize=14, pad=20)\n",
    "plt.xlabel('C (Regularization Parameter)', fontsize=12)\n",
    "plt.ylabel('Gamma', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 분포 정의\n",
    "param_distributions = {\n",
    "    'C': uniform(0.1, 100),  # 0.1 ~ 100.1 균등 분포\n",
    "    'gamma': uniform(0.001, 1),  # 0.001 ~ 1.001 균등 분포\n",
    "    'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "# Randomized Search 실행\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_distributions,\n",
    "    n_iter=50,  # 50개 조합 시도\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_scaled, y_cancer)\n",
    "\n",
    "print(\"\\n=== Randomized Search 결과 ===\")\n",
    "print(f\"최적 파라미터: {random_search.best_params_}\")\n",
    "print(f\"최적 점수: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search vs Randomized Search 비교\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': ['Grid Search', 'Randomized Search'],\n",
    "    'Best Score': [grid_search.best_score_, random_search.best_score_],\n",
    "    'N Iterations': [len(grid_search.cv_results_['params']), \n",
    "                     len(random_search.cv_results_['params'])]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Grid Search vs Randomized Search ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\nRandomized Search:\")\n",
    "print(\"  - 장점: 계산 효율적, 연속 분포 탐색 가능\")\n",
    "print(\"  - 단점: 최적해 보장 없음\")\n",
    "print(\"\\nGrid Search:\")\n",
    "print(\"  - 장점: 모든 조합 탐색, 최적해 보장 (그리드 내)\")\n",
    "print(\"  - 단점: 조합 수가 기하급수적으로 증가\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 파라미터 그리드\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_cancer, y_cancer)\n",
    "\n",
    "print(\"\\n=== Random Forest Grid Search 결과 ===\")\n",
    "print(f\"최적 파라미터: {rf_grid_search.best_params_}\")\n",
    "print(f\"최적 점수: {rf_grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance 시각화\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': cancer.feature_names,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances (Optimized Random Forest)', fontsize=14, pad=20)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Features:\")\n",
    "print(feature_importance.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 중첩 교차검증 (Nested Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중첩 CV: 외부 루프(모델 평가) + 내부 루프(하이퍼파라미터 튜닝)\n",
    "\n",
    "# 내부 CV (하이퍼파라미터 튜닝)\n",
    "param_grid_nested = {'C': [0.1, 1, 10], 'gamma': [0.1, 0.01]}\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search_nested = GridSearchCV(\n",
    "    SVC(kernel='rbf', random_state=42), \n",
    "    param_grid_nested, \n",
    "    cv=inner_cv, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# 외부 CV (모델 평가)\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "nested_scores = cross_val_score(\n",
    "    grid_search_nested, \n",
    "    X_scaled, \n",
    "    y_cancer, \n",
    "    cv=outer_cv, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(\"=== 중첩 교차검증 결과 ===\")\n",
    "print(f\"각 외부 폴드 점수: {nested_scores}\")\n",
    "print(f\"평균 점수: {nested_scores.mean():.4f} (+/- {nested_scores.std():.4f})\")\n",
    "\n",
    "# 비교: 일반 CV vs 중첩 CV\n",
    "grid_search_nested.fit(X_scaled, y_cancer)\n",
    "print(f\"\\n일반 CV 최적 점수: {grid_search_nested.best_score_:.4f}\")\n",
    "print(f\"중첩 CV 평균 점수: {nested_scores.mean():.4f}\")\n",
    "print(\"\\n중첩 CV가 더 현실적인 일반화 성능을 추정합니다.\")\n",
    "print(\"일반 CV는 과대평가될 수 있습니다 (데이터 누수).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 파이프라인과 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 정의\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# 파라미터 이름: step__parameter\n",
    "param_grid_pipeline = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': [0.1, 0.01, 0.001],\n",
    "    'svm__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "grid_search_pipeline = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid_pipeline, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 스케일링되지 않은 데이터 사용 (파이프라인이 처리)\n",
    "grid_search_pipeline.fit(X_cancer, y_cancer)\n",
    "\n",
    "print(\"\\n=== 파이프라인 Grid Search 결과 ===\")\n",
    "print(f\"최적 파라미터: {grid_search_pipeline.best_params_}\")\n",
    "print(f\"최적 점수: {grid_search_pipeline.best_score_:.4f}\")\n",
    "print(\"\\n파이프라인 사용의 장점:\")\n",
    "print(\"  - 전처리 단계를 자동으로 포함\")\n",
    "print(\"  - CV에서 데이터 누수 방지\")\n",
    "print(\"  - 코드 간결성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 곡선 (Learning Curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 계산\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    grid_search_pipeline.best_estimator_,\n",
    "    X_cancer, y_cancer,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 평균 및 표준편차\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.2, color='blue')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, \n",
    "                 alpha=0.2, color='orange')\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', linewidth=2, \n",
    "         label='Training Score')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='orange', linewidth=2, \n",
    "         label='Validation Score')\n",
    "plt.xlabel('Training Set Size', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Learning Curve', fontsize=14, pad=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"학습 곡선 해석:\")\n",
    "print(\"  - 두 곡선이 모두 낮음 → 과소적합\")\n",
    "print(\"  - 훈련 곡선 높고 검증 곡선 낮음 → 과적합\")\n",
    "print(\"  - 두 곡선이 수렴 → 적절한 적합\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 검증 곡선 (Validation Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C 파라미터에 대한 검증 곡선\n",
    "param_range = np.logspace(-4, 2, 10)\n",
    "\n",
    "train_scores_val, test_scores_val = validation_curve(\n",
    "    SVC(kernel='rbf', gamma=0.01, random_state=42),\n",
    "    X_scaled, y_cancer,\n",
    "    param_name='C',\n",
    "    param_range=param_range,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean_val = train_scores_val.mean(axis=1)\n",
    "train_std_val = train_scores_val.std(axis=1)\n",
    "test_mean_val = test_scores_val.mean(axis=1)\n",
    "test_std_val = test_scores_val.std(axis=1)\n",
    "\n",
    "# 검증 곡선 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(param_range, train_mean_val, 'o-', color='blue', linewidth=2, \n",
    "             label='Training Score')\n",
    "plt.semilogx(param_range, test_mean_val, 'o-', color='orange', linewidth=2, \n",
    "             label='Validation Score')\n",
    "plt.fill_between(param_range, train_mean_val - train_std_val, \n",
    "                 train_mean_val + train_std_val, alpha=0.2, color='blue')\n",
    "plt.fill_between(param_range, test_mean_val - test_std_val, \n",
    "                 test_mean_val + test_std_val, alpha=0.2, color='orange')\n",
    "plt.xlabel('C (Regularization Parameter)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Validation Curve (SVM RBF)', fontsize=14, pad=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"검증 곡선 해석:\")\n",
    "print(\"  - 왼쪽(작은 C): 과소적합 (정규화 강함)\")\n",
    "print(\"  - 중간: 적절한 복잡도\")\n",
    "print(\"  - 오른쪽(큰 C): 과적합 가능성 (정규화 약함)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 커스텀 스코어링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 스코어링 함수\n",
    "def custom_f1_score(y_true, y_pred):\n",
    "    \"\"\"가중 평균 F1-score\"\"\"\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "custom_scorer = make_scorer(custom_f1_score)\n",
    "\n",
    "# 커스텀 스코어러 사용\n",
    "scores_custom = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42), \n",
    "    X, y, \n",
    "    cv=5, \n",
    "    scoring=custom_scorer\n",
    ")\n",
    "\n",
    "print(\"=== 커스텀 스코어링 함수 ===\")\n",
    "print(f\"커스텀 F1-score: {scores_custom.mean():.4f} (+/- {scores_custom.std():.4f})\")\n",
    "\n",
    "# 내장 스코어링 함수들\n",
    "print(\"\\n내장 스코어링 함수:\")\n",
    "print(\"  분류: 'accuracy', 'precision', 'recall', 'f1', 'roc_auc'\")\n",
    "print(\"  회귀: 'r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# 최적 모델 저장\n",
    "best_model = grid_search_pipeline.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "print(\"최적 모델이 'best_model.pkl'에 저장되었습니다.\")\n",
    "\n",
    "# 결과 저장\n",
    "results = {\n",
    "    'best_params': grid_search_pipeline.best_params_,\n",
    "    'best_score': grid_search_pipeline.best_score_,\n",
    "    'cv_results': {\n",
    "        k: v.tolist() if isinstance(v, np.ndarray) else v\n",
    "        for k, v in grid_search_pipeline.cv_results_.items()\n",
    "        if k in ['params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('tuning_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"튜닝 결과가 'tuning_results.json'에 저장되었습니다.\")\n",
    "\n",
    "# 모델 로드\n",
    "loaded_model = joblib.load('best_model.pkl')\n",
    "print(f\"\\n로드된 모델: {loaded_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### 교차검증 방법 선택\n",
    "\n",
    "| 기법 | 용도 | 특징 |\n",
    "|------|------|------|\n",
    "| K-Fold | 일반적인 평가 | 데이터를 K개로 분할 |\n",
    "| Stratified K-Fold | 불균형 데이터 | 클래스 비율 유지 |\n",
    "| Time Series Split | 시계열 데이터 | 시간 순서 유지 |\n",
    "| Leave-One-Out | 작은 데이터셋 | 계산 비용 높음 |\n",
    "\n",
    "### 하이퍼파라미터 튜닝 방법\n",
    "\n",
    "| 방법 | 장점 | 단점 | 사용 시기 |\n",
    "|------|------|------|----------|\n",
    "| Grid Search | 완전 탐색 | 계산 비용 높음 | 파라미터 적고 범위 명확 |\n",
    "| Randomized Search | 효율적 | 최적해 보장 없음 | 파라미터 많고 범위 불확실 |\n",
    "| Nested CV | 신뢰성 높음 | 계산 비용 매우 높음 | 연구, 벤치마크 |\n",
    "\n",
    "### 실전 팁\n",
    "\n",
    "1. **작은 데이터셋**: Stratified K-Fold (k=5 or 10)\n",
    "2. **큰 데이터셋**: Stratified K-Fold (k=3) 또는 단일 train/test split\n",
    "3. **시계열**: Time Series Split\n",
    "4. **파라미터 탐색**: Grid Search (좁은 범위) → Randomized Search (넓은 범위)\n",
    "5. **파이프라인**: 전처리 포함하여 데이터 누수 방지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
