{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 05. 데이터 전처리 (Data Preprocessing)\n",
    "\n",
    "## 학습 목표\n",
    "- 결측치 처리 전략 이해\n",
    "- 특성 스케일링 방법 비교\n",
    "- 범주형 변수 인코딩\n",
    "- 불균형 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. 결측치 처리 (Handling Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 있는 샘플 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'age': [25, 30, np.nan, 40, 35, np.nan, 50, 28],\n",
    "    'income': [50000, np.nan, 60000, 80000, np.nan, 70000, 90000, 55000],\n",
    "    'score': [85, 90, 75, np.nan, 88, 92, np.nan, 78]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"원본 데이터:\")\n",
    "print(df)\n",
    "print(f\"\\n결측치 개수:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\n결측치 비율:\\n{df.isnull().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### 1.1 SimpleImputer - 기본 대체 전략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값으로 대체\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df_mean = pd.DataFrame(\n",
    "    imputer_mean.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "# 중앙값으로 대체\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "df_median = pd.DataFrame(\n",
    "    imputer_median.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "# 최빈값으로 대체\n",
    "imputer_frequent = SimpleImputer(strategy='most_frequent')\n",
    "df_frequent = pd.DataFrame(\n",
    "    imputer_frequent.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "# 상수값으로 대체\n",
    "imputer_constant = SimpleImputer(strategy='constant', fill_value=0)\n",
    "df_constant = pd.DataFrame(\n",
    "    imputer_constant.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "print(\"평균값 대체:\")\n",
    "print(df_mean)\n",
    "print(f\"\\n중앙값 대체 (age 컬럼): {df_median['age'].values}\")\n",
    "print(f\"최빈값 대체 (age 컬럼): {df_frequent['age'].values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### 1.2 KNNImputer - K-최근접 이웃 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 기반 결측치 대체\n",
    "imputer_knn = KNNImputer(n_neighbors=3)\n",
    "df_knn = pd.DataFrame(\n",
    "    imputer_knn.fit_transform(df),\n",
    "    columns=df.columns\n",
    ")\n",
    "\n",
    "print(\"KNN 대체:\")\n",
    "print(df_knn)\n",
    "\n",
    "# 시각화 비교\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, (method, df_filled) in zip(axes, [\n",
    "    ('Mean', df_mean), \n",
    "    ('Median', df_median), \n",
    "    ('KNN', df_knn)\n",
    "]):\n",
    "    ax.scatter(df_filled['age'], df_filled['income'], alpha=0.7, s=100)\n",
    "    ax.set_xlabel('Age')\n",
    "    ax.set_ylabel('Income')\n",
    "    ax.set_title(f'{method} Imputation')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 2. 특성 스케일링 (Feature Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일이 다른 데이터 생성\n",
    "np.random.seed(42)\n",
    "data_scale = {\n",
    "    'age': np.random.randint(20, 60, 100),\n",
    "    'income': np.random.randint(30000, 150000, 100),\n",
    "    'score': np.random.uniform(0, 100, 100)\n",
    "}\n",
    "df_scale = pd.DataFrame(data_scale)\n",
    "\n",
    "print(\"원본 데이터 통계:\")\n",
    "print(df_scale.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 2.1 StandardScaler (표준화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler: (x - mean) / std\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(df_scale),\n",
    "    columns=df_scale.columns\n",
    ")\n",
    "\n",
    "print(\"StandardScaler 결과:\")\n",
    "print(df_standard.describe())\n",
    "print(f\"\\n평균: {df_standard.mean().values}\")\n",
    "print(f\"표준편차: {df_standard.std().values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### 2.2 MinMaxScaler (정규화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler: (x - min) / (max - min)\n",
    "scaler_minmax = MinMaxScaler(feature_range=(0, 1))\n",
    "df_minmax = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(df_scale),\n",
    "    columns=df_scale.columns\n",
    ")\n",
    "\n",
    "print(\"MinMaxScaler 결과:\")\n",
    "print(df_minmax.describe())\n",
    "print(f\"\\n최솟값: {df_minmax.min().values}\")\n",
    "print(f\"최댓값: {df_minmax.max().values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### 2.3 RobustScaler (이상치에 강건)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler: (x - median) / IQR\n",
    "scaler_robust = RobustScaler()\n",
    "df_robust = pd.DataFrame(\n",
    "    scaler_robust.fit_transform(df_scale),\n",
    "    columns=df_scale.columns\n",
    ")\n",
    "\n",
    "print(\"RobustScaler 결과:\")\n",
    "print(df_robust.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### 2.4 스케일러 비교 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 이상치 추가\n",
    "df_outlier = df_scale.copy()\n",
    "df_outlier.loc[0, 'income'] = 500000  # 이상치 추가\n",
    "\n",
    "scalers = [\n",
    "    ('Original', df_outlier),\n",
    "    ('StandardScaler', pd.DataFrame(StandardScaler().fit_transform(df_outlier), columns=df_outlier.columns)),\n",
    "    ('MinMaxScaler', pd.DataFrame(MinMaxScaler().fit_transform(df_outlier), columns=df_outlier.columns)),\n",
    "    ('RobustScaler', pd.DataFrame(RobustScaler().fit_transform(df_outlier), columns=df_outlier.columns))\n",
    "]\n",
    "\n",
    "for ax, (name, data) in zip(axes, scalers):\n",
    "    ax.boxplot([data['age'], data['income'], data['score']], labels=['age', 'income', 'score'])\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 3. 범주형 변수 인코딩 (Categorical Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 샘플\n",
    "data_cat = {\n",
    "    'color': ['red', 'blue', 'green', 'red', 'blue', 'green', 'red'],\n",
    "    'size': ['S', 'M', 'L', 'M', 'S', 'L', 'M'],\n",
    "    'quality': ['good', 'excellent', 'poor', 'good', 'excellent', 'poor', 'good']\n",
    "}\n",
    "df_cat = pd.DataFrame(data_cat)\n",
    "\n",
    "print(\"범주형 데이터:\")\n",
    "print(df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### 3.1 LabelEncoder (레이블 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder: 범주를 정수로 변환\n",
    "le_color = LabelEncoder()\n",
    "df_cat['color_encoded'] = le_color.fit_transform(df_cat['color'])\n",
    "\n",
    "print(\"LabelEncoder 결과:\")\n",
    "print(df_cat[['color', 'color_encoded']])\n",
    "print(f\"\\n클래스: {le_color.classes_}\")\n",
    "print(f\"변환: {dict(zip(le_color.classes_, le_color.transform(le_color.classes_)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### 3.2 OneHotEncoder (원-핫 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder: 범주를 이진 벡터로 변환\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "color_onehot = ohe.fit_transform(df_cat[['color']])\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_onehot = pd.DataFrame(\n",
    "    color_onehot,\n",
    "    columns=ohe.get_feature_names_out(['color'])\n",
    ")\n",
    "\n",
    "print(\"OneHotEncoder 결과:\")\n",
    "print(pd.concat([df_cat['color'], df_onehot], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### 3.3 OrdinalEncoder (순서형 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrdinalEncoder: 순서가 있는 범주형 변수\n",
    "oe = OrdinalEncoder(categories=[['poor', 'good', 'excellent']])\n",
    "df_cat['quality_encoded'] = oe.fit_transform(df_cat[['quality']])\n",
    "\n",
    "print(\"OrdinalEncoder 결과:\")\n",
    "print(df_cat[['quality', 'quality_encoded']])\n",
    "print(f\"\\n순서: poor(0) < good(1) < excellent(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### 3.4 Pandas get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas의 get_dummies (간편한 원-핫 인코딩)\n",
    "df_dummies = pd.get_dummies(df_cat[['color', 'size']], prefix=['color', 'size'])\n",
    "\n",
    "print(\"pd.get_dummies 결과:\")\n",
    "print(df_dummies.head())\n",
    "\n",
    "# drop_first=True로 다중공선성 방지\n",
    "df_dummies_drop = pd.get_dummies(df_cat[['color', 'size']], prefix=['color', 'size'], drop_first=True)\n",
    "print(f\"\\ndrop_first=True (shape: {df_dummies_drop.shape}):\")\n",
    "print(df_dummies_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 4. 특성 선택 (Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Iris 데이터 로드\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print(f\"원본 데이터: {X.shape}\")\n",
    "print(f\"특성 이름: {iris.feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "### 4.1 SelectKBest (통계적 선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-통계량 기반 선택\n",
    "selector_f = SelectKBest(score_func=f_classif, k=2)\n",
    "X_kbest_f = selector_f.fit_transform(X, y)\n",
    "\n",
    "# 상호정보량 기반 선택\n",
    "selector_mi = SelectKBest(score_func=mutual_info_classif, k=2)\n",
    "X_kbest_mi = selector_mi.fit_transform(X, y)\n",
    "\n",
    "print(\"SelectKBest (F-statistic):\")\n",
    "scores_f = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'Score': selector_f.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "print(scores_f)\n",
    "\n",
    "print(\"\\nSelectKBest (Mutual Information):\")\n",
    "scores_mi = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'Score': selector_mi.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "print(scores_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "### 4.2 RFE (재귀적 특성 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with Random Forest\n",
    "estimator = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "selector_rfe = RFE(estimator, n_features_to_select=2, step=1)\n",
    "X_rfe = selector_rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"RFE 결과:\")\n",
    "rfe_result = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'Selected': selector_rfe.support_,\n",
    "    'Ranking': selector_rfe.ranking_\n",
    "}).sort_values('Ranking')\n",
    "print(rfe_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "### 4.3 특성 중요도 (랜덤 포레스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트 특성 중요도\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance['Feature'], importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance - Iris Dataset')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## 5. 불균형 데이터 처리 (Imbalanced Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 불균형 데이터 생성 (10:1 비율)\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # 90% vs 10%\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 클래스 분포 확인\n",
    "unique, counts = np.unique(y_imb, return_counts=True)\n",
    "print(\"클래스 분포:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {cnt} ({cnt/len(y_imb)*100:.1f}%)\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Class 0', 'Class 1'], counts, color=['skyblue', 'salmon'])\n",
    "plt.ylabel('Count')\n",
    "plt.title('Imbalanced Dataset Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "### 5.1 SMOTE 개념 (이론)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE (Synthetic Minority Over-sampling Technique) 개념 설명\n",
    "print(\"\"\"\n",
    "SMOTE 작동 원리:\n",
    "\n",
    "1. 소수 클래스의 각 샘플에 대해:\n",
    "   - K개의 최근접 이웃을 찾음 (보통 k=5)\n",
    "   \n",
    "2. 랜덤하게 선택된 이웃과의 선형 보간:\n",
    "   - new_sample = sample + λ × (neighbor - sample)\n",
    "   - λ는 0과 1 사이의 랜덤값\n",
    "   \n",
    "3. 합성 샘플을 생성하여 소수 클래스 증강\n",
    "\n",
    "장점:\n",
    "- 과적합 위험이 낮음 (단순 복제가 아님)\n",
    "- 결정 경계가 더 일반화됨\n",
    "\n",
    "단점:\n",
    "- 노이즈에 민감할 수 있음\n",
    "- 고차원 데이터에서는 효과가 제한적\n",
    "\n",
    "사용 방법:\n",
    "- pip install imbalanced-learn\n",
    "- from imblearn.over_sampling import SMOTE\n",
    "- smote = SMOTE(random_state=42)\n",
    "- X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### 5.2 클래스 가중치 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 가중치 없음\n",
    "clf_no_weight = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf_no_weight.fit(X_train_imb, y_train_imb)\n",
    "y_pred_no_weight = clf_no_weight.predict(X_test_imb)\n",
    "\n",
    "# 가중치 조정 (balanced)\n",
    "clf_balanced = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "clf_balanced.fit(X_train_imb, y_train_imb)\n",
    "y_pred_balanced = clf_balanced.predict(X_test_imb)\n",
    "\n",
    "print(\"=== 가중치 없음 ===\")\n",
    "print(classification_report(y_test_imb, y_pred_no_weight))\n",
    "\n",
    "print(\"\\n=== 가중치 조정 (balanced) ===\")\n",
    "print(classification_report(y_test_imb, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## 6. 실전 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 혼합 데이터 생성\n",
    "data_mixed = {\n",
    "    'age': [25, np.nan, 35, 40, 30, 45, np.nan, 28],\n",
    "    'income': [50000, 60000, np.nan, 80000, 70000, 90000, 55000, np.nan],\n",
    "    'city': ['Seoul', 'Busan', 'Seoul', 'Daegu', 'Busan', 'Seoul', 'Daegu', 'Busan'],\n",
    "    'education': ['Bachelor', 'Master', 'PhD', 'Bachelor', 'Master', 'PhD', 'Bachelor', 'Master'],\n",
    "    'purchased': [0, 1, 1, 0, 1, 1, 0, 1]\n",
    "}\n",
    "df_mixed = pd.DataFrame(data_mixed)\n",
    "\n",
    "X_mixed = df_mixed.drop('purchased', axis=1)\n",
    "y_mixed = df_mixed['purchased']\n",
    "\n",
    "print(\"혼합 데이터:\")\n",
    "print(df_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형/범주형 특성 분리\n",
    "numeric_features = ['age', 'income']\n",
    "categorical_features = ['city', 'education']\n",
    "\n",
    "# 수치형 전처리 파이프라인\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 범주형 전처리 파이프라인\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# ColumnTransformer로 결합\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 전체 파이프라인\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# 학습 (작은 데이터이므로 전체 사용)\n",
    "pipeline.fit(X_mixed, y_mixed)\n",
    "\n",
    "# 새로운 데이터 예측\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [30],\n",
    "    'income': [70000],\n",
    "    'city': ['Seoul'],\n",
    "    'education': ['Master']\n",
    "})\n",
    "\n",
    "prediction = pipeline.predict(new_data)\n",
    "probability = pipeline.predict_proba(new_data)\n",
    "\n",
    "print(f\"\\n예측 결과: {prediction[0]}\")\n",
    "print(f\"확률: {probability[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "**결측치 처리:**\n",
    "- **SimpleImputer**: 평균, 중앙값, 최빈값, 상수로 대체\n",
    "- **KNNImputer**: K-최근접 이웃 기반 대체\n",
    "\n",
    "**특성 스케일링:**\n",
    "- **StandardScaler**: 평균 0, 표준편차 1 (정규분포 가정)\n",
    "- **MinMaxScaler**: 0-1 범위로 정규화\n",
    "- **RobustScaler**: 중앙값과 IQR 사용 (이상치에 강건)\n",
    "\n",
    "**범주형 인코딩:**\n",
    "- **LabelEncoder**: 순서 없는 분류 (타겟 변수용)\n",
    "- **OneHotEncoder**: 이진 벡터로 변환 (다중공선성 주의)\n",
    "- **OrdinalEncoder**: 순서가 있는 범주형\n",
    "\n",
    "**불균형 데이터:**\n",
    "- **SMOTE**: 합성 샘플 생성 (요구사항: imbalanced-learn)\n",
    "- **class_weight**: 모델 가중치 조정\n",
    "\n",
    "### 다음 단계\n",
    "- Pipeline과 ColumnTransformer 활용\n",
    "- 교차 검증과 전처리 통합\n",
    "- 실전 프로젝트 적용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
