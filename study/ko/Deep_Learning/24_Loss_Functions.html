{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>24. ì†ì‹¤ í•¨ìˆ˜(Loss Functions) - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Deep_Learning/">Deep Learning</a>
    <span class="separator">/</span>
    <span class="current">24. ì†ì‹¤ í•¨ìˆ˜(Loss Functions)</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>24. ì†ì‹¤ í•¨ìˆ˜(Loss Functions)</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Deep_Learning/23_Training_Optimization.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">23. í•™ìŠµ ìµœì í™”</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Deep_Learning/25_Optimizers.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">25. ì˜µí‹°ë§ˆì´ì €(Optimizers)</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">í•™ìŠµ ëª©í‘œ</a></li>
<li><a href="#1">1. ì†ì‹¤ í•¨ìˆ˜ ì†Œê°œ</a><ul>
<li><a href="#11">1.1 ì‹ ê²½ë§ í›ˆë ¨ì—ì„œì˜ ì—­í• </a></li>
<li><a href="#12-loss-landscape-visualization">1.2 ì†ì‹¤ ê²½ê´€ ì‹œê°í™”(Loss Landscape Visualization)</a></li>
<li><a href="#13">1.3 ìµœì í™”ì™€ì˜ ê´€ê³„</a></li>
</ul>
</li>
<li><a href="#2-regression-losses">2. íšŒê·€ ì†ì‹¤(Regression Losses)</a><ul>
<li><a href="#21-mean-squared-error-l2-loss">2.1 í‰ê·  ì œê³± ì˜¤ì°¨(Mean Squared Error, L2 Loss)</a></li>
<li><a href="#22-mean-absolute-error-l1-loss">2.2 í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(Mean Absolute Error, L1 Loss)</a></li>
<li><a href="#23-huber-loss-smooth-l1">2.3 í›„ë²„ ì†ì‹¤(Huber Loss, Smooth L1)</a></li>
<li><a href="#24-log-cosh-loss">2.4 ë¡œê·¸-ì½”ì‹œ ì†ì‹¤(Log-Cosh Loss)</a></li>
<li><a href="#25">2.5 íšŒê·€ ì†ì‹¤ ë¹„êµ</a></li>
</ul>
</li>
<li><a href="#3-classification-losses">3. ë¶„ë¥˜ ì†ì‹¤(Classification Losses)</a><ul>
<li><a href="#31-binary-cross-entropy-bce">3.1 ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼(Binary Cross-Entropy, BCE)</a></li>
<li><a href="#32-cross-entropy-loss-multi-class">3.2 êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤(Cross-Entropy Loss, Multi-Class)</a></li>
<li><a href="#33-label-smoothing">3.3 ë ˆì´ë¸” ìŠ¤ë¬´ë”©(Label Smoothing)</a></li>
<li><a href="#34-focal-loss">3.4 í¬ì»¬ ì†ì‹¤(Focal Loss)</a></li>
<li><a href="#35-bce-vs-cross-entropy">3.5 BCE vs Cross-Entropy</a></li>
</ul>
</li>
<li><a href="#4-ranking-and-metric-learning-losses">4. ìˆœìœ„ ë° ë©”íŠ¸ë¦­ í•™ìŠµ ì†ì‹¤(Ranking and Metric Learning Losses)</a><ul>
<li><a href="#41-contrastive-loss">4.1 ëŒ€ì¡° ì†ì‹¤(Contrastive Loss)</a></li>
<li><a href="#42-triplet-loss">4.2 íŠ¸ë¦¬í”Œë › ì†ì‹¤(Triplet Loss)</a></li>
<li><a href="#43-infonce-nt-xent">4.3 InfoNCE / NT-Xent ì†ì‹¤</a></li>
</ul>
</li>
<li><a href="#5-segmentation-and-detection-losses">5. ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ê²€ì¶œ ì†ì‹¤(Segmentation and Detection Losses)</a><ul>
<li><a href="#51-dice-loss">5.1 ë‹¤ì´ìŠ¤ ì†ì‹¤(Dice Loss)</a></li>
<li><a href="#52-iou-giou">5.2 IoU ì†ì‹¤ / GIoU ì†ì‹¤</a></li>
<li><a href="#53-combined-losses">5.3 ê²°í•© ì†ì‹¤(Combined Losses)</a></li>
</ul>
</li>
<li><a href="#6-generative-model-losses">6. ìƒì„± ëª¨ë¸ ì†ì‹¤(Generative Model Losses)</a><ul>
<li><a href="#61-adversarial-loss-gan">6.1 ì ëŒ€ì  ì†ì‹¤(Adversarial Loss, GAN)</a></li>
<li><a href="#62-vae">6.2 VAE ì†ì‹¤</a></li>
<li><a href="#63-perceptual-loss">6.3 ì§€ê°ì  ì†ì‹¤(Perceptual Loss)</a></li>
</ul>
</li>
<li><a href="#7-advanced-topics">7. ê³ ê¸‰ ì£¼ì œ(Advanced Topics)</a><ul>
<li><a href="#71-multi-task-loss-weighting">7.1 ë‹¤ì¤‘ ì‘ì—… ì†ì‹¤ ê°€ì¤‘ì¹˜(Multi-Task Loss Weighting)</a></li>
<li><a href="#72-curriculum-loss">7.2 ì»¤ë¦¬í˜ëŸ¼ ì†ì‹¤(Curriculum Loss)</a></li>
<li><a href="#73">7.3 ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜</a></li>
<li><a href="#74">7.4 ìˆ˜ì¹˜ ì•ˆì •ì„± íŒ</a></li>
</ul>
</li>
<li><a href="#8-practical-guide">8. ì‹¤ìš© ê°€ì´ë“œ(Practical Guide)</a><ul>
<li><a href="#81">8.1 ì†ì‹¤ ì„ íƒ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬</a></li>
<li><a href="#82">8.2 ë¹„êµ í‘œ</a></li>
<li><a href="#83">8.3 í”í•œ í•¨ì •</a></li>
<li><a href="#84">8.4 ë””ë²„ê¹… íŒ</a></li>
<li><a href="#85">8.5 ì†ì‹¤ í•¨ìˆ˜ê°€ ìˆ˜ë ´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥</a></li>
</ul>
</li>
<li><a href="#_2">ì—°ìŠµ ë¬¸ì œ</a><ul>
<li><a href="#1-tversky">ì—°ìŠµ ë¬¸ì œ 1: Tversky ì†ì‹¤ êµ¬í˜„</a></li>
<li><a href="#2">ì—°ìŠµ ë¬¸ì œ 2: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì§€ê°ì  ì†ì‹¤</a></li>
<li><a href="#3">ì—°ìŠµ ë¬¸ì œ 3: ì ì‘ì  ì†ì‹¤ ê· í˜•</a></li>
</ul>
</li>
<li><a href="#_3">ì°¸ê³  ìë£Œ</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <p><a href="./23_Training_Optimization.md">ì´ì „: í•™ìŠµ ìµœì í™”</a> | <a href="./25_Optimizers.md">ë‹¤ìŒ: ì˜µí‹°ë§ˆì´ì €</a></p>
<hr />
<h1 id="24-loss-functions">24. ì†ì‹¤ í•¨ìˆ˜(Loss Functions)<a class="header-link" href="#24-loss-functions" title="Permanent link">&para;</a></h1>
<h2 id="_1">í•™ìŠµ ëª©í‘œ<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>ì‹ ê²½ë§ í›ˆë ¨ì—ì„œ ì†ì‹¤ í•¨ìˆ˜ì˜ ì—­í• ê³¼ ìµœì í™”ì™€ì˜ ê´€ê³„ ì´í•´í•˜ê¸°</li>
<li>íšŒê·€ ì†ì‹¤(MSE, MAE, Huber)ê³¼ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ í™œìš©ë²• ìµíˆê¸°</li>
<li>ë¶„ë¥˜ ì†ì‹¤(BCE, Cross-Entropy, Focal Loss)ê³¼ ê· í˜•/ë¶ˆê· í˜• ë°ì´í„°ì…‹ì—ì„œì˜ ì‚¬ìš© ì‚¬ë¡€ í•™ìŠµí•˜ê¸°</li>
<li>í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ë©”íŠ¸ë¦­ í•™ìŠµ ì†ì‹¤(Contrastive, Triplet, InfoNCE) íƒêµ¬í•˜ê¸°</li>
<li>ì„¸ê·¸ë©˜í…Œì´ì…˜, ê²€ì¶œ, ìƒì„± ëª¨ë¸ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ PyTorchë¡œ êµ¬í˜„í•˜ê¸°</li>
</ul>
<p><strong>ë‚œì´ë„</strong>: â­â­â­</p>
<hr />
<h2 id="1">1. ì†ì‹¤ í•¨ìˆ˜ ì†Œê°œ<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 ì‹ ê²½ë§ í›ˆë ¨ì—ì„œì˜ ì—­í• <a class="header-link" href="#11" title="Permanent link">&para;</a></h3>
<p>ì†ì‹¤ í•¨ìˆ˜(ëª©ì  í•¨ìˆ˜(objective function) ë˜ëŠ” ë¹„ìš© í•¨ìˆ˜(cost function)ë¼ê³ ë„ í•¨)ëŠ” ì‹ ê²½ë§ì˜ ì˜ˆì¸¡ì´ ì •ë‹µê³¼ ì–¼ë§ˆë‚˜ ì˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. í›ˆë ¨ ì¤‘ì—ëŠ” SGDë‚˜ Adamê³¼ ê°™ì€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="nv">Training</span><span class="w"> </span><span class="k">Loop</span>:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚<span class="w">                                                         </span>â”‚
â”‚<span class="w">  </span><span class="nv">Input</span><span class="w"> </span><span class="ss">(</span><span class="nv">x</span><span class="ss">)</span><span class="w"> </span>â”€â”€â–¶<span class="w"> </span><span class="nv">Model</span><span class="ss">(</span>Î¸<span class="ss">)</span><span class="w"> </span>â”€â”€â–¶<span class="w"> </span><span class="nv">Prediction</span><span class="w"> </span><span class="ss">(</span>Å·<span class="ss">)</span><span class="w">            </span>â”‚
â”‚<span class="w">                                  </span>â”‚<span class="w">                      </span>â”‚
â”‚<span class="w">                                  </span>â–¼<span class="w">                      </span>â”‚
â”‚<span class="w">                         </span><span class="nv">Loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">L</span><span class="ss">(</span>Å·,<span class="w"> </span><span class="nv">y</span><span class="ss">)</span><span class="w">                 </span>â”‚
â”‚<span class="w">                                  </span>â”‚<span class="w">                      </span>â”‚
â”‚<span class="w">                                  </span>â–¼<span class="w">                      </span>â”‚
â”‚<span class="w">                         </span>âˆ‚<span class="nv">L</span><span class="o">/</span>âˆ‚Î¸<span class="w"> </span><span class="ss">(</span><span class="nv">Backprop</span><span class="ss">)</span><span class="w">               </span>â”‚
â”‚<span class="w">                                  </span>â”‚<span class="w">                      </span>â”‚
â”‚<span class="w">                                  </span>â–¼<span class="w">                      </span>â”‚
â”‚<span class="w">                    </span>Î¸<span class="w"> </span>â†<span class="w"> </span>Î¸<span class="w"> </span><span class="o">-</span><span class="w"> </span>Î·Â·âˆ‚<span class="nv">L</span><span class="o">/</span>âˆ‚Î¸<span class="w"> </span><span class="ss">(</span><span class="nv">Update</span><span class="ss">)</span><span class="w">            </span>â”‚
â”‚<span class="w">                                  </span>â”‚<span class="w">                      </span>â”‚
â”‚<span class="w">                                  </span>â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚<span class="w">                                                         </span>â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<p><strong>ì¢‹ì€ ì†ì‹¤ í•¨ìˆ˜ì˜ ì£¼ìš” íŠ¹ì„±:</strong>
- <strong>ë¯¸ë¶„ ê°€ëŠ¥(Differentiable)</strong>: ì—­ì „íŒŒë¥¼ ìœ„í•œ ê¸°ìš¸ê¸°ê°€ ìˆì–´ì•¼ í•¨
- <strong>ë³¼ë¡(Convex, ì´ìƒì ìœ¼ë¡œ)</strong>: ë‹¨ì¼ ì „ì—­ ìµœì†Ÿê°’ì´ ìˆìœ¼ë©´ ìµœì í™”ê°€ ë” ì‰¬ì›€
- <strong>ì‘ì—… ì •ë ¬(Task-aligned)</strong>: ê°€ëŠ¥í•œ ê²½ìš° ì‹¤ì œ í‰ê°€ ì§€í‘œë¥¼ ë°˜ì˜
- <strong>ìˆ˜ì¹˜ì ìœ¼ë¡œ ì•ˆì •ì (Numerically stable)</strong>: ì˜¤ë²„í”Œë¡œ/ì–¸ë”í”Œë¡œ ë°©ì§€</p>
<h3 id="12-loss-landscape-visualization">1.2 ì†ì‹¤ ê²½ê´€ ì‹œê°í™”(Loss Landscape Visualization)<a class="header-link" href="#12-loss-landscape-visualization" title="Permanent link">&para;</a></h3>
<p>ì†ì‹¤ ê²½ê´€ì€ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ì†ì‹¤ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes3D</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_loss_landscape</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Visualize a simple 2D loss landscape&quot;&quot;&quot;</span>
    <span class="c1"># Create a grid of parameter values</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span>

    <span class="c1"># Example loss: Rosenbrock function (non-convex)</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">W1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="n">W2</span> <span class="o">-</span> <span class="n">W1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

    <span class="c1"># Plot 3D surface</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;w1&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;w2&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;3D Loss Landscape&#39;</span><span class="p">)</span>

    <span class="c1"># Plot contour</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
    <span class="n">contour</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;w1&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;w2&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Contour Plot&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;loss_landscape.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">visualize_loss_landscape</span><span class="p">()</span>
</code></pre></div>

<h3 id="13">1.3 ìµœì í™”ì™€ì˜ ê´€ê³„<a class="header-link" href="#13" title="Permanent link">&para;</a></h3>
<p>ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ìµœì í™” ë¬¸ì œë¥¼ ë§Œë“­ë‹ˆë‹¤:</p>
<table>
<thead>
<tr>
<th>ì†ì‹¤ ìœ í˜•</th>
<th>ê²½ê´€</th>
<th>ìµœì í™” ê³¼ì œ</th>
</tr>
</thead>
<tbody>
<tr>
<td>MSE</td>
<td>ë¶€ë“œëŸ½ê³  ë³¼ë¡í•¨</td>
<td>ì‰¬ì›€, ì•ˆì •ì ì¸ ê¸°ìš¸ê¸°</td>
</tr>
<tr>
<td>Cross-Entropy</td>
<td>ë¶€ë“œëŸ½ê³  ë³¼ë¡í•¨</td>
<td>ê¸°ìš¸ê¸° ì†Œì‹¤ ê°€ëŠ¥</td>
</tr>
<tr>
<td>Triplet Loss</td>
<td>ë¹„ë³¼ë¡, ë§ì€ ì§€ì—­ ìµœì†Ÿê°’</td>
<td>ì‹ ì¤‘í•œ ë§ˆì´ë‹ í•„ìš”</td>
</tr>
<tr>
<td>GAN Loss</td>
<td>ë¹„ë³¼ë¡, ì•ˆì¥ì </td>
<td>ë¶ˆì•ˆì •, ëª¨ë“œ ë¶•ê´´</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-regression-losses">2. íšŒê·€ ì†ì‹¤(Regression Losses)<a class="header-link" href="#2-regression-losses" title="Permanent link">&para;</a></h2>
<p>íšŒê·€ ì†ì‹¤ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤(ì˜ˆ: ì£¼íƒ ê°€ê²©, ì˜¨ë„, ì¢Œí‘œ).</p>
<h3 id="21-mean-squared-error-l2-loss">2.1 í‰ê·  ì œê³± ì˜¤ì°¨(Mean Squared Error, L2 Loss)<a class="header-link" href="#21-mean-squared-error-l2-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>MSE = (1/n) Î£(Å·áµ¢ - yáµ¢)Â²
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- í° ì˜¤ì°¨ë¥¼ í¬ê²Œ íŒ¨ë„í‹°(ì´ì°¨ í•¨ìˆ˜)
- ì´ìƒì¹˜ì— ë¯¼ê°í•¨
- ëª¨ë“  ê³³ì—ì„œ ë¶€ë“œëŸ¬ìš´ ê¸°ìš¸ê¸°</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Built-in version</span>
<span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Example usage</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">7.8</span><span class="p">])</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.0825</span>

<span class="c1"># Manual implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mse_manual</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">loss_manual</span> <span class="o">=</span> <span class="n">mse_manual</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Manual MSE: </span><span class="si">{</span><span class="n">loss_manual</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.0825</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- í° ì˜¤ì°¨ë¥¼ í¬ê²Œ íŒ¨ë„í‹°í•´ì•¼ í•˜ëŠ” íšŒê·€ ì‘ì—…
- ì‹¬ê°í•œ ì´ìƒì¹˜ê°€ ì—†ëŠ” ë°ì´í„°
- ìµœì í™”ë¥¼ ìœ„í•´ ë¶€ë“œëŸ¬ìš´ ê¸°ìš¸ê¸°ê°€ í•„ìš”í•  ë•Œ</p>
<h3 id="22-mean-absolute-error-l1-loss">2.2 í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(Mean Absolute Error, L1 Loss)<a class="header-link" href="#22-mean-absolute-error-l1-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>MAE = (1/n) Î£|Å·áµ¢ - yáµ¢|
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- ì„ í˜• íŒ¨ë„í‹°(ì´ìƒì¹˜ì— ê°•ê±´í•¨)
- ê¸°ìš¸ê¸° í¬ê¸°ê°€ ì¼ì •í•¨
- 0ì—ì„œ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ(ë¯¸ë¶„ ë¶ˆê°€ëŠ¥)</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Built-in version</span>
<span class="n">mae_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">7.8</span><span class="p">])</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">mae_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MAE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.2250</span>

<span class="c1"># Manual implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mae_manual</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">))</span>

<span class="n">loss_manual</span> <span class="o">=</span> <span class="n">mae_manual</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Manual MAE: </span><span class="si">{</span><span class="n">loss_manual</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.2250</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ì´ìƒì¹˜ê°€ ìˆëŠ” ë°ì´í„°
- ëª¨ë“  ì˜¤ì°¨ë¥¼ ë™ë“±í•˜ê²Œ ê°€ì¤‘í•´ì•¼ í•  ë•Œ
- ê°•ê±´í•œ íšŒê·€ ì‘ì—…</p>
<h3 id="23-huber-loss-smooth-l1">2.3 í›„ë²„ ì†ì‹¤(Huber Loss, Smooth L1)<a class="header-link" href="#23-huber-loss-smooth-l1" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>         â§  0.5(Å· - y)Â²          if |Å· - y| â‰¤ Î´
L_Î´(Å·,y) = â¨
         â©  Î´|Å· - y| - 0.5Î´Â²    otherwise
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- L1ê³¼ L2ì˜ ì¥ì ì„ ê²°í•©
- ì‘ì€ ì˜¤ì°¨ì—ëŠ” ì´ì°¨, í° ì˜¤ì°¨ì—ëŠ” ì„ í˜•
- Î´(ì „í™˜ì )ë¡œ ì œì–´ë¨</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Built-in version (SmoothL1Loss uses Î´=1.0)</span>
<span class="n">huber_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># beta is Î´</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">])</span>  <span class="c1"># Last value is outlier</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Huber Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.4125</span>

<span class="c1"># Manual implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">huber_manual</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">target</span>
    <span class="n">abs_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
    <span class="n">quadratic</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">abs_error</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">delta</span><span class="p">)</span>
    <span class="n">linear</span> <span class="o">=</span> <span class="n">abs_error</span> <span class="o">-</span> <span class="n">quadratic</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">quadratic</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">linear</span><span class="p">)</span>

<span class="n">loss_manual</span> <span class="o">=</span> <span class="n">huber_manual</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Manual Huber: </span><span class="si">{</span><span class="n">loss_manual</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># 0.4125</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ì¼ë¶€ ì´ìƒì¹˜ê°€ ìˆì§€ë§Œ ì—¬ì „íˆ í° ì˜¤ì°¨ë¥¼ íŒ¨ë„í‹°í•˜ê³  ì‹¶ì„ ë•Œ
- ê°ì²´ ê²€ì¶œ(ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€)
- ë¡œë³´í‹±ìŠ¤(ì„¼ì„œ í“¨ì „)</p>
<h3 id="24-log-cosh-loss">2.4 ë¡œê·¸-ì½”ì‹œ ì†ì‹¤(Log-Cosh Loss)<a class="header-link" href="#24-log-cosh-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>L(Å·, y) = Î£ log(cosh(Å·áµ¢ - yáµ¢))
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- ë‘ ë²ˆ ë¯¸ë¶„ ê°€ëŠ¥(Huberë³´ë‹¤ ë¶€ë“œëŸ¬ì›€)
- ì‘ì€ xì— ëŒ€í•´ ëŒ€ëµ (xÂ²/2), í° xì— ëŒ€í•´ |x|
- MSEë³´ë‹¤ ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•¨</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">log_cosh_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Log-Cosh Loss&quot;&quot;&quot;</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">target</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">error</span><span class="p">)))</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">])</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">log_cosh_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Log-Cosh Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ë‘ ë²ˆ ë¯¸ë¶„ ê°€ëŠ¥í•œ ì†ì‹¤ì´ í•„ìš”í•  ë•Œ(ì˜ˆ: Hessian ê¸°ë°˜ ìµœì í™”ê¸°)
- XGBoost ë° ê¸°íƒ€ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë°©ë²•</p>
<h3 id="25">2.5 íšŒê·€ ì†ì‹¤ ë¹„êµ<a class="header-link" href="#25" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compare_regression_losses</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare different regression losses&quot;&quot;&quot;</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

    <span class="c1"># Calculate losses</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">errors</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
    <span class="n">huber</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="mf">0.5</span> <span class="o">*</span> <span class="n">errors</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
    <span class="p">)</span>
    <span class="n">log_cosh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">errors</span><span class="p">))</span>

    <span class="c1"># Plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">mse</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE (L2)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">mae</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE (L1)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">huber</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Huber (Î´=1)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">log_cosh</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Log-Cosh&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction Error (Å· - y)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Regression Losses&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Gradient plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">grad_mse</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">errors</span>
    <span class="n">grad_mae</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
    <span class="n">grad_huber</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">errors</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">grad_log_cosh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">grad_mse</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE grad&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">grad_mae</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE grad&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">grad_huber</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Huber grad&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">grad_log_cosh</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Log-Cosh grad&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction Error (Å· - y)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gradient&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss Gradients&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;regression_losses.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">compare_regression_losses</span><span class="p">()</span>
</code></pre></div>

<p><strong>ë¹„êµ í‘œ:</strong></p>
<table>
<thead>
<tr>
<th>ì†ì‹¤</th>
<th>ì´ìƒì¹˜ ê°•ê±´ì„±</th>
<th>ê¸°ìš¸ê¸° ë¶€ë“œëŸ¬ì›€</th>
<th>ì‚¬ìš© ì‚¬ë¡€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MSE</strong></td>
<td>ë‚®ìŒ</td>
<td>ë†’ìŒ</td>
<td>ê¹¨ë—í•œ ë°ì´í„°, ì•ˆì •ì ì¸ í›ˆë ¨</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>ë†’ìŒ</td>
<td>ë‚®ìŒ (0ì—ì„œ ë¶ˆì—°ì†)</td>
<td>ì´ìƒì¹˜ê°€ ìˆëŠ” ë°ì´í„°</td>
</tr>
<tr>
<td><strong>Huber</strong></td>
<td>ì¤‘ê°„</td>
<td>ì¤‘ê°„</td>
<td>MSE/MAE ì‚¬ì´ ê· í˜•</td>
</tr>
<tr>
<td><strong>Log-Cosh</strong></td>
<td>ì¤‘ê°„-ë†’ìŒ</td>
<td>ë†’ìŒ (ë‘ ë²ˆ ë¯¸ë¶„ ê°€ëŠ¥)</td>
<td>ê³ ê¸‰ ìµœì í™”ê¸°</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="3-classification-losses">3. ë¶„ë¥˜ ì†ì‹¤(Classification Losses)<a class="header-link" href="#3-classification-losses" title="Permanent link">&para;</a></h2>
<p>ë¶„ë¥˜ ì†ì‹¤ì€ ì´ì‚° ë ˆì´ë¸” ì˜ˆì¸¡ ì‘ì—…ì— ì‚¬ìš©ë©ë‹ˆë‹¤.</p>
<h3 id="31-binary-cross-entropy-bce">3.1 ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼(Binary Cross-Entropy, BCE)<a class="header-link" href="#31-binary-cross-entropy-bce" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>BCE = -(1/n) Î£ [yáµ¢ log(Å·áµ¢) + (1-yáµ¢) log(1-Å·áµ¢)]

where:
- yáµ¢ âˆˆ {0, 1} (true label)
- Å·áµ¢ âˆˆ (0, 1) (predicted probability)
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- ì´ì§„ ë¶„ë¥˜ìš©(2ê°œ í´ë˜ìŠ¤)
- í™•ë¥ ì„ ì¶œë ¥í•˜ê¸° ìœ„í•´ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” í•„ìš”
- ë³¼ë¡ ì†ì‹¤ í•¨ìˆ˜</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Method 1: BCELoss (requires sigmoid applied first)</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>  <span class="c1"># Raw outputs</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>  <span class="c1"># Binary labels</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">bce_loss</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Method 2: BCEWithLogitsLoss (numerically stable, combines sigmoid + BCE)</span>
<span class="n">bce_with_logits</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">loss_stable</span> <span class="o">=</span> <span class="n">bce_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BCE with Logits: </span><span class="si">{</span><span class="n">loss_stable</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Manual implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">bce_manual</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Manual BCE (expects probabilities)&quot;&quot;&quot;</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-7</span>  <span class="c1"># For numerical stability</span>
    <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
        <span class="n">target</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">)</span> <span class="o">+</span>
        <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred_probs</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">loss_manual</span> <span class="o">=</span> <span class="n">bce_manual</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Manual BCE: </span><span class="si">{</span><span class="n">loss_manual</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì´ì§„ ë¶„ë¥˜ ì˜ˆì œ:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">BinaryClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Single output</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Raw logit</span>

<span class="c1"># Training setup</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BinaryClassifier</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Dummy data</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># Batch of 32</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="c1"># Training step</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ì´ì§„ ë¶„ë¥˜(ìŠ¤íŒ¸/ìŠ¤íŒ¸ ì•„ë‹˜, ê³ ì–‘ì´/ê°œ)
- ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜(ê° ë ˆì´ë¸”ì´ ë…ë¦½ì )
- ì‹œê·¸ëª¨ì´ë“œ ì¶œë ¥ í™œì„±í™”</p>
<h3 id="32-cross-entropy-loss-multi-class">3.2 êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤(Cross-Entropy Loss, Multi-Class)<a class="header-link" href="#32-cross-entropy-loss-multi-class" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code><span class="nv">CE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="ss">(</span><span class="mi">1</span><span class="o">/</span><span class="nv">n</span><span class="ss">)</span><span class="w"> </span>Î£áµ¢<span class="w"> </span>Î£â±¼<span class="w"> </span><span class="nv">y</span>áµ¢â±¼<span class="w"> </span><span class="nv">log</span><span class="ss">(</span>Å·áµ¢â±¼<span class="ss">)</span>

<span class="nv">where</span>:
<span class="o">-</span><span class="w"> </span><span class="nv">y</span>áµ¢â±¼<span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">sample</span><span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">class</span><span class="w"> </span><span class="nv">j</span>,<span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">0</span>
<span class="o">-</span><span class="w"> </span>Å·áµ¢â±¼<span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">predicted</span><span class="w"> </span><span class="nv">probability</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">class</span><span class="w"> </span><span class="nv">j</span>
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ìš©(K &gt; 2 í´ë˜ìŠ¤)
- ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™” í•„ìš”
- PyTorchì˜ <code>CrossEntropyLoss</code>ëŠ” softmax + NLLLossë¥¼ ê²°í•©í•¨</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Method 1: CrossEntropyLoss (combines log_softmax + NLLLoss)</span>
<span class="n">ce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>  <span class="c1"># Sample 1</span>
    <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>  <span class="c1"># Sample 2</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span>  <span class="c1"># Sample 3</span>
<span class="p">])</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># Class indices</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CrossEntropy Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Method 2: Manual with softmax + NLLLoss</span>
<span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nll_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">log_probs</span> <span class="o">=</span> <span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="n">loss_manual</span> <span class="o">=</span> <span class="n">nll_loss</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Manual CE (LogSoftmax + NLL): </span><span class="si">{</span><span class="n">loss_manual</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Method 3: From scratch</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cross_entropy_manual</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Manual cross-entropy implementation&quot;&quot;&quot;</span>
    <span class="c1"># Compute log softmax</span>
    <span class="n">max_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">exp_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span> <span class="o">-</span> <span class="n">max_logits</span><span class="p">)</span>  <span class="c1"># Numerical stability</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span> <span class="o">-</span> <span class="n">max_logits</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="c1"># Gather log probabilities for correct classes</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_probs</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">targets</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">loss_scratch</span> <span class="o">=</span> <span class="n">cross_entropy_manual</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;From Scratch CE: </span><span class="si">{</span><span class="n">loss_scratch</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì˜ˆì œ:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultiClassClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Raw logits (no softmax)</span>

<span class="c1"># Training setup</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MultiClassClassifier</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Dummy data</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>  <span class="c1"># Batch of 64</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,))</span>  <span class="c1"># Class indices</span>

<span class="c1"># Training step</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Inference</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted Class: </span><span class="si">{</span><span class="n">predicted_class</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class Probabilities: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="33-label-smoothing">3.3 ë ˆì´ë¸” ìŠ¤ë¬´ë”©(Label Smoothing)<a class="header-link" href="#33-label-smoothing" title="Permanent link">&para;</a></h3>
<p><strong>ê°œë…:</strong>
í•˜ë“œ ë ˆì´ë¸”(0 ë˜ëŠ” 1) ëŒ€ì‹  ì†Œí”„íŠ¸ ë ˆì´ë¸” ì‚¬ìš©:</p>
<div class="highlight"><pre><span></span><code>y_smooth = y(1 - Îµ) + Îµ/K

where:
<span class="k">-</span> Îµ is smoothing parameter (e.g., 0.1)
<span class="k">-</span> K is number of classes
</code></pre></div>

<p><strong>ì¥ì :</strong>
- ê³¼ì‹ ë¢° ë°©ì§€
- ë” ë‚˜ì€ ì¼ë°˜í™”
- ì •ê·œí™” íš¨ê³¼</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LabelSmoothingCrossEntropy</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            logits: (batch_size, num_classes)</span>
<span class="sd">            targets: (batch_size,) class indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Create smooth targets</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">true_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">log_probs</span><span class="p">)</span>
            <span class="n">true_dist</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">true_dist</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">true_dist</span> <span class="o">*</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Example usage</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">LabelSmoothingCrossEntropy</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># 4 samples, 5 classes</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label Smoothing CE: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Compare with standard CE</span>
<span class="n">standard_ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">loss_standard</span> <span class="o">=</span> <span class="n">standard_ce</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard CE: </span><span class="si">{</span><span class="n">loss_standard</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ì´ë¯¸ì§€ ë¶„ë¥˜(ImageNet, CIFAR)
- ê³¼ì‹ ë¢° ë°©ì§€
- ëª¨ë¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜</p>
<h3 id="34-focal-loss">3.4 í¬ì»¬ ì†ì‹¤(Focal Loss)<a class="header-link" href="#34-focal-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code><span class="nv">FL</span><span class="ss">(</span><span class="nv">p</span>â‚œ<span class="ss">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span>Î±â‚œ<span class="ss">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">p</span>â‚œ<span class="ss">)</span><span class="o">^</span>Î³<span class="w"> </span><span class="nv">log</span><span class="ss">(</span><span class="nv">p</span>â‚œ<span class="ss">)</span>

<span class="nv">where</span>:
<span class="o">-</span><span class="w"> </span><span class="nv">p</span>â‚œ<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">p</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nv">y</span><span class="o">=</span><span class="mi">1</span>,<span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">1</span><span class="o">-</span><span class="nv">p</span>
<span class="o">-</span><span class="w"> </span>Î±<span class="w"> </span><span class="nv">balances</span><span class="w"> </span><span class="nv">class</span><span class="w"> </span><span class="nv">frequencies</span>
<span class="o">-</span><span class="w"> </span>Î³<span class="w"> </span><span class="nv">focuses</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">hard</span><span class="w"> </span><span class="nv">examples</span><span class="w"> </span><span class="ss">(</span><span class="nv">typically</span><span class="w"> </span><span class="mi">2</span><span class="ss">)</span>
</code></pre></div>

<p><strong>ë™ê¸°:</strong>
- í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°(ì˜ˆ: ê°ì²´ ê²€ì¶œì—ì„œ 1:1000 ë¹„ìœ¨)
- ì‰¬ìš´ ì˜ˆì œì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³  ì–´ë ¤ìš´ ë„¤ê±°í‹°ë¸Œì— ì§‘ì¤‘
- RetinaNet ë…¼ë¬¸ì—ì„œ ë„ì…</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">FocalLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            alpha: Weighting factor for class imbalance (default 0.25)</span>
<span class="sd">            gamma: Focusing parameter (default 2.0)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">reduction</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            logits: (N, C) raw predictions</span>
<span class="sd">            targets: (N,) class indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">ce_loss</span><span class="p">)</span>  <span class="c1"># Probability of correct class</span>

        <span class="c1"># Focal loss formula</span>
        <span class="n">focal_weight</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>
        <span class="n">focal_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">focal_weight</span> <span class="o">*</span> <span class="n">ce_loss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">focal_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">focal_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">focal_loss</span>

<span class="c1"># Binary Focal Loss variant</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BinaryFocalLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            logits: (N,) or (N, 1) raw predictions</span>
<span class="sd">            targets: (N,) or (N, 1) binary labels {0, 1}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bce_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span>
        <span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">p_t</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>

        <span class="n">alpha_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">focal_weight</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_t</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span>

        <span class="n">focal_loss</span> <span class="o">=</span> <span class="n">alpha_t</span> <span class="o">*</span> <span class="n">focal_weight</span> <span class="o">*</span> <span class="n">bce_loss</span>
        <span class="k">return</span> <span class="n">focal_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Example: Imbalanced dataset</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">focal_loss</span> <span class="o">=</span> <span class="n">FocalLoss</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># Simulate imbalanced batch (mostly class 0)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>   <span class="c1"># 80% class 0</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>    <span class="c1"># 15% class 1</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">5</span><span class="p">,),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># 5% class 2</span>
<span class="p">])</span>

<span class="n">loss_focal</span> <span class="o">=</span> <span class="n">focal_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">loss_ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Focal Loss: </span><span class="si">{</span><span class="n">loss_focal</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CE Loss: </span><span class="si">{</span><span class="n">loss_ce</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>í¬ì»¬ ì†ì‹¤ ì‹œê°í™”:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_focal_loss</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Visualize how focal loss down-weights easy examples&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># Probability of correct class</span>

    <span class="c1"># Standard CE</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="c1"># Focal loss with different Î³</span>
    <span class="n">fl_gamma_0</span> <span class="o">=</span> <span class="n">ce</span>  <span class="c1"># Î³=0 is same as CE</span>
    <span class="n">fl_gamma_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">ce</span>
    <span class="n">fl_gamma_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">ce</span>
    <span class="n">fl_gamma_5</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="mi">5</span> <span class="o">*</span> <span class="n">ce</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">ce</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;CE (Î³=0)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">fl_gamma_1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;FL (Î³=1)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">fl_gamma_2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;FL (Î³=2)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">fl_gamma_5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;FL (Î³=5)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Probability of Correct Class (p)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Focal Loss: Down-weighting Easy Examples&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Annotate easy vs hard examples</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="s1">&#39;Hard Examples</span><span class="se">\n</span><span class="s1">(low confidence)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="s1">&#39;Easy Examples</span><span class="se">\n</span><span class="s1">(high confidence)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;focal_loss.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">visualize_focal_loss</span><span class="p">()</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ê°ì²´ ê²€ì¶œ(RetinaNet, FCOS)
- ë¶ˆê· í˜• ë¶„ë¥˜(ì‚¬ê¸° íƒì§€, ì˜ë£Œ ì§„ë‹¨)
- ë§ì€ ì‰¬ìš´ ë„¤ê±°í‹°ë¸Œê°€ ìˆì„ ë•Œ</p>
<h3 id="35-bce-vs-cross-entropy">3.5 BCE vs Cross-Entropy<a class="header-link" href="#35-bce-vs-cross-entropy" title="Permanent link">&para;</a></h3>
<p><strong>ì˜ì‚¬ê²°ì • ê°€ì´ë“œ:</strong></p>
<table>
<thead>
<tr>
<th>ì‘ì—…</th>
<th>ì†ì‹¤</th>
<th>í™œì„±í™”</th>
<th>ë¹„ê³ </th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ì´ì§„ ë¶„ë¥˜</strong></td>
<td><code>BCEWithLogitsLoss</code></td>
<td>None (í¬í•¨ë¨)</td>
<td>2ê°œ í´ë˜ìŠ¤, ìƒí˜¸ ë°°íƒ€ì </td>
</tr>
<tr>
<td><strong>ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜</strong></td>
<td><code>CrossEntropyLoss</code></td>
<td>None (í¬í•¨ë¨)</td>
<td>Kê°œ í´ë˜ìŠ¤, ìƒí˜¸ ë°°íƒ€ì </td>
</tr>
<tr>
<td><strong>ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜</strong></td>
<td><code>BCEWithLogitsLoss</code></td>
<td>None (í¬í•¨ë¨)</td>
<td>ì—¬ëŸ¬ ë…ë¦½ ë ˆì´ë¸”</td>
</tr>
<tr>
<td><strong>ë¶ˆê· í˜• ë¶„ë¥˜</strong></td>
<td><code>FocalLoss</code></td>
<td>Softmax</td>
<td>í´ë˜ìŠ¤ ë¶ˆê· í˜•</td>
</tr>
</tbody>
</table>
<p><strong>ì˜ˆì œ: ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Multi-label: Each sample can belong to multiple classes</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiLabelClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Raw logits</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MultiLabelClassifier</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>  <span class="c1"># Use BCE, not CE!</span>

<span class="c1"># Multi-label targets (sample can have multiple 1s)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># Sample 1: classes 0, 2, 4</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># Sample 2: classes 1, 2</span>
    <span class="c1"># ... more samples</span>
<span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multi-Label Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="4-ranking-and-metric-learning-losses">4. ìˆœìœ„ ë° ë©”íŠ¸ë¦­ í•™ìŠµ ì†ì‹¤(Ranking and Metric Learning Losses)<a class="header-link" href="#4-ranking-and-metric-learning-losses" title="Permanent link">&para;</a></h2>
<p>ì´ ì†ì‹¤ë“¤ì€ ìœ ì‚¬í•œ í•­ëª©ì€ ê°€ê¹ê³  ë¹„ìœ ì‚¬í•œ í•­ëª©ì€ ë©€ë¦¬ ë–¨ì–´ì§„ ì„ë² ë”©ì„ í•™ìŠµí•©ë‹ˆë‹¤.</p>
<h3 id="41-contrastive-loss">4.1 ëŒ€ì¡° ì†ì‹¤(Contrastive Loss)<a class="header-link" href="#41-contrastive-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>L = (1/2) <span class="gs">* [y *</span> dÂ² + (1-y) * max(0, m - d)Â²]

where:
<span class="k">-</span> d = ||f(xâ‚) - f(xâ‚‚)||â‚‚ (Euclidean distance)
<span class="k">-</span> y = 1 if similar, 0 if dissimilar
<span class="k">-</span> m is margin (e.g., 1.0)
</code></pre></div>

<p><strong>ì‚¬ìš© ì‚¬ë¡€:</strong>
- ìƒ´ ë„¤íŠ¸ì›Œí¬(Siamese networks)
- ì–¼êµ´ ê²€ì¦
- ì„œëª… ê²€ì¦</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ContrastiveLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            output1: (N, embedding_dim) embeddings from first input</span>
<span class="sd">            output2: (N, embedding_dim) embeddings from second input</span>
<span class="sd">            label: (N,) 1 if similar, 0 if dissimilar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">euclidean_distance</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">)</span>

        <span class="n">loss_contrastive</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">label</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">euclidean_distance</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span>
            <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">-</span> <span class="n">euclidean_distance</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span> <span class="mi">2</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">loss_contrastive</span>

<span class="c1"># Siamese Network Example</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SiameseNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward_one</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_one</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_one</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out1</span><span class="p">,</span> <span class="n">out2</span>

<span class="c1"># Training</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SiameseNetwork</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">ContrastiveLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Dummy data</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>  <span class="c1"># 1=similar, 0=dissimilar</span>

<span class="c1"># Training step</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">output1</span><span class="p">,</span> <span class="n">output2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Contrastive Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="42-triplet-loss">4.2 íŠ¸ë¦¬í”Œë › ì†ì‹¤(Triplet Loss)<a class="header-link" href="#42-triplet-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>L = max(0, d(a, p) - d(a, n) + margin)

where:
- a: anchor
- p: positive (same class as anchor)
- n: negative (different class)
- d(x, y) = ||f(x) - f(y)||â‚‚
</code></pre></div>

<p><strong>ë§ˆì´ë‹ ì „ëµ:</strong>
- <strong>í•˜ë“œ ë„¤ê±°í‹°ë¸Œ</strong>: max d(a, p) - d(a, n)
- <strong>ì„¸ë¯¸-í•˜ë“œ ë„¤ê±°í‹°ë¸Œ</strong>: d(a, p) &lt; d(a, n) &lt; d(a, p) + margin
- <strong>ë°°ì¹˜-ì˜¬</strong>: ë°°ì¹˜ ë‚´ ëª¨ë“  ìœ íš¨í•œ íŠ¸ë¦¬í”Œë ›</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            anchor: (N, embedding_dim)</span>
<span class="sd">            positive: (N, embedding_dim)</span>
<span class="sd">            negative: (N, embedding_dim)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">distance_positive</span> <span class="o">=</span> <span class="p">(</span><span class="n">anchor</span> <span class="o">-</span> <span class="n">positive</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">distance_negative</span> <span class="o">=</span> <span class="p">(</span><span class="n">anchor</span> <span class="o">-</span> <span class="n">negative</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">distance_positive</span> <span class="o">-</span> <span class="n">distance_negative</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Online Triplet Mining</span>
<span class="k">class</span><span class="w"> </span><span class="nc">OnlineTripletLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">margin</span> <span class="o">=</span> <span class="n">margin</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            embeddings: (N, embedding_dim)</span>
<span class="sd">            labels: (N,) class labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute pairwise distances</span>
        <span class="n">pairwise_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># For each anchor, get hardest positive and negative</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">triplet_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">num_triplets</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># Positive mask: same class as anchor</span>
            <span class="n">pos_mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">pos_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Exclude anchor itself</span>

            <span class="c1"># Negative mask: different class</span>
            <span class="n">neg_mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">pos_mask</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">and</span> <span class="n">neg_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="c1"># Hardest positive</span>
                <span class="n">hardest_positive_dist</span> <span class="o">=</span> <span class="n">pairwise_dist</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">pos_mask</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

                <span class="c1"># Hardest negative (closest negative)</span>
                <span class="n">hardest_negative_dist</span> <span class="o">=</span> <span class="n">pairwise_dist</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">neg_mask</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span>
                    <span class="n">hardest_positive_dist</span> <span class="o">-</span> <span class="n">hardest_negative_dist</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin</span>
                <span class="p">)</span>
                <span class="n">triplet_loss</span> <span class="o">+=</span> <span class="n">loss</span>
                <span class="n">num_triplets</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">triplet_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_triplets</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">TripletLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">online_criterion</span> <span class="o">=</span> <span class="n">OnlineTripletLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Method 1: Pre-mined triplets</span>
<span class="n">anchor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">positive</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">negative</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Triplet Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Method 2: Online mining</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,))</span>  <span class="c1"># 10 classes</span>

<span class="n">loss_online</span> <span class="o">=</span> <span class="n">online_criterion</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Online Triplet Loss: </span><span class="si">{</span><span class="n">loss_online</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>í›ˆë ¨ ì˜ˆì œ:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">EmbeddingNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EmbeddingNet</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">OnlineTripletLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Simulate batch</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,))</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ì–¼êµ´ ì¸ì‹(FaceNet)
- ì‚¬ëŒ ì¬ì‹ë³„
- ì´ë¯¸ì§€ ê²€ìƒ‰</p>
<h3 id="43-infonce-nt-xent">4.3 InfoNCE / NT-Xent ì†ì‹¤<a class="header-link" href="#43-infonce-nt-xent" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>L = -log [exp(sim(z_i, z_j)/Ï„) / Î£â‚– exp(sim(z_i, z_k)/Ï„)]

where:
<span class="k">-</span> z_i, z_j are positive pair embeddings
<span class="k">-</span> Ï„ is temperature parameter (e.g., 0.07)
<span class="k">-</span> sim(u, v) = uÂ·v / (||u|| ||v||) (cosine similarity)
</code></pre></div>

<p><strong>ì‚¬ìš© ì‚¬ë¡€:</strong>
- ìê¸°ì§€ë„ í•™ìŠµ(Self-supervised learning, SimCLR, MoCo)
- ëŒ€ì¡°ì  ì–¸ì–´-ì´ë¯¸ì§€ ì‚¬ì „ í›ˆë ¨(CLIP)</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">InfoNCELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.07</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            z_i: (N, embedding_dim) embeddings of view 1</span>
<span class="sd">            z_j: (N, embedding_dim) embeddings of view 2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">z_i</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Normalize embeddings</span>
        <span class="n">z_i</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z_i</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z_j</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z_j</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute similarity matrix</span>
        <span class="n">representations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (2N, dim)</span>
        <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">representations</span><span class="p">,</span> <span class="n">representations</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># (2N, 2N)</span>

        <span class="c1"># Create labels: positive pairs are at (i, N+i) and (N+i, i)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">z_i</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Mask to remove self-similarity</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z_i</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute loss</span>
        <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">similarity_matrix</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># Simplified NT-Xent (for SimCLR)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">NTXentLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simplified version&quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">z_i</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># L2 normalize</span>
        <span class="n">z_i</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z_i</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z_j</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">z_j</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Positive similarity</span>
        <span class="n">pos_sim</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_i</span> <span class="o">*</span> <span class="n">z_j</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>  <span class="c1"># (N,)</span>

        <span class="c1"># All similarities</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (2N, dim)</span>
        <span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>  <span class="c1"># (2N, 2N)</span>

        <span class="c1"># Remove diagonal</span>
        <span class="n">sim_matrix</span><span class="o">.</span><span class="n">fill_diagonal_</span><span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>

        <span class="c1"># Compute loss for i -&gt; j</span>
        <span class="n">pos_sim_expanded</span> <span class="o">=</span> <span class="n">pos_sim</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, 1)</span>
        <span class="n">negatives_i</span> <span class="o">=</span> <span class="n">sim_matrix</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>  <span class="c1"># (N, 2N)</span>
        <span class="n">logits_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pos_sim_expanded</span><span class="p">,</span> <span class="n">negatives_i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, 2N+1)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z_i</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits_i</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># Example usage</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">InfoNCELoss</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.07</span><span class="p">)</span>

<span class="c1"># Simulate augmented views</span>
<span class="n">z_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># View 1 embeddings</span>
<span class="n">z_j</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># View 2 embeddings</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">z_i</span><span class="p">,</span> <span class="n">z_j</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;InfoNCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ìê¸°ì§€ë„ ì‚¬ì „ í›ˆë ¨(SimCLR)
- ë¹„ì „-ì–¸ì–´ ëª¨ë¸(CLIP)
- ëŒ€ì¡° í•™ìŠµ</p>
<hr />
<h2 id="5-segmentation-and-detection-losses">5. ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ê²€ì¶œ ì†ì‹¤(Segmentation and Detection Losses)<a class="header-link" href="#5-segmentation-and-detection-losses" title="Permanent link">&para;</a></h2>
<h3 id="51-dice-loss">5.1 ë‹¤ì´ìŠ¤ ì†ì‹¤(Dice Loss)<a class="header-link" href="#51-dice-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code>Dice Loss = 1 - (2 * |X âˆ© Y|) / (|X| + |Y|)

where:
<span class="k">-</span> X is predicted segmentation
<span class="k">-</span> Y is ground truth
</code></pre></div>

<p><strong>íŠ¹ì„±:</strong>
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬(ë°°ê²½ vs ì „ê²½)
- IoUì˜ ë¯¸ë¶„ ê°€ëŠ¥í•œ ê·¼ì‚¬
- ë²”ìœ„: [0, 1]</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DiceLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            smooth: Smoothing constant to avoid division by zero</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span> <span class="o">=</span> <span class="n">smooth</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: (N, C, H, W) predicted probabilities</span>
<span class="sd">            target: (N, C, H, W) one-hot encoded ground truth</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pred_flat</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_flat</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">intersection</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_flat</span> <span class="o">*</span> <span class="n">target_flat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">dice_score</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">intersection</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
            <span class="n">pred_flat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">target_flat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dice_score</span>

<span class="c1"># Multi-class Dice Loss</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiClassDiceLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smooth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span> <span class="o">=</span> <span class="n">smooth</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: (N, C, H, W) logits</span>
<span class="sd">            target: (N, H, W) class indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pred_softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Convert target to one-hot</span>
        <span class="n">target_one_hot</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="n">target_one_hot</span> <span class="o">=</span> <span class="n">target_one_hot</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
            <span class="n">pred_c</span> <span class="o">=</span> <span class="n">pred_softmax</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span>
            <span class="n">target_c</span> <span class="o">=</span> <span class="n">target_one_hot</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span>

            <span class="n">intersection</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_c</span> <span class="o">*</span> <span class="n">target_c</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">dice</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">intersection</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">pred_c</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">target_c</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">smooth</span>
            <span class="p">)</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dice</span>

        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_classes</span>

<span class="c1"># Example usage</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span>

<span class="c1"># Binary segmentation</span>
<span class="n">pred_binary</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
<span class="n">target_binary</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">dice_loss</span> <span class="o">=</span> <span class="n">DiceLoss</span><span class="p">()</span>
<span class="n">loss_binary</span> <span class="o">=</span> <span class="n">dice_loss</span><span class="p">(</span><span class="n">pred_binary</span><span class="p">,</span> <span class="n">target_binary</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binary Dice Loss: </span><span class="si">{</span><span class="n">loss_binary</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Multi-class segmentation</span>
<span class="n">pred_multi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="n">target_multi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>

<span class="n">dice_multi</span> <span class="o">=</span> <span class="n">MultiClassDiceLoss</span><span class="p">()</span>
<span class="n">loss_multi</span> <span class="o">=</span> <span class="n">dice_multi</span><span class="p">(</span><span class="n">pred_multi</span><span class="p">,</span> <span class="n">target_multi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multi-class Dice Loss: </span><span class="si">{</span><span class="n">loss_multi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="52-iou-giou">5.2 IoU ì†ì‹¤ / GIoU ì†ì‹¤<a class="header-link" href="#52-iou-giou" title="Permanent link">&para;</a></h3>
<p><strong>IoU (Intersection over Union):</strong></p>
<div class="highlight"><pre><span></span><code>IoU = Area(Intersection) / Area(Union)
</code></pre></div>

<p><strong>GIoU (Generalized IoU):</strong></p>
<div class="highlight"><pre><span></span><code>GIoU = IoU - |C \ (A âˆª B)| / |C|

where C is smallest box enclosing A and B
</code></pre></div>

<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">iou_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">target_boxes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        pred_boxes: (N, 4) [x1, y1, x2, y2]</span>
<span class="sd">        target_boxes: (N, 4) [x1, y1, x2, y2]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Intersection coordinates</span>
    <span class="n">x1_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">y1_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">x2_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">y2_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># Intersection area</span>
    <span class="n">inter_area</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x2_inter</span> <span class="o">-</span> <span class="n">x1_inter</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> \
                 <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">y2_inter</span> <span class="o">-</span> <span class="n">y1_inter</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Union area</span>
    <span class="n">pred_area</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> \
                <span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">target_area</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> \
                  <span class="p">(</span><span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">union_area</span> <span class="o">=</span> <span class="n">pred_area</span> <span class="o">+</span> <span class="n">target_area</span> <span class="o">-</span> <span class="n">inter_area</span>

    <span class="c1"># IoU</span>
    <span class="n">iou</span> <span class="o">=</span> <span class="n">inter_area</span> <span class="o">/</span> <span class="p">(</span><span class="n">union_area</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>

    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">iou</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">giou_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">target_boxes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generalized IoU Loss&quot;&quot;&quot;</span>
    <span class="c1"># Intersection</span>
    <span class="n">x1_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">y1_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">x2_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">y2_inter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="n">inter_area</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x2_inter</span> <span class="o">-</span> <span class="n">x1_inter</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> \
                 <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">y2_inter</span> <span class="o">-</span> <span class="n">y1_inter</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Union</span>
    <span class="n">pred_area</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> \
                <span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">target_area</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> \
                  <span class="p">(</span><span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">union_area</span> <span class="o">=</span> <span class="n">pred_area</span> <span class="o">+</span> <span class="n">target_area</span> <span class="o">-</span> <span class="n">inter_area</span>

    <span class="c1"># IoU</span>
    <span class="n">iou</span> <span class="o">=</span> <span class="n">inter_area</span> <span class="o">/</span> <span class="p">(</span><span class="n">union_area</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>

    <span class="c1"># Enclosing box</span>
    <span class="n">x1_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">y1_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">x2_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">y2_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">target_boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="n">enclosing_area</span> <span class="o">=</span> <span class="p">(</span><span class="n">x2_c</span> <span class="o">-</span> <span class="n">x1_c</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y2_c</span> <span class="o">-</span> <span class="n">y1_c</span><span class="p">)</span>

    <span class="c1"># GIoU</span>
    <span class="n">giou</span> <span class="o">=</span> <span class="n">iou</span> <span class="o">-</span> <span class="p">(</span><span class="n">enclosing_area</span> <span class="o">-</span> <span class="n">union_area</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">enclosing_area</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>

    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">giou</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Example usage</span>
<span class="n">pred_boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">]</span>
<span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">target_boxes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">55</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">65</span><span class="p">]</span>
<span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">loss_iou</span> <span class="o">=</span> <span class="n">iou_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">target_boxes</span><span class="p">)</span>
<span class="n">loss_giou</span> <span class="o">=</span> <span class="n">giou_loss</span><span class="p">(</span><span class="n">pred_boxes</span><span class="p">,</span> <span class="n">target_boxes</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;IoU Loss: </span><span class="si">{</span><span class="n">loss_iou</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GIoU Loss: </span><span class="si">{</span><span class="n">loss_giou</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="53-combined-losses">5.3 ê²°í•© ì†ì‹¤(Combined Losses)<a class="header-link" href="#53-combined-losses" title="Permanent link">&para;</a></h3>
<p><strong>ì˜ˆì œ: ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ CE + Dice:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CombinedLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ce_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dice_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce_weight</span> <span class="o">=</span> <span class="n">ce_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dice_weight</span> <span class="o">=</span> <span class="n">dice_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dice</span> <span class="o">=</span> <span class="n">MultiClassDiceLoss</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: (N, C, H, W) logits</span>
<span class="sd">            target: (N, H, W) class indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ce_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">dice_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dice</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce_weight</span> <span class="o">*</span> <span class="n">ce_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dice_weight</span> <span class="o">*</span> <span class="n">dice_loss</span>

<span class="c1"># Example</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CombinedLoss</span><span class="p">(</span><span class="n">ce_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dice_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Combined Loss (CE + Dice): </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="6-generative-model-losses">6. ìƒì„± ëª¨ë¸ ì†ì‹¤(Generative Model Losses)<a class="header-link" href="#6-generative-model-losses" title="Permanent link">&para;</a></h2>
<h3 id="61-adversarial-loss-gan">6.1 ì ëŒ€ì  ì†ì‹¤(Adversarial Loss, GAN)<a class="header-link" href="#61-adversarial-loss-gan" title="Permanent link">&para;</a></h3>
<p><strong>Minimax GAN:</strong></p>
<div class="highlight"><pre><span></span><code>min_G max_D V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]
</code></pre></div>

<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Standard GAN loss</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gan_loss_discriminator</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Discriminator loss&quot;&quot;&quot;</span>
    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">real_output</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_output</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">fake_output</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gan_loss_generator</span><span class="p">(</span><span class="n">fake_output</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generator loss (non-saturating)&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">fake_output</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># Wasserstein GAN loss</span>
<span class="k">def</span><span class="w"> </span><span class="nf">wgan_loss_discriminator</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;WGAN discriminator loss&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">real_output</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fake_output</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">wgan_loss_generator</span><span class="p">(</span><span class="n">fake_output</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;WGAN generator loss&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">real_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Discriminator output for real images</span>
<span class="n">fake_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Discriminator output for fake images</span>

<span class="c1"># Standard GAN</span>
<span class="n">d_loss</span> <span class="o">=</span> <span class="n">gan_loss_discriminator</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">)</span>
<span class="n">g_loss</span> <span class="o">=</span> <span class="n">gan_loss_generator</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GAN D Loss: </span><span class="si">{</span><span class="n">d_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, G Loss: </span><span class="si">{</span><span class="n">g_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># WGAN</span>
<span class="n">d_loss_wgan</span> <span class="o">=</span> <span class="n">wgan_loss_discriminator</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">)</span>
<span class="n">g_loss_wgan</span> <span class="o">=</span> <span class="n">wgan_loss_generator</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WGAN D Loss: </span><span class="si">{</span><span class="n">d_loss_wgan</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, G Loss: </span><span class="si">{</span><span class="n">g_loss_wgan</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="62-vae">6.2 VAE ì†ì‹¤<a class="header-link" href="#62-vae" title="Permanent link">&para;</a></h3>
<p><strong>ê³µì‹:</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">L</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Reconstruction</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">KL</span><span class="w"> </span><span class="n">Divergence</span>
<span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">E</span><span class="p">[</span><span class="nb">log</span><span class="w"> </span><span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="o">|</span><span class="n">z</span><span class="p">)]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">KL</span><span class="p">(</span><span class="n">q</span><span class="p">(</span><span class="n">z</span><span class="o">|</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">p</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</code></pre></div>

<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        recon_x: Reconstructed input</span>
<span class="sd">        x: Original input</span>
<span class="sd">        mu: Mean of latent distribution</span>
<span class="sd">        logvar: Log variance of latent distribution</span>
<span class="sd">        beta: Weight for KL term (Î²-VAE)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Reconstruction loss (BCE for binary images, MSE for continuous)</span>
    <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span>
        <span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span>
    <span class="p">)</span>

    <span class="c1"># KL divergence: -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)</span>
    <span class="n">kl_div</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_div</span>

<span class="c1"># Example VAE</span>
<span class="k">class</span><span class="w"> </span><span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">recon_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>

<span class="c1"># Training</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>  <span class="c1"># Dummy data</span>
<span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;VAE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="63-perceptual-loss">6.3 ì§€ê°ì  ì†ì‹¤(Perceptual Loss)<a class="header-link" href="#63-perceptual-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê°œë…:</strong>
í”½ì…€ë³„ ë¹„êµ ëŒ€ì‹  ì‚¬ì „ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬(ì˜ˆ: VGG)ì˜ íŠ¹ì§•ë³„ ë¹„êµ ì‚¬ìš©.</p>
<p><strong>PyTorch êµ¬í˜„:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PerceptualLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;relu1_2&#39;</span><span class="p">,</span> <span class="s1">&#39;relu2_2&#39;</span><span class="p">,</span> <span class="s1">&#39;relu3_3&#39;</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Load pretrained VGG16</span>
        <span class="n">vgg</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

        <span class="c1"># Map layer names to indices</span>
        <span class="n">layer_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;relu1_2&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;relu2_2&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">&#39;relu3_3&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">&#39;relu4_3&#39;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span> <span class="s1">&#39;relu5_3&#39;</span><span class="p">:</span> <span class="mi">30</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">layer_map</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">vgg</span><span class="p">[:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>

        <span class="c1"># Freeze parameters</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: (N, 3, H, W) predicted image</span>
<span class="sd">            target: (N, 3, H, W) target image</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">extractor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">pred_features</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
            <span class="n">target_features</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">pred_features</span><span class="p">,</span> <span class="n">target_features</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">)</span>

<span class="c1"># Example usage (requires torchvision)</span>
<span class="c1"># perceptual_loss = PerceptualLoss()</span>
<span class="c1"># pred_img = torch.randn(4, 3, 224, 224)</span>
<span class="c1"># target_img = torch.randn(4, 3, 224, 224)</span>
<span class="c1"># loss = perceptual_loss(pred_img, target_img)</span>
<span class="c1"># print(f&quot;Perceptual Loss: {loss.item():.4f}&quot;)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‹œê¸°:</strong>
- ìŠ¤íƒ€ì¼ ì „ì´
- ì´ˆí•´ìƒë„(Super-resolution)
- ì´ë¯¸ì§€ ê°„ ë³€í™˜</p>
<hr />
<h2 id="7-advanced-topics">7. ê³ ê¸‰ ì£¼ì œ(Advanced Topics)<a class="header-link" href="#7-advanced-topics" title="Permanent link">&para;</a></h2>
<h3 id="71-multi-task-loss-weighting">7.1 ë‹¤ì¤‘ ì‘ì—… ì†ì‹¤ ê°€ì¤‘ì¹˜(Multi-Task Loss Weighting)<a class="header-link" href="#71-multi-task-loss-weighting" title="Permanent link">&para;</a></h3>
<p><strong>ë¬¸ì œ:</strong>
ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— í›ˆë ¨í•  ë•Œ ì†ì‹¤ì˜ ê· í˜•ì„ ì–´ë–»ê²Œ ë§ì¶œê¹Œ?</p>
<p><strong>ë°©ë²• 1: ìˆ˜ë™ ê°€ì¤‘ì¹˜</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">total_loss</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">*</span> <span class="n">task1_loss</span> <span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="n">task2_loss</span> <span class="o">+</span> <span class="n">w3</span> <span class="o">*</span> <span class="n">task3_loss</span>
</code></pre></div>

<p><strong>ë°©ë²• 2: ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜(Uncertainty Weighting)</strong></p>
<p>"Multi-Task Learning Using Uncertainty to Weigh Losses" (Kendall et al., 2018) ê¸°ë°˜.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultiTaskLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_tasks</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Learnable log variance for each task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_vars</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            losses: List of losses for each task</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">losses</span><span class="p">):</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_vars</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_vars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">total_loss</span>

<span class="c1"># Example</span>
<span class="n">mtl</span> <span class="o">=</span> <span class="n">MultiTaskLoss</span><span class="p">(</span><span class="n">num_tasks</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">mtl</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Simulate task losses</span>
<span class="n">task_losses</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.5</span><span class="p">),</span>  <span class="c1"># Task 1</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.8</span><span class="p">),</span>  <span class="c1"># Task 2</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.2</span><span class="p">),</span>  <span class="c1"># Task 3</span>
<span class="p">]</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="n">mtl</span><span class="p">(</span><span class="n">task_losses</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Multi-task Loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Learned weights: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mtl</span><span class="o">.</span><span class="n">log_vars</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ë°©ë²• 3: GradNorm</strong></p>
<p>ê¸°ìš¸ê¸°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì‘ì—… ì†ì‹¤ì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">GradNorm</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_tasks</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            model: Shared network</span>
<span class="sd">            num_tasks: Number of tasks</span>
<span class="sd">            alpha: Restoring force (typically 1.5)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span> <span class="o">=</span> <span class="n">num_tasks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_tasks</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_losses</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">shared_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update task weights based on gradient norms&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_losses</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initial_losses</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="c1"># Compute weighted loss</span>
        <span class="n">weighted_losses</span> <span class="o">=</span> <span class="n">losses</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">weighted_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="c1"># Compute gradients</span>
        <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Get gradient norms for shared layers</span>
        <span class="n">grad_norms</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_tasks</span><span class="p">):</span>
            <span class="c1"># ... compute grad norm for task i</span>
            <span class="k">pass</span>

        <span class="c1"># Update weights (simplified version)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

<span class="c1"># Note: Full GradNorm implementation requires careful gradient manipulation</span>
</code></pre></div>

<h3 id="72-curriculum-loss">7.2 ì»¤ë¦¬í˜ëŸ¼ ì†ì‹¤(Curriculum Loss)<a class="header-link" href="#72-curriculum-loss" title="Permanent link">&para;</a></h3>
<p><strong>ê°œë…:</strong>
ì‰¬ìš´ ì˜ˆì œë¡œ í›ˆë ¨ì„ ì‹œì‘í•˜ê³  ì ì°¨ ë‚œì´ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CurriculumLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_criterion</span><span class="p">,</span> <span class="n">total_epochs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_criterion</span> <span class="o">=</span> <span class="n">base_criterion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span> <span class="o">=</span> <span class="n">total_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">difficulty</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: Predictions</span>
<span class="sd">            target: Ground truth</span>
<span class="sd">            difficulty: (N,) difficulty score for each sample [0, 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute base loss</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="c1"># Curriculum weight: easier samples first</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_epochs</span>
        <span class="n">threshold</span> <span class="o">=</span> <span class="n">progress</span>  <span class="c1"># Gradually increase difficulty threshold</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">difficulty</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span> <span class="o">*</span> <span class="n">weights</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">losses</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Example usage</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">CurriculumLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">),</span> <span class="n">total_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,))</span>
    <span class="n">difficulty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>  <span class="c1"># Random difficulty scores</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">difficulty</span><span class="p">)</span>
    <span class="c1"># ... backward, optimize ...</span>

    <span class="n">criterion</span><span class="o">.</span><span class="n">step_epoch</span><span class="p">()</span>
</code></pre></div>

<h3 id="73">7.3 ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜<a class="header-link" href="#73" title="Permanent link">&para;</a></h3>
<p><strong>ì»¤ìŠ¤í…€ ì†ì‹¤ í…œí”Œë¦¿:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CustomLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param1</span><span class="p">,</span> <span class="n">param2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param1</span> <span class="o">=</span> <span class="n">param1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param2</span> <span class="o">=</span> <span class="n">param2</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pred: Model predictions</span>
<span class="sd">            target: Ground truth</span>

<span class="sd">        Returns:</span>
<span class="sd">            loss: Scalar tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Implement your loss computation</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Example</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># Example: Asymmetric Loss (penalize overestimation more than underestimation)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AsymmetricMSELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">over_penalty</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">over_penalty</span> <span class="o">=</span> <span class="n">over_penalty</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">target</span>

        <span class="c1"># Penalize overestimation more</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">error</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">over_penalty</span> <span class="o">*</span> <span class="n">error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">error</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Usage</span>
<span class="n">asymmetric_loss</span> <span class="o">=</span> <span class="n">AsymmetricMSELoss</span><span class="p">(</span><span class="n">over_penalty</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">asymmetric_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Asymmetric Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="74">7.4 ìˆ˜ì¹˜ ì•ˆì •ì„± íŒ<a class="header-link" href="#74" title="Permanent link">&para;</a></h3>
<p><strong>ë¬¸ì œ 1: Log-Sum-Exp íŠ¸ë¦­</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Numerically unstable (can overflow)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">unstable_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># Stable version</span>
<span class="k">def</span><span class="w"> </span><span class="nf">stable_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_max</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">exp_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_x</span><span class="p">)</span>

<span class="c1"># Example</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1000.0</span><span class="p">,</span> <span class="mf">1001.0</span><span class="p">,</span> <span class="mf">1002.0</span><span class="p">])</span>
<span class="c1"># unstable_softmax(x)  # Would cause overflow</span>
<span class="n">stable</span> <span class="o">=</span> <span class="n">stable_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stable Softmax: </span><span class="si">{</span><span class="n">stable</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ë¬¸ì œ 2: log(0) ë°©ì§€</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Bad: Can produce NaN</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="c1"># Good: Add small epsilon</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>

<span class="c1"># Better: Use clamp</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="n">epsilon</span><span class="p">))</span>

<span class="c1"># Best: Use built-in stable versions</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div>

<p><strong>ë¬¸ì œ 3: ê¸°ìš¸ê¸° í´ë¦¬í•‘(Gradient Clipping)</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Prevent exploding gradients</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Or clip by value</span>
<span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_value_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="8-practical-guide">8. ì‹¤ìš© ê°€ì´ë“œ(Practical Guide)<a class="header-link" href="#8-practical-guide" title="Permanent link">&para;</a></h2>
<h3 id="81">8.1 ì†ì‹¤ ì„ íƒ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬<a class="header-link" href="#81" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">Start</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="n">Regression</span><span class="err">?</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Clean</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">outliers</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">MSE</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Data</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">outliers</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">MAE</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">Huber</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Need</span><span class="w"> </span><span class="n">smooth</span><span class="w"> </span><span class="n">gradients</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Huber</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">Log</span><span class="o">-</span><span class="n">Cosh</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="n">Classification</span><span class="err">?</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Binary</span><span class="w"> </span><span class="n">classification</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">BCEWithLogitsLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Multi</span><span class="o">-</span><span class="k">class</span><span class="w"> </span><span class="p">(</span><span class="n">mutually</span><span class="w"> </span><span class="n">exclusive</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">CrossEntropyLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Multi</span><span class="o">-</span><span class="n">label</span><span class="w"> </span><span class="p">(</span><span class="n">independent</span><span class="w"> </span><span class="n">labels</span><span class="p">)</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">BCEWithLogitsLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Class</span><span class="w"> </span><span class="n">imbalance</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">FocalLoss</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">weighted</span><span class="w"> </span><span class="n">CE</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="n">Segmentation</span><span class="err">?</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Small</span><span class="w"> </span><span class="n">objects</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">DiceLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Class</span><span class="w"> </span><span class="n">imbalance</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">DiceLoss</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">FocalLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Balanced</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">CrossEntropyLoss</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">CE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Dice</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="nb nb-Type">Object</span><span class="w"> </span><span class="n">Detection</span><span class="err">?</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Classification</span><span class="w"> </span><span class="n">head</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">CrossEntropyLoss</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">FocalLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Bounding</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="n">regression</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">IoU</span><span class="w"> </span><span class="n">Loss</span><span class="p">,</span><span class="w"> </span><span class="n">GIoU</span><span class="w"> </span><span class="n">Loss</span><span class="p">,</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">Smooth</span><span class="w"> </span><span class="n">L1</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="n">Metric</span><span class="w"> </span><span class="n">Learning</span><span class="err">?</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Pair</span><span class="w"> </span><span class="n">verification</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">ContrastiveLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">Triplet</span><span class="w"> </span><span class="n">comparison</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">TripletLoss</span>
<span class="w">  </span><span class="err">â”‚</span><span class="w">    </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Self</span><span class="o">-</span><span class="n">supervised</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">InfoNCE</span><span class="w"> </span><span class="p">(</span><span class="n">NT</span><span class="o">-</span><span class="n">Xent</span><span class="p">)</span>
<span class="w">  </span><span class="err">â”‚</span>
<span class="w">  </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Task</span><span class="p">:</span><span class="w"> </span><span class="n">Generative</span><span class="w"> </span><span class="n">Model</span><span class="err">?</span>
<span class="w">       </span><span class="err">â”‚</span>
<span class="w">       </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">GAN</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Adversarial</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="p">(</span><span class="n">BCE</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">Wasserstein</span><span class="p">)</span>
<span class="w">       </span><span class="err">â”œâ”€</span><span class="w"> </span><span class="n">VAE</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Reconstruction</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">KL</span><span class="w"> </span><span class="n">Divergence</span>
<span class="w">       </span><span class="err">â””â”€</span><span class="w"> </span><span class="n">Image</span><span class="w"> </span><span class="n">translation</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="n">Perceptual</span><span class="w"> </span><span class="n">Loss</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">L1</span><span class="o">/</span><span class="n">L2</span>
</code></pre></div>

<h3 id="82">8.2 ë¹„êµ í‘œ<a class="header-link" href="#82" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ì‘ì—…</th>
<th>ì†ì‹¤ í•¨ìˆ˜</th>
<th>í™œì„±í™”</th>
<th>ë¹„ê³ </th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>íšŒê·€</strong></td>
<td>MSE</td>
<td>None</td>
<td>ê¹¨ë—í•œ ë°ì´í„°</td>
</tr>
<tr>
<td></td>
<td>MAE</td>
<td>None</td>
<td>ì´ìƒì¹˜ ê°•ê±´í•¨</td>
</tr>
<tr>
<td></td>
<td>Huber</td>
<td>None</td>
<td>L1/L2 ê· í˜•</td>
</tr>
<tr>
<td><strong>ì´ì§„ ë¶„ë¥˜</strong></td>
<td>BCEWithLogitsLoss</td>
<td>None (ë‚´ë¶€ sigmoid)</td>
<td>ìˆ˜ì¹˜ì ìœ¼ë¡œ ì•ˆì •ì </td>
</tr>
<tr>
<td><strong>ë‹¤ì¤‘ í´ë˜ìŠ¤</strong></td>
<td>CrossEntropyLoss</td>
<td>None (ë‚´ë¶€ softmax)</td>
<td>ìƒí˜¸ ë°°íƒ€ì </td>
</tr>
<tr>
<td><strong>ë‹¤ì¤‘ ë ˆì´ë¸”</strong></td>
<td>BCEWithLogitsLoss</td>
<td>None (ë‚´ë¶€ sigmoid)</td>
<td>ë…ë¦½ ë ˆì´ë¸”</td>
</tr>
<tr>
<td><strong>ë¶ˆê· í˜• ë¶„ë¥˜</strong></td>
<td>FocalLoss</td>
<td>Softmax</td>
<td>ë¶ˆê· í˜• í•´ê²°</td>
</tr>
<tr>
<td><strong>ì„¸ê·¸ë©˜í…Œì´ì…˜</strong></td>
<td>DiceLoss</td>
<td>Softmax</td>
<td>í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬</td>
</tr>
<tr>
<td></td>
<td>CE + Dice</td>
<td>Softmax</td>
<td>ê²°í•© ì ‘ê·¼ë²•</td>
</tr>
<tr>
<td><strong>ê²€ì¶œ(bbox)</strong></td>
<td>IoU / GIoU Loss</td>
<td>None</td>
<td>ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€</td>
</tr>
<tr>
<td><strong>ê²€ì¶œ(class)</strong></td>
<td>FocalLoss</td>
<td>Softmax</td>
<td>ì‰¬ìš´ ë„¤ê±°í‹°ë¸Œ ì²˜ë¦¬</td>
</tr>
<tr>
<td><strong>ì–¼êµ´ ê²€ì¦</strong></td>
<td>ContrastiveLoss</td>
<td>None</td>
<td>ìƒ´ ë„¤íŠ¸ì›Œí¬</td>
</tr>
<tr>
<td><strong>ì–¼êµ´ ì¸ì‹</strong></td>
<td>TripletLoss</td>
<td>None</td>
<td>íŠ¸ë¦¬í”Œë › ë§ˆì´ë‹</td>
</tr>
<tr>
<td><strong>ìê¸°ì§€ë„</strong></td>
<td>InfoNCE</td>
<td>None</td>
<td>ëŒ€ì¡° í•™ìŠµ</td>
</tr>
<tr>
<td><strong>GAN</strong></td>
<td>BCELoss (ì ëŒ€ì )</td>
<td>Sigmoid</td>
<td>Minimax ê²Œì„</td>
</tr>
<tr>
<td><strong>VAE</strong></td>
<td>BCE/MSE + KL</td>
<td>Sigmoid/None</td>
<td>ì¬êµ¬ì„± + ì •ê·œí™”</td>
</tr>
</tbody>
</table>
<h3 id="83">8.3 í”í•œ í•¨ì •<a class="header-link" href="#83" title="Permanent link">&para;</a></h3>
<p><strong>1. ì˜ëª»ëœ reduction ì‚¬ìš©</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Bad: Default reduction=&#39;mean&#39; might not be what you want</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Good: Explicit reduction</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>  <span class="c1"># or &#39;sum&#39;, &#39;none&#39;</span>
</code></pre></div>

<p><strong>2. í™œì„±í™” ì ìš© ìŠê¸°</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Bad: Using BCELoss with raw logits</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Raw logits</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># Wrong! BCELoss expects probabilities</span>

<span class="c1"># Good: Use BCEWithLogitsLoss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Or apply sigmoid first</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div>

<p><strong>3. ì˜ëª»ëœ íƒ€ê²Ÿ í˜•ì‹</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># CrossEntropyLoss expects class indices, not one-hot</span>
<span class="c1"># Bad</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>  <span class="c1"># One-hot</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># Error!</span>

<span class="c1"># Good</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Class indices</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div>

<p><strong>4. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì•ˆí•¨</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Bad: Ignoring class imbalance (e.g., 95% class 0, 5% class 1)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Good: Use class weights</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">])</span>  <span class="c1"># Weight minority class higher</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">class_weights</span><span class="p">)</span>

<span class="c1"># Or use FocalLoss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">FocalLoss</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
</code></pre></div>

<p><strong>5. ì˜ëª»ëœ ì†ì‹¤ ìŠ¤ì¼€ì¼ë§</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Bad: Losses of different magnitudes</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>  <span class="c1"># loss1 ~ 0.01, loss2 ~ 100.0</span>

<span class="c1"># Good: Normalize or weight appropriately</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">loss2</span>
<span class="c1"># Or use learnable weights</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">*</span> <span class="n">loss1</span> <span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="n">loss2</span>
</code></pre></div>

<h3 id="84">8.4 ë””ë²„ê¹… íŒ<a class="header-link" href="#84" title="Permanent link">&para;</a></h3>
<p><strong>1. ì†ì‹¤ ê°’ í™•ì¸</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Monitor loss statistics</span>
<span class="k">def</span><span class="w"> </span><span class="nf">check_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Loss&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is NaN!&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is Inf!&quot;</span>
    <span class="k">assert</span> <span class="n">loss</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is negative!&quot;</span>

<span class="c1"># Use in training</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">check_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>2. ì†ì‹¤ ê²½ê´€ ì‹œê°í™”</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Track loss over training</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># ... training ...</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training Loss Curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>  <span class="c1"># Use log scale if loss varies widely</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p><strong>3. ê¸°ì¤€ì„ ê³¼ ë¹„êµ</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Sanity check: random predictions should give expected loss</span>
<span class="c1"># For CrossEntropyLoss with C classes: expected loss â‰ˆ log(C)</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">random_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">random_target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="p">(</span><span class="mi">100</span><span class="p">,))</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">random_pred</span><span class="p">,</span> <span class="n">random_target</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Random Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected: </span><span class="si">{</span><span class="n">expected</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># Should be â‰ˆ 2.3026 for 10 classes</span>
</code></pre></div>

<p><strong>4. ê¸°ìš¸ê¸° íë¦„ í™•ì¸</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Check if gradients are flowing</span>
<span class="k">def</span><span class="w"> </span><span class="nf">check_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: grad norm = </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">grad_norm</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  WARNING: Zero gradient!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: No gradient!&quot;</span><span class="p">)</span>

<span class="c1"># After backward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">check_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>

<h3 id="85">8.5 ì†ì‹¤ í•¨ìˆ˜ê°€ ìˆ˜ë ´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥<a class="header-link" href="#85" title="Permanent link">&para;</a></h3>
<p><strong>ì˜ˆì œ: ìˆ˜ë ´ ì†ë„ ë¹„êµ</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Simple model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimpleNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_with_loss</span><span class="p">(</span><span class="n">criterion</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train and return loss history&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNet</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="c1"># Dummy data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">losses</span>

<span class="c1"># Compare different losses</span>
<span class="n">mse_losses</span> <span class="o">=</span> <span class="n">train_with_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">())</span>
<span class="n">mae_losses</span> <span class="o">=</span> <span class="n">train_with_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">())</span>
<span class="n">huber_losses</span> <span class="o">=</span> <span class="n">train_with_loss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mse_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mae_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">huber_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Huber&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Convergence Speed Comparison&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;convergence_comparison.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="_2">ì—°ìŠµ ë¬¸ì œ<a class="header-link" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="1-tversky">ì—°ìŠµ ë¬¸ì œ 1: Tversky ì†ì‹¤ êµ¬í˜„<a class="header-link" href="#1-tversky" title="Permanent link">&para;</a></h3>
<p>Tversky ì†ì‹¤ì€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ Dice ì†ì‹¤ì˜ ì¼ë°˜í™”ë¡œ, ê±°ì§“ ì–‘ì„±/ìŒì„± íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<div class="highlight"><pre><span></span><code>Tversky = (TP) / (TP + Î±*FP + Î²*FN)

where:
<span class="k">-</span> TP = true positives
<span class="k">-</span> FP = false positives
<span class="k">-</span> FN = false negatives
<span class="k">-</span> Î±, Î² control the trade-off (typically Î± + Î² = 1)
</code></pre></div>

<p><strong>ê³¼ì œ:</strong>
1. <code>TverskyLoss</code>ë¥¼ PyTorch <code>nn.Module</code>ë¡œ êµ¬í˜„í•˜ê¸°
2. Î±=0.3, Î²=0.7ë¡œ í…ŒìŠ¤íŠ¸(ê±°ì§“ ìŒì„± ê°ì†Œì— ì§‘ì¤‘)
3. ì´ì§„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‘ì—…ì—ì„œ DiceLossì™€ ë¹„êµ</p>
<p><strong>ìŠ¤íƒ€í„° ì½”ë“œ:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TverskyLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">smooth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># TODO: Initialize parameters</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="c1"># TODO: Implement Tversky loss</span>
        <span class="c1"># Hint: Calculate TP, FP, FN</span>
        <span class="k">pass</span>
</code></pre></div>

<h3 id="2">ì—°ìŠµ ë¬¸ì œ 2: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì§€ê°ì  ì†ì‹¤<a class="header-link" href="#2" title="Permanent link">&para;</a></h3>
<p>ì‚¬ì „ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ì˜ ì—¬ëŸ¬ ë ˆì´ì–´(ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼)ì—ì„œ íŠ¹ì§•ì„ ë¹„êµí•˜ëŠ” ì§€ê°ì  ì†ì‹¤ì„ êµ¬í˜„í•©ë‹ˆë‹¤.</p>
<p><strong>ê³¼ì œ:</strong>
1. VGG16ì˜ <code>['relu2_2', 'relu3_3', 'relu4_3']</code> ë ˆì´ì–´ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
2. ê° ë ˆì´ì–´ì—ì„œ ì˜ˆì¸¡ íŠ¹ì§•ê³¼ íƒ€ê²Ÿ íŠ¹ì§• ê°„ MSE ê³„ì‚°
3. í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë¡œ ì†ì‹¤ ê²°í•©
4. ì´ë¯¸ì§€ ì¬êµ¬ì„± ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸</p>
<p><strong>ì§ˆë¬¸:</strong>
- ë‹¤ì–‘í•œ ë ˆì´ì–´ê°€ ì†ì‹¤ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ë‚˜ìš”?
- ì´ˆê¸° ë ˆì´ì–´ë§Œ ì‚¬ìš©í•  ë•Œì™€ ê¹Šì€ ë ˆì´ì–´ë§Œ ì‚¬ìš©í•  ë•Œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ë‚˜ìš”?</p>
<h3 id="3">ì—°ìŠµ ë¬¸ì œ 3: ì ì‘ì  ì†ì‹¤ ê· í˜•<a class="header-link" href="#3" title="Permanent link">&para;</a></h3>
<p>ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìœ„í•œ ì ì‘ì  ì†ì‹¤ ê· í˜• ìŠ¤í‚´ì„ êµ¬í˜„í•©ë‹ˆë‹¤.</p>
<p><strong>ê³¼ì œ:</strong>
ì„¸ ê°€ì§€ ì‘ì—…ìœ¼ë¡œ ììœ¨ ì£¼í–‰ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ìˆìŠµë‹ˆë‹¤:
1. ì˜ë¯¸ì  ì„¸ê·¸ë©˜í…Œì´ì…˜(CrossEntropyLoss)
2. ê¹Šì´ ì¶”ì •(L1Loss)
3. ê°ì²´ ê²€ì¶œ(FocalLoss)</p>
<p>êµ¬í˜„:
1. ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ê°€ì¤‘ì¹˜(7.1ì ˆ)
2. í›ˆë ¨ ì¤‘ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì¶”ì 
3. í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ ê°€ì¤‘ì¹˜ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì‹œê°í™”</p>
<p><strong>ìŠ¤íƒ€í„° ì½”ë“œ:</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultiTaskModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># TODO: Define three task heads</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># TODO: Return predictions for all three tasks</span>
        <span class="k">pass</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># TODO:</span>
    <span class="c1"># 1. Forward pass</span>
    <span class="c1"># 2. Compute three losses</span>
    <span class="c1"># 3. Apply uncertainty weighting</span>
    <span class="c1"># 4. Backward and optimize</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>ì§ˆë¬¸:</strong>
- ì–´ë–¤ ì‘ì—…ì´ ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë°›ë‚˜ìš”? ì™œ ê·¸ëŸ´ê¹Œìš”?
- ê°€ì¤‘ì¹˜ê°€ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì•ˆì •í™”ë˜ë‚˜ìš”?
- ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ë¥´ê²Œ ì´ˆê¸°í™”í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?</p>
<hr />
<h2 id="_3">ì°¸ê³  ìë£Œ<a class="header-link" href="#_3" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>ì†ì‹¤ í•¨ìˆ˜ ì„œë² ì´:</strong></li>
<li>
<p>Janocha, K., &amp; Czarnecki, W. M. (2017). "On Loss Functions for Deep Neural Networks in Classification"</p>
</li>
<li>
<p><strong>íšŒê·€ ì†ì‹¤:</strong></p>
</li>
<li>
<p>Huber, P. J. (1964). "Robust Estimation of a Location Parameter"</p>
</li>
<li>
<p><strong>ë¶„ë¥˜ ì†ì‹¤:</strong></p>
</li>
<li>Lin, T. Y., et al. (2017). "Focal Loss for Dense Object Detection" (RetinaNet)</li>
<li>
<p>MÃ¼ller, R., et al. (2019). "When Does Label Smoothing Help?"</p>
</li>
<li>
<p><strong>ë©”íŠ¸ë¦­ í•™ìŠµ:</strong></p>
</li>
<li>Schroff, F., et al. (2015). "FaceNet: A Unified Embedding for Face Recognition and Clustering" (Triplet Loss)</li>
<li>Chopra, S., et al. (2005). "Learning a Similarity Metric Discriminatively" (Contrastive Loss)</li>
<li>
<p>Chen, T., et al. (2020). "A Simple Framework for Contrastive Learning of Visual Representations" (SimCLR, NT-Xent)</p>
</li>
<li>
<p><strong>ì„¸ê·¸ë©˜í…Œì´ì…˜ ì†ì‹¤:</strong></p>
</li>
<li>Milletari, F., et al. (2016). "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation" (Dice Loss)</li>
<li>
<p>Rezatofighi, H., et al. (2019). "Generalized Intersection over Union" (GIoU)</p>
</li>
<li>
<p><strong>ìƒì„± ëª¨ë¸:</strong></p>
</li>
<li>Goodfellow, I., et al. (2014). "Generative Adversarial Networks"</li>
<li>Kingma, D. P., &amp; Welling, M. (2013). "Auto-Encoding Variational Bayes"</li>
<li>
<p>Johnson, J., et al. (2016). "Perceptual Losses for Real-Time Style Transfer and Super-Resolution"</p>
</li>
<li>
<p><strong>ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ:</strong></p>
</li>
<li>Kendall, A., et al. (2018). "Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics"</li>
<li>
<p>Chen, Z., et al. (2018). "GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks"</p>
</li>
<li>
<p><strong>PyTorch ë¬¸ì„œ:</strong></p>
</li>
<li>https://pytorch.org/docs/stable/nn.html#loss-functions</li>
<li>
<p>https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html</p>
</li>
<li>
<p><strong>ì¶”ê°€ ë¦¬ì†ŒìŠ¤:</strong></p>
</li>
<li>Murphy, K. P. (2022). "Probabilistic Machine Learning: An Introduction" (Chapter on Loss Functions)</li>
<li>Goodfellow, I., et al. (2016). "Deep Learning" (Chapter 8: Optimization for Training Deep Models)</li>
</ol>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Deep_Learning/23_Training_Optimization.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">23. í•™ìŠµ ìµœì í™”</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Deep_Learning/25_Optimizers.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">25. ì˜µí‹°ë§ˆì´ì €(Optimizers)</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}