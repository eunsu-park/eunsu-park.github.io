{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>26. ì •ê·œí™” ë ˆì´ì–´(Normalization Layers) - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Deep_Learning/">Deep Learning</a>
    <span class="separator">/</span>
    <span class="current">26. ì •ê·œí™” ë ˆì´ì–´(Normalization Layers)</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>26. ì •ê·œí™” ë ˆì´ì–´(Normalization Layers)</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Deep_Learning/25_Optimizers.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">25. ì˜µí‹°ë§ˆì´ì €(Optimizers)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Deep_Learning/27_TensorBoard.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">27. TensorBoard ì‹œê°í™”</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">í•™ìŠµ ëª©í‘œ</a></li>
<li><a href="#1">1. ì™œ ì •ê·œí™”ê°€ í•„ìš”í•œê°€?</a><ul>
<li><a href="#11-internal-covariate-shift">1.1 ë¬¸ì œ: ë‚´ë¶€ ê³µë³€ëŸ‰ ë³€í™”(Internal Covariate Shift)</a></li>
<li><a href="#12-loss-landscape-smoothing">1.2 í˜„ëŒ€ì  ì´í•´: ì†ì‹¤ í•¨ìˆ˜ ì§€í˜• í‰í™œí™”(Loss Landscape Smoothing)</a></li>
<li><a href="#13-normalization-axes">1.3 ì •ê·œí™” ì¶•(Normalization Axes)</a></li>
</ul>
</li>
<li><a href="#2-batch-normalization">2. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)</a><ul>
<li><a href="#21">2.1 í•µì‹¬ ê°œë…</a></li>
<li><a href="#22-vs">2.2 í›ˆë ¨ ëª¨ë“œ vs ì¶”ë¡  ëª¨ë“œ</a></li>
<li><a href="#23-batchnorm">2.3 BatchNormì„ ì–´ë””ì— ë°°ì¹˜í• ê¹Œ?</a></li>
<li><a href="#24-pytorch-batchnorm">2.4 PyTorch BatchNorm</a></li>
<li><a href="#25">2.5 ìˆ˜ë™ êµ¬í˜„</a></li>
<li><a href="#26-batchnorm">2.6 BatchNormì˜ í•œê³„</a></li>
</ul>
</li>
<li><a href="#3-layer-normalization">3. ë ˆì´ì–´ ì •ê·œí™”(Layer Normalization)</a><ul>
<li><a href="#31">3.1 í•µì‹¬ ê°œë…</a></li>
<li><a href="#32-layernorm">3.2 ì™œ íŠ¸ëœìŠ¤í¬ë¨¸ì— LayerNormì„ ì‚¬ìš©í•˜ëŠ”ê°€?</a></li>
<li><a href="#33-pytorch-layernorm">3.3 PyTorch LayerNorm</a></li>
<li><a href="#34">3.4 ìˆ˜ë™ êµ¬í˜„</a></li>
<li><a href="#35">3.5 ì‚¬ìš© ì‚¬ë¡€</a></li>
</ul>
</li>
<li><a href="#4-group-normalization">4. ê·¸ë£¹ ì •ê·œí™”(Group Normalization)</a><ul>
<li><a href="#41">4.1 í•µì‹¬ ê°œë…</a></li>
<li><a href="#42">4.2 ê³µì‹</a></li>
<li><a href="#43-pytorch-groupnorm">4.3 PyTorch GroupNorm</a></li>
<li><a href="#44">4.4 ê·¸ë£¹ ìˆ˜ ì„ íƒí•˜ê¸°</a></li>
<li><a href="#45">4.5 ì‚¬ìš© ì‚¬ë¡€</a></li>
</ul>
</li>
<li><a href="#5-instance-normalization">5. ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”(Instance Normalization)</a><ul>
<li><a href="#51">5.1 í•µì‹¬ ê°œë…</a></li>
<li><a href="#52">5.2 ê³µì‹</a></li>
<li><a href="#53-pytorch-instancenorm">5.3 PyTorch InstanceNorm</a></li>
<li><a href="#54-instance-normalization">5.4 ì™œ Instance Normalizationì„ ì‚¬ìš©í•˜ëŠ”ê°€?</a></li>
<li><a href="#55">5.5 ì‚¬ìš© ì‚¬ë¡€</a></li>
</ul>
</li>
<li><a href="#6-rmsnorm-root-mean-square-normalization">6. RMSNorm (Root Mean Square Normalization)</a><ul>
<li><a href="#61">6.1 í•µì‹¬ ê°œë…</a></li>
<li><a href="#62-rmsnorm">6.2 ì™œ RMSNormì„ ì‚¬ìš©í•˜ëŠ”ê°€?</a></li>
<li><a href="#63">6.3 ìˆ˜ë™ êµ¬í˜„</a></li>
<li><a href="#64-layernorm">6.4 LayerNormê³¼ ë¹„êµ</a></li>
<li><a href="#65-llama-rmsnorm">6.5 LLaMAì—ì„œì˜ RMSNorm</a></li>
<li><a href="#66">6.6 ì‚¬ìš© ì‚¬ë¡€</a></li>
</ul>
</li>
<li><a href="#7">7. ê¸°íƒ€ ì •ê·œí™” ê¸°ë²•</a><ul>
<li><a href="#71-weight-normalization">7.1 ê°€ì¤‘ì¹˜ ì •ê·œí™”(Weight Normalization)</a></li>
<li><a href="#72-spectral-normalization">7.2 ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™”(Spectral Normalization)</a></li>
<li><a href="#73-adaptive-instance-normalization-adain">7.3 ì ì‘ì  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”(Adaptive Instance Normalization, AdaIN)</a></li>
<li><a href="#74">7.4 ë¹„êµ í‘œ</a></li>
</ul>
</li>
<li><a href="#8">8. ì¢…í•© ë¹„êµ</a><ul>
<li><a href="#81">8.1 ì‹œê°ì  ë¹„êµ</a></li>
<li><a href="#82">8.2 ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ?</a><ul>
<li><a href="#_2">ê²°ì • íŠ¸ë¦¬</a></li>
<li><a href="#_3">ì•„í‚¤í…ì²˜ë³„ ê¶Œì¥ ì‚¬í•­</a></li>
</ul>
</li>
<li><a href="#83">8.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬</a></li>
</ul>
</li>
<li><a href="#9">9. ì‹¤ìš©ì ì¸ íŒ</a><ul>
<li><a href="#91">9.1 Î³ì™€ Î²ì˜ ì´ˆê¸°í™”</a></li>
<li><a href="#92">9.2 ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì™€ì˜ ìƒí˜¸ì‘ìš©</a></li>
<li><a href="#93">9.3 ì •ê·œí™”ì™€ í•™ìŠµë¥ </a></li>
<li><a href="#94">9.4 ì¼ë°˜ì ì¸ ë²„ê·¸ì™€ í•¨ì •</a><ul>
<li><a href="#1-modeleval">ë²„ê·¸ 1: model.eval() ìŠê¸°</a></li>
<li><a href="#2">ë²„ê·¸ 2: ì˜ëª»ëœ ì°¨ì› ìˆœì„œ</a></li>
<li><a href="#3-groupnorm">ë²„ê·¸ 3: í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ì±„ë„ì„ ê°€ì§„ GroupNorm</a></li>
<li><a href="#4-batch_size-1-batchnorm">ë²„ê·¸ 4: batch_size = 1ì¸ BatchNorm</a></li>
<li><a href="#5-batchnorm">ë²„ê·¸ 5: ê³ ì • ë° í›ˆë ¨ ê°€ëŠ¥ BatchNorm í˜¼í•©</a></li>
</ul>
</li>
<li><a href="#95">9.5 ëª¨ë²” ì‚¬ë¡€ ì²´í¬ë¦¬ìŠ¤íŠ¸</a></li>
</ul>
</li>
<li><a href="#_4">ì—°ìŠµ ë¬¸ì œ</a><ul>
<li><a href="#1_1">ì—°ìŠµ ë¬¸ì œ 1: ì •ê·œí™” ë°©ë²• êµ¬í˜„ ë° ë¹„êµ</a></li>
<li><a href="#2-rmsnorm-vs-layernorm">ì—°ìŠµ ë¬¸ì œ 2: íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ RMSNorm vs LayerNorm</a></li>
<li><a href="#3">ì—°ìŠµ ë¬¸ì œ 3: ìŠ¤íƒ€ì¼ ì „ì´ë¥¼ ìœ„í•œ ì ì‘ì  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”</a></li>
</ul>
</li>
<li><a href="#_5">ì°¸ê³  ìë£Œ</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <p><a href="./25_Optimizers.md">ì´ì „: ì˜µí‹°ë§ˆì´ì €</a> | <a href="./27_TensorBoard.md">ë‹¤ìŒ: TensorBoard ì‹œê°í™”</a></p>
<hr />
<h1 id="26-normalization-layers">26. ì •ê·œí™” ë ˆì´ì–´(Normalization Layers)<a class="header-link" href="#26-normalization-layers" title="Permanent link">&para;</a></h1>
<h2 id="_1">í•™ìŠµ ëª©í‘œ<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>ë”¥ëŸ¬ë‹ì—ì„œ ì •ê·œí™”ì˜ í•„ìš”ì„±ê³¼ ì†ì‹¤ í•¨ìˆ˜ ì§€í˜•ì„ ë¶€ë“œëŸ½ê²Œ ë§Œë“œëŠ” ì›ë¦¬ ì´í•´í•˜ê¸°</li>
<li>ë°°ì¹˜ ì •ê·œí™”, ë ˆì´ì–´ ì •ê·œí™”, ê·¸ë£¹ ì •ê·œí™”ì™€ ê°ê°ì˜ ì‚¬ìš© ì‚¬ë¡€ ë§ˆìŠ¤í„°í•˜ê¸°</li>
<li>í˜„ëŒ€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì—ì„œ ì„ í˜¸ë˜ëŠ” RMSNorm í•™ìŠµí•˜ê¸°</li>
<li>ì •ê·œí™” ë ˆì´ì–´ë¥¼ ì²˜ìŒë¶€í„° êµ¬í˜„í•˜ê³  ê³„ì‚°ìƒì˜ ì˜ë¯¸ ì´í•´í•˜ê¸°</li>
<li>ì•„í‚¤í…ì²˜ì™€ ë°°ì¹˜ í¬ê¸° ì œì•½ì— ë”°ë¼ ì ì ˆí•œ ì •ê·œí™” ê¸°ë²• ì ìš©í•˜ê¸°</li>
</ul>
<hr />
<h2 id="1">1. ì™œ ì •ê·œí™”ê°€ í•„ìš”í•œê°€?<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11-internal-covariate-shift">1.1 ë¬¸ì œ: ë‚´ë¶€ ê³µë³€ëŸ‰ ë³€í™”(Internal Covariate Shift)<a class="header-link" href="#11-internal-covariate-shift" title="Permanent link">&para;</a></h3>
<p><strong>ë‚´ë¶€ ê³µë³€ëŸ‰ ë³€í™”</strong>ëŠ” í›ˆë ¨ ì¤‘ ë„¤íŠ¸ì›Œí¬ í™œì„±í™”(activation) ë¶„í¬ì˜ ë³€í™”ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ˆê¸° ë ˆì´ì–´ì˜ íŒŒë¼ë¯¸í„°ê°€ ë³€ê²½ë˜ë©´ í›„ë°˜ ë ˆì´ì–´ì˜ ì…ë ¥ì´ ë³€í™”í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ì ì‘í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<p><strong>ì›ë˜ ë™ê¸°</strong> (Ioffe &amp; Szegedy, 2015):
- ë ˆì´ì–´ ê°„ í™œì„±í™” ë¶„í¬ ì•ˆì •í™”
- ê° ë ˆì´ì–´ê°€ ë” ì•ˆì •ì ì¸ ì…ë ¥ ë¶„í¬ì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨
- ë°œì‚° ì—†ì´ ë” ë†’ì€ í•™ìŠµë¥  ì‚¬ìš© ê°€ëŠ¥</p>
<h3 id="12-loss-landscape-smoothing">1.2 í˜„ëŒ€ì  ì´í•´: ì†ì‹¤ í•¨ìˆ˜ ì§€í˜• í‰í™œí™”(Loss Landscape Smoothing)<a class="header-link" href="#12-loss-landscape-smoothing" title="Permanent link">&para;</a></h3>
<p>ìµœê·¼ ì—°êµ¬(Santurkar et al., 2018)ëŠ” ì •ê·œí™”ì˜ ì£¼ìš” ì´ì ì´ <strong>ì†ì‹¤ í•¨ìˆ˜ ì§€í˜• í‰í™œí™”</strong>ë¼ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤:</p>
<div class="highlight"><pre><span></span><code>ì •ê·œí™” ì—†ìŒ:                   ì •ê·œí™” ìˆìŒ:

    |\                              /\
    | \        /\                  /  \
    |  \  /\  /  \                /    \
    |___\/  \/____\__           /______\_____

    ê±°ì¹ ê³  ë¶ˆê·œì¹™í•œ               ë” ë¶€ë“œëŸ½ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ
    ê¸°ìš¸ê¸°                        ê¸°ìš¸ê¸°
</code></pre></div>

<p><strong>ì´ì </strong>:
1. <strong>ë” ë¹ ë¥¸ ìˆ˜ë ´</strong> â€” ë¶€ë“œëŸ¬ìš´ ê¸°ìš¸ê¸°ë¡œ ë” í° ìŠ¤í… ê°€ëŠ¥
2. <strong>ë” ë†’ì€ í•™ìŠµë¥ </strong> â€” ë°œì‚° ìœ„í—˜ ê°ì†Œ
3. <strong>ì •ê·œí™” íš¨ê³¼</strong> â€” ë°°ì¹˜ í†µê³„ì˜ ë…¸ì´ì¦ˆê°€ ì•”ë¬µì  ì •ê·œí™” ì—­í• 
4. <strong>ì´ˆê¸°í™” ë¯¼ê°ë„ ê°ì†Œ</strong> â€” ì‹ ì¤‘í•œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì— ëŒ€í•œ ì˜ì¡´ë„ ê°ì†Œ</p>
<h3 id="13-normalization-axes">1.3 ì •ê·œí™” ì¶•(Normalization Axes)<a class="header-link" href="#13-normalization-axes" title="Permanent link">&para;</a></h3>
<p>ë‹¤ì–‘í•œ ì •ê·œí™” ë°©ë²•ì€ ì„œë¡œ ë‹¤ë¥¸ ì°¨ì›ì—ì„œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:</p>
<div class="highlight"><pre><span></span><code>ì…ë ¥ í…ì„œ í˜•íƒœ: (N, C, H, W)
N = ë°°ì¹˜ í¬ê¸°
C = ì±„ë„
H, W = ê³µê°„ ì°¨ì›

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë°°ì¹˜ ì •ê·œí™”:       Nì— ëŒ€í•´ ì •ê·œí™”      ê° (C, H, W)ì— ëŒ€í•´  â”‚
â”‚  ë ˆì´ì–´ ì •ê·œí™”:     C,H,Wì— ëŒ€í•´ ì •ê·œí™”  ê° Nì— ëŒ€í•´          â”‚
â”‚  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”:   H,Wì— ëŒ€í•´ ì •ê·œí™”    ê° (N, C)ì— ëŒ€í•´     â”‚
â”‚  ê·¸ë£¹ ì •ê·œí™”:       C/G,H,Wì— ëŒ€í•´ ì •ê·œí™” ê° (N, G)ì— ëŒ€í•´   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<hr />
<h2 id="2-batch-normalization">2. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)<a class="header-link" href="#2-batch-normalization" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 í•µì‹¬ ê°œë…<a class="header-link" href="#21" title="Permanent link">&para;</a></h3>
<p><strong>ë°°ì¹˜ ì •ê·œí™”</strong>(BatchNorm)ëŠ” ê° íŠ¹ì„±ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì›ì—ì„œ í™œì„±í™”ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.</p>
<p><strong>ì•Œê³ ë¦¬ì¦˜</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="err">ì…ë ¥</span><span class="o">:</span><span class="w"> </span><span class="err">ë¯¸ë‹ˆë°°ì¹˜</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">{</span><span class="n">xâ‚</span><span class="o">,</span><span class="w"> </span><span class="o">...,</span><span class="w"> </span><span class="n">xâ‚˜</span><span class="o">}</span>
<span class="err">íŒŒë¼ë¯¸í„°</span><span class="o">:</span><span class="w"> </span><span class="err">Î³</span><span class="w"> </span><span class="o">(</span><span class="err">ìŠ¤ì¼€ì¼</span><span class="o">),</span><span class="w"> </span><span class="err">Î²</span><span class="w"> </span><span class="o">(</span><span class="err">ì‹œí”„íŠ¸</span><span class="o">)</span><span class="w"> </span><span class="err">â€”</span><span class="w"> </span><span class="err">í•™ìŠµ</span><span class="w"> </span><span class="err">ê°€ëŠ¥</span>

<span class="mi">1</span><span class="o">.</span><span class="w"> </span><span class="err">ë°°ì¹˜</span><span class="w"> </span><span class="err">í†µê³„</span><span class="w"> </span><span class="err">ê³„ì‚°</span><span class="o">:</span>
<span class="w">   </span><span class="err">Î¼</span><span class="n">_B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="o">)</span><span class="w"> </span><span class="err">Î£</span><span class="w"> </span><span class="n">xáµ¢</span><span class="w">                    </span><span class="err">#</span><span class="w"> </span><span class="err">í‰ê· </span>
<span class="w">   </span><span class="err">ÏƒÂ²</span><span class="n">_B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="o">)</span><span class="w"> </span><span class="err">Î£</span><span class="w"> </span><span class="o">(</span><span class="n">xáµ¢</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">Î¼</span><span class="n">_B</span><span class="o">)</span><span class="err">Â²</span><span class="w">          </span><span class="err">#</span><span class="w"> </span><span class="err">ë¶„ì‚°</span>

<span class="mi">2</span><span class="o">.</span><span class="w"> </span><span class="err">ì •ê·œí™”</span><span class="o">:</span>
<span class="w">   </span><span class="n">x</span><span class="err">Ì‚áµ¢</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">(</span><span class="n">xáµ¢</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">Î¼</span><span class="n">_B</span><span class="o">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">âˆš</span><span class="o">(</span><span class="err">ÏƒÂ²</span><span class="n">_B</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">Îµ</span><span class="o">)</span><span class="w">       </span><span class="err">#</span><span class="w"> </span><span class="err">ÎµëŠ”</span><span class="w"> </span><span class="err">ìˆ˜ì¹˜</span><span class="w"> </span><span class="err">ì•ˆì •ì„±ì„</span><span class="w"> </span><span class="err">ìœ„í•¨</span>

<span class="mi">3</span><span class="o">.</span><span class="w"> </span><span class="err">ìŠ¤ì¼€ì¼</span><span class="w"> </span><span class="err">ë°</span><span class="w"> </span><span class="err">ì‹œí”„íŠ¸</span><span class="o">:</span>
<span class="w">   </span><span class="n">yáµ¢</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">Î³</span><span class="w"> </span><span class="n">x</span><span class="err">Ì‚áµ¢</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">Î²</span><span class="w">                        </span><span class="err">#</span><span class="w"> </span><span class="err">í•™ìŠµ</span><span class="w"> </span><span class="err">ê°€ëŠ¥í•œ</span><span class="w"> </span><span class="err">ë³€í™˜</span>
</code></pre></div>

<p><strong>ì™œ ìŠ¤ì¼€ì¼ê³¼ ì‹œí”„íŠ¸ê°€ í•„ìš”í•œê°€?</strong> ë„¤íŠ¸ì›Œí¬ê°€ í•„ìš”í•œ ê²½ìš° ì •ê·œí™”ë¥¼ ì·¨ì†Œí•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: <code>Î³ = âˆšÏƒÂ²</code>, <code>Î² = Î¼</code>ë¡œ ì›ë˜ ë¶„í¬ ë³µì›).</p>
<h3 id="22-vs">2.2 í›ˆë ¨ ëª¨ë“œ vs ì¶”ë¡  ëª¨ë“œ<a class="header-link" href="#22-vs" title="Permanent link">&para;</a></h3>
<p><strong>í›ˆë ¨</strong>:
- ë°°ì¹˜ í†µê³„ ì‚¬ìš© (Î¼_B, ÏƒÂ²_B)
- ì¶”ë¡ ì„ ìœ„í•œ ì´ë™ í‰ê·  ì—…ë°ì´íŠ¸:
  <code>running_mean = momentum Ã— running_mean + (1 - momentum) Ã— Î¼_B
  running_var = momentum Ã— running_var + (1 - momentum) Ã— ÏƒÂ²_B</code></p>
<p><strong>ì¶”ë¡ </strong>:
- ì´ë™ í†µê³„ ì‚¬ìš© (ê³ ì •ë¨)
- í˜„ì¬ ë°°ì¹˜ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># í›ˆë ¨ ëª¨ë“œ</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">bn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ë°°ì¹˜ í†µê³„ ì‚¬ìš©</span>

<span class="c1"># ì¶”ë¡  ëª¨ë“œ</span>
<span class="n">bn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ì´ë™ í†µê³„ ì‚¬ìš©</span>
</code></pre></div>

<h3 id="23-batchnorm">2.3 BatchNormì„ ì–´ë””ì— ë°°ì¹˜í• ê¹Œ?<a class="header-link" href="#23-batchnorm" title="Permanent link">&para;</a></h3>
<p><strong>ì˜µì…˜ 1: í™œì„±í™” í•¨ìˆ˜ ì´í›„</strong> (ì›ë³¸ ë…¼ë¬¸)</p>
<div class="highlight"><pre><span></span><code>Linear/Conv â†’ Activation â†’ BatchNorm
</code></pre></div>

<p><strong>ì˜µì…˜ 2: í™œì„±í™” í•¨ìˆ˜ ì´ì „</strong> (ì¼ë°˜ì ì¸ ê´€í–‰)</p>
<div class="highlight"><pre><span></span><code>Linear/Conv â†’ BatchNorm â†’ Activation
</code></pre></div>

<p><strong>í˜„ëŒ€ì  í•©ì˜</strong>: í™œì„±í™” í•¨ìˆ˜ ì´ì „ì´ ì‹¤ì œë¡œ ë” ì˜ ì‘ë™í•˜ë©°, íŠ¹íˆ ReLUì™€ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ ê·¸ë ‡ìŠµë‹ˆë‹¤.</p>
<h3 id="24-pytorch-batchnorm">2.4 PyTorch BatchNorm<a class="header-link" href="#24-pytorch-batchnorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># ì™„ì „ ì—°ê²° ë ˆì´ì–´ìš© (1D)</span>
<span class="n">bn1d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="c1"># í•©ì„±ê³± ë ˆì´ì–´ìš© (2D)</span>
<span class="n">bn2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="c1"># 3D í•©ì„±ê³±ìš© (ë¹„ë””ì˜¤, ë³¼ë¥¨ ë°ì´í„°)</span>
<span class="n">bn3d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># ì˜ˆì œ CNN ë¸”ë¡</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ConvBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>  <span class="c1"># (N, C, H, W)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([32, 64, 224, 224])</span>
</code></pre></div>

<h3 id="25">2.5 ìˆ˜ë™ êµ¬í˜„<a class="header-link" href="#25" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">BatchNorm2dManual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>

        <span class="c1"># í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>

        <span class="c1"># ì´ë™ í†µê³„ (ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì§€ ì•ŠìŒ)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_var&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;num_batches_tracked&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x í˜•íƒœ: (N, C, H, W)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># ë°°ì¹˜ í†µê³„ ê³„ì‚°</span>
            <span class="c1"># ê° ì±„ë„ Cì— ëŒ€í•´ (N, H, W)ì—ì„œ í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># í˜•íƒœ: (C,)</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># í˜•íƒœ: (C,)</span>

            <span class="c1"># ì´ë™ í†µê³„ ì—…ë°ì´íŠ¸</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="n">mean</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="n">var</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># ì´ë™ í†µê³„ ì‚¬ìš©</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_mean</span>
            <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">running_var</span>

        <span class="c1"># ì •ê·œí™”</span>
        <span class="c1"># ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ ìœ„í•´ ì¬êµ¬ì„±: (1, C, 1, 1)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">x_norm</span> <span class="o">+</span> <span class="n">beta</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># í…ŒìŠ¤íŠ¸</span>
<span class="n">manual_bn</span> <span class="o">=</span> <span class="n">BatchNorm2dManual</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">pytorch_bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

<span class="c1"># í›ˆë ¨ ëª¨ë“œ</span>
<span class="n">manual_bn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">pytorch_bn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">out_manual</span> <span class="o">=</span> <span class="n">manual_bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">out_pytorch</span> <span class="o">=</span> <span class="n">pytorch_bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì¶œë ¥ í˜•íƒœ: </span><span class="si">{</span><span class="n">out_manual</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;í‰ê· ì´ 0ì— ê°€ê¹Œì›€: </span><span class="si">{</span><span class="n">out_manual</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;í‘œì¤€í¸ì°¨ê°€ 1ì— ê°€ê¹Œì›€: </span><span class="si">{</span><span class="n">out_manual</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="26-batchnorm">2.6 BatchNormì˜ í•œê³„<a class="header-link" href="#26-batchnorm" title="Permanent link">&para;</a></h3>
<p><strong>1. ë°°ì¹˜ í¬ê¸° ì˜ì¡´ì„±</strong>
- ì‘ì€ ë°°ì¹˜ â†’ ë…¸ì´ì¦ˆê°€ ë§ì€ í†µê³„ â†’ ì„±ëŠ¥ ì €í•˜
- ë°°ì¹˜ í¬ê¸° &lt; 8ì€ ë¬¸ì œê°€ ë¨</p>
<p><strong>2. ì‹œí€€ìŠ¤ ëª¨ë¸ (RNN)</strong>
- ë°°ì¹˜ ë‚´ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ ê¸¸ì´
- ì‹œê°„ ì°¨ì›ì— ì ìš©í•˜ê¸° ì–´ë ¤ì›€</p>
<p><strong>3. ë¶„ì‚° í›ˆë ¨</strong>
- ê° GPUê°€ ë‹¤ë¥¸ ë°°ì¹˜ë¥¼ ê°€ì§
- Sync BatchNorm í•„ìš” (ë¹„ìš©ì´ ë†’ìŒ)</p>
<p><strong>4. ì˜¨ë¼ì¸ í•™ìŠµ</strong>
- í•œ ë²ˆì— ë‹¨ì¼ ìƒ˜í”Œ
- ë°°ì¹˜ í†µê³„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ</p>
<hr />
<h2 id="3-layer-normalization">3. ë ˆì´ì–´ ì •ê·œí™”(Layer Normalization)<a class="header-link" href="#3-layer-normalization" title="Permanent link">&para;</a></h2>
<h3 id="31">3.1 í•µì‹¬ ê°œë…<a class="header-link" href="#31" title="Permanent link">&para;</a></h3>
<p><strong>ë ˆì´ì–´ ì •ê·œí™”</strong>(LayerNorm)ëŠ” ê° ìƒ˜í”Œì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ëª¨ë“  íŠ¹ì„±ì—ì„œ ì •ê·œí™”í•˜ë¯€ë¡œ ë°°ì¹˜ì— ë…ë¦½ì ì…ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="n">BatchNorm</span><span class="o">:</span><span class="w">  </span><span class="err">ê°</span><span class="w"> </span><span class="err">íŠ¹ì„±ì—</span><span class="w"> </span><span class="err">ëŒ€í•´</span><span class="w"> </span><span class="err">ìƒ˜í”Œ</span><span class="w"> </span><span class="err">ê°„</span><span class="w"> </span><span class="err">ì •ê·œí™”</span>
<span class="n">LayerNorm</span><span class="o">:</span><span class="w">  </span><span class="err">ê°</span><span class="w"> </span><span class="err">ìƒ˜í”Œì—</span><span class="w"> </span><span class="err">ëŒ€í•´</span><span class="w"> </span><span class="err">íŠ¹ì„±</span><span class="w"> </span><span class="err">ê°„</span><span class="w"> </span><span class="err">ì •ê·œí™”</span>
</code></pre></div>

<p><strong>ê³µì‹</strong>:</p>
<div class="highlight"><pre><span></span><code>ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œ xì— ëŒ€í•´:
  Î¼ = (1/D) Î£ xáµ¢                        # íŠ¹ì„± ê°„ í‰ê· 
  ÏƒÂ² = (1/D) Î£ (xáµ¢ - Î¼)Â²                # íŠ¹ì„± ê°„ ë¶„ì‚°
  xÌ‚áµ¢ = (xáµ¢ - Î¼) / âˆš(ÏƒÂ² + Îµ)             # ì •ê·œí™”
  yáµ¢ = Î³ xÌ‚áµ¢ + Î²                         # ìŠ¤ì¼€ì¼ ë° ì‹œí”„íŠ¸
</code></pre></div>

<h3 id="32-layernorm">3.2 ì™œ íŠ¸ëœìŠ¤í¬ë¨¸ì— LayerNormì„ ì‚¬ìš©í•˜ëŠ”ê°€?<a class="header-link" href="#32-layernorm" title="Permanent link">&para;</a></h3>
<p><strong>ì¥ì </strong>:
1. <strong>ë°°ì¹˜ ë…ë¦½ì </strong> â€” ë°°ì¹˜ í¬ê¸° = 1ì—ì„œ ì‘ë™
2. <strong>ì‹œí€€ìŠ¤ ê¸¸ì´ ë…ë¦½ì </strong> â€” ê° ìœ„ì¹˜ê°€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì •ê·œí™”ë¨
3. <strong>ì¶”ë¡  ì‹œ ê²°ì •ë¡ ì </strong> â€” ì´ë™ í†µê³„ ë¶ˆí•„ìš”</p>
<p><strong>íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜</strong>:</p>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pre-Norm (í˜„ëŒ€):                        â”‚
â”‚    x â†’ LayerNorm â†’ Attention â†’ Add(x)   â”‚
â”‚    x â†’ LayerNorm â†’ FFN â†’ Add(x)         â”‚
â”‚                                          â”‚
â”‚  Post-Norm (ì›ë³¸):                       â”‚
â”‚    x â†’ Attention â†’ Add(x) â†’ LayerNorm   â”‚
â”‚    x â†’ FFN â†’ Add(x) â†’ LayerNorm         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<p><strong>Pre-Norm vs Post-Norm</strong>:
- <strong>Pre-Norm</strong>: ë” ë‚˜ì€ ê¸°ìš¸ê¸° íë¦„, í›ˆë ¨í•˜ê¸° ì‰¬ì›€, GPT, LLaMAì—ì„œ ì‚¬ìš©
- <strong>Post-Norm</strong>: ì›ë³¸ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ìì¸, ì‹ ì¤‘í•œ íŠœë‹ìœ¼ë¡œ ì•½ê°„ ë” ë‚˜ì€ ì„±ëŠ¥</p>
<h3 id="33-pytorch-layernorm">3.3 PyTorch LayerNorm<a class="header-link" href="#33-pytorch-layernorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># íŠ¸ëœìŠ¤í¬ë¨¸ìš© LayerNorm</span>
<span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>  <span class="c1"># d_model = 512</span>

<span class="c1"># ì˜ˆì œ: Pre-Normì„ ì‚¬ìš©í•œ ì…€í”„ ì–´í…ì…˜</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">d_model</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Pre-Norm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (batch, seq_len, d_model)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([32, 100, 512])</span>
</code></pre></div>

<h3 id="34">3.4 ìˆ˜ë™ êµ¬í˜„<a class="header-link" href="#34" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LayerNormManual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span> <span class="o">=</span> <span class="n">normalized_shape</span>

        <span class="c1"># í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x í˜•íƒœ: (N, ..., normalized_shape)</span>
        <span class="c1"># ì˜ˆ: íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê²½ìš° (N, seq_len, d_model)</span>

        <span class="c1"># ë§ˆì§€ë§‰ ì°¨ì›ì—ì„œ í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°</span>
        <span class="c1"># ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ ìœ„í•´ ì°¨ì› ìœ ì§€</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
                          <span class="k">else</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="n">mean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># ì •ê·œí™”</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

        <span class="c1"># ìŠ¤ì¼€ì¼ ë° ì‹œí”„íŠ¸</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x_norm</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># í…ŒìŠ¤íŠ¸</span>
<span class="n">manual_ln</span> <span class="o">=</span> <span class="n">LayerNormManual</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">pytorch_ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (batch, seq, features)</span>

<span class="n">out_manual</span> <span class="o">=</span> <span class="n">manual_ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">out_pytorch</span> <span class="o">=</span> <span class="n">pytorch_ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì¶œë ¥ í˜•íƒœ: </span><span class="si">{</span><span class="n">out_manual</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ìƒ˜í”Œë‹¹ í‰ê· ì´ 0ì— ê°€ê¹Œì›€: </span><span class="si">{</span><span class="n">out_manual</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ìƒ˜í”Œë‹¹ í‘œì¤€í¸ì°¨ê°€ 1ì— ê°€ê¹Œì›€: </span><span class="si">{</span><span class="n">out_manual</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="35">3.5 ì‚¬ìš© ì‚¬ë¡€<a class="header-link" href="#35" title="Permanent link">&para;</a></h3>
<p><strong>ê°€ì¥ ì í•©í•œ ê²½ìš°</strong>:
- íŠ¸ëœìŠ¤í¬ë¨¸ (BERT, GPT, ViT)
- RNN, LSTM
- ì‘ì€ ë°°ì¹˜ í¬ê¸°
- ê°€ë³€ ì‹œí€€ìŠ¤ ê¸¸ì´</p>
<hr />
<h2 id="4-group-normalization">4. ê·¸ë£¹ ì •ê·œí™”(Group Normalization)<a class="header-link" href="#4-group-normalization" title="Permanent link">&para;</a></h2>
<h3 id="41">4.1 í•µì‹¬ ê°œë…<a class="header-link" href="#41" title="Permanent link">&para;</a></h3>
<p><strong>ê·¸ë£¹ ì •ê·œí™”</strong>(GroupNorm)ëŠ” ì±„ë„ì„ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ê·¸ë£¹ ë‚´ì—ì„œ ì •ê·œí™”í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code>ì…ë ¥: (N, C, H, W)
ê·¸ë£¹: G

C ì±„ë„ì„ ê°ê° (C/G) ì±„ë„ì”© Gê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• 
ê° ê·¸ë£¹ì„ ë…ë¦½ì ìœ¼ë¡œ ì •ê·œí™”

íŠ¹ìˆ˜ ì‚¬ë¡€:
  G = 1     â†’ ë ˆì´ì–´ ì •ê·œí™” (í•œ ê·¸ë£¹ = ëª¨ë“  ì±„ë„)
  G = C     â†’ ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™” (ê° ì±„ë„ì´ í•˜ë‚˜ì˜ ê·¸ë£¹)
  G = 32    â†’ ì¼ë°˜ì ì¸ ì„ íƒ (Wu &amp; He, 2018)
</code></pre></div>

<p><strong>ì‹œê°í™”</strong>:</p>
<div class="highlight"><pre><span></span><code>ì±„ë„: [c0, c1, c2, c3, c4, c5, c6, c7]
ê·¸ë£¹ (G=4): [c0,c1] [c2,c3] [c4,c5] [c6,c7]

ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´:
  ê° ê·¸ë£¹ì— ëŒ€í•´:
    (C/G, H, W)ì—ì„œ í‰ê· /ë¶„ì‚° ê³„ì‚°
    ì •ê·œí™”
</code></pre></div>

<h3 id="42">4.2 ê³µì‹<a class="header-link" href="#42" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>ê° ìƒ˜í”Œ n, ê·¸ë£¹ gì— ëŒ€í•´:
  Î¼â‚™,â‚˜ = (1/(C/G Â· H Â· W)) Î£ x_n,g,h,w
  ÏƒÂ²â‚™,â‚˜ = (1/(C/G Â· H Â· W)) Î£ (x_n,g,h,w - Î¼â‚™,â‚˜)Â²
  xÌ‚_n,g,h,w = (x_n,g,h,w - Î¼â‚™,â‚˜) / âˆš(ÏƒÂ²â‚™,â‚˜ + Îµ)
  y_n,c,h,w = Î³_c Â· xÌ‚_n,c,h,w + Î²_c
</code></pre></div>

<h3 id="43-pytorch-groupnorm">4.3 PyTorch GroupNorm<a class="header-link" href="#43-pytorch-groupnorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># 32ê°œ ê·¸ë£¹ì„ ì‚¬ìš©í•œ GroupNorm (ì¼ë°˜ì ì¸ ì„ íƒ)</span>
<span class="n">gn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="c1"># ì˜ˆì œ: GroupNormì„ ì‚¬ìš©í•œ ResNet ë¸”ë¡</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ResNetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNetBlock</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">)</span>  <span class="c1"># ì‘ì€ ë°°ì¹˜ í¬ê¸°!</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([4, 64, 56, 56])</span>
</code></pre></div>

<h3 id="44">4.4 ê·¸ë£¹ ìˆ˜ ì„ íƒí•˜ê¸°<a class="header-link" href="#44" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># ê·œì¹™: num_channelsëŠ” num_groupsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì ¸ì•¼ í•¨</span>

<span class="c1"># ì¼ë°˜ì ì¸ êµ¬ì„±</span>
<span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>   <span class="c1"># 64 ì±„ë„, 32 ê·¸ë£¹ â†’ ê·¸ë£¹ë‹¹ 2 ì±„ë„</span>
    <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>  <span class="c1"># 128 ì±„ë„, 32 ê·¸ë£¹ â†’ ê·¸ë£¹ë‹¹ 4 ì±„ë„</span>
    <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>  <span class="c1"># 256 ì±„ë„, 32 ê·¸ë£¹ â†’ ê·¸ë£¹ë‹¹ 8 ì±„ë„</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">channels</span><span class="p">,</span> <span class="n">groups</span> <span class="ow">in</span> <span class="n">configs</span><span class="p">:</span>
    <span class="n">gn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>  <span class="c1"># ì‘ì€ ë°°ì¹˜!</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">gn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">channels</span><span class="si">}</span><span class="s2"> ì±„ë„, </span><span class="si">{</span><span class="n">groups</span><span class="si">}</span><span class="s2"> ê·¸ë£¹ â†’ &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;ê·¸ë£¹ë‹¹ </span><span class="si">{</span><span class="n">channels</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">groups</span><span class="si">}</span><span class="s2"> ì±„ë„, í˜•íƒœ: </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># íŠ¹ìˆ˜ ì‚¬ë¡€</span>
<span class="n">gn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>      <span class="c1"># G=1 â†’ LayerNorm ë™ì‘</span>
<span class="n">gn_instance</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>  <span class="c1"># G=C â†’ InstanceNorm ë™ì‘</span>
</code></pre></div>

<h3 id="45">4.5 ì‚¬ìš© ì‚¬ë¡€<a class="header-link" href="#45" title="Permanent link">&para;</a></h3>
<p><strong>ê°€ì¥ ì í•©í•œ ê²½ìš°</strong>:
- ê°ì²´ íƒì§€ (Mask R-CNN, Faster R-CNN)
- ì´ë¯¸ì§€ ë¶„í• 
- ì‘ì€ ë°°ì¹˜ í¬ê¸° (ë°°ì¹˜ í¬ê¸° = 1, 2, 4)
- ê³ ì •ëœ BatchNormì„ ì‚¬ìš©í•œ ì „ì´ í•™ìŠµ
- BatchNorm í†µê³„ê°€ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì‹œë‚˜ë¦¬ì˜¤</p>
<p><strong>ì„±ëŠ¥</strong>:
- COCO ê°ì²´ íƒì§€: GroupNormì€ í° ë°°ì¹˜ì—ì„œ BatchNormê³¼ ì¼ì¹˜
- ì‘ì€ ë°°ì¹˜(1-4)ì—ì„œ: GroupNormì´ BatchNormì„ í¬ê²Œ ëŠ¥ê°€í•¨</p>
<hr />
<h2 id="5-instance-normalization">5. ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”(Instance Normalization)<a class="header-link" href="#5-instance-normalization" title="Permanent link">&para;</a></h2>
<h3 id="51">5.1 í•µì‹¬ ê°œë…<a class="header-link" href="#51" title="Permanent link">&para;</a></h3>
<p><strong>ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”</strong>(InstanceNorm)ëŠ” ê° ìƒ˜í”Œì˜ ê° ì±„ë„ì„ ë…ë¦½ì ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code>ê° ìƒ˜í”Œ, ê° ì±„ë„ì— ëŒ€í•´:
  ê³µê°„ ì°¨ì› (H, W)ì—ì„œ í‰ê· ê³¼ ë¶„ì‚° ê³„ì‚°
  ì •ê·œí™”
</code></pre></div>

<p><strong>G = Cì¸ GroupNormê³¼ ë™ì¼</strong> (ê° ì±„ë„ì´ ìì²´ ê·¸ë£¹).</p>
<h3 id="52">5.2 ê³µì‹<a class="header-link" href="#52" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>ê° ìƒ˜í”Œ n, ì±„ë„ cì— ëŒ€í•´:
  Î¼â‚™,c = (1/(H Â· W)) Î£ x_n,c,h,w
  ÏƒÂ²â‚™,c = (1/(H Â· W)) Î£ (x_n,c,h,w - Î¼â‚™,c)Â²
  xÌ‚_n,c,h,w = (x_n,c,h,w - Î¼â‚™,c) / âˆš(ÏƒÂ²â‚™,c + Îµ)
  y_n,c,h,w = Î³_c Â· xÌ‚_n,c,h,w + Î²_c
</code></pre></div>

<h3 id="53-pytorch-instancenorm">5.3 PyTorch InstanceNorm<a class="header-link" href="#53-pytorch-instancenorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># 2D ì´ë¯¸ì§€ìš©</span>
<span class="n">in2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>

<span class="c1"># 1D ì‹œí€€ìŠ¤ìš©</span>
<span class="n">in1d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm1d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>

<span class="c1"># ì˜ˆì œ: ìŠ¤íƒ€ì¼ ì „ì´ ë„¤íŠ¸ì›Œí¬</span>
<span class="k">class</span><span class="w"> </span><span class="nc">StyleTransferBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">StyleTransferBlock</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># ë°°ì¹˜ í¬ê¸° = 1ë„ ê´œì°®ìŒ!</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([1, 64, 256, 256])</span>
</code></pre></div>

<h3 id="54-instance-normalization">5.4 ì™œ Instance Normalizationì„ ì‚¬ìš©í•˜ëŠ”ê°€?<a class="header-link" href="#54-instance-normalization" title="Permanent link">&para;</a></h3>
<p><strong>í•µì‹¬ í†µì°°</strong>: ìŠ¤íƒ€ì¼ ì „ì´ì˜ ê²½ìš°, ì¸ìŠ¤í„´ìŠ¤ë³„ ëŒ€ë¹„ ì •ë³´ë¥¼ ì •ê·œí™”í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.</p>
<p><strong>ì˜ˆì œ</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># ì½˜í…ì¸ ì™€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ë¡œë“œ</span>
<span class="n">content</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;content.jpg&#39;</span><span class="p">)</span>
<span class="n">style</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;style.jpg&#39;</span><span class="p">)</span>

<span class="c1"># InstanceNormì„ ì‚¬ìš©í•œ ìŠ¤íƒ€ì¼ ì „ì´</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FastStyleTransfer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># ì¸ì½”ë”</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># InstanceNormì„ ì‚¬ìš©í•œ ì”ì°¨ ë¸”ë¡</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_residual_block</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="c1"># ë””ì½”ë”</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_residual_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<h3 id="55">5.5 ì‚¬ìš© ì‚¬ë¡€<a class="header-link" href="#55" title="Permanent link">&para;</a></h3>
<p><strong>ê°€ì¥ ì í•©í•œ ê²½ìš°</strong>:
- ìŠ¤íƒ€ì¼ ì „ì´ (neural style, fast style transfer)
- ì´ë¯¸ì§€ ê°„ ë³€í™˜ (pix2pix, CycleGAN)
- ìƒì„± ëª¨ë¸ (ì´ë¯¸ì§€ í•©ì„±ìš© GAN)
- í…ìŠ¤ì²˜ í•©ì„±</p>
<hr />
<h2 id="6-rmsnorm-root-mean-square-normalization">6. RMSNorm (Root Mean Square Normalization)<a class="header-link" href="#6-rmsnorm-root-mean-square-normalization" title="Permanent link">&para;</a></h2>
<h3 id="61">6.1 í•µì‹¬ ê°œë…<a class="header-link" href="#61" title="Permanent link">&para;</a></h3>
<p><strong>RMSNorm</strong>ì€ í‰ê·  ì¤‘ì‹¬í™”ë¥¼ ì œê±°í•˜ì—¬ LayerNormì„ ë‹¨ìˆœí™”í•˜ê³  ì œê³± í‰ê·  ì œê³±ê·¼(root mean square)ìœ¼ë¡œë§Œ ì •ê·œí™”í•©ë‹ˆë‹¤.</p>
<p><strong>í•µì‹¬ ì°¨ì´</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="n">LayerNorm</span><span class="o">:</span><span class="w">  </span><span class="n">x</span><span class="err">Ì‚</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">Î¼</span><span class="o">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="err">Ïƒ</span><span class="w">           </span><span class="err">#</span><span class="w"> </span><span class="err">ì¤‘ì‹¬í™”</span><span class="w"> </span><span class="err">í›„</span><span class="w"> </span><span class="err">ìŠ¤ì¼€ì¼</span><span class="w"> </span><span class="err">ì¡°ì •</span>
<span class="n">RMSNorm</span><span class="o">:</span><span class="w">    </span><span class="n">x</span><span class="err">Ì‚</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">RMS</span><span class="o">(</span><span class="n">x</span><span class="o">)</span><span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="err">ìŠ¤ì¼€ì¼</span><span class="w"> </span><span class="err">ì¡°ì •ë§Œ</span>
</code></pre></div>

<p><strong>ê³µì‹</strong>:</p>
<div class="highlight"><pre><span></span><code>RMS(x) = âˆš((1/n) Î£ xáµ¢Â²)
xÌ‚áµ¢ = xáµ¢ / RMS(x)
yáµ¢ = Î³ Â· xÌ‚áµ¢                            # ìŠ¤ì¼€ì¼ (ë°”ì´ì–´ìŠ¤ Î² ì—†ìŒ)
</code></pre></div>

<h3 id="62-rmsnorm">6.2 ì™œ RMSNormì„ ì‚¬ìš©í•˜ëŠ”ê°€?<a class="header-link" href="#62-rmsnorm" title="Permanent link">&para;</a></h3>
<p><strong>ì¥ì </strong>:
1. <strong>ë” ê°„ë‹¨í•œ ê³„ì‚°</strong> â€” í‰ê·  ê³„ì‚°ì´ë‚˜ ë¹¼ê¸° ì—†ìŒ
2. <strong>ë” ë¹ ë¦„</strong> â€” ëŒ€í˜• ëª¨ë¸ì—ì„œ ì•½ 10-15% ì†ë„ í–¥ìƒ
3. <strong>ìœ ì‚¬í•œ ì„±ëŠ¥</strong> â€” ê²½í—˜ì ìœ¼ë¡œ LayerNormê³¼ ì¼ì¹˜
4. <strong>ê´‘ë²”ìœ„í•œ ì±„íƒ</strong> â€” LLaMA, LLaMA 2, LLaMA 3, Gemma, Mistral</p>
<p><strong>ê³„ì‚° ì ˆê°</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="n">LayerNorm</span><span class="o">:</span><span class="w">  </span><span class="mi">2</span><span class="err">ë²ˆì˜</span><span class="w"> </span><span class="err">íŒ¨ìŠ¤</span><span class="w"> </span><span class="o">(</span><span class="err">í‰ê· </span><span class="o">,</span><span class="w"> </span><span class="err">ê·¸</span><span class="w"> </span><span class="err">ë‹¤ìŒ</span><span class="w"> </span><span class="err">ë¶„ì‚°</span><span class="o">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="err">ë²ˆì˜</span><span class="w"> </span><span class="err">ì—°ì‚°</span><span class="w"> </span><span class="o">(</span><span class="err">ë¹¼ê¸°</span><span class="o">,</span><span class="w"> </span><span class="err">ë‚˜ëˆ„ê¸°</span><span class="o">)</span>
<span class="n">RMSNorm</span><span class="o">:</span><span class="w">    </span><span class="mi">1</span><span class="err">ë²ˆì˜</span><span class="w"> </span><span class="err">íŒ¨ìŠ¤</span><span class="w"> </span><span class="o">(</span><span class="n">RMS</span><span class="o">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="err">ë²ˆì˜</span><span class="w"> </span><span class="err">ì—°ì‚°</span><span class="w"> </span><span class="o">(</span><span class="err">ë‚˜ëˆ„ê¸°</span><span class="o">)</span>
</code></pre></div>

<h3 id="63">6.3 ìˆ˜ë™ êµ¬í˜„<a class="header-link" href="#63" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x í˜•íƒœ: (..., dim)</span>

        <span class="c1"># RMS ê³„ì‚°</span>
        <span class="n">rms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

        <span class="c1"># ì •ê·œí™” ë° ìŠ¤ì¼€ì¼</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="n">rms</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="n">x_norm</span>

        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># í…ŒìŠ¤íŠ¸</span>
<span class="n">rms_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (batch, seq, features)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">rms_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì¶œë ¥ í˜•íƒœ: </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RMS: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">**</span><span class="w"> </span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ì•½ 1.0ì´ì–´ì•¼ í•¨</span>
</code></pre></div>

<h3 id="64-layernorm">6.4 LayerNormê³¼ ë¹„êµ<a class="header-link" href="#64-layernorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">rms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">rms</span><span class="p">)</span>

<span class="c1"># ë²¤ì¹˜ë§ˆí¬</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">rms_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># ì›Œë°ì—…</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">rms_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># LayerNorm íƒ€ì´ë°</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">ln_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># RMSNorm íƒ€ì´ë°</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">rms_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
<span class="n">rms_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LayerNorm: </span><span class="si">{</span><span class="n">ln_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RMSNorm:   </span><span class="si">{</span><span class="n">rms_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì†ë„ í–¥ìƒ:   </span><span class="si">{</span><span class="n">ln_time</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">rms_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="65-llama-rmsnorm">6.5 LLaMAì—ì„œì˜ RMSNorm<a class="header-link" href="#65-llama-rmsnorm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LLaMATransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;RMSNormì„ ì‚¬ìš©í•œ LLaMA ìŠ¤íƒ€ì¼ íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_ratio</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># RMSNormì„ ì‚¬ìš©í•œ Pre-normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">mlp_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span>  <span class="c1"># LLaMAëŠ” SiLU (Swish) í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš©</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">mlp_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># RMSNormì„ ì‚¬ìš©í•œ ì–´í…ì…˜</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">h</span>

        <span class="c1"># RMSNormì„ ì‚¬ìš©í•œ FFN</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">h</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># ì‚¬ìš© ì˜ˆì œ</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LLaMATransformerBlock</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>  <span class="c1"># (batch, seq_len, dim)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([1, 2048, 4096])</span>
</code></pre></div>

<h3 id="66">6.6 ì‚¬ìš© ì‚¬ë¡€<a class="header-link" href="#66" title="Permanent link">&para;</a></h3>
<p><strong>ê°€ì¥ ì í•©í•œ ê²½ìš°</strong>:
- ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLaMA, Mistral, Gemma)
- ì†ë„ê°€ ì¤‘ìš”í•œ ëª¨ë“  íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸
- ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ëŠ” ëª¨ë¸ (LayerNorm ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •ì´ ì•„ë‹˜)</p>
<hr />
<h2 id="7">7. ê¸°íƒ€ ì •ê·œí™” ê¸°ë²•<a class="header-link" href="#7" title="Permanent link">&para;</a></h2>
<h3 id="71-weight-normalization">7.1 ê°€ì¤‘ì¹˜ ì •ê·œí™”(Weight Normalization)<a class="header-link" href="#71-weight-normalization" title="Permanent link">&para;</a></h3>
<p><strong>ê°€ì¤‘ì¹˜ ì •ê·œí™”</strong>ëŠ” í¬ê¸°ì™€ ë°©í–¥ì„ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ì¬ë§¤ê°œë³€ìˆ˜í™”í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="err">ì›ë³¸</span><span class="o">:</span><span class="w">                </span><span class="n">w</span>
<span class="err">ì¬ë§¤ê°œë³€ìˆ˜í™”</span><span class="o">:</span><span class="w">        </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="err">Â·</span><span class="w"> </span><span class="o">(</span><span class="n">v</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="o">||</span><span class="n">v</span><span class="o">||)</span>

<span class="n">g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">ìŠ¤ì¹¼ë¼</span><span class="w"> </span><span class="err">í¬ê¸°</span><span class="w"> </span><span class="o">(</span><span class="err">í•™ìŠµ</span><span class="w"> </span><span class="err">ê°€ëŠ¥</span><span class="o">)</span>
<span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">ë°©í–¥</span><span class="w"> </span><span class="err">ë²¡í„°</span><span class="w"> </span><span class="o">(</span><span class="err">í•™ìŠµ</span><span class="w"> </span><span class="err">ê°€ëŠ¥</span><span class="o">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">weight_norm</span>

<span class="c1"># ë ˆì´ì–´ì— ê°€ì¤‘ì¹˜ ì •ê·œí™” ì ìš©</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">weight_norm</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>

<span class="c1"># ê°€ì¤‘ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì¬ë§¤ê°œë³€ìˆ˜í™”ë¨: weight = g * v / ||v||</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight_g</span><span class="p">)</span>  <span class="c1"># í¬ê¸° íŒŒë¼ë¯¸í„°</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight_v</span><span class="p">)</span>  <span class="c1"># ë°©í–¥ íŒŒë¼ë¯¸í„°</span>

<span class="c1"># ìˆœì „íŒŒ</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># ê°€ì¤‘ì¹˜ ì •ê·œí™” ì œê±° (gì™€ vë¥¼ ë‹¤ì‹œ weightë¡œ ë³‘í•©)</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">remove_weight_norm</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‚¬ë¡€</strong>: RNN, GAN, ê°•í™” í•™ìŠµ (A3C)</p>
<h3 id="72-spectral-normalization">7.2 ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™”(Spectral Normalization)<a class="header-link" href="#72-spectral-normalization" title="Permanent link">&para;</a></h3>
<p><strong>ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™”</strong>ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ ìŠ¤í™íŠ¸ëŸ¼ ë…¸ë¦„(ìµœëŒ€ íŠ¹ì´ê°’)ì„ 1ë¡œ ì œí•œí•˜ì—¬ GAN í›ˆë ¨ì„ ì•ˆì •í™”í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code>ìŠ¤í™íŠ¸ëŸ¼ ë…¸ë¦„: Ïƒ(W) = Wì˜ ìµœëŒ€ íŠ¹ì´ê°’
ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜: W_SN = W / Ïƒ(W)
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">spectral_norm</span>

<span class="c1"># ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™” ì ìš©</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">spectral_norm</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>

<span class="c1"># ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•œ íŒë³„ì (GANìš©)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SNDiscriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">SNDiscriminator</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([16, 1, 5, 5])</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‚¬ë¡€</strong>: GAN íŒë³„ì (SNGAN, BigGAN, StyleGAN2)</p>
<h3 id="73-adaptive-instance-normalization-adain">7.3 ì ì‘ì  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”(Adaptive Instance Normalization, AdaIN)<a class="header-link" href="#73-adaptive-instance-normalization-adain" title="Permanent link">&para;</a></h3>
<p><strong>AdaIN</strong>ì€ ìŠ¤íƒ€ì¼ ì…ë ¥ì— ê¸°ë°˜í•˜ì—¬ InstanceNorm í†µê³„ë¥¼ ì ì‘ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì‹¤ì‹œê°„ ìŠ¤íƒ€ì¼ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code>AdaIN(content, style) = Ïƒ(style) Â· ((content - Î¼(content)) / Ïƒ(content)) + Î¼(style)

ìŠ¤íƒ€ì¼ í†µê³„ (í‰ê· , í‘œì¤€í¸ì°¨)ë¥¼ ì½˜í…ì¸  íŠ¹ì„±ìœ¼ë¡œ ì „ì†¡
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdaIN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">style</span><span class="p">):</span>
        <span class="c1"># content, style: (N, C, H, W)</span>

        <span class="c1"># í†µê³„ ê³„ì‚°</span>
        <span class="n">content_mean</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">content_std</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">style_mean</span> <span class="o">=</span> <span class="n">style</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">style_std</span> <span class="o">=</span> <span class="n">style</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># ì½˜í…ì¸  ì •ê·œí™”, ê·¸ ë‹¤ìŒ ìŠ¤íƒ€ì¼ í†µê³„ ì ìš©</span>
        <span class="n">normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">content</span> <span class="o">-</span> <span class="n">content_mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">content_std</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
        <span class="n">stylized</span> <span class="o">=</span> <span class="n">normalized</span> <span class="o">*</span> <span class="n">style_std</span> <span class="o">+</span> <span class="n">style_mean</span>

        <span class="k">return</span> <span class="n">stylized</span>

<span class="c1"># AdaINì„ ì‚¬ìš©í•œ ìŠ¤íƒ€ì¼ ì „ì´</span>
<span class="k">class</span><span class="w"> </span><span class="nc">StyleTransferNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adain</span> <span class="o">=</span> <span class="n">AdaIN</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">style</span><span class="p">):</span>
        <span class="n">content_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
        <span class="n">style_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">style</span><span class="p">)</span>

        <span class="c1"># AdaIN ë ˆì´ì–´</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adain</span><span class="p">(</span><span class="n">content_feat</span><span class="p">,</span> <span class="n">style_feat</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="c1"># ì‚¬ìš©ë²•</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">StyleTransferNet</span><span class="p">()</span>
<span class="n">content</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="n">style</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="n">stylized</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">style</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stylized</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># torch.Size([1, 3, 256, 256])</span>
</code></pre></div>

<p><strong>ì‚¬ìš© ì‚¬ë¡€</strong>: ì‹¤ì‹œê°„ ìŠ¤íƒ€ì¼ ì „ì´, ì´ë¯¸ì§€ ê°„ ë³€í™˜</p>
<h3 id="74">7.4 ë¹„êµ í‘œ<a class="header-link" href="#74" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ë°©ë²•</th>
<th>ì •ê·œí™” ëŒ€ìƒ</th>
<th>í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°</th>
<th>ë°°ì¹˜ ì˜ì¡´ì </th>
<th>ì‚¬ìš© ì‚¬ë¡€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Batch Norm</strong></td>
<td>ê° (C,H,W)ì— ëŒ€í•´ (N)</td>
<td>Î³, Î², ì´ë™ í†µê³„</td>
<td>ì˜ˆ</td>
<td>CNN, í° ë°°ì¹˜</td>
</tr>
<tr>
<td><strong>Layer Norm</strong></td>
<td>ê° Nì— ëŒ€í•´ (C,H,W)</td>
<td>Î³, Î²</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>íŠ¸ëœìŠ¤í¬ë¨¸, RNN</td>
</tr>
<tr>
<td><strong>Instance Norm</strong></td>
<td>ê° (N,C)ì— ëŒ€í•´ (H,W)</td>
<td>Î³, Î² (ì„ íƒì )</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>ìŠ¤íƒ€ì¼ ì „ì´, GAN</td>
</tr>
<tr>
<td><strong>Group Norm</strong></td>
<td>ê° (N,G)ì— ëŒ€í•´ (C/G,H,W)</td>
<td>Î³, Î²</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>íƒì§€, ì‘ì€ ë°°ì¹˜</td>
</tr>
<tr>
<td><strong>RMSNorm</strong></td>
<td>ê° Nì— ëŒ€í•´ (C,H,W)</td>
<td>Î³</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>LLM, ë¹ ë¥¸ íŠ¸ëœìŠ¤í¬ë¨¸</td>
</tr>
<tr>
<td><strong>Weight Norm</strong></td>
<td>ê°€ì¤‘ì¹˜ ë²¡í„°</td>
<td>g, v</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>RNN, GAN</td>
</tr>
<tr>
<td><strong>Spectral Norm</strong></td>
<td>ê°€ì¤‘ì¹˜ í–‰ë ¬</td>
<td>â€”</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>GAN íŒë³„ì</td>
</tr>
<tr>
<td><strong>AdaIN</strong></td>
<td>ìŠ¤íƒ€ì¼ì— ë”°ë¼ (H,W)</td>
<td>â€”</td>
<td>ì•„ë‹ˆì˜¤</td>
<td>ìŠ¤íƒ€ì¼ ì „ì´</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="8">8. ì¢…í•© ë¹„êµ<a class="header-link" href="#8" title="Permanent link">&para;</a></h2>
<h3 id="81">8.1 ì‹œê°ì  ë¹„êµ<a class="header-link" href="#81" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>ì…ë ¥ í…ì„œ: (N, C, H, W)
N = ë°°ì¹˜ (4ê°œ ìƒ˜í”Œ)
C = ì±„ë„ (3)
H, W = ë†’ì´, ë„ˆë¹„ (32 Ã— 32)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë°°ì¹˜ ì •ê·œí™”                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚ N=0  â”‚ N=1  â”‚ N=2  â”‚ N=3  â”‚                                      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤  ê° (C, H, W) ìœ„ì¹˜ì— ëŒ€í•´:           â”‚
â”‚  â”‚ c=0  â”‚ c=0  â”‚ c=0  â”‚ c=0  â”‚  Nì—ì„œ í‰ê· /ë¶„ì‚° ê³„ì‚°                â”‚
â”‚  â”‚ h,w  â”‚ h,w  â”‚ h,w  â”‚ h,w  â”‚  (4ê°œ ê°’)                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚  ì •ê·œí™”: (x - Î¼_batch) / Ïƒ_batch                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë ˆì´ì–´ ì •ê·œí™”                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚  â”‚       N=0                 â”‚  ê° ìƒ˜í”Œì— ëŒ€í•´:                      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  ëª¨ë“  (C, H, W)ì—ì„œ                  â”‚
â”‚  â”‚ c=0   â”‚ c=1   â”‚ c=2       â”‚  í‰ê· /ë¶„ì‚° ê³„ì‚°                       â”‚
â”‚  â”‚ (all  â”‚ (all  â”‚ (all      â”‚  (3 Ã— 32 Ã— 32 = 3072ê°œ ê°’)           â”‚
â”‚  â”‚ h,w)  â”‚ h,w)  â”‚ h,w)      â”‚                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚  ì •ê·œí™”: (x - Î¼_layer) / Ïƒ_layer                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚  â”‚  N=0, C=0      â”‚  ê° (ìƒ˜í”Œ, ì±„ë„)ì— ëŒ€í•´:                         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  (H, W)ì—ì„œ                                     â”‚
â”‚  â”‚   (all h,w)    â”‚  í‰ê· /ë¶„ì‚° ê³„ì‚°                                  â”‚
â”‚  â”‚                â”‚  (32 Ã— 32 = 1024ê°œ ê°’)                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚  ì •ê·œí™”: (x - Î¼_instance) / Ïƒ_instance                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ê·¸ë£¹ ì •ê·œí™” (G=3, ê·¸ë£¹ë‹¹ 1ì±„ë„)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚  â”‚ N=0, G=0       â”‚  ê° (ìƒ˜í”Œ, ê·¸ë£¹)ì— ëŒ€í•´:                         â”‚
â”‚  â”‚ (c=0ë§Œ)        â”‚  (C/G, H, W)ì—ì„œ                                â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  í‰ê· /ë¶„ì‚° ê³„ì‚°                                  â”‚
â”‚  â”‚   (all h,w)    â”‚  (1 Ã— 32 Ã— 32 = 1024ê°œ ê°’)                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚  ì •ê·œí™”: (x - Î¼_group) / Ïƒ_group                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="82">8.2 ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ?<a class="header-link" href="#82" title="Permanent link">&para;</a></h3>
<h4 id="_2">ê²°ì • íŠ¸ë¦¬<a class="header-link" href="#_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code>íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•˜ê³  ìˆë‚˜ìš”?
  â”œâ”€ ì˜ˆ â†’ LayerNorm ë˜ëŠ” RMSNorm
  â”‚         â”œâ”€ ì†ë„ê°€ ì¤‘ìš”? â†’ RMSNorm (LLaMA, Mistral)
  â”‚         â””â”€ ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ â†’ LayerNorm (BERT, ViT)
  â”‚
  â””â”€ ì•„ë‹ˆì˜¤ â†’ CNNì„ ì‚¬ìš©í•˜ê³  ìˆë‚˜ìš”?
           â”œâ”€ ì˜ˆ â†’ ë°°ì¹˜ í¬ê¸°ê°€ í°ê°€ìš” (â‰¥16)?
           â”‚         â”œâ”€ ì˜ˆ â†’ BatchNorm
           â”‚         â””â”€ ì•„ë‹ˆì˜¤ â†’ GroupNorm
           â”‚
           â””â”€ ì•„ë‹ˆì˜¤ â†’ GANì´ë‚˜ ìŠ¤íƒ€ì¼ ì „ì´ì¸ê°€ìš”?
                     â”œâ”€ ì˜ˆ â†’ InstanceNorm ë˜ëŠ” AdaIN
                     â””â”€ ì•„ë‹ˆì˜¤ â†’ LayerNorm (ì•ˆì „í•œ ê¸°ë³¸ê°’)
</code></pre></div>

<h4 id="_3">ì•„í‚¤í…ì²˜ë³„ ê¶Œì¥ ì‚¬í•­<a class="header-link" href="#_3" title="Permanent link">&para;</a></h4>
<p><strong>í•©ì„±ê³± ì‹ ê²½ë§(CNN)</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># í‘œì¤€ ë¶„ë¥˜ (ImageNet)</span>
<span class="c1"># ë°°ì¹˜ í¬ê¸°: 32-256</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>  <span class="c1"># â† í° ë°°ì¹˜ì— BatchNorm</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p><strong>ê°ì²´ íƒì§€ / ë¶„í• </strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Mask R-CNN, Faster R-CNN</span>
<span class="c1"># ë°°ì¹˜ í¬ê¸°: 1-4 (í° ì´ë¯¸ì§€ì— ëŒ€í•´ GPU ë©”ëª¨ë¦¬ ì œí•œ)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DetectionBackbone</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>  <span class="c1"># â† ì‘ì€ ë°°ì¹˜ì— GroupNorm</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p><strong>íŠ¸ëœìŠ¤í¬ë¨¸ (ë¹„ì „ ë˜ëŠ” ì–¸ì–´)</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># BERT, GPT, ViT</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># â† LayerNorm í‘œì¤€</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">d_model</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<p><strong>ëŒ€í˜• ì–¸ì–´ ëª¨ë¸</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># LLaMA, Mistral, Gemma</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LLMTransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>  <span class="c1"># â† ì†ë„ë¥¼ ìœ„í•œ RMSNorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
</code></pre></div>

<p><strong>ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§(GAN)</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># ìƒì„±ì: ìŠ¤íƒ€ì¼ì„ ìœ„í•œ InstanceNorm</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>  <span class="c1"># â† InstanceNorm</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>

<span class="c1"># íŒë³„ì: ìŠ¤í™íŠ¸ëŸ¼ ì •ê·œí™”</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>  <span class="c1"># â† SpectralNorm</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div>

<h3 id="83">8.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬<a class="header-link" href="#83" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">benchmark_normalization</span><span class="p">(</span><span class="n">norm_layer</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ì •ê·œí™” ë ˆì´ì–´ ë²¤ì¹˜ë§ˆí¬.&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

    <span class="c1"># ì›Œë°ì—…</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="k">return</span> <span class="n">elapsed</span>

<span class="c1"># í…ŒìŠ¤íŠ¸ êµ¬ì„±</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">channels</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>

<span class="c1"># ì •ê·œí™” ë ˆì´ì–´</span>
<span class="n">norms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;BatchNorm2d&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
    <span class="s1">&#39;GroupNorm (G=32)&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">channels</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
    <span class="s1">&#39;InstanceNorm2d&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì…ë ¥ í˜•íƒœ: </span><span class="si">{</span><span class="n">input_shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ë°˜ë³µ íšŸìˆ˜: 1000</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">norm</span> <span class="ow">in</span> <span class="n">norms</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">norm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">benchmark_normalization</span><span class="p">(</span><span class="n">norm</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

<span class="c1"># ìƒëŒ€ ì†ë„</span>
<span class="n">baseline</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;BatchNorm2d&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BatchNorm2d ëŒ€ë¹„:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">elapsed</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">elapsed</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">baseline</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>ì¼ë°˜ì ì¸ ê²°ê³¼</strong> (RTX 3090):</p>
<div class="highlight"><pre><span></span><code><span class="n">BatchNorm2d</span><span class="w">         </span><span class="o">:</span><span class="w"> </span><span class="mf">0.1234</span><span class="n">s</span><span class="w">  </span><span class="o">(</span><span class="mf">1.00</span><span class="n">x</span><span class="o">)</span>
<span class="n">GroupNorm</span><span class="w"> </span><span class="o">(</span><span class="n">G</span><span class="o">=</span><span class="mi">32</span><span class="o">)</span><span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="mf">0.1456</span><span class="n">s</span><span class="w">  </span><span class="o">(</span><span class="mf">1.18</span><span class="n">x</span><span class="o">)</span>
<span class="n">InstanceNorm2d</span><span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="mf">0.1389</span><span class="n">s</span><span class="w">  </span><span class="o">(</span><span class="mf">1.13</span><span class="n">x</span><span class="o">)</span>
</code></pre></div>

<p><strong>íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê²½ìš°</strong> (seq_len=2048, d_model=4096):</p>
<div class="highlight"><pre><span></span><code><span class="n">LayerNorm</span><span class="w">           </span><span class="o">:</span><span class="w"> </span><span class="mf">0.2145</span><span class="n">s</span><span class="w">  </span><span class="o">(</span><span class="mf">1.00</span><span class="n">x</span><span class="o">)</span>
<span class="n">RMSNorm</span><span class="w">             </span><span class="o">:</span><span class="w"> </span><span class="mf">0.1876</span><span class="n">s</span><span class="w">  </span><span class="o">(</span><span class="mf">0.87</span><span class="n">x</span><span class="o">)</span><span class="w">  </span><span class="err">â†</span><span class="w"> </span><span class="err">ì•½</span><span class="w"> </span><span class="mi">13</span><span class="o">%</span><span class="w"> </span><span class="err">ë¹ ë¦„</span>
</code></pre></div>

<hr />
<h2 id="9">9. ì‹¤ìš©ì ì¸ íŒ<a class="header-link" href="#9" title="Permanent link">&para;</a></h2>
<h3 id="91">9.1 Î³ì™€ Î²ì˜ ì´ˆê¸°í™”<a class="header-link" href="#91" title="Permanent link">&para;</a></h3>
<p><strong>ê¸°ë³¸ ì´ˆê¸°í™”</strong> (PyTorch):</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Î³ (ìŠ¤ì¼€ì¼)ì€ 1ë¡œ ì´ˆê¸°í™”</span>
<span class="c1"># Î² (ì‹œí”„íŠ¸)ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”</span>
<span class="c1"># ì²˜ìŒì—ëŠ” ì›ë˜ ë¶„í¬ë¥¼ ìœ ì§€í•¨</span>
</code></pre></div>

<p><strong>íŠ¹ìˆ˜ ì‚¬ë¡€</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># ì”ì°¨ ë¸”ë¡ì— ëŒ€í•´ Î³ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™” (He et al., 2019)</span>
<span class="c1"># &quot;Fixup Initialization&quot; â€” ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì— ë„ì›€</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>

        <span class="c1"># ê° ë¸”ë¡ì˜ ë§ˆì§€ë§‰ BatchNormì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Î³ = 0</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="c1"># Î² = 0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># ì²˜ìŒì—ëŠ” 0ì„ ì¶œë ¥í•˜ë¯€ë¡œ out = identity</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>

<h3 id="92">9.2 ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì™€ì˜ ìƒí˜¸ì‘ìš©<a class="header-link" href="#92" title="Permanent link">&para;</a></h3>
<p><strong>BatchNormì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì— ëœ ë¯¼ê°í•˜ê²Œ ë§Œë“¤ì§€ë§Œ</strong>, ì—¬ì „íˆ ì ì ˆí•œ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.init</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">init</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ConvBNReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># ReLUë¥¼ ìœ„í•œ He ì´ˆê¸°í™”</span>
        <span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<h3 id="93">9.3 ì •ê·œí™”ì™€ í•™ìŠµë¥ <a class="header-link" href="#93" title="Permanent link">&para;</a></h3>
<p><strong>í•µì‹¬ í†µì°°</strong>: ì •ê·œí™”ëŠ” ë” ë†’ì€ í•™ìŠµë¥ ì„ í—ˆìš©í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="c1"># ì •ê·œí™” ì—†ìŒ</span>
<span class="n">model_no_norm</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">use_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_no_norm</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># ë³´ìˆ˜ì ì¸ í•™ìŠµë¥ </span>

<span class="c1"># BatchNorm/LayerNorm ì‚¬ìš©</span>
<span class="n">model_with_norm</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">use_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_with_norm</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># 10ë°° ë†’ì€ í•™ìŠµë¥ !</span>

<span class="c1"># LayerNormì„ ì‚¬ìš©í•œ í˜„ëŒ€ íŠ¸ëœìŠ¤í¬ë¨¸</span>
<span class="c1"># ì›Œë°ì—…ê³¼ í•¨ê»˜ ë” ë†’ì€ í•™ìŠµë¥  ì‚¬ìš© ê°€ëŠ¥</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div>

<p><strong>í•™ìŠµë¥  ìŠ¤ì¼€ì¼ë§ ê·œì¹™</strong> (Goyal et al., 2017):</p>
<div class="highlight"><pre><span></span><code>ë°°ì¹˜ í¬ê¸°ë¥¼ kë°° ì¦ê°€ì‹œí‚¬ ë•Œ, í•™ìŠµë¥ ë„ kë°° ì¦ê°€
(BatchNormì—ì„œë§Œ ì‘ë™!)

ë°°ì¹˜ 256, í•™ìŠµë¥  0.1  â†’  ë°°ì¹˜ 1024, í•™ìŠµë¥  0.4
</code></pre></div>

<h3 id="94">9.4 ì¼ë°˜ì ì¸ ë²„ê·¸ì™€ í•¨ì •<a class="header-link" href="#94" title="Permanent link">&para;</a></h3>
<h4 id="1-modeleval">ë²„ê·¸ 1: model.eval() ìŠê¸°<a class="header-link" href="#1-modeleval" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># í›ˆë ¨ ëª¨ë“œ</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">out_train</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># ì¶”ë¡  â€” ì˜ëª»ë¨! ì—¬ì „íˆ ë°°ì¹˜ í†µê³„ ì‚¬ìš©</span>
<span class="c1"># out_test = model(x)  # ë²„ê·¸: ì—¬ì „íˆ í›ˆë ¨ ëª¨ë“œ!</span>

<span class="c1"># ì¶”ë¡  â€” ì˜¬ë°”ë¦„</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># í‰ê°€ ëª¨ë“œë¡œ ì „í™˜!</span>
<span class="n">out_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì¶œë ¥ì´ ê°™ì€ê°€? </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out_train</span><span class="p">,</span><span class="w"> </span><span class="n">out_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># False</span>
</code></pre></div>

<h4 id="2">ë²„ê·¸ 2: ì˜ëª»ëœ ì°¨ì› ìˆœì„œ<a class="header-link" href="#2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># ì˜ëª»ë¨: LayerNormì— ëŒ€í•´ (seq_len, batch, features)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (seq, batch, features)</span>
<span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ì‘ë™í•˜ì§€ë§Œ ë§ˆì§€ë§‰ ì°¨ì›ë§Œ ì •ê·œí™”</span>

<span class="c1"># ì˜¬ë°”ë¦„: íŠ¹ì„±ì— ëŒ€í•´ ì •ê·œí™” (ë§ˆì§€ë§‰ ì°¨ì›)</span>
<span class="c1"># í…ì„œ ë ˆì´ì•„ì›ƒì´ normalized_shapeê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸!</span>

<span class="c1"># (batch, seq, features)ì˜ ê²½ìš° â€” í˜„ì¬ í‘œì¤€</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>  <span class="c1"># (batch, seq, features)</span>
<span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ì˜¬ë°”ë¦„: íŠ¹ì„± ì°¨ì›ì—ì„œ ì •ê·œí™”</span>
</code></pre></div>

<h4 id="3-groupnorm">ë²„ê·¸ 3: í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ì±„ë„ì„ ê°€ì§„ GroupNorm<a class="header-link" href="#3-groupnorm" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># ì˜ëª»ë¨: num_channelsê°€ num_groupsë¡œ ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ì§€ ì•ŠìŒ</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">gn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># 50 % 32 != 0</span>
<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì˜¤ë¥˜: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ì˜¬ë°”ë¦„: ë‚˜ëˆ„ì–´ë–¨ì–´ì§€ë„ë¡ í™•ì¸</span>
<span class="n">gn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">num_groups</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>  <span class="c1"># 64 % 32 == 0 âœ“</span>
</code></pre></div>

<h4 id="4-batch_size-1-batchnorm">ë²„ê·¸ 4: batch_size = 1ì¸ BatchNorm<a class="header-link" href="#4-batch_size-1-batchnorm" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># ë¬¸ì œ: ë‹¨ì¼ ìƒ˜í”Œì„ ê°€ì§„ BatchNorm</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>  <span class="c1"># ë°°ì¹˜ í¬ê¸° = 1</span>

<span class="n">bn</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ë¶„ì‚° = 0! (ë‹¨ì¼ ìƒ˜í”Œ)</span>
<span class="c1"># NaN ë˜ëŠ” ë¶ˆì•ˆì •í•œ í›ˆë ¨ ë°œìƒ</span>

<span class="c1"># í•´ê²°ì±… 1: GroupNorm ë˜ëŠ” LayerNorm ì‚¬ìš©</span>
<span class="n">gn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">gn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># batch_size=1ì—ì„œ ì˜ ì‘ë™</span>

<span class="c1"># í•´ê²°ì±… 2: BatchNormì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •</span>
<span class="n">bn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># ì´ë™ í†µê³„ ì‚¬ìš©</span>
</code></pre></div>

<h4 id="5-batchnorm">ë²„ê·¸ 5: ê³ ì • ë° í›ˆë ¨ ê°€ëŠ¥ BatchNorm í˜¼í•©<a class="header-link" href="#5-batchnorm" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># ë¬¸ì œ: ê³ ì •ëœ BatchNorm í†µê³„ë¡œ ë¯¸ì„¸ ì¡°ì •</span>
<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># ëª¨ë“  íŒŒë¼ë¯¸í„° ê³ ì •</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">pretrained_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># ì´ê²ƒìœ¼ë¡œ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ! BatchNormì€ ì—¬ì „íˆ í›ˆë ¨ ëª¨ë“œ í†µê³„ ì‚¬ìš©</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># ë²„ê·¸: BatchNormì´ í›ˆë ¨ ëª¨ë“œ!</span>

<span class="c1"># í•´ê²°ì±…: í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • ë˜ëŠ” BatchNorm ëª¨ë“ˆì„ í‰ê°€ë¡œ ì„¤ì •</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># ì¶”ë¡ ì— ì•ˆì „</span>

<span class="c1"># ë¯¸ì„¸ ì¡°ì •ì˜ ê²½ìš°:</span>
<span class="k">def</span><span class="w"> </span><span class="nf">set_bn_eval</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">pretrained_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">set_bn_eval</span><span class="p">)</span>  <span class="c1"># í›ˆë ¨ ì¤‘ BatchNormì„ í‰ê°€ ëª¨ë“œë¡œ ìœ ì§€</span>
</code></pre></div>

<h3 id="95">9.5 ëª¨ë²” ì‚¬ë¡€ ì²´í¬ë¦¬ìŠ¤íŠ¸<a class="header-link" href="#95" title="Permanent link">&para;</a></h3>
<p>âœ… <strong>ì¶”ë¡  ì „ì— í•­ìƒ <code>model.eval()</code> í˜¸ì¶œ</strong></p>
<p>âœ… <strong>ì•„í‚¤í…ì²˜ì— ë§ëŠ” ì •ê·œí™” ì‚¬ìš©</strong>:
   - CNN (í° ë°°ì¹˜) â†’ BatchNorm
   - CNN (ì‘ì€ ë°°ì¹˜) â†’ GroupNorm
   - íŠ¸ëœìŠ¤í¬ë¨¸ â†’ LayerNorm ë˜ëŠ” RMSNorm
   - GAN â†’ InstanceNorm (ìƒì„±ì), SpectralNorm (íŒë³„ì)</p>
<p>âœ… <strong>ì ì ˆí•œ ì´ˆê¸°í™” ì‚¬ìš©</strong> (ReLUì— Kaiming, Tanhì— Xavier)</p>
<p>âœ… <strong>ì •ê·œí™” ì‚¬ìš© ì‹œ í•™ìŠµë¥  ì¦ê°€</strong></p>
<p>âœ… <strong>ì „ì´ í•™ìŠµì˜ ê²½ìš°</strong>, BatchNorm í†µê³„ ê³ ì • ë˜ëŠ” GroupNormìœ¼ë¡œ ëŒ€ì²´ ê³ ë ¤</p>
<p>âœ… <strong>ì´ë™ í†µê³„ ëª¨ë‹ˆí„°ë§</strong> â€” í›ˆë ¨ ì¤‘ ì•ˆì •í™”ë˜ëŠ”ì§€ í™•ì¸</p>
<p>âœ… <strong>ë¶„ì‚° í›ˆë ¨ì˜ ê²½ìš°</strong>, í•„ìš”ì‹œ SyncBatchNorm ì‚¬ìš©:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="o">.</span><span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="_4">ì—°ìŠµ ë¬¸ì œ<a class="header-link" href="#_4" title="Permanent link">&para;</a></h2>
<h3 id="1_1">ì—°ìŠµ ë¬¸ì œ 1: ì •ê·œí™” ë°©ë²• êµ¬í˜„ ë° ë¹„êµ<a class="header-link" href="#1_1" title="Permanent link">&para;</a></h3>
<p>ë‹¤ì–‘í•œ ì •ê·œí™” ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” CNNì„ êµ¬í˜„í•˜ê³  CIFAR-10ì—ì„œ ì„±ëŠ¥ì„ ë¹„êµí•˜ì„¸ìš”.</p>
<p><strong>ê³¼ì œ</strong>:
1. ê°ê° ë‹¤ë¥¸ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ëŠ” 4ê°œì˜ ë™ì¼í•œ CNN ìƒì„±:
   - BatchNorm2d
   - GroupNorm (32ê°œ ê·¸ë£¹)
   - LayerNorm
   - ì •ê·œí™” ì—†ìŒ (ê¸°ì¤€ì„ )
2. ê°ê° CIFAR-10ì—ì„œ 20 ì—í¬í¬ í›ˆë ¨
3. í›ˆë ¨ ê³¡ì„  (ì†ì‹¤ ë° ì •í™•ë„) í”Œë¡¯
4. ê°ê°ì˜ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ ë³´ê³ 
5. ë°°ì¹˜ í¬ê¸° [4, 16, 64]ë¡œ ì‹¤í—˜í•˜ê³  ì–´ë–¤ ì •ê·œí™”ê°€ ê°€ì¥ ê²¬ê³ í•œì§€ ê´€ì°°</p>
<p><strong>ì‹œì‘ ì½”ë“œ</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CIFAR10Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">=</span> <span class="n">norm_type</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">conv_block</span><span class="p">(</span><span class="n">in_c</span><span class="p">,</span> <span class="n">out_c</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_c</span><span class="p">,</span> <span class="n">out_c</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>

            <span class="k">if</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s1">&#39;batch&#39;</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_c</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s1">&#39;group&#39;</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_c</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s1">&#39;layer&#39;</span><span class="p">:</span>
                <span class="c1"># 2Dìš© LayerNorm: (C, H, W)ì— ëŒ€í•´ ì •ê·œí™”</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_c</span><span class="p">))</span>  <span class="c1"># G=1ì€ LayerNorm</span>
            <span class="c1"># &#39;none&#39;: ì •ê·œí™” ì—†ìŒ</span>

            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># TODO: í›ˆë ¨ ë£¨í”„ ë° ë¹„êµ êµ¬í˜„</span>
</code></pre></div>

<h3 id="2-rmsnorm-vs-layernorm">ì—°ìŠµ ë¬¸ì œ 2: íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ RMSNorm vs LayerNorm<a class="header-link" href="#2-rmsnorm-vs-layernorm" title="Permanent link">&para;</a></h3>
<p>ì‘ì€ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ êµ¬í˜„í•˜ê³  ì†ë„ì™€ ì„±ëŠ¥ ì¸¡ë©´ì—ì„œ RMSNormê³¼ LayerNormì„ ë¹„êµí•˜ì„¸ìš”.</p>
<p><strong>ê³¼ì œ</strong>:
1. ë¬¸ì ìˆ˜ì¤€ ì–¸ì–´ ëª¨ë¸ êµ¬í˜„ (ë‹¤ìŒ ë¬¸ì ì˜ˆì¸¡)
2. ë‘ ë²„ì „ í›ˆë ¨: LayerNorm ì‚¬ìš©, RMSNorm ì‚¬ìš©
3. í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì‚¬ìš© (ì˜ˆ: Shakespeare, WikiText-2)
4. ì¸¡ì •:
   - ì—í¬í¬ë‹¹ í›ˆë ¨ ì‹œê°„
   - ìµœì¢… perplexity
   - ì¶”ë¡  ì†ë„
5. ë¶„ì„: RMSNormì´ ë” ë¹ ë¥´ë©´ì„œë„ LayerNorm ì„±ëŠ¥ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?</p>
<p><strong>ì‹œì‘ ì½”ë“œ</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TransformerLM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                 <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="s1">&#39;layer&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>

        <span class="c1"># ì •ê·œí™” ì„ íƒ</span>
        <span class="k">if</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s1">&#39;layer&#39;</span><span class="p">:</span>
            <span class="n">norm_cls</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s1">&#39;rms&#39;</span><span class="p">:</span>
            <span class="n">norm_cls</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">norm_cls</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch, seq_len)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">:]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="c1"># TODO: í›ˆë ¨ ë° ë²¤ì¹˜ë§ˆí‚¹ êµ¬í˜„</span>
</code></pre></div>

<h3 id="3">ì—°ìŠµ ë¬¸ì œ 3: ìŠ¤íƒ€ì¼ ì „ì´ë¥¼ ìœ„í•œ ì ì‘ì  ì¸ìŠ¤í„´ìŠ¤ ì •ê·œí™”<a class="header-link" href="#3" title="Permanent link">&para;</a></h3>
<p>AdaINì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ìŠ¤íƒ€ì¼ ì „ì´ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.</p>
<p><strong>ê³¼ì œ</strong>:
1. ì¤‘ê°„ì— AdaINì„ ì‚¬ìš©í•œ ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ êµ¬í˜„
2. ì¸ì½”ë”ë¡œ ì‚¬ì „ í›ˆë ¨ëœ VGG ë„¤íŠ¸ì›Œí¬ ì‚¬ìš© (ê°€ì¤‘ì¹˜ ê³ ì •)
3. ì´ë¯¸ì§€ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” ë””ì½”ë” í›ˆë ¨
4. ìŠ¤íƒ€ì¼ í†µê³„ë¥¼ ì „ì†¡í•˜ëŠ” AdaIN ë ˆì´ì–´ êµ¬í˜„
5. ì½˜í…ì¸  ë° ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ì—ì„œ í…ŒìŠ¤íŠ¸ (torchvision ë°ì´í„°ì…‹ ë˜ëŠ” ìì²´ ì´ë¯¸ì§€ ì‚¬ìš©)
6. ìŠ¤íƒ€ì¼í™”ëœ ì¶œë ¥ ì‹œê°í™”
7. <strong>ë³´ë„ˆìŠ¤</strong>: ì œì–´ ê°€ëŠ¥í•œ ìŠ¤íƒ€ì¼ ì „ì´ êµ¬í˜„ (ì½˜í…ì¸ /ìŠ¤íƒ€ì¼ í˜¼í•©ì„ ìœ„í•œ Î± íŒŒë¼ë¯¸í„°)</p>
<p><strong>ì‹œì‘ ì½”ë“œ</strong>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdaIN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">style</span><span class="p">):</span>
        <span class="c1"># TODO: AdaIN êµ¬í˜„</span>
        <span class="c1"># 1. ì½˜í…ì¸ ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°</span>
        <span class="c1"># 2. ìŠ¤íƒ€ì¼ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°</span>
        <span class="c1"># 3. ì½˜í…ì¸  ì •ê·œí™”, ìŠ¤íƒ€ì¼ í†µê³„ ì ìš©</span>
        <span class="k">pass</span>

<span class="k">class</span><span class="w"> </span><span class="nc">StyleTransferNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># ì¸ì½”ë”: VGG19 (ê³ ì •ë¨)</span>
        <span class="n">vgg</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">vgg</span><span class="o">.</span><span class="n">children</span><span class="p">())[:</span><span class="mi">21</span><span class="p">])</span>  <span class="c1"># relu4_1ê¹Œì§€</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># AdaIN ë ˆì´ì–´</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adain</span> <span class="o">=</span> <span class="n">AdaIN</span><span class="p">()</span>

        <span class="c1"># ë””ì½”ë”: ì¸ì½”ë”ì˜ ê±°ìš¸</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># TODO: ë””ì½”ë” êµ¬í˜„ (ì¸ì½”ë”ì˜ ì—­ìˆœ)</span>
            <span class="c1"># ConvTranspose2d ë˜ëŠ” Upsample + Conv2d ì‚¬ìš©</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">style</span><span class="p">):</span>
        <span class="c1"># TODO:</span>
        <span class="c1"># 1. ì½˜í…ì¸ ì™€ ìŠ¤íƒ€ì¼ ì¸ì½”ë”©</span>
        <span class="c1"># 2. AdaIN ì ìš©</span>
        <span class="c1"># 3. ë””ì½”ë”©</span>
        <span class="k">pass</span>

<span class="c1"># TODO: ì§€ê° ì†ì‹¤ì„ ì‚¬ìš©í•œ í›ˆë ¨ ë£¨í”„ êµ¬í˜„</span>
</code></pre></div>

<hr />
<h2 id="_5">ì°¸ê³  ìë£Œ<a class="header-link" href="#_5" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Batch Normalization</strong>:</li>
<li>Ioffe &amp; Szegedy (2015). "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift." ICML.</li>
<li>
<p>Santurkar et al. (2018). "How Does Batch Normalization Help Optimization?" NeurIPS.</p>
</li>
<li>
<p><strong>Layer Normalization</strong>:</p>
</li>
<li>
<p>Ba et al. (2016). "Layer Normalization." arXiv:1607.06450.</p>
</li>
<li>
<p><strong>Group Normalization</strong>:</p>
</li>
<li>
<p>Wu &amp; He (2018). "Group Normalization." ECCV.</p>
</li>
<li>
<p><strong>Instance Normalization</strong>:</p>
</li>
<li>
<p>Ulyanov et al. (2016). "Instance Normalization: The Missing Ingredient for Fast Stylization." arXiv:1607.08022.</p>
</li>
<li>
<p><strong>RMSNorm</strong>:</p>
</li>
<li>Zhang &amp; Sennrich (2019). "Root Mean Square Layer Normalization." NeurIPS.</li>
<li>
<p>Touvron et al. (2023). "LLaMA: Open and Efficient Foundation Language Models." arXiv:2302.13971.</p>
</li>
<li>
<p><strong>Spectral Normalization</strong>:</p>
</li>
<li>
<p>Miyato et al. (2018). "Spectral Normalization for Generative Adversarial Networks." ICLR.</p>
</li>
<li>
<p><strong>AdaIN</strong>:</p>
</li>
<li>
<p>Huang &amp; Belongie (2017). "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization." ICCV.</p>
</li>
<li>
<p><strong>ì¢…í•© ë¶„ì„</strong>:</p>
</li>
<li>Bjorck et al. (2018). "Understanding Batch Normalization." NeurIPS.</li>
<li>
<p>Goyal et al. (2017). "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour." arXiv:1706.02677.</p>
</li>
<li>
<p><strong>PyTorch ë¬¸ì„œ</strong>:</p>
</li>
<li>https://pytorch.org/docs/stable/nn.html#normalization-layers</li>
<li>https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html</li>
<li>https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html</li>
<li>
<p>https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html</p>
</li>
<li>
<p><strong>ì‹¤ìš© ê°€ì´ë“œ</strong>:</p>
<ul>
<li>He et al. (2019). "Bag of Tricks for Image Classification with Convolutional Neural Networks." CVPR.</li>
<li>Xiong et al. (2020). "On Layer Normalization in the Transformer Architecture." ICML.</li>
</ul>
</li>
</ol>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Deep_Learning/25_Optimizers.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">25. ì˜µí‹°ë§ˆì´ì €(Optimizers)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Deep_Learning/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Deep_Learning/27_TensorBoard.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">27. TensorBoard ì‹œê°í™”</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}