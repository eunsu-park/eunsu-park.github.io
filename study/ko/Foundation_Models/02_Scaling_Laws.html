{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scaling Laws - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Foundation_Models/">Foundation Models</a>
    <span class="separator">/</span>
    <span class="current">Scaling Laws</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>Scaling Laws</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Foundation_Models/01_Foundation_Model_Paradigm.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Foundation Model íŒ¨ëŸ¬ë‹¤ì„</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Foundation_Models/03_Emergent_Abilities.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">Emergent Abilities (ì°½ë°œì  ëŠ¥ë ¥)</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">í•™ìŠµ ëª©í‘œ</a></li>
<li><a href="#1-scaling-laws">1. Scaling Lawsë€?</a><ul>
<li><a href="#11">1.1 ì •ì˜</a></li>
<li><a href="#12">1.2 ì™œ ì¤‘ìš”í•œê°€?</a></li>
</ul>
</li>
<li><a href="#2-kaplan-scaling-laws-2020">2. Kaplan Scaling Laws (2020)</a><ul>
<li><a href="#21-openai">2.1 OpenAI ì´ˆê¸° ì—°êµ¬</a></li>
<li><a href="#22">2.2 ì‹œê°í™”</a></li>
<li><a href="#23-kaplan">2.3 Kaplan ë²•ì¹™ì— ë”°ë¥¸ ëª¨ë¸ ì„¤ê³„</a></li>
</ul>
</li>
<li><a href="#3-chinchilla-scaling-laws-2022">3. Chinchilla Scaling Laws (2022)</a><ul>
<li><a href="#31-deepmind">3.1 DeepMindì˜ ì¬ë°œê²¬</a></li>
<li><a href="#32-chinchilla-vs-gopher">3.2 Chinchilla vs Gopher ë¹„êµ</a></li>
<li><a href="#33">3.3 ê¸°ì¡´ ëª¨ë¸ë“¤ì˜ ìƒíƒœ</a></li>
</ul>
</li>
<li><a href="#4">4. ìˆ˜í•™ì  í‘œí˜„</a><ul>
<li><a href="#41-loss">4.1 Loss í•¨ìˆ˜</a></li>
<li><a href="#42-python-scaling-law">4.2 Pythonìœ¼ë¡œ Scaling Law ì‹œë®¬ë ˆì´ì…˜</a></li>
</ul>
</li>
<li><a href="#5">5. ì‹¤ì œ ëª¨ë¸ì—ì„œì˜ ì ìš©</a><ul>
<li><a href="#51-scaling">5.1 ì£¼ìš” ëª¨ë¸ Scaling ë¹„êµ</a></li>
<li><a href="#52-over-training">5.2 Over-trainingì˜ ì¥ì </a></li>
<li><a href="#53">5.3 ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸</a></li>
</ul>
</li>
<li><a href="#6-scaling-law">6. Scaling Lawì˜ í™•ì¥</a><ul>
<li><a href="#61-scaling">6.1 ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œì˜ Scaling</a></li>
<li><a href="#62-fine-tuning-scaling-laws">6.2 Fine-tuning Scaling Laws</a></li>
<li><a href="#63-inference-scaling-test-time-compute">6.3 Inference Scaling (Test-time Compute)</a></li>
</ul>
</li>
<li><a href="#7-scaling">7. Scalingì˜ í•œê³„</a><ul>
<li><a href="#71">7.1 ë¬¼ë¦¬ì  í•œê³„</a></li>
<li><a href="#72-scaling">7.2 Scaling ì™¸ì˜ ê°œì„  ë°©í–¥</a></li>
</ul>
</li>
<li><a href="#_2">ì •ë¦¬</a><ul>
<li><a href="#_3">í•µì‹¬ ê°œë…</a></li>
<li><a href="#_4">ì‹¤ë¬´ ê³µì‹</a></li>
<li><a href="#_5">ë‹¤ìŒ ë‹¨ê³„</a></li>
</ul>
</li>
<li><a href="#_6">ì°¸ê³  ìë£Œ</a><ul>
<li><a href="#_7">í•µì‹¬ ë…¼ë¬¸</a></li>
<li><a href="#_8">ì¶”ê°€ ìë£Œ</a></li>
</ul>
</li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="scaling-laws">Scaling Laws<a class="header-link" href="#scaling-laws" title="Permanent link">&para;</a></h1>
<h2 id="_1">í•™ìŠµ ëª©í‘œ<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>Scaling Lawsì˜ ê°œë…ê³¼ ìˆ˜í•™ì  í˜•íƒœ ì´í•´</li>
<li>Kaplan et al. vs Chinchilla ë²•ì¹™ ë¹„êµ</li>
<li>Compute-optimal í•™ìŠµ ì „ëµ ìŠµë“</li>
<li>ì‹¤ë¬´ì—ì„œì˜ Scaling Laws í™œìš©ë²• íŒŒì•…</li>
</ul>
<hr />
<h2 id="1-scaling-laws">1. Scaling Lawsë€?<a class="header-link" href="#1-scaling-laws" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 ì •ì˜<a class="header-link" href="#11" title="Permanent link">&para;</a></h3>
<p><strong>Scaling Laws</strong>ëŠ” ëª¨ë¸ì˜ <strong>íŒŒë¼ë¯¸í„° ìˆ˜(N)</strong>, <strong>ë°ì´í„° ì–‘(D)</strong>, <strong>ê³„ì‚°ëŸ‰(C)</strong>ê³¼ <strong>ì„±ëŠ¥(Loss)</strong>ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•˜ëŠ” ê²½í—˜ì  ë²•ì¹™ì…ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Scaling Laws í•µì‹¬ ê´€ê³„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Loss â‰ˆ A/N^Î± + B/D^Î² + E                                       â”‚
â”‚                                                                 â”‚
â”‚  N = ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜                                             â”‚
â”‚  D = í•™ìŠµ ë°ì´í„° í† í° ìˆ˜                                          â”‚
â”‚  C = ê³„ì‚°ëŸ‰ (FLOPs) â‰ˆ 6 Ã— N Ã— D                                  â”‚
â”‚  E = ë‹¬ì„± ë¶ˆê°€ëŠ¥í•œ ìµœì†Œ ì†ì‹¤ (entropy of data)                    â”‚
â”‚                                                                 â”‚
â”‚  í•µì‹¬ ë°œê²¬:                                                       â”‚
â”‚  â€¢ LossëŠ” N, Dì— ëŒ€í•´ Power Lawë¡œ ê°ì†Œ                            â”‚
â”‚  â€¢ Cë¥¼ ê³ ì •í•  ë•Œ, Nê³¼ Dì˜ ìµœì  ë¹„ìœ¨ì´ ì¡´ì¬                          â”‚
â”‚  â€¢ ë” í° ëª¨ë¸ì€ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ í™œìš©                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="12">1.2 ì™œ ì¤‘ìš”í•œê°€?<a class="header-link" href="#12" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Scaling Lawsì˜ ì‹¤ë¬´ì  ê°€ì¹˜:</span>

<span class="sd">1. ë¹„ìš© ì˜ˆì¸¡</span>
<span class="sd">   - í•™ìŠµ ì „ì— í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì¶”ì • ê°€ëŠ¥</span>
<span class="sd">   - &quot;10B ëª¨ë¸ì„ í•™ìŠµí•˜ë ¤ë©´ ì–¼ë§ˆë‚˜ í•„ìš”í•œê°€?&quot;</span>

<span class="sd">2. ìµœì  í• ë‹¹</span>
<span class="sd">   - ê³ ì •ëœ ì˜ˆì‚°ì—ì„œ ëª¨ë¸ í¬ê¸° vs ë°ì´í„° ì–‘ ê²°ì •</span>
<span class="sd">   - &quot;100M$ ìˆì„ ë•Œ, ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì •ì€?&quot;</span>

<span class="sd">3. ì„±ëŠ¥ ì˜ˆì¸¡</span>
<span class="sd">   - ì‘ì€ ëª¨ë¸ë¡œ í° ëª¨ë¸ì˜ ì„±ëŠ¥ ì¶”ì •</span>
<span class="sd">   - &quot;í˜„ì¬ 7B ëª¨ë¸, 70Bë¡œ í‚¤ìš°ë©´ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜?&quot;</span>

<span class="sd">4. ì—°êµ¬ ê³„íš</span>
<span class="sd">   - íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ê°€ í° ì—°êµ¬ ë°©í–¥ ê²°ì •</span>
<span class="sd">   - &quot;ë°ì´í„°ë¥¼ ëŠ˜ë¦´ê¹Œ, ëª¨ë¸ì„ í‚¤ìš¸ê¹Œ?&quot;</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<hr />
<h2 id="2-kaplan-scaling-laws-2020">2. Kaplan Scaling Laws (2020)<a class="header-link" href="#2-kaplan-scaling-laws-2020" title="Permanent link">&para;</a></h2>
<h3 id="21-openai">2.1 OpenAI ì´ˆê¸° ì—°êµ¬<a class="header-link" href="#21-openai" title="Permanent link">&para;</a></h3>
<p>Kaplan et al.ì˜ 2020ë…„ ë…¼ë¬¸ "Scaling Laws for Neural Language Models"ì—ì„œ ë°œê²¬í•œ ë²•ì¹™:</p>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kaplan Scaling Laws                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Loss vs Parameters                                          â”‚
â”‚     L(N) = (N_c / N)^Î±_N, where Î±_N â‰ˆ 0.076                     â”‚
â”‚                                                                 â”‚
â”‚  2. Loss vs Data                                                â”‚
â”‚     L(D) = (D_c / D)^Î±_D, where Î±_D â‰ˆ 0.095                     â”‚
â”‚                                                                 â”‚
â”‚  3. Loss vs Compute                                             â”‚
â”‚     L(C) = (C_c / C)^Î±_C, where Î±_C â‰ˆ 0.050                     â”‚
â”‚                                                                 â”‚
â”‚  í•µì‹¬ ì£¼ì¥:                                                       â”‚
â”‚  â€¢ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ê°€ì¥ ì¤‘ìš” (Î±_N &lt; Î±_D)                            â”‚
â”‚  â€¢ ê°™ì€ computeë©´, í° ëª¨ë¸ + ì ì€ ë°ì´í„°ê°€ ìœ ë¦¬                    â”‚
â”‚  â€¢ N âˆ C^0.73, D âˆ C^0.27 (Compute ìµœì  í• ë‹¹)                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="22">2.2 ì‹œê°í™”<a class="header-link" href="#22" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>   Loss (Log)
       â”‚
   3.5 â”œâ”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 100M params
       â”‚   â•²
   3.0 â”œâ”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  1B params
       â”‚       â•²
   2.5 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10B params
       â”‚           â•²
   2.0 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€100B params
       â”‚               â•²
   1.5 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  1T params (ì˜ˆì¸¡)
       â”‚
       â””â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â–¶
          10^18  19   20   21   22   23   Compute (FLOPs)

   â€¢ ì§ì„  = Power Law (ë¡œê·¸ ìŠ¤ì¼€ì¼ì—ì„œ ì„ í˜•)
   â€¢ ê¸°ìš¸ê¸° = Î±_C â‰ˆ 0.05
</code></pre></div>

<h3 id="23-kaplan">2.3 Kaplan ë²•ì¹™ì— ë”°ë¥¸ ëª¨ë¸ ì„¤ê³„<a class="header-link" href="#23-kaplan" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Kaplan ë²•ì¹™ ì ìš© ì˜ˆì‹œ:</span>

<span class="sd">Compute budget: 10^21 FLOPs</span>

<span class="sd">Kaplan ìµœì  í• ë‹¹:</span>
<span class="sd">- N âˆ C^0.73 â†’ N â‰ˆ 10^15 (ì•½ 1ì¡° íŒŒë¼ë¯¸í„°?!)</span>
<span class="sd">- D âˆ C^0.27 â†’ D â‰ˆ 10^9 (ì•½ 10ì–µ í† í°)</span>

<span class="sd">ë¬¸ì œì :</span>
<span class="sd">- ëª¨ë¸ì´ ë„ˆë¬´ ì»¤ì§€ê³  ë°ì´í„°ê°€ ë¶€ì¡±</span>
<span class="sd">- ì‹¤ì œ GPT-3 (175B)ëŠ” ì´ ë²•ì¹™ì„ ë”°ëì§€ë§Œ...</span>
<span class="sd">- Chinchillaê°€ ì´ë¥¼ ë°˜ë°•</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<hr />
<h2 id="3-chinchilla-scaling-laws-2022">3. Chinchilla Scaling Laws (2022)<a class="header-link" href="#3-chinchilla-scaling-laws-2022" title="Permanent link">&para;</a></h2>
<h3 id="31-deepmind">3.1 DeepMindì˜ ì¬ë°œê²¬<a class="header-link" href="#31-deepmind" title="Permanent link">&para;</a></h3>
<p>Hoffmann et al.ì˜ "Training Compute-Optimal Large Language Models"ëŠ” Kaplan ë²•ì¹™ì„ ìˆ˜ì •:</p>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Chinchilla Scaling Laws                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  í•µì‹¬ ë°œê²¬: ê¸°ì¡´ ëª¨ë¸ë“¤ì€ Under-trained!                           â”‚
â”‚                                                                 â”‚
â”‚  Compute-optimal scaling:                                        â”‚
â”‚  â€¢ N âˆ C^0.5  (íŒŒë¼ë¯¸í„° ìˆ˜)                                      â”‚
â”‚  â€¢ D âˆ C^0.5  (ë°ì´í„° í† í° ìˆ˜)                                   â”‚
â”‚  â€¢ ì¦‰, Nê³¼ Dë¥¼ ë™ì¼ ë¹„ìœ¨ë¡œ ì¦ê°€ì‹œì¼œì•¼ ìµœì                          â”‚
â”‚                                                                 â”‚
â”‚  ì‹¤ìš©ì  ê·œì¹™:                                                     â”‚
â”‚  D â‰ˆ 20 Ã— N  (í† í° ìˆ˜ â‰ˆ 20 Ã— íŒŒë¼ë¯¸í„° ìˆ˜)                        â”‚
â”‚                                                                 â”‚
â”‚  ì˜ˆì‹œ:                                                           â”‚
â”‚  â€¢ 1B ëª¨ë¸ â†’ 20B í† í° í•„ìš”                                       â”‚
â”‚  â€¢ 7B ëª¨ë¸ â†’ 140B í† í° í•„ìš”                                      â”‚
â”‚  â€¢ 70B ëª¨ë¸ â†’ 1.4T í† í° í•„ìš”                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="32-chinchilla-vs-gopher">3.2 Chinchilla vs Gopher ë¹„êµ<a class="header-link" href="#32-chinchilla-vs-gopher" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Chinchilla (70B) vs Gopher (280B)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ëª¨ë¸        â”‚ íŒŒë¼ë¯¸í„°  â”‚ í•™ìŠµ í† í°  â”‚ Compute   â”‚ ì„±ëŠ¥       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Gopher     â”‚ 280B     â”‚ 300B      â”‚ 5.0Ã—10^23 â”‚ ê¸°ì¤€        â”‚
â”‚  Chinchilla â”‚ 70B      â”‚ 1.4T      â”‚ 5.0Ã—10^23 â”‚ +10% í–¥ìƒ   â”‚
â”‚                                                                 â”‚
â”‚  ê²°ë¡ :                                                           â”‚
â”‚  â€¢ ê°™ì€ Computeë¡œ 4ë°° ì‘ì€ ëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥!                    â”‚
â”‚  â€¢ GopherëŠ” Under-trained (ë°ì´í„° ë¶€ì¡±)                          â”‚
â”‚  â€¢ ëª¨ë¸ í¬ê¸°ë§Œ í‚¤ìš°ë©´ ë¹„íš¨ìœ¨ì                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="33">3.3 ê¸°ì¡´ ëª¨ë¸ë“¤ì˜ ìƒíƒœ<a class="header-link" href="#33" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>             Tokens (D)
                â”‚
          10T   â”œ                               â— LLaMA 2 (2023)
                â”‚                           â—
           1T   â”œ                       â— Chinchilla (Optimal)
                â”‚                   â•±
         100B   â”œ               â•±       â— GPT-3 (Under-trained)
                â”‚           â•±
          10B   â”œ       â•±
                â”‚   â•±                   â— Gopher (Very Under-trained)
           1B   â”œâ”€
                â””â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â–¶
                   1B  10B 100B  1T  10T      Parameters (N)

             â•± = Compute-optimal frontier (D â‰ˆ 20N)

             ì ë“¤ì´ ì„  ì•„ë˜ì— ìˆìœ¼ë©´ Under-trained
</code></pre></div>

<hr />
<h2 id="4">4. ìˆ˜í•™ì  í‘œí˜„<a class="header-link" href="#4" title="Permanent link">&para;</a></h2>
<h3 id="41-loss">4.1 Loss í•¨ìˆ˜<a class="header-link" href="#41-loss" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Scaling Lawì˜ ìˆ˜í•™ì  í˜•íƒœ:</span>

<span class="sd">1. ë‹¨ì¼ ë³€ìˆ˜ Scaling</span>
<span class="sd">   L(N) = (N_c / N)^Î± + L_âˆ     # íŒŒë¼ë¯¸í„°ë§Œ ê³ ë ¤</span>
<span class="sd">   L(D) = (D_c / D)^Î² + L_âˆ     # ë°ì´í„°ë§Œ ê³ ë ¤</span>

<span class="sd">2. ê²°í•©ëœ Scaling (Chinchilla)</span>
<span class="sd">   L(N, D) = E + A/N^Î± + B/D^Î²</span>

<span class="sd">   where:</span>
<span class="sd">   - E â‰ˆ 1.69 (irreducible loss, ë°ì´í„° ì—”íŠ¸ë¡œí”¼)</span>
<span class="sd">   - A â‰ˆ 406.4</span>
<span class="sd">   - B â‰ˆ 410.7</span>
<span class="sd">   - Î± â‰ˆ 0.34</span>
<span class="sd">   - Î² â‰ˆ 0.28</span>

<span class="sd">3. Compute ê´€ì </span>
<span class="sd">   C â‰ˆ 6 Ã— N Ã— D  (FLOPs for training)</span>

<span class="sd">   ìµœì í™”: min L(N, D) subject to C = 6ND</span>

<span class="sd">   ê²°ê³¼: N* âˆ C^0.5, D* âˆ C^0.5</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<h3 id="42-python-scaling-law">4.2 Pythonìœ¼ë¡œ Scaling Law ì‹œë®¬ë ˆì´ì…˜<a class="header-link" href="#42-python-scaling-law" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">chinchilla_loss</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">A</span><span class="o">=</span><span class="mf">406.4</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mf">410.7</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.34</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.28</span><span class="p">,</span> <span class="n">E</span><span class="o">=</span><span class="mf">1.69</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Chinchilla Scaling Lawì— ë”°ë¥¸ Loss ê³„ì‚°</span>

<span class="sd">    Args:</span>
<span class="sd">        N: íŒŒë¼ë¯¸í„° ìˆ˜ (billions)</span>
<span class="sd">        D: í† í° ìˆ˜ (billions)</span>

<span class="sd">    Returns:</span>
<span class="sd">        ì˜ˆìƒ Loss (perplexityì˜ log)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">E</span> <span class="o">+</span> <span class="n">A</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">**</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">B</span> <span class="o">/</span> <span class="p">(</span><span class="n">D</span> <span class="o">**</span> <span class="n">beta</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">optimal_allocation</span><span class="p">(</span><span class="n">compute_budget</span><span class="p">,</span> <span class="n">flops_per_token</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ì£¼ì–´ì§„ Compute budgetì—ì„œ ìµœì ì˜ N, D ê³„ì‚°</span>

<span class="sd">    Args:</span>
<span class="sd">        compute_budget: ì´ FLOPs (ì˜ˆ: 10^23)</span>
<span class="sd">        flops_per_token: í† í°ë‹¹ FLOPs (ì•½ 6N)</span>

<span class="sd">    Returns:</span>
<span class="sd">        optimal_N, optimal_D (in billions)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Chinchilla ìµœì  ë¹„ìœ¨: D â‰ˆ 20N</span>
    <span class="c1"># C = 6 * N * D = 6 * N * 20N = 120 * N^2</span>
    <span class="c1"># N = sqrt(C / 120)</span>

    <span class="n">optimal_N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">compute_budget</span> <span class="o">/</span> <span class="mi">120</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span>  <span class="c1"># billions</span>
    <span class="n">optimal_D</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">*</span> <span class="n">optimal_N</span>                        <span class="c1"># billions</span>

    <span class="k">return</span> <span class="n">optimal_N</span><span class="p">,</span> <span class="n">optimal_D</span>

<span class="c1"># ì˜ˆì‹œ: 10^23 FLOPs ì˜ˆì‚°</span>
<span class="n">compute</span> <span class="o">=</span> <span class="mf">1e23</span>
<span class="n">N_opt</span><span class="p">,</span> <span class="n">D_opt</span> <span class="o">=</span> <span class="n">optimal_allocation</span><span class="p">(</span><span class="n">compute</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Compute budget: 10^23 FLOPs&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal parameters: </span><span class="si">{</span><span class="n">N_opt</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">B&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal tokens: </span><span class="si">{</span><span class="n">D_opt</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">B&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected loss: </span><span class="si">{</span><span class="n">chinchilla_loss</span><span class="p">(</span><span class="n">N_opt</span><span class="p">,</span><span class="w"> </span><span class="n">D_opt</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ì‹œê°í™”: N vs Dì— ë”°ë¥¸ Loss</span>
<span class="n">N_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>  <span class="c1"># 1B to 1000B</span>
<span class="n">D_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>  <span class="c1"># 1B to 10000B</span>

<span class="n">N_grid</span><span class="p">,</span> <span class="n">D_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">N_range</span><span class="p">,</span> <span class="n">D_range</span><span class="p">)</span>
<span class="n">Loss_grid</span> <span class="o">=</span> <span class="n">chinchilla_loss</span><span class="p">(</span><span class="n">N_grid</span><span class="p">,</span> <span class="n">D_grid</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">N_grid</span><span class="p">,</span> <span class="n">D_grid</span><span class="p">,</span> <span class="n">Loss_grid</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Parameters N (Billions)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tokens D (Billions)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Chinchilla Scaling Law: Loss Contours&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">N_range</span><span class="p">,</span> <span class="mi">20</span><span class="o">*</span><span class="n">N_range</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Optimal ratio (D=20N)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="5">5. ì‹¤ì œ ëª¨ë¸ì—ì„œì˜ ì ìš©<a class="header-link" href="#5" title="Permanent link">&para;</a></h2>
<h3 id="51-scaling">5.1 ì£¼ìš” ëª¨ë¸ Scaling ë¹„êµ<a class="header-link" href="#51-scaling" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ëª¨ë¸</th>
<th>íŒŒë¼ë¯¸í„° (N)</th>
<th>í† í° (D)</th>
<th>D/N ë¹„ìœ¨</th>
<th>ìƒíƒœ</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-3</td>
<td>175B</td>
<td>300B</td>
<td>1.7</td>
<td>Under-trained</td>
</tr>
<tr>
<td>Gopher</td>
<td>280B</td>
<td>300B</td>
<td>1.1</td>
<td>Very Under-trained</td>
</tr>
<tr>
<td>Chinchilla</td>
<td>70B</td>
<td>1.4T</td>
<td>20</td>
<td>Optimal</td>
</tr>
<tr>
<td>LLaMA 1</td>
<td>65B</td>
<td>1.4T</td>
<td>21.5</td>
<td>Near-optimal</td>
</tr>
<tr>
<td>LLaMA 2</td>
<td>70B</td>
<td>2T</td>
<td>28.6</td>
<td>Slight Over-trained</td>
</tr>
<tr>
<td>Mistral</td>
<td>7B</td>
<td>8T (ì¶”ì •)</td>
<td>~1000</td>
<td>Over-trained</td>
</tr>
</tbody>
</table>
<h3 id="52-over-training">5.2 Over-trainingì˜ ì¥ì <a class="header-link" href="#52-over-training" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Over-training ì „ëµ (LLaMA 2, Mistral)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ChinchillaëŠ” &quot;í•™ìŠµ&quot; ìµœì ì´ì§€ë§Œ, &quot;ë°°í¬&quot;ëŠ” ë‹¤ë¦„!                    â”‚
â”‚                                                                 â”‚
â”‚  ë°°í¬ ê´€ì ì—ì„œ:                                                   â”‚
â”‚  â€¢ ì¶”ë¡  ë¹„ìš© âˆ N (ëª¨ë¸ í¬ê¸°)                                      â”‚
â”‚  â€¢ í•™ìŠµì€ í•œ ë²ˆ, ì¶”ë¡ ì€ ìˆ˜ì¡° ë²ˆ                                   â”‚
â”‚                                                                 â”‚
â”‚  ë”°ë¼ì„œ:                                                         â”‚
â”‚  â€¢ ì‘ì€ ëª¨ë¸ + ë§ì€ ë°ì´í„° = ì¶”ë¡  íš¨ìœ¨ì                            â”‚
â”‚  â€¢ &quot;Inference-optimal&quot; â‰  &quot;Compute-optimal&quot;                      â”‚
â”‚                                                                 â”‚
â”‚  LLaMA 2 ì „ëµ:                                                   â”‚
â”‚  â€¢ 70B ëª¨ë¸ì— 2T í† í° (D/N â‰ˆ 29)                                 â”‚
â”‚  â€¢ Chinchillaë³´ë‹¤ ë” ì˜¤ë˜ í•™ìŠµ                                    â”‚
â”‚  â€¢ ê²°ê³¼: ì‘ì€ ëª¨ë¸ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥                                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="53">5.3 ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸<a class="header-link" href="#53" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">ì‹¤ë¬´ì—ì„œì˜ Scaling ì „ëµ:</span>

<span class="sd">1. ì—°êµ¬/ì‹¤í—˜ ë‹¨ê³„ (Compute-limited)</span>
<span class="sd">   - Chinchilla ê·œì¹™ ë”°ë¥´ê¸°: D â‰ˆ 20N</span>
<span class="sd">   - ì‘ì€ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ë°˜ë³µ</span>

<span class="sd">2. í”„ë¡œë•ì…˜ ë°°í¬ (Inference-limited)</span>
<span class="sd">   - Over-training ê³ ë ¤: D &gt; 20N</span>
<span class="sd">   - ì‘ì€ ëª¨ë¸ + ë§ì€ ë°ì´í„°</span>
<span class="sd">   - ì˜ˆ: Mistral 7B &gt; LLaMA 2 13B (ì¼ë¶€ íƒœìŠ¤í¬)</span>

<span class="sd">3. ì˜ˆì‚° ê³„íš</span>
<span class="sd">   - C = 6 * N * D (FLOPs)</span>
<span class="sd">   - GPU hours â‰ˆ C / (GPU_FLOPS * utilization)</span>
<span class="sd">   - ì˜ˆ: A100 80GB = ~300 TFLOPS (ì‹¤íš¨)</span>

<span class="sd">4. ìŠ¤ì¼€ì¼ì—… ì „ëµ</span>
<span class="sd">   - ì‘ì€ ëª¨ë¸ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</span>
<span class="sd">   - Scaling Lawë¡œ í° ëª¨ë¸ ì„±ëŠ¥ ì˜ˆì¸¡</span>
<span class="sd">   - ê²€ì¦ í›„ ëŒ€ê·œëª¨ í•™ìŠµ ì‹¤í–‰</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">estimate_training_cost</span><span class="p">(</span><span class="n">N_billions</span><span class="p">,</span> <span class="n">D_billions</span><span class="p">,</span> <span class="n">gpu_price_per_hour</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    í•™ìŠµ ë¹„ìš© ì¶”ì •</span>

<span class="sd">    Args:</span>
<span class="sd">        N_billions: íŒŒë¼ë¯¸í„° ìˆ˜ (B)</span>
<span class="sd">        D_billions: í† í° ìˆ˜ (B)</span>
<span class="sd">        gpu_price_per_hour: GPU ì‹œê°„ë‹¹ ë¹„ìš© (USD)</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: ì˜ˆìƒ ë¹„ìš© ì •ë³´</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">N_billions</span> <span class="o">*</span> <span class="mf">1e9</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">D_billions</span> <span class="o">*</span> <span class="mf">1e9</span>

    <span class="c1"># 6ND FLOPs for training</span>
    <span class="n">total_flops</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">D</span>

    <span class="c1"># A100 80GB: ~300 TFLOPS effective</span>
    <span class="n">gpu_tflops</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">gpu_flops</span> <span class="o">=</span> <span class="n">gpu_tflops</span> <span class="o">*</span> <span class="mf">1e12</span>

    <span class="c1"># ì´ GPU ì‹œê°„</span>
    <span class="n">total_gpu_seconds</span> <span class="o">=</span> <span class="n">total_flops</span> <span class="o">/</span> <span class="n">gpu_flops</span>
    <span class="n">total_gpu_hours</span> <span class="o">=</span> <span class="n">total_gpu_seconds</span> <span class="o">/</span> <span class="mi">3600</span>

    <span class="c1"># ë¹„ìš©</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="n">total_gpu_hours</span> <span class="o">*</span> <span class="n">gpu_price_per_hour</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;total_flops&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_flops</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;gpu_hours&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_gpu_hours</span><span class="si">:</span><span class="s2">,.0f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cost_usd&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;$</span><span class="si">{</span><span class="n">total_cost</span><span class="si">:</span><span class="s2">,.0f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cost_with_8gpus&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;$</span><span class="si">{</span><span class="n">total_cost</span><span class="o">/</span><span class="mi">8</span><span class="si">:</span><span class="s2">,.0f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">total_gpu_hours</span><span class="o">/</span><span class="mi">8</span><span class="si">:</span><span class="s2">,.0f</span><span class="si">}</span><span class="s2"> hours)&quot;</span>
    <span class="p">}</span>

<span class="c1"># ì˜ˆì‹œ: LLaMA 2 7B í•™ìŠµ ë¹„ìš©</span>
<span class="n">cost_7b</span> <span class="o">=</span> <span class="n">estimate_training_cost</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LLaMA 2 7B (2T tokens):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cost_7b</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="6-scaling-law">6. Scaling Lawì˜ í™•ì¥<a class="header-link" href="#6-scaling-law" title="Permanent link">&para;</a></h2>
<h3 id="61-scaling">6.1 ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œì˜ Scaling<a class="header-link" href="#61-scaling" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ë„ë©”ì¸ë³„ Scaling Laws                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Vision (ViT):                                                  â”‚
â”‚  â€¢ ë¹„ìŠ·í•œ power law ê´€ì°°                                         â”‚
â”‚  â€¢ Î± â‰ˆ 0.05 (Languageë³´ë‹¤ ì‘ìŒ)                                 â”‚
â”‚  â€¢ ë°ì´í„° í’ˆì§ˆì´ ë” ì¤‘ìš”                                          â”‚
â”‚                                                                 â”‚
â”‚  Multimodal (CLIP):                                             â”‚
â”‚  â€¢ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§ ë³„ë„ ìµœì í™” í•„ìš”                        â”‚
â”‚  â€¢ ë°ì´í„° ìŒì˜ í’ˆì§ˆì´ í•µì‹¬                                        â”‚
â”‚                                                                 â”‚
â”‚  Code:                                                          â”‚
â”‚  â€¢ ë” ê°€íŒŒë¥¸ scaling (Î± ë” í¼)                                   â”‚
â”‚  â€¢ ê³ í’ˆì§ˆ ì½”ë“œ ë°ì´í„°ê°€ í¬ì†Œ                                       â”‚
â”‚                                                                 â”‚
â”‚  Reasoning:                                                     â”‚
â”‚  â€¢ Emergent behaviorë¡œ ì¸í•´ smoothí•˜ì§€ ì•ŠìŒ                      â”‚
â”‚  â€¢ íŠ¹ì • ì„ê³„ì ì—ì„œ ê°‘ìê¸° ì„±ëŠ¥ í–¥ìƒ                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div>

<h3 id="62-fine-tuning-scaling-laws">6.2 Fine-tuning Scaling Laws<a class="header-link" href="#62-fine-tuning-scaling-laws" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Fine-tuningì—ë„ Scaling Law ì ìš©:</span>

<span class="sd">ì—°êµ¬ ê²°ê³¼:</span>
<span class="sd">- ë” í° base model = ë” ì ì€ fine-tuning ë°ì´í„° í•„ìš”</span>
<span class="sd">- Fine-tuning ë°ì´í„°ë„ power lawë¡œ ìŠ¤ì¼€ì¼</span>
<span class="sd">- LoRA ë“± PEFTë„ ìœ ì‚¬í•œ íŒ¨í„´</span>

<span class="sd">ì‹¤ìš©ì  ê·œì¹™:</span>
<span class="sd">- Base ëª¨ë¸ í¬ê¸° Ã— 10 = Fine-tuning ë°ì´í„° ì–‘ (ëŒ€ëµ)</span>
<span class="sd">- 7B ëª¨ë¸: ~1K-10K examples</span>
<span class="sd">- 70B ëª¨ë¸: ~100-1K examples (ê°™ì€ ì„±ëŠ¥ ë‹¬ì„± ì‹œ)</span>

<span class="sd">ë‹¨, í’ˆì§ˆ &gt; ì–‘:</span>
<span class="sd">- ê³ í’ˆì§ˆ ë°ì´í„° 100ê°œ &gt; ì €í’ˆì§ˆ ë°ì´í„° 10,000ê°œ</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<h3 id="63-inference-scaling-test-time-compute">6.3 Inference Scaling (Test-time Compute)<a class="header-link" href="#63-inference-scaling-test-time-compute" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span>
<span class="err">â”‚</span><span class="w">                    </span><span class="nx">Inference</span><span class="w"> </span><span class="nx">Scaling</span><span class="w"> </span><span class="p">(</span><span class="nx">o1</span><span class="w"> </span><span class="nx">ë°©ì‹</span><span class="p">)</span><span class="w">                    </span><span class="err">â”‚</span>
<span class="err">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">ì „í†µì </span><span class="w"> </span><span class="nx">Scaling</span><span class="p">:</span><span class="w"> </span><span class="nx">í•™ìŠµ</span><span class="w"> </span><span class="nx">ì‹œ</span><span class="w"> </span><span class="nx">compute</span><span class="w"> </span><span class="nx">ì¦ê°€</span><span class="w">                             </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">Inference</span><span class="w"> </span><span class="nx">Scaling</span><span class="p">:</span><span class="w"> </span><span class="nx">ì¶”ë¡ </span><span class="w"> </span><span class="nx">ì‹œ</span><span class="w"> </span><span class="nx">compute</span><span class="w"> </span><span class="nx">ì¦ê°€</span><span class="w">                         </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">ë°©ë²•</span><span class="p">:</span><span class="w">                                                           </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Chain</span><span class="o">-</span><span class="nx">of</span><span class="o">-</span><span class="nx">Thought</span><span class="w"> </span><span class="nx">ê¸¸ê²Œ</span><span class="w"> </span><span class="nx">ìƒì„±</span><span class="w">                                    </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">ì—¬ëŸ¬</span><span class="w"> </span><span class="nx">ë‹µë³€</span><span class="w"> </span><span class="nx">ìƒì„±</span><span class="w"> </span><span class="nx">í›„</span><span class="w"> </span><span class="nx">íˆ¬í‘œ</span><span class="w"> </span><span class="p">(</span><span class="k">Self</span><span class="o">-</span><span class="nx">consistency</span><span class="p">)</span><span class="w">                      </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Tree</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">Thoughts</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">Beam</span><span class="w"> </span><span class="nx">Search</span><span class="w">                               </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">Verification</span><span class="o">/</span><span class="nx">Refinement</span><span class="w"> </span><span class="nx">ë°˜ë³µ</span><span class="w">                                  </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="nx">íš¨ê³¼</span><span class="p">:</span><span class="w">                                                           </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">ì–´ë ¤ìš´</span><span class="w"> </span><span class="nx">ë¬¸ì œì—ì„œ</span><span class="w"> </span><span class="nx">ì •í™•ë„</span><span class="w"> </span><span class="nx">í¬ê²Œ</span><span class="w"> </span><span class="nx">í–¥ìƒ</span><span class="w">                                </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">í•™ìŠµ</span><span class="w"> </span><span class="nx">ì—†ì´</span><span class="w"> </span><span class="nx">ì„±ëŠ¥</span><span class="w"> </span><span class="nx">í–¥ìƒ</span><span class="w"> </span><span class="nx">ê°€ëŠ¥</span><span class="w">                                       </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">  </span><span class="err">â€¢</span><span class="w"> </span><span class="nx">GPT</span><span class="o">-</span><span class="mi">4</span><span class="w"> </span><span class="err">â†’</span><span class="w"> </span><span class="nx">o1ìœ¼ë¡œì˜</span><span class="w"> </span><span class="nx">íŒ¨ëŸ¬ë‹¤ì„</span><span class="w"> </span><span class="p">(</span><span class="nx">ì¶”ë¡ </span><span class="w"> </span><span class="nx">ì‹œê°„</span><span class="w"> </span><span class="nx">scaling</span><span class="p">)</span><span class="w">                   </span><span class="err">â”‚</span>
<span class="err">â”‚</span><span class="w">                                                                 </span><span class="err">â”‚</span>
<span class="err">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span>
</code></pre></div>

<hr />
<h2 id="7-scaling">7. Scalingì˜ í•œê³„<a class="header-link" href="#7-scaling" title="Permanent link">&para;</a></h2>
<h3 id="71">7.1 ë¬¼ë¦¬ì  í•œê³„<a class="header-link" href="#71" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Scalingì˜ ì‹¤ì œ í•œê³„:</span>

<span class="sd">1. ë°ì´í„° í•œê³„</span>
<span class="sd">   - ì¸í„°ë„· í…ìŠ¤íŠ¸ ì´ëŸ‰: ~10-50T í† í°</span>
<span class="sd">   - ê³ í’ˆì§ˆ ë°ì´í„°ëŠ” í›¨ì”¬ ì ìŒ</span>
<span class="sd">   - 2024ë…„ ê¸°ì¤€, ë°ì´í„° ê³ ê°ˆ ë…¼ì˜ ì‹œì‘</span>

<span class="sd">2. ì»´í“¨íŠ¸ í•œê³„</span>
<span class="sd">   - ì „ë ¥ ì†Œë¹„ (MW ë‹¨ìœ„)</span>
<span class="sd">   - ë°˜ë„ì²´ ê³µê¸‰</span>
<span class="sd">   - ë¹„ìš© (ìˆ˜ì‹­ì–µ ë‹¬ëŸ¬)</span>

<span class="sd">3. ì•„í‚¤í…ì²˜ í•œê³„</span>
<span class="sd">   - Attentionì˜ O(nÂ²) ë³µì¡ë„</span>
<span class="sd">   - Memory bandwidth bottleneck</span>
<span class="sd">   - Communication overhead in distributed training</span>

<span class="sd">4. ìˆ˜ìµ ì²´ê° (Diminishing Returns)</span>
<span class="sd">   - Î± â‰ˆ 0.05ëŠ” 10ë°° compute â†’ ~12% loss ê°ì†Œ</span>
<span class="sd">   - ì ì  ë” í° íˆ¬ì í•„ìš”</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<h3 id="72-scaling">7.2 Scaling ì™¸ì˜ ê°œì„  ë°©í–¥<a class="header-link" href="#72-scaling" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ë°©í–¥</th>
<th>ì„¤ëª…</th>
<th>ì˜ˆì‹œ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Architecture</strong></td>
<td>ë” íš¨ìœ¨ì ì¸ êµ¬ì¡°</td>
<td>Mamba, RWKV, Hyena</td>
</tr>
<tr>
<td><strong>Data Quality</strong></td>
<td>ê³ í’ˆì§ˆ ë°ì´í„° íë ˆì´ì…˜</td>
<td>Phi, LIMA</td>
</tr>
<tr>
<td><strong>Synthetic Data</strong></td>
<td>AIë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±</td>
<td>Self-Instruct</td>
</tr>
<tr>
<td><strong>Efficient Training</strong></td>
<td>í•™ìŠµ íš¨ìœ¨ ê°œì„ </td>
<td>Flash Attention, ZeRO</td>
</tr>
<tr>
<td><strong>Test-time Compute</strong></td>
<td>ì¶”ë¡  ì‹œ ê³„ì‚° ì¦ê°€</td>
<td>CoT, Self-consistency, o1</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="_2">ì •ë¦¬<a class="header-link" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="_3">í•µì‹¬ ê°œë…<a class="header-link" href="#_3" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Scaling Laws</strong>: íŒŒë¼ë¯¸í„°, ë°ì´í„°, ê³„ì‚°ëŸ‰ê³¼ ì„±ëŠ¥ì˜ power law ê´€ê³„</li>
<li><strong>Kaplan</strong>: Nì„ ìš°ì„ ì‹œ (í° ëª¨ë¸ + ì ì€ ë°ì´í„°)</li>
<li><strong>Chinchilla</strong>: Nê³¼ D ê· í˜• (D â‰ˆ 20N)</li>
<li><strong>Over-training</strong>: ì¶”ë¡  íš¨ìœ¨ì„ ìœ„í•´ ì‘ì€ ëª¨ë¸ì„ ë” ì˜¤ë˜ í•™ìŠµ</li>
</ul>
<h3 id="_4">ì‹¤ë¬´ ê³µì‹<a class="header-link" href="#_4" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>Compute-optimal: D â‰ˆ 20 Ã— N (í† í°)
Training FLOPs: C â‰ˆ 6 Ã— N Ã— D
Inference-optimal: ì‘ì€ N, í° D
</code></pre></div>

<h3 id="_5">ë‹¤ìŒ ë‹¨ê³„<a class="header-link" href="#_5" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="03_Emergent_Abilities.md">03_Emergent_Abilities.md</a>: ê·œëª¨ì— ë”°ë¥¸ ì°½ë°œì  ëŠ¥ë ¥</li>
<li><a href="08_LLaMA_Family.md">08_LLaMA_Family.md</a>: Scaling ì ìš© ì‚¬ë¡€ (LLaMA)</li>
</ul>
<hr />
<h2 id="_6">ì°¸ê³  ìë£Œ<a class="header-link" href="#_6" title="Permanent link">&para;</a></h2>
<h3 id="_7">í•µì‹¬ ë…¼ë¬¸<a class="header-link" href="#_7" title="Permanent link">&para;</a></h3>
<ul>
<li>Kaplan et al. (2020). "Scaling Laws for Neural Language Models"</li>
<li>Hoffmann et al. (2022). "Training Compute-Optimal Large Language Models" (Chinchilla)</li>
<li>Touvron et al. (2023). "LLaMA 2: Open Foundation and Fine-Tuned Chat Models"</li>
</ul>
<h3 id="_8">ì¶”ê°€ ìë£Œ<a class="header-link" href="#_8" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://epochai.org/trends">Epoch AI Compute Trends</a></li>
<li><a href="https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/ai-scaling-calculator">AI Scaling Calculator</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Foundation_Models/01_Foundation_Model_Paradigm.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Foundation Model íŒ¨ëŸ¬ë‹¤ì„</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Foundation_Models/03_Emergent_Abilities.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">Emergent Abilities (ì°½ë°œì  ëŠ¥ë ¥)</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}