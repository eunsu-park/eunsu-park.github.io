{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>06. Pre-training μΈν”„λΌ - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">π </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">π’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        ν•κµ­μ–΄
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">β€οΈ</span>
                    <span class="theme-icon dark">π™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Foundation_Models/">Foundation Models</a>
    <span class="separator">/</span>
    <span class="current">06. Pre-training μΈν”„λΌ</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>06. Pre-training μΈν”„λΌ</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Foundation_Models/05_Data_Curation.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">05. λ°μ΄ν„° νλ μ΄μ…</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">π”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">π“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Foundation_Models/07_Tokenization_Deep_Dive.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">07. Tokenization μ‹¬ν™”</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">κ°μ”</a></li>
<li><a href="#1">1. λ¶„μ‚° ν•™μµ ν¨λ¬λ‹¤μ„</a><ul>
<li><a href="#11">1.1 λ³‘λ ¬ν™” μ „λµ κ°μ”</a></li>
<li><a href="#12">1.2 λ©”λ¨λ¦¬ λ¶„μ„</a></li>
</ul>
</li>
<li><a href="#2-fsdp-fully-sharded-data-parallel">2. FSDP (Fully Sharded Data Parallel)</a><ul>
<li><a href="#21-fsdp">2.1 FSDP κ°λ…</a></li>
<li><a href="#22-pytorch-fsdp">2.2 PyTorch FSDP κµ¬ν„</a></li>
</ul>
</li>
<li><a href="#3-deepspeed-zero">3. DeepSpeed ZeRO</a><ul>
<li><a href="#31-zero">3.1 ZeRO λ‹¨κ³„λ³„ λΉ„κµ</a></li>
<li><a href="#32-deepspeed">3.2 DeepSpeed μ„¤μ •</a></li>
<li><a href="#33-deepspeed">3.3 DeepSpeed ν•™μµ μ½”λ“</a></li>
</ul>
</li>
<li><a href="#4-activation-checkpointing-gradient-checkpointing">4. Activation Checkpointing (Gradient Checkpointing)</a><ul>
<li><a href="#41">4.1 κ°λ…</a></li>
<li><a href="#42">4.2 κµ¬ν„</a></li>
</ul>
</li>
<li><a href="#5">5. ν•™μµ μ•μ •μ„±</a><ul>
<li><a href="#51-loss-spike">5.1 Loss Spike λ€μ‘</a></li>
<li><a href="#52">5.2 μ²΄ν¬ν¬μΈνΈ μ „λµ</a></li>
</ul>
</li>
<li><a href="#6">6. ν•™μµλ¥  μ¤μΌ€μ¤„λ§</a><ul>
<li><a href="#61-warmup-cosine-decay">6.1 Warmup + Cosine Decay</a></li>
</ul>
</li>
<li><a href="#7">7. μ‹¤μµ: μ™„μ „ν• ν•™μµ μ¤ν¬λ¦½νΈ</a></li>
<li><a href="#_2">μ°Έκ³  μλ£</a><ul>
<li><a href="#_3">λ¬Έμ„</a></li>
<li><a href="#_4">λ…Όλ¬Έ</a></li>
<li><a href="#_5">κ΄€λ ¨ λ μ¨</a></li>
</ul>
</li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="06-pre-training">06. Pre-training μΈν”„λΌ<a class="header-link" href="#06-pre-training" title="Permanent link">&para;</a></h1>
<h2 id="_1">κ°μ”<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<p>λ€κ·λ¨ Foundation Model ν•™μµμ€ μμ² κ°μ GPUμ—μ„ μμ£Όμ—μ„ μκ°μ›”κ°„ μ§„ν–‰λ©λ‹λ‹¤. μ΄ λ μ¨μ—μ„λ” λ¶„μ‚° ν•™μµ μ „λµ, λ©”λ¨λ¦¬ μµμ ν™”, ν•™μµ μ•μ •μ„± κΈ°λ²•μ„ λ‹¤λ£Ήλ‹λ‹¤.</p>
<hr />
<h2 id="1">1. λ¶„μ‚° ν•™μµ ν¨λ¬λ‹¤μ„<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 λ³‘λ ¬ν™” μ „λµ κ°μ”<a class="header-link" href="#11" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                     λ¶„μ‚° ν•™μµ ν¨λ¬λ‹¤μ„                            β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚                                                                  β”‚
β”‚  Data Parallelism (DP)         Tensor Parallelism (TP)          β”‚
β”‚  β”β”€β”€β”€β”€β”€β” β”β”€β”€β”€β”€β”€β”               β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”              β”‚
β”‚  β”‚GPU 0β”‚ β”‚GPU 1β”‚               β”‚   W = [W1 | W2]  β”‚              β”‚
β”‚  β”‚Modelβ”‚ β”‚Modelβ”‚               β”‚GPU0    GPU1      β”‚              β”‚
β”‚  β”‚Data1β”‚ β”‚Data2β”‚               β”‚ W1      W2       β”‚              β”‚
β”‚  β””β”€β”€β”€β”€β”€β” β””β”€β”€β”€β”€β”€β”               β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”              β”‚
β”‚  λ™μΌ λ¨λΈ, λ‹¤λ¥Έ λ°μ΄ν„°         λ μ΄μ–΄λ¥Ό GPUκ°„ λ¶„ν•                β”‚
β”‚                                                                  β”‚
β”‚  Pipeline Parallelism (PP)     Sequence Parallelism (SP)        β”‚
β”‚  β”β”€β”€β”€β”€β”€β” β”β”€β”€β”€β”€β”€β”               β”β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”             β”‚
β”‚  β”‚GPU 0β”‚ β”‚GPU 1β”‚               β”‚ S1 β”‚ S2 β”‚ S3 β”‚ S4 β”‚             β”‚
β”‚  β”‚L1-L6β”‚β†’β”‚L7-12β”‚               β”‚GPU0β”‚GPU1β”‚GPU2β”‚GPU3β”‚             β”‚
β”‚  β””β”€β”€β”€β”€β”€β” β””β”€β”€β”€β”€β”€β”               β””β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”             β”‚
β”‚  λ μ΄μ–΄λ¥Ό μμ°¨ λ¶„ν•              μ‹ν€€μ¤λ¥Ό GPUκ°„ λ¶„ν•                β”‚
β”‚                                                                  β”‚
β”‚  3D Parallelism: DP + TP + PP μ΅°ν•©                              β”‚
β”‚                                                                  β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
</code></pre></div>

<h3 id="12">1.2 λ©”λ¨λ¦¬ λ¶„μ„<a class="header-link" href="#12" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">estimate_training_memory</span><span class="p">(</span>
    <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>  <span class="c1"># νλΌλ―Έν„° μ</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dtype_bytes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># fp16/bf16 = 2, fp32 = 4</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;adam&#39;</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ν•™μµ μ‹ GPU λ©”λ¨λ¦¬ μ¶”μ •</span>

<span class="sd">    λ©”λ¨λ¦¬ κµ¬μ„±:</span>
<span class="sd">    1. Model Parameters</span>
<span class="sd">    2. Gradients</span>
<span class="sd">    3. Optimizer States</span>
<span class="sd">    4. Activations (forward pass)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># 1. λ¨λΈ νλΌλ―Έν„°</span>
    <span class="n">param_memory</span> <span class="o">=</span> <span class="n">num_params</span> <span class="o">*</span> <span class="n">dtype_bytes</span>

    <span class="c1"># 2. Gradients (νλΌλ―Έν„°μ™€ λ™μΌ)</span>
    <span class="n">grad_memory</span> <span class="o">=</span> <span class="n">num_params</span> <span class="o">*</span> <span class="n">dtype_bytes</span>

    <span class="c1"># 3. Optimizer States</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;adam&#39;</span><span class="p">:</span>
        <span class="c1"># Adam: momentum(fp32) + variance(fp32)</span>
        <span class="n">optimizer_memory</span> <span class="o">=</span> <span class="n">num_params</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># 8 bytes per param</span>
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;sgd&#39;</span><span class="p">:</span>
        <span class="n">optimizer_memory</span> <span class="o">=</span> <span class="n">num_params</span> <span class="o">*</span> <span class="mi">4</span>  <span class="c1"># momentum only</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer_memory</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 4. Activations (κ·Όμ‚¬μΉ)</span>
    <span class="c1"># κ° λ μ΄μ–΄: attention + FFN activations</span>
    <span class="n">bytes_per_token</span> <span class="o">=</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">dtype_bytes</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># κ·Όμ‚¬</span>
    <span class="n">activation_memory</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_len</span> <span class="o">*</span> <span class="n">bytes_per_token</span> <span class="o">*</span> <span class="n">num_layers</span>

    <span class="c1"># Activation checkpointing μ‹ 1/sqrt(L) λ΅ κ°μ†</span>

    <span class="n">total</span> <span class="o">=</span> <span class="n">param_memory</span> <span class="o">+</span> <span class="n">grad_memory</span> <span class="o">+</span> <span class="n">optimizer_memory</span> <span class="o">+</span> <span class="n">activation_memory</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;parameters_gb&#39;</span><span class="p">:</span> <span class="n">param_memory</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s1">&#39;gradients_gb&#39;</span><span class="p">:</span> <span class="n">grad_memory</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s1">&#39;optimizer_gb&#39;</span><span class="p">:</span> <span class="n">optimizer_memory</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s1">&#39;activations_gb&#39;</span><span class="p">:</span> <span class="n">activation_memory</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s1">&#39;total_gb&#39;</span><span class="p">:</span> <span class="n">total</span> <span class="o">/</span> <span class="mf">1e9</span>
    <span class="p">}</span>


<span class="c1"># μμ‹: 7B λ¨λΈ</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">estimate_training_memory</span><span class="p">(</span>
    <span class="n">num_params</span><span class="o">=</span><span class="mf">7e9</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">seq_len</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;7B λ¨λΈ λ©”λ¨λ¦¬ μ¶”μ •:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">memory</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

<span class="c1"># μ¶λ ¥:</span>
<span class="c1"># parameters_gb: 14.0 GB</span>
<span class="c1"># gradients_gb: 14.0 GB</span>
<span class="c1"># optimizer_gb: 56.0 GB</span>
<span class="c1"># activations_gb: ~21.5 GB (batch_size=4)</span>
<span class="c1"># total_gb: ~105.5 GB</span>
</code></pre></div>

<hr />
<h2 id="2-fsdp-fully-sharded-data-parallel">2. FSDP (Fully Sharded Data Parallel)<a class="header-link" href="#2-fsdp-fully-sharded-data-parallel" title="Permanent link">&para;</a></h2>
<h3 id="21-fsdp">2.1 FSDP κ°λ…<a class="header-link" href="#21-fsdp" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”</span>
<span class="err">β”‚</span><span class="w">                      </span><span class="n">FSDP</span><span class="w"> </span><span class="n">λ™μ‘</span><span class="w"> </span><span class="n">μ›λ¦¬</span><span class="w">                         </span><span class="err">β”‚</span>
<span class="err">β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤</span>
<span class="err">β”‚</span><span class="w">                                                             </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">κΈ°μ΅΄</span><span class="w"> </span><span class="n">DDP</span><span class="o">:</span><span class="w">                                                  </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">GPU</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="n">Full</span><span class="w"> </span><span class="n">Model</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">[</span><span class="n">Data</span><span class="w"> </span><span class="mi">0</span><span class="p">]</span><span class="w">                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">GPU</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="n">Full</span><span class="w"> </span><span class="n">Model</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">[</span><span class="n">Data</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w">                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="err">β†’</span><span class="w"> </span><span class="n">κ°</span><span class="w"> </span><span class="n">GPUμ—</span><span class="w"> </span><span class="n">μ „μ²΄</span><span class="w"> </span><span class="n">λ¨λΈ</span><span class="w"> </span><span class="n">λ³µμ </span><span class="w"> </span><span class="p">(</span><span class="n">λΉ„ν¨μ¨</span><span class="p">)</span><span class="w">                          </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                             </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">FSDP</span><span class="w"> </span><span class="p">(</span><span class="n">Zero</span><span class="w"> </span><span class="n">Stage</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="o">:</span><span class="w">                                       </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">GPU</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="n">Shard</span><span class="w"> </span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">[</span><span class="n">Data</span><span class="w"> </span><span class="mi">0</span><span class="p">]</span><span class="w">                               </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">GPU</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="n">Shard</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">[</span><span class="n">Data</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w">                               </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                             </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">Forward</span><span class="w"> </span><span class="n">μ‹</span><span class="o">:</span><span class="w"> </span><span class="n">All</span><span class="o">-</span><span class="n">Gatherλ΅</span><span class="w"> </span><span class="n">μ „μ²΄</span><span class="w"> </span><span class="n">νλΌλ―Έν„°</span><span class="w"> </span><span class="n">μμ§‘</span><span class="w">                </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">Backward</span><span class="w"> </span><span class="n">μ‹</span><span class="o">:</span><span class="w"> </span><span class="n">Reduce</span><span class="o">-</span><span class="n">Scatterλ΅</span><span class="w"> </span><span class="n">gradient</span><span class="w"> </span><span class="n">λ¶„μ‚°</span><span class="w">               </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                             </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">λ©”λ¨λ¦¬</span><span class="o">:</span><span class="w"> </span><span class="p">(</span><span class="n">Params</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Grads</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Optim</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Activations</span><span class="w">         </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                             </span><span class="err">β”‚</span>
<span class="err">β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”</span>
</code></pre></div>

<h3 id="22-pytorch-fsdp">2.2 PyTorch FSDP κµ¬ν„<a class="header-link" href="#22-pytorch-fsdp" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.fsdp</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">FullyShardedDataParallel</span> <span class="k">as</span> <span class="n">FSDP</span><span class="p">,</span>
    <span class="n">MixedPrecision</span><span class="p">,</span>
    <span class="n">BackwardPrefetch</span><span class="p">,</span>
    <span class="n">ShardingStrategy</span><span class="p">,</span>
    <span class="n">CPUOffload</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.fsdp.wrap</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">transformer_auto_wrap_policy</span><span class="p">,</span>
    <span class="n">size_based_auto_wrap_policy</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">functools</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup_fsdp_training</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;FSDP ν•™μµ μ„¤μ •&quot;&quot;&quot;</span>

    <span class="c1"># λ¶„μ‚° μ΄κΈ°ν™”</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
    <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">])</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>

    <span class="c1"># λ¨λΈ μƒμ„±</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MyTransformerModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="c1"># Mixed Precision μ„¤μ •</span>
    <span class="n">mixed_precision</span> <span class="o">=</span> <span class="n">MixedPrecision</span><span class="p">(</span>
        <span class="n">param_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>      <span class="c1"># νλΌλ―Έν„°</span>
        <span class="n">reduce_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>     <span class="c1"># gradient reduction</span>
        <span class="n">buffer_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>     <span class="c1"># λ²„νΌ</span>
    <span class="p">)</span>

    <span class="c1"># Auto Wrap Policy: Transformer λ μ΄μ–΄ λ‹¨μ„λ΅ μƒ¤λ”©</span>
    <span class="n">wrap_policy</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
        <span class="n">transformer_auto_wrap_policy</span><span class="p">,</span>
        <span class="n">transformer_layer_cls</span><span class="o">=</span><span class="p">{</span><span class="n">TransformerBlock</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="c1"># FSDP λν•‘</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">FSDP</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">sharding_strategy</span><span class="o">=</span><span class="n">ShardingStrategy</span><span class="o">.</span><span class="n">FULL_SHARD</span><span class="p">,</span>  <span class="c1"># Zero-3</span>
        <span class="n">mixed_precision</span><span class="o">=</span><span class="n">mixed_precision</span><span class="p">,</span>
        <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">wrap_policy</span><span class="p">,</span>
        <span class="n">backward_prefetch</span><span class="o">=</span><span class="n">BackwardPrefetch</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">,</span>
        <span class="n">cpu_offload</span><span class="o">=</span><span class="n">CPUOffload</span><span class="p">(</span><span class="n">offload_params</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">device_id</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_step_fsdp</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scaler</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;FSDP ν•™μµ μ¤ν…&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Forward</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

    <span class="c1"># Backward</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Gradient clipping (FSDPμ—μ„λ” μ£Όμ ν•„μ”)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># Optimizer step</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


<span class="c1"># μ²΄ν¬ν¬μΈνΈ μ €μ¥/λ΅λ“</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.fsdp</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">FullStateDictConfig</span><span class="p">,</span>
    <span class="n">StateDictType</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">save_fsdp_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;FSDP μ²΄ν¬ν¬μΈνΈ μ €μ¥&quot;&quot;&quot;</span>

    <span class="c1"># Full State Dict μ„¤μ •</span>
    <span class="n">full_state_dict_config</span> <span class="o">=</span> <span class="n">FullStateDictConfig</span><span class="p">(</span>
        <span class="n">offload_to_cpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">rank0_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">with</span> <span class="n">FSDP</span><span class="o">.</span><span class="n">state_dict_type</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">StateDictType</span><span class="o">.</span><span class="n">FULL_STATE_DICT</span><span class="p">,</span>
        <span class="n">full_state_dict_config</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">optim_state</span> <span class="o">=</span> <span class="n">FSDP</span><span class="o">.</span><span class="n">optim_state_dict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">,</span>
                <span class="s1">&#39;optimizer&#39;</span><span class="p">:</span> <span class="n">optim_state</span><span class="p">,</span>
            <span class="p">},</span> <span class="n">path</span><span class="p">)</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="3-deepspeed-zero">3. DeepSpeed ZeRO<a class="header-link" href="#3-deepspeed-zero" title="Permanent link">&para;</a></h2>
<h3 id="31-zero">3.1 ZeRO λ‹¨κ³„λ³„ λΉ„κµ<a class="header-link" href="#31-zero" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="err">β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”</span>
<span class="err">β”‚</span><span class="w">                     </span><span class="n">DeepSpeed</span><span class="w"> </span><span class="n">ZeRO</span><span class="w"> </span><span class="err">λ‹¨κ³„</span><span class="w">                    </span><span class="err">β”‚</span>
<span class="err">β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤</span>
<span class="err">β”‚</span><span class="w">                                                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">Stage</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="n">Optimizer</span><span class="w"> </span><span class="n">State</span><span class="w"> </span><span class="n">Partitioning</span><span class="w">                    </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">Optimizer</span><span class="w"> </span><span class="n">states</span><span class="w"> </span><span class="p">(</span><span class="n">Adam</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="p">)</span><span class="err">λ§</span><span class="w"> </span><span class="err">λ¶„ν• </span><span class="w">                    </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">λ©”λ¨λ¦¬</span><span class="w"> </span><span class="err">μ κ°</span><span class="p">:</span><span class="w"> </span><span class="o">~</span><span class="mi">4</span><span class="n">x</span><span class="w">                                        </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">Stage</span><span class="w"> </span><span class="mi">2</span><span class="p">:</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Gradient</span><span class="w"> </span><span class="n">Partitioning</span><span class="w">                         </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">Gradientsλ„</span><span class="w"> </span><span class="err">λ¶„ν• </span><span class="w">                                        </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">λ©”λ¨λ¦¬</span><span class="w"> </span><span class="err">μ κ°</span><span class="p">:</span><span class="w"> </span><span class="o">~</span><span class="mi">8</span><span class="n">x</span><span class="w">                                        </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">Stage</span><span class="w"> </span><span class="mi">3</span><span class="p">:</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Parameter</span><span class="w"> </span><span class="n">Partitioning</span><span class="w">                        </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">Parametersλ„</span><span class="w"> </span><span class="err">λ¶„ν• </span><span class="w"> </span><span class="p">(</span><span class="n">FSDPμ™€</span><span class="w"> </span><span class="err">μ μ‚¬</span><span class="p">)</span><span class="w">                         </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="err">λ©”λ¨λ¦¬</span><span class="w"> </span><span class="err">μ κ°</span><span class="p">:</span><span class="w"> </span><span class="o">~</span><span class="n">N</span><span class="w"> </span><span class="p">(</span><span class="n">GPU</span><span class="w"> </span><span class="err">μμ—</span><span class="w"> </span><span class="err">λΉ„λ΅€</span><span class="p">)</span><span class="w">                         </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                            </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">ZeRO</span><span class="o">-</span><span class="n">Offload</span><span class="p">:</span><span class="w"> </span><span class="n">CPU</span><span class="o">/</span><span class="n">NVMeλ΅</span><span class="w"> </span><span class="err">μ¤ν”„λ΅λ“</span><span class="w">                         </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">  </span><span class="n">ZeRO</span><span class="o">-</span><span class="n">Infinity</span><span class="p">:</span><span class="w"> </span><span class="err">λ¬΄ν•</span><span class="w"> </span><span class="err">λ¨λΈ</span><span class="w"> </span><span class="err">ν¬κΈ°</span><span class="w"> </span><span class="err">μ§€μ›</span><span class="w">                        </span><span class="err">β”‚</span>
<span class="err">β”‚</span><span class="w">                                                            </span><span class="err">β”‚</span>
<span class="err">β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”</span>
</code></pre></div>

<h3 id="32-deepspeed">3.2 DeepSpeed μ„¤μ •<a class="header-link" href="#32-deepspeed" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># ds_config.json</span>
<span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>

    <span class="c1"># FP16 μ„¤μ •</span>
    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;loss_scale&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># dynamic</span>
        <span class="s2">&quot;loss_scale_window&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="s2">&quot;initial_scale_power&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s2">&quot;hysteresis&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;min_loss_scale&quot;</span><span class="p">:</span> <span class="mi">1</span>
    <span class="p">},</span>

    <span class="c1"># BF16 μ„¤μ • (λ€μ•)</span>
    <span class="s2">&quot;bf16&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>

    <span class="c1"># ZeRO Stage 3</span>
    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;offload_optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>  <span class="c1"># or &quot;nvme&quot;</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">},</span>
        <span class="s2">&quot;offload_param&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">},</span>
        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;sub_group_size&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="s2">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s2">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
        <span class="s2">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">},</span>

    <span class="c1"># Gradient Checkpointing</span>
    <span class="s2">&quot;activation_checkpointing&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;partition_activations&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;cpu_checkpointing&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;contiguous_memory_optimization&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;number_checkpoints&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;synchronize_checkpoint_boundary&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;profile&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>

    <span class="c1"># Optimizer</span>
    <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">3e-4</span><span class="p">,</span>
            <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">],</span>
            <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">,</span>
            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.01</span>
        <span class="p">}</span>
    <span class="p">},</span>

    <span class="c1"># Scheduler</span>
    <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;WarmupDecayLR&quot;</span><span class="p">,</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;warmup_min_lr&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;warmup_max_lr&quot;</span><span class="p">:</span> <span class="mf">3e-4</span><span class="p">,</span>
            <span class="s2">&quot;warmup_num_steps&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
            <span class="s2">&quot;total_num_steps&quot;</span><span class="p">:</span> <span class="mi">100000</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="33-deepspeed">3.3 DeepSpeed ν•™μµ μ½”λ“<a class="header-link" href="#33-deepspeed" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_with_deepspeed</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;DeepSpeed ν•™μµ λ£¨ν”„&quot;&quot;&quot;</span>

    <span class="c1"># λ¨λΈ λ° λ°μ΄ν„°</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MyTransformerModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">create_dataloader</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="c1"># DeepSpeed μ΄κΈ°ν™”</span>
    <span class="n">model_engine</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">model_parameters</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">config</span><span class="o">=</span><span class="n">ds_config</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># ν•™μµ λ£¨ν”„</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model_engine</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="c1"># Forward</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model_engine</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

            <span class="c1"># Backward (DeepSpeedκ°€ gradient scaling/accumulation μ²λ¦¬)</span>
            <span class="n">model_engine</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># Step</span>
            <span class="n">model_engine</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># μ²΄ν¬ν¬μΈνΈ μ €μ¥</span>
    <span class="n">model_engine</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">)</span>


<span class="c1"># μ‹¤ν–‰</span>
<span class="c1"># deepspeed --num_gpus=8 train.py --deepspeed_config ds_config.json</span>
</code></pre></div>

<hr />
<h2 id="4-activation-checkpointing-gradient-checkpointing">4. Activation Checkpointing (Gradient Checkpointing)<a class="header-link" href="#4-activation-checkpointing-gradient-checkpointing" title="Permanent link">&para;</a></h2>
<h3 id="41">4.1 κ°λ…<a class="header-link" href="#41" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>μΌλ° Forward:
Layer 1 β†’ [Act1 μ €μ¥] β†’ Layer 2 β†’ [Act2 μ €μ¥] β†’ ... β†’ Loss

Backward μ‹ Act1, Act2 λ“±μ„ μ‚¬μ©ν•μ—¬ gradient κ³„μ‚°
β†’ λ©”λ¨λ¦¬: O(L) - λ μ΄μ–΄ μμ— λΉ„λ΅€

Activation Checkpointing:
Layer 1 β†’ [μ²΄ν¬ν¬μΈνΈ] β†’ Layer 2 β†’ Layer 3 β†’ [μ²΄ν¬ν¬μΈνΈ] β†’ ... β†’ Loss

Backward μ‹ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬κ³„μ‚°
β†’ λ©”λ¨λ¦¬: O(βL) - λ£¨νΈ λ μ΄μ–΄ μ
β†’ κ³„μ‚°: ~33% μ¦κ°€ (μ¬κ³„μ‚° λΉ„μ©)
</code></pre></div>

<h3 id="42">4.2 κµ¬ν„<a class="header-link" href="#42" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.checkpoint</span><span class="w"> </span><span class="kn">import</span> <span class="n">checkpoint</span><span class="p">,</span> <span class="n">checkpoint_sequential</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlockWithCheckpoint</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checkpointingμ΄ μ μ©λ Transformer λΈ”λ΅&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">use_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_checkpoint</span> <span class="o">=</span> <span class="n">use_checkpoint</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_checkpoint</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># Checkpointing μ‚¬μ©</span>
            <span class="k">return</span> <span class="n">checkpoint</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_forward_impl</span><span class="p">,</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">use_reentrant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># PyTorch 2.0+ κ¶μ¥</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_impl</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="c1"># Attention</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="n">x</span>

        <span class="c1"># FFN</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="n">x</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TransformerWithSelectiveCheckpoint</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;μ„ νƒμ  Checkpointing&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerBlockWithCheckpoint</span><span class="p">(</span>
                <span class="n">config</span><span class="p">,</span>
                <span class="c1"># μΌλ¶€ λ μ΄μ–΄λ§ checkpoint</span>
                <span class="n">use_checkpoint</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">checkpoint_ratio</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>

<hr />
<h2 id="5">5. ν•™μµ μ•μ •μ„±<a class="header-link" href="#5" title="Permanent link">&para;</a></h2>
<h3 id="51-loss-spike">5.1 Loss Spike λ€μ‘<a class="header-link" href="#51-loss-spike" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TrainingStabilizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ν•™μµ μ•μ •μ„± κ΄€λ¦¬&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loss_spike_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>  <span class="c1"># μ΄μ „ λ€λΉ„ 5λ°°</span>
        <span class="n">grad_norm_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
        <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_spike_threshold</span> <span class="o">=</span> <span class="n">loss_spike_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_norm_threshold</span> <span class="o">=</span> <span class="n">grad_norm_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_norm_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skipped_steps</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_loss_spike</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loss spike κ°μ§€&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">avg_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="o">&gt;</span> <span class="n">avg_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_spike_threshold</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;β οΈ Loss spike detected: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (avg: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Gradient norm μ²΄ν¬&quot;&quot;&quot;</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="n">total_norm</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="n">is_spike</span> <span class="o">=</span> <span class="n">total_norm</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_norm_threshold</span>

        <span class="k">if</span> <span class="n">is_spike</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;β οΈ Gradient spike: </span><span class="si">{</span><span class="n">total_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">grad_norm_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">total_norm</span><span class="p">,</span> <span class="n">is_spike</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">should_skip_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ν•΄λ‹Ή stepμ„ κ±΄λ„λ›Έμ§€ κ²°μ •&quot;&quot;&quot;</span>
        <span class="n">loss_spike</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_loss_spike</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">grad_spike</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">loss_spike</span> <span class="ow">or</span> <span class="n">grad_spike</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">skipped_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">stable_training_step</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">stabilizer</span><span class="p">,</span> <span class="n">scaler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;μ•μ •μ μΈ ν•™μµ μ¤ν…&quot;&quot;&quot;</span>

    <span class="c1"># Forward</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

    <span class="c1"># Loss spike μ²΄ν¬</span>
    <span class="k">if</span> <span class="n">stabilizer</span><span class="o">.</span><span class="n">should_skip_step</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipping step (total skipped: </span><span class="si">{</span><span class="n">stabilizer</span><span class="o">.</span><span class="n">skipped_steps</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Backward</span>
    <span class="k">if</span> <span class="n">scaler</span><span class="p">:</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Gradient clipping</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</code></pre></div>

<h3 id="52">5.2 μ²΄ν¬ν¬μΈνΈ μ „λµ<a class="header-link" href="#52" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CheckpointManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">save_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">max_checkpoints</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">save_interval_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">save_interval_hours</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span> <span class="o">=</span> <span class="n">save_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_checkpoints</span> <span class="o">=</span> <span class="n">max_checkpoints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_interval_steps</span> <span class="o">=</span> <span class="n">save_interval_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_interval_hours</span> <span class="o">=</span> <span class="n">save_interval_hours</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_save_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">should_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ—¬λ¶€ κ²°μ •&quot;&quot;&quot;</span>
        <span class="c1"># μ¤ν… κΈ°λ°</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_interval_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># μ‹κ°„ κΈ°λ°</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_save_time</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()</span> <span class="o">/</span> <span class="mi">3600</span>
        <span class="k">if</span> <span class="n">elapsed</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_interval_hours</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">,</span>
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">extra</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;μ²΄ν¬ν¬μΈνΈ μ €μ¥&quot;&quot;&quot;</span>
        <span class="n">checkpoint_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;checkpoint-</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">checkpoint_name</span><span class="p">)</span>

        <span class="c1"># μ €μ¥</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">step</span><span class="p">,</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">scheduler</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="o">**</span><span class="n">extra</span>
        <span class="p">}</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">checkpoint_path</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>

        <span class="c1"># λ©”νƒ€λ°μ΄ν„°</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">checkpoint_path</span><span class="p">,</span>
            <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">step</span><span class="p">,</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">()</span>
        <span class="p">})</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_save_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

        <span class="c1"># μ¤λλ μ²΄ν¬ν¬μΈνΈ μ‚­μ </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cleanup</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;π’Ύ Saved checkpoint: </span><span class="si">{</span><span class="n">checkpoint_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;μ¤λλ μ²΄ν¬ν¬μΈνΈ μ •λ¦¬&quot;&quot;&quot;</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_checkpoints</span><span class="p">:</span>
            <span class="n">oldest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">oldest</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">oldest</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;π—‘οΈ Removed old checkpoint: </span><span class="si">{</span><span class="n">oldest</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_latest</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;μµμ‹  μ²΄ν¬ν¬μΈνΈ λ΅λ“&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">:</span>
            <span class="c1"># λ””λ ‰ν† λ¦¬μ—μ„ μ°ΎκΈ°</span>
            <span class="n">files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span>
                <span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;checkpoint-&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.pt&quot;</span><span class="p">)</span>
            <span class="p">])</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">files</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>

            <span class="n">latest</span> <span class="o">=</span> <span class="n">files</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">latest</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="6">6. ν•™μµλ¥  μ¤μΌ€μ¤„λ§<a class="header-link" href="#6" title="Permanent link">&para;</a></h2>
<h3 id="61-warmup-cosine-decay">6.1 Warmup + Cosine Decay<a class="header-link" href="#61-warmup-cosine-decay" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">LambdaLR</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_cosine_schedule_with_warmup</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">min_lr_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">num_cycles</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Warmup + Cosine Decay μ¤μΌ€μ¤„λ¬</span>

<span class="sd">    ν•™μµ μ΄κΈ°: Linear warmup (0 β†’ max_lr)</span>
<span class="sd">    μ΄ν›„: Cosine decay (max_lr β†’ min_lr)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
        <span class="c1"># Warmup</span>
        <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">num_warmup_steps</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="p">))</span>

        <span class="c1"># Cosine decay</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span> <span class="o">-</span> <span class="n">num_warmup_steps</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span>
            <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">-</span> <span class="n">num_warmup_steps</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">cosine_decay</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">num_cycles</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">progress</span><span class="p">))</span>

        <span class="c1"># min_lrκΉμ§€λ§ κ°μ†</span>
        <span class="n">decayed</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">min_lr_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_decay</span> <span class="o">+</span> <span class="n">min_lr_ratio</span>

        <span class="k">return</span> <span class="n">decayed</span>

    <span class="k">return</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>


<span class="c1"># WSD (Warmup-Stable-Decay) μ¤μΌ€μ¤„λ¬ (Llama 2)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_wsd_schedule</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_stable_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_decay_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">min_lr_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Warmup-Stable-Decay μ¤μΌ€μ¤„λ¬</span>

<span class="sd">    1. Warmup: 0 β†’ max_lr</span>
<span class="sd">    2. Stable: max_lr μ μ§€</span>
<span class="sd">    3. Decay: max_lr β†’ min_lr (cosine)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_steps</span> <span class="o">=</span> <span class="n">num_warmup_steps</span> <span class="o">+</span> <span class="n">num_stable_steps</span> <span class="o">+</span> <span class="n">num_decay_steps</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">num_warmup_steps</span><span class="p">:</span>
            <span class="c1"># Warmup phase</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="p">))</span>

        <span class="k">elif</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">num_warmup_steps</span> <span class="o">+</span> <span class="n">num_stable_steps</span><span class="p">:</span>
            <span class="c1"># Stable phase</span>
            <span class="k">return</span> <span class="mf">1.0</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Decay phase</span>
            <span class="n">decay_step</span> <span class="o">=</span> <span class="n">current_step</span> <span class="o">-</span> <span class="n">num_warmup_steps</span> <span class="o">-</span> <span class="n">num_stable_steps</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">decay_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_decay_steps</span><span class="p">))</span>
            <span class="n">cosine_decay</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">progress</span><span class="p">))</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">min_lr_ratio</span><span class="p">)</span> <span class="o">*</span> <span class="n">cosine_decay</span> <span class="o">+</span> <span class="n">min_lr_ratio</span>

    <span class="k">return</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="7">7. μ‹¤μµ: μ™„μ „ν• ν•™μµ μ¤ν¬λ¦½νΈ<a class="header-link" href="#7" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedSampler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;μ™„μ „ν• λ¶„μ‚° ν•™μµ μ¤ν¬λ¦½νΈ&quot;&quot;&quot;</span>

    <span class="c1"># 1. λ¶„μ‚° μ΄κΈ°ν™”</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
    <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">])</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>

    <span class="c1"># Rank 0λ§ λ΅κΉ…</span>
    <span class="n">is_main</span> <span class="o">=</span> <span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">is_main</span><span class="p">:</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s2">&quot;foundation-model-training&quot;</span><span class="p">)</span>

    <span class="c1"># 2. μ„¤μ •</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">,</span>
        <span class="s1">&#39;num_layers&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s1">&#39;num_heads&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s1">&#39;vocab_size&#39;</span><span class="p">:</span> <span class="mi">50257</span><span class="p">,</span>
        <span class="s1">&#39;max_seq_len&#39;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># per GPU</span>
        <span class="s1">&#39;gradient_accumulation&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">3e-4</span><span class="p">,</span>
        <span class="s1">&#39;warmup_steps&#39;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
        <span class="s1">&#39;total_steps&#39;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="s1">&#39;max_grad_norm&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">effective_batch</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;gradient_accumulation&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">world_size</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Effective batch size: </span><span class="si">{</span><span class="n">effective_batch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 3. λ¨λΈ</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">TransformerModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="c1"># Activation checkpointing</span>
    <span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>

    <span class="c1"># DDP λλ” FSDP</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">local_rank</span><span class="p">])</span>

    <span class="c1"># 4. λ°μ΄ν„°</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">PretrainingDataset</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 5. Optimizer &amp; Scheduler</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">],</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">],</span>
        <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_cosine_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;warmup_steps&#39;</span><span class="p">],</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># 6. μ ν‹Έλ¦¬ν‹°</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">()</span>
    <span class="n">stabilizer</span> <span class="o">=</span> <span class="n">TrainingStabilizer</span><span class="p">()</span>
    <span class="n">checkpoint_mgr</span> <span class="o">=</span> <span class="n">CheckpointManager</span><span class="p">(</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">)</span>

    <span class="c1"># μ²΄ν¬ν¬μΈνΈ λ³µμ›</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_mgr</span><span class="o">.</span><span class="n">load_latest</span><span class="p">()</span>
    <span class="n">start_step</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">checkpoint</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">]:</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">])</span>
        <span class="n">start_step</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">is_main</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resumed from step </span><span class="si">{</span><span class="n">start_step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># 7. ν•™μµ λ£¨ν”„</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">global_step</span> <span class="o">=</span> <span class="n">start_step</span>
    <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  <span class="c1"># μ¶©λ¶„ν ν° μ</span>
        <span class="n">sampler</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="c1"># Forward (Mixed Precision)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span> <span class="o">/</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;gradient_accumulation&#39;</span><span class="p">]</span>

            <span class="c1"># Backward</span>
            <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">accumulated_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Gradient Accumulation</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;gradient_accumulation&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Gradient clipping</span>
                <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
                <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                    <span class="n">config</span><span class="p">[</span><span class="s1">&#39;max_grad_norm&#39;</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="c1"># Step</span>
                <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
                <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">global_step</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># λ΅κΉ…</span>
                <span class="k">if</span> <span class="n">is_main</span> <span class="ow">and</span> <span class="n">global_step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">lr</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">accumulated_loss</span><span class="p">,</span>
                        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                        <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="n">grad_norm</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="n">global_step</span><span class="p">,</span>
                    <span class="p">})</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">global_step</span><span class="si">}</span><span class="s2">: loss=</span><span class="si">{</span><span class="n">accumulated_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">accumulated_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

                <span class="c1"># μ²΄ν¬ν¬μΈνΈ</span>
                <span class="k">if</span> <span class="n">checkpoint_mgr</span><span class="o">.</span><span class="n">should_save</span><span class="p">(</span><span class="n">global_step</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">is_main</span><span class="p">:</span>
                        <span class="n">checkpoint_mgr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                            <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
                            <span class="n">global_step</span><span class="p">,</span> <span class="n">accumulated_loss</span>
                        <span class="p">)</span>

                <span class="c1"># μΆ…λ£ μ΅°κ±΄</span>
                <span class="k">if</span> <span class="n">global_step</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]:</span>
                    <span class="k">break</span>

        <span class="k">if</span> <span class="n">global_step</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;total_steps&#39;</span><span class="p">]:</span>
            <span class="k">break</span>

    <span class="c1"># μ •λ¦¬</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">is_main</span><span class="p">:</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># μ‹¤ν–‰:</span>
<span class="c1"># torchrun --nproc_per_node=8 --nnodes=4 --node_rank=0 \</span>
<span class="c1">#          --master_addr=&quot;master&quot; --master_port=29500 train.py</span>
</code></pre></div>

<hr />
<h2 id="_2">μ°Έκ³  μλ£<a class="header-link" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="_3">λ¬Έμ„<a class="header-link" href="#_3" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://pytorch.org/docs/stable/fsdp.html">PyTorch FSDP</a></li>
<li><a href="https://www.deepspeed.ai/">DeepSpeed</a></li>
<li><a href="https://github.com/NVIDIA/Megatron-LM">Megatron-LM</a></li>
</ul>
<h3 id="_4">λ…Όλ¬Έ<a class="header-link" href="#_4" title="Permanent link">&para;</a></h3>
<ul>
<li>Rajbhandari et al. (2020). "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models"</li>
<li>Narayanan et al. (2021). "Efficient Large-Scale Language Model Training on GPU Clusters"</li>
</ul>
<h3 id="_5">κ΄€λ ¨ λ μ¨<a class="header-link" href="#_5" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="../Deep_Learning/11_Model_Deployment.md">../Deep_Learning/11_Model_Deployment.md</a></li>
<li><a href="../MLOps/08_Model_Serving_Basics.md">../MLOps/08_Model_Serving_Basics.md</a></li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Foundation_Models/05_Data_Curation.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">05. λ°μ΄ν„° νλ μ΄μ…</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">π”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Foundation_Models/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">π“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Foundation_Models/07_Tokenization_Deep_Dive.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">07. Tokenization μ‹¬ν™”</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">β†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}