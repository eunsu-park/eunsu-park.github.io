{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>07. νμΈνλ‹ - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">π </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">π’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        ν•κµ­μ–΄
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">β€οΈ</span>
                    <span class="theme-icon dark">π™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/LLM_and_NLP/">LLM and NLP</a>
    <span class="separator">/</span>
    <span class="current">07. νμΈνλ‹</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>07. νμΈνλ‹</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/LLM_and_NLP/06_HuggingFace_Basics.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">06. HuggingFace κΈ°μ΄</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">π”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/LLM_and_NLP/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">π“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/LLM_and_NLP/08_Prompt_Engineering.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">08. ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">ν•™μµ λ©ν‘</a></li>
<li><a href="#1">1. νμΈνλ‹ κ°μ”</a><ul>
<li><a href="#_2">μ „μ΄ν•™μµ ν¨λ¬λ‹¤μ„</a></li>
<li><a href="#_3">νμΈνλ‹ μ „λµ</a></li>
</ul>
</li>
<li><a href="#2">2. ν…μ¤νΈ λ¶„λ¥ νμΈνλ‹</a><ul>
<li><a href="#_4">κΈ°λ³Έ νμ΄ν”„λΌμΈ</a></li>
<li><a href="#_5">λ‹¤μ¤‘ λ μ΄λΈ” λ¶„λ¥</a></li>
</ul>
</li>
<li><a href="#3-ner">3. ν† ν° λ¶„λ¥ (NER) νμΈνλ‹</a><ul>
<li><a href="#ner">NER λ°μ΄ν„° ν•μ‹</a></li>
<li><a href="#_6">ν† ν° μ •λ ¬</a></li>
<li><a href="#ner_1">NER νμΈνλ‹</a></li>
</ul>
</li>
<li><a href="#4-qa">4. μ§μμ‘λ‹µ (QA) νμΈνλ‹</a><ul>
<li><a href="#squad">SQuAD λ°μ΄ν„°</a></li>
<li><a href="#qa">QA μ „μ²λ¦¬</a></li>
<li><a href="#qa_1">QA λ¨λΈ</a></li>
</ul>
</li>
<li><a href="#5-peft">5. ν¨μ¨μ μΈ νμΈνλ‹ (PEFT)</a><ul>
<li><a href="#lora-low-rank-adaptation">LoRA (Low-Rank Adaptation)</a></li>
<li><a href="#qlora-quantized-lora">QLoRA (Quantized LoRA)</a></li>
<li><a href="#prompt-tuning">Prompt Tuning</a></li>
</ul>
</li>
<li><a href="#6">6. λ€ν™”ν• λ¨λΈ νμΈνλ‹</a><ul>
<li><a href="#instruction-tuning">Instruction Tuning λ°μ΄ν„° ν•μ‹</a></li>
<li><a href="#sft-supervised-fine-tuning">SFT (Supervised Fine-Tuning)</a></li>
<li><a href="#dpo-direct-preference-optimization">DPO (Direct Preference Optimization)</a></li>
</ul>
</li>
<li><a href="#7">7. ν•™μµ μµμ ν™”</a><ul>
<li><a href="#gradient-checkpointing">Gradient Checkpointing</a></li>
<li><a href="#mixed-precision">Mixed Precision</a></li>
<li><a href="#gradient-accumulation">Gradient Accumulation</a></li>
<li><a href="#deepspeed">DeepSpeed</a></li>
</ul>
</li>
<li><a href="#8">8. μ „μ²΄ νμΈνλ‹ μμ </a></li>
<li><a href="#_7">μ •λ¦¬</a><ul>
<li><a href="#_8">νμΈνλ‹ μ„ νƒ κ°€μ΄λ“</a></li>
<li><a href="#_9">ν•µμ‹¬ μ½”λ“</a></li>
</ul>
</li>
<li><a href="#_10">λ‹¤μ λ‹¨κ³„</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="07">07. νμΈνλ‹<a class="header-link" href="#07" title="Permanent link">&para;</a></h1>
<h2 id="_1">ν•™μµ λ©ν‘<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>νμΈνλ‹ μ „λµ μ΄ν•΄</li>
<li>λ‹¤μ–‘ν• νƒμ¤ν¬ νμΈνλ‹</li>
<li>ν¨μ¨μ μΈ νμΈνλ‹ κΈ°λ²• (LoRA, QLoRA)</li>
<li>μ‹¤μ „ νμΈνλ‹ νμ΄ν”„λΌμΈ</li>
</ul>
<hr />
<h2 id="1">1. νμΈνλ‹ κ°μ”<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="_2">μ „μ΄ν•™μµ ν¨λ¬λ‹¤μ„<a class="header-link" href="#_2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>μ‚¬μ „ν•™μµ (Pre-training)
    β”‚  λ€κ·λ¨ ν…μ¤νΈλ΅ μΌλ°μ μΈ μ–Έμ–΄ μ΄ν•΄ ν•™μµ
    β–Ό
νμΈνλ‹ (Fine-tuning)
    β”‚  νΉμ • νƒμ¤ν¬ λ°μ΄ν„°λ΅ λ¨λΈ μ΅°μ •
    β–Ό
νƒμ¤ν¬ μν–‰
</code></pre></div>

<h3 id="_3">νμΈνλ‹ μ „λµ<a class="header-link" href="#_3" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>μ „λµ</th>
<th>μ„¤λ…</th>
<th>μ‚¬μ© μ‹μ </th>
</tr>
</thead>
<tbody>
<tr>
<td>Full Fine-tuning</td>
<td>μ „μ²΄ νλΌλ―Έν„° μ—…λ°μ΄νΈ</td>
<td>μ¶©λ¶„ν• λ°μ΄ν„°, μ»΄ν“¨ν…</td>
</tr>
<tr>
<td>Feature Extraction</td>
<td>λ¶„λ¥κΈ°λ§ ν•™μµ</td>
<td>μ μ€ λ°μ΄ν„°</td>
</tr>
<tr>
<td>LoRA</td>
<td>μ €λ­ν¬ μ–΄λ‘ν„°</td>
<td>ν¨μ¨μ μΈ ν•™μµ</td>
</tr>
<tr>
<td>Prompt Tuning</td>
<td>ν”„λ΅¬ν”„νΈλ§ ν•™μµ</td>
<td>λ§¤μ° μ μ€ λ°μ΄ν„°</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2">2. ν…μ¤νΈ λ¶„λ¥ νμΈνλ‹<a class="header-link" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="_4">κΈ°λ³Έ νμ΄ν”„λΌμΈ<a class="header-link" href="#_4" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
    <span class="n">TrainingArguments</span><span class="p">,</span>
    <span class="n">Trainer</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>

<span class="c1"># λ°μ΄ν„° λ΅λ“</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;imdb&quot;</span><span class="p">)</span>

<span class="c1"># ν† ν¬λ‚μ΄μ €</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">tokenize</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span>
    <span class="p">)</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># λ¨λΈ</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="c1"># ν•™μµ μ„¤μ •</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./output&quot;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<h3 id="_5">λ‹¤μ¤‘ λ μ΄λΈ” λ¶„λ¥<a class="header-link" href="#_5" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># λ‹¤μ¤‘ λ μ΄λΈ”μ© λ¨λΈ</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">problem_type</span><span class="o">=</span><span class="s2">&quot;multi_label_classification&quot;</span>
<span class="p">)</span>

<span class="c1"># μ†μ‹¤ ν•¨μ μλ™μΌλ΅ BCEWithLogitsLoss μ‚¬μ©</span>

<span class="c1"># λ μ΄λΈ” ν•μ‹: [1, 0, 1, 0, 1] (λ‹¤μ¤‘ λ μ΄λΈ”)</span>
</code></pre></div>

<hr />
<h2 id="3-ner">3. ν† ν° λ¶„λ¥ (NER) νμΈνλ‹<a class="header-link" href="#3-ner" title="Permanent link">&para;</a></h2>
<h3 id="ner">NER λ°μ΄ν„° ν•μ‹<a class="header-link" href="#ner" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># CoNLL-2003 NER λ°μ΄ν„°μ…‹</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;conll2003&quot;</span><span class="p">)</span>

<span class="c1"># μƒν”</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># {&#39;tokens&#39;: [&#39;EU&#39;, &#39;rejects&#39;, &#39;German&#39;, &#39;call&#39;, ...],</span>
<span class="c1">#  &#39;ner_tags&#39;: [3, 0, 7, 0, ...]}</span>

<span class="c1"># λ μ΄λΈ”</span>
<span class="n">label_names</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">names</span>
<span class="c1"># [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;]</span>
</code></pre></div>

<h3 id="_6">ν† ν° μ •λ ¬<a class="header-link" href="#_6" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_and_align_labels</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">],</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># μ΄λ―Έ ν† ν°ν™”λ μ…λ ¥</span>
    <span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s1">&#39;ner_tags&#39;</span><span class="p">]):</span>
        <span class="n">word_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">word_ids</span><span class="p">(</span><span class="n">batch_index</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">label_ids</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">word_idx</span> <span class="ow">in</span> <span class="n">word_ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">word_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># νΉμ ν† ν°</span>
            <span class="k">elif</span> <span class="n">word_idx</span> <span class="o">!=</span> <span class="n">previous_word_idx</span><span class="p">:</span>
                <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="n">word_idx</span><span class="p">])</span>  <span class="c1"># μ²« ν† ν°</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">label_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># μ„λΈμ›λ“ λ¬΄μ‹</span>
            <span class="n">previous_word_idx</span> <span class="o">=</span> <span class="n">word_idx</span>

        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

    <span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">tokenized</span>
</code></pre></div>

<h3 id="ner_1">NER νμΈνλ‹<a class="header-link" href="#ner_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># seqeval λ©”νΈλ¦­</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>
<span class="n">seqeval</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;seqeval&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># μ‹¤μ  λ μ΄λΈ”λ§ μ¶”μ¶</span>
    <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">true_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">true_labs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">:</span>
                <span class="n">true_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
                <span class="n">true_labs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
        <span class="n">true_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">true_preds</span><span class="p">)</span>
        <span class="n">true_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">true_labs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">seqeval</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">true_predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">true_labels</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="4-qa">4. μ§μμ‘λ‹µ (QA) νμΈνλ‹<a class="header-link" href="#4-qa" title="Permanent link">&para;</a></h2>
<h3 id="squad">SQuAD λ°μ΄ν„°<a class="header-link" href="#squad" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;squad&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># {&#39;id&#39;: &#39;...&#39;, &#39;title&#39;: &#39;University_of_Notre_Dame&#39;,</span>
<span class="c1">#  &#39;context&#39;: &#39;Architecturally, the school has...&#39;,</span>
<span class="c1">#  &#39;question&#39;: &#39;To whom did the Virgin Mary appear in 1858?&#39;,</span>
<span class="c1">#  &#39;answers&#39;: {&#39;text&#39;: [&#39;Saint Bernadette Soubirous&#39;], &#39;answer_start&#39;: [515]}}</span>
</code></pre></div>

<h3 id="qa">QA μ „μ²λ¦¬<a class="header-link" href="#qa" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">prepare_train_features</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;question&#39;</span><span class="p">],</span>
        <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">],</span>
        <span class="n">truncation</span><span class="o">=</span><span class="s2">&quot;only_second&quot;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;overflow_to_sample_mapping&quot;</span><span class="p">)</span>
    <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">tokenized</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;offset_mapping&quot;</span><span class="p">)</span>

    <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offsets</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">cls_index</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">)</span>

        <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;answers&quot;</span><span class="p">][</span><span class="n">sample_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s2">&quot;answer_start&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
            <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">start_char</span> <span class="o">=</span> <span class="n">answers</span><span class="p">[</span><span class="s2">&quot;answer_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">end_char</span> <span class="o">=</span> <span class="n">start_char</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

            <span class="c1"># ν† ν° μ„μΉ μ°ΎκΈ°</span>
            <span class="n">token_start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">token_end</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offsets</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;=</span> <span class="n">start_char</span> <span class="o">&lt;</span> <span class="n">end</span><span class="p">:</span>
                    <span class="n">token_start</span> <span class="o">=</span> <span class="n">idx</span>
                <span class="k">if</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="n">end_char</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="p">:</span>
                    <span class="n">token_end</span> <span class="o">=</span> <span class="n">idx</span>
                    <span class="k">break</span>

            <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_start</span><span class="p">)</span>
            <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_end</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tokenized</span>
</code></pre></div>

<h3 id="qa_1">QA λ¨λΈ<a class="header-link" href="#qa_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForQuestionAnswering</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>

<span class="c1"># μ¶λ ¥: start_logits, end_logits</span>
</code></pre></div>

<hr />
<h2 id="5-peft">5. ν¨μ¨μ μΈ νμΈνλ‹ (PEFT)<a class="header-link" href="#5-peft" title="Permanent link">&para;</a></h2>
<h3 id="lora-low-rank-adaptation">LoRA (Low-Rank Adaptation)<a class="header-link" href="#lora-low-rank-adaptation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">TaskType</span>

<span class="c1"># LoRA μ„¤μ •</span>
<span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>                      <span class="c1"># λ­ν¬</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>            <span class="c1"># μ¤μΌ€μΌλ§</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">],</span>  <span class="c1"># μ μ© λ¨λ“</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span>
<span class="p">)</span>

<span class="c1"># λ¨λΈμ— LoRA μ μ©</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>

<span class="c1"># ν•™μµ κ°€λ¥ν• νλΌλ―Έν„° ν™•μΈ</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>
<span class="c1"># trainable params: 294,912 || all params: 109,482,240 || trainable%: 0.27%</span>
</code></pre></div>

<h3 id="qlora-quantized-lora">QLoRA (Quantized LoRA)<a class="header-link" href="#qlora-quantized-lora" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># 4λΉ„νΈ μ–‘μν™” μ„¤μ •</span>
<span class="n">bnb_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
<span class="p">)</span>

<span class="c1"># μ–‘μν™”λ λ¨λΈ λ΅λ“</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;meta-llama/Llama-2-7b-hf&quot;</span><span class="p">,</span>
    <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>

<span class="c1"># LoRA μ μ©</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
</code></pre></div>

<h3 id="prompt-tuning">Prompt Tuning<a class="header-link" href="#prompt-tuning" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTuningConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">PromptTuningConfig</span><span class="p">(</span>
    <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">CAUSAL_LM</span><span class="p">,</span>
    <span class="n">num_virtual_tokens</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">prompt_tuning_init</span><span class="o">=</span><span class="s2">&quot;TEXT&quot;</span><span class="p">,</span>
    <span class="n">prompt_tuning_init_text</span><span class="o">=</span><span class="s2">&quot;Classify the sentiment: &quot;</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="6">6. λ€ν™”ν• λ¨λΈ νμΈνλ‹<a class="header-link" href="#6" title="Permanent link">&para;</a></h2>
<h3 id="instruction-tuning">Instruction Tuning λ°μ΄ν„° ν•μ‹<a class="header-link" href="#instruction-tuning" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Alpaca ν•μ‹</span>
<span class="p">{</span>
    <span class="s2">&quot;instruction&quot;</span><span class="p">:</span> <span class="s2">&quot;Summarize the following text.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Long article text here...&quot;</span><span class="p">,</span>
    <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Summary of the article.&quot;</span>
<span class="p">}</span>

<span class="c1"># ChatML ν•μ‹</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">&lt;|system|&gt;</span>
<span class="sd">You are a helpful assistant.</span>
<span class="sd">&lt;|user|&gt;</span>
<span class="sd">What is the capital of France?</span>
<span class="sd">&lt;|assistant|&gt;</span>
<span class="sd">The capital of France is Paris.</span>
<span class="sd">&quot;&quot;&quot;</span>
</code></pre></div>

<h3 id="sft-supervised-fine-tuning">SFT (Supervised Fine-Tuning)<a class="header-link" href="#sft-supervised-fine-tuning" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">dataset_text_field</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
    <span class="n">max_seq_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./sft_output&quot;</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<h3 id="dpo-direct-preference-optimization">DPO (Direct Preference Optimization)<a class="header-link" href="#dpo-direct-preference-optimization" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DPOTrainer</span>

<span class="c1"># μ„ νΈλ„ λ°μ΄ν„°</span>
<span class="c1"># {&#39;prompt&#39;: &#39;...&#39;, &#39;chosen&#39;: &#39;...&#39;, &#39;rejected&#39;: &#39;...&#39;}</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">ref_model</span><span class="o">=</span><span class="n">ref_model</span><span class="p">,</span>  <span class="c1"># κΈ°μ¤€ λ¨λΈ</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="7">7. ν•™μµ μµμ ν™”<a class="header-link" href="#7" title="Permanent link">&para;</a></h2>
<h3 id="gradient-checkpointing">Gradient Checkpointing<a class="header-link" href="#gradient-checkpointing" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>
</code></pre></div>

<h3 id="mixed-precision">Mixed Precision<a class="header-link" href="#mixed-precision" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="o">...</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># λλ” bf16=True</span>
<span class="p">)</span>
</code></pre></div>

<h3 id="gradient-accumulation">Gradient Accumulation<a class="header-link" href="#gradient-accumulation" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># μ‹¤ν¨ λ°°μΉ = 4 * 8 = 32</span>
<span class="p">)</span>
</code></pre></div>

<h3 id="deepspeed">DeepSpeed<a class="header-link" href="#deepspeed" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="o">...</span><span class="p">,</span>
    <span class="n">deepspeed</span><span class="o">=</span><span class="s2">&quot;ds_config.json&quot;</span>
<span class="p">)</span>

<span class="c1"># ds_config.json</span>
<span class="p">{</span>
    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">},</span>
    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<hr />
<h2 id="8">8. μ „μ²΄ νμΈνλ‹ μμ <a class="header-link" href="#8" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
    <span class="n">TrainingArguments</span><span class="p">,</span>
    <span class="n">Trainer</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">TaskType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>

<span class="c1"># 1. λ°μ΄ν„°</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;imdb&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">tokenize</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenized</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="s1">&#39;torch&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">])</span>

<span class="c1"># 2. λ¨λΈ + LoRA</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">],</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="n">TaskType</span><span class="o">.</span><span class="n">SEQ_CLS</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>

<span class="c1"># 3. ν•™μµ μ„¤μ •</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./lora_imdb&quot;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># 4. λ©”νΈλ¦­</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">eval_pred</span><span class="o">.</span><span class="n">predictions</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">eval_pred</span><span class="o">.</span><span class="n">label_ids</span><span class="p">)</span>

<span class="c1"># 5. ν•™μµ</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># 6. μ €μ¥</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;./lora_imdb_final&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2 id="_7">μ •λ¦¬<a class="header-link" href="#_7" title="Permanent link">&para;</a></h2>
<h3 id="_8">νμΈνλ‹ μ„ νƒ κ°€μ΄λ“<a class="header-link" href="#_8" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>μƒν™©</th>
<th>μ¶”μ² λ°©λ²•</th>
</tr>
</thead>
<tbody>
<tr>
<td>μ¶©λ¶„ν• λ°μ΄ν„° + GPU</td>
<td>Full Fine-tuning</td>
</tr>
<tr>
<td>μ ν•λ GPU λ©”λ¨λ¦¬</td>
<td>LoRA / QLoRA</td>
</tr>
<tr>
<td>λ§¤μ° μ μ€ λ°μ΄ν„°</td>
<td>Prompt Tuning</td>
</tr>
<tr>
<td>LLM μ •λ ¬</td>
<td>SFT + DPO/RLHF</td>
</tr>
</tbody>
</table>
<h3 id="_9">ν•µμ‹¬ μ½”λ“<a class="header-link" href="#_9" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># LoRA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>
<span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">target_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>

<span class="c1"># Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2 id="_10">λ‹¤μ λ‹¨κ³„<a class="header-link" href="#_10" title="Permanent link">&para;</a></h2>
<p><a href="./08_Prompt_Engineering.md">08_Prompt_Engineering.md</a>μ—μ„ ν¨κ³Όμ μΈ ν”„λ΅¬ν”„νΈ μ‘μ„± κΈ°λ²•μ„ ν•™μµν•©λ‹λ‹¤.</p>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/LLM_and_NLP/06_HuggingFace_Basics.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">06. HuggingFace κΈ°μ΄</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">π”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/LLM_and_NLP/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">π“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/LLM_and_NLP/08_Prompt_Engineering.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">08. ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">β†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}