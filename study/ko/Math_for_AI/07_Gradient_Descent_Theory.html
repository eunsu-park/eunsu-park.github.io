{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>07. ê²½ì‚¬ í•˜ê°•ë²• ì´ë¡  (Gradient Descent Theory) - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Math_for_AI/">Math for AI</a>
    <span class="separator">/</span>
    <span class="current">07. ê²½ì‚¬ í•˜ê°•ë²• ì´ë¡  (Gradient Descent Theory)</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>07. ê²½ì‚¬ í•˜ê°•ë²• ì´ë¡  (Gradient Descent Theory)</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Math_for_AI/06_Optimization_Fundamentals.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">06. ìµœì í™” ê¸°ì´ˆ (Optimization Fundamentals)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Math_for_AI/08_Probability_for_ML.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">08. ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ í™•ë¥ ë¡  (Probability for Machine Learning)</span>
        </a>
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">í•™ìŠµ ëª©í‘œ</a></li>
<li><a href="#1">1. ê²½ì‚¬ í•˜ê°•ë²• ê¸°ë³¸</a><ul>
<li><a href="#11">1.1 ê¸°ë³¸ ì›ë¦¬</a></li>
<li><a href="#12-1">1.2 1ì°¨ í…Œì¼ëŸ¬ ê·¼ì‚¬</a></li>
<li><a href="#13">1.3 êµ¬í˜„ ë° ì‹œê°í™”</a></li>
<li><a href="#14">1.4 í•™ìŠµë¥ ì˜ ì„ íƒ</a></li>
</ul>
</li>
<li><a href="#2-convergence-analysis">2. ìˆ˜ë ´ ë¶„ì„ (Convergence Analysis)</a><ul>
<li><a href="#21">2.1 ë¦½ì‹œì¸  ì—°ì† ê·¸ë˜ë””ì–¸íŠ¸</a></li>
<li><a href="#22">2.2 ë³¼ë¡ í•¨ìˆ˜ì—ì„œì˜ ìˆ˜ë ´</a></li>
<li><a href="#23">2.3 ê°•ë³¼ë¡ í•¨ìˆ˜ì—ì„œì˜ ìˆ˜ë ´</a></li>
<li><a href="#24">2.4 ìˆ˜ë ´ ì†ë„ ì‹œë®¬ë ˆì´ì…˜</a></li>
</ul>
</li>
<li><a href="#3-stochastic-gradient-descent">3. í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²• (Stochastic Gradient Descent)</a><ul>
<li><a href="#31-vs">3.1 ë°°ì¹˜ vs ë¯¸ë‹ˆë°°ì¹˜</a></li>
<li><a href="#32-sgd">3.2 SGDì˜ ì¥ì ê³¼ ë‹¨ì </a></li>
<li><a href="#33">3.3 ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°ì˜ ì˜í–¥</a></li>
<li><a href="#34-sgd">3.4 SGDì˜ ë¶„ì‚°ê³¼ í•™ìŠµë¥ </a></li>
</ul>
</li>
<li><a href="#4">4. ëª¨ë©˜í…€ ê¸°ë°˜ ë°©ë²•</a><ul>
<li><a href="#41-sgd">4.1 ëª¨ë©˜í…€ SGD</a></li>
<li><a href="#42-nag">4.2 ë„¤ìŠ¤í…Œë¡œí”„ ê°€ì† ê²½ì‚¬ë²• (NAG)</a></li>
</ul>
</li>
<li><a href="#5">5. ì ì‘ì  í•™ìŠµë¥  ë°©ë²•</a><ul>
<li><a href="#51-adagrad">5.1 AdaGrad</a></li>
<li><a href="#52-rmsprop">5.2 RMSProp</a></li>
<li><a href="#53-adam">5.3 Adam</a></li>
<li><a href="#54">5.4 êµ¬í˜„ ë° ë¹„êµ</a></li>
<li><a href="#55-adam-bias-correction">5.5 Adamì˜ í¸í–¥ ë³´ì • (Bias Correction)</a></li>
</ul>
</li>
<li><a href="#6">6. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„</a><ul>
<li><a href="#61">6.1 ì£¼ìš” ìŠ¤ì¼€ì¤„ë§ ì „ëµ</a></li>
</ul>
</li>
<li><a href="#7">7. ì‹ ê²½ë§ ìµœì í™”ì˜ ì‹¤ì „ ê³ ë ¤ì‚¬í•­</a><ul>
<li><a href="#71">7.1 ì†ì‹¤ ì§€í˜•ì˜ ê¸°í•˜í•™</a></li>
<li><a href="#72-sharp-minima-vs-flat-minima">7.2 Sharp Minima vs Flat Minima</a></li>
<li><a href="#73-gradient-clipping">7.3 ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (Gradient Clipping)</a></li>
<li><a href="#74">7.4 ì‹¤ì „ ìµœì í™” ë ˆì‹œí”¼</a></li>
</ul>
</li>
<li><a href="#_2">ì—°ìŠµ ë¬¸ì œ</a></li>
<li><a href="#_3">ì°¸ê³  ìë£Œ</a></li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="07-gradient-descent-theory">07. ê²½ì‚¬ í•˜ê°•ë²• ì´ë¡  (Gradient Descent Theory)<a class="header-link" href="#07-gradient-descent-theory" title="Permanent link">&para;</a></h1>
<h2 id="_1">í•™ìŠµ ëª©í‘œ<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>ê²½ì‚¬ í•˜ê°•ë²•ì˜ ê¸°ë³¸ ì›ë¦¬ì™€ ì—…ë°ì´íŠ¸ ê·œì¹™ì„ ì´í•´í•˜ê³  êµ¬í˜„í•œë‹¤</li>
<li>ë³¼ë¡ í•¨ìˆ˜ì™€ ê°•ë³¼ë¡ í•¨ìˆ˜ì—ì„œì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•œë‹¤</li>
<li>í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(SGD)ì˜ ì›ë¦¬ì™€ ë¯¸ë‹ˆë°°ì¹˜ì˜ ì—­í• ì„ í•™ìŠµí•œë‹¤</li>
<li>ëª¨ë©˜í…€ê³¼ ë„¤ìŠ¤í…Œë¡œí”„ ê°€ì† ê²½ì‚¬ë²•ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ë¬¼ë¦¬ì  ì§ê´€ìœ¼ë¡œ ì´í•´í•œë‹¤</li>
<li>Adam, RMSProp ë“± ì ì‘ì  í•™ìŠµë¥  ë°©ë²•ì˜ ìœ ë„ ê³¼ì •ì„ í•™ìŠµí•œë‹¤</li>
<li>ì‹ ê²½ë§ ìµœì í™”ì—ì„œì˜ ì‹¤ì „ ê³ ë ¤ì‚¬í•­ì„ ì´í•´í•˜ê³  ì ìš©í•œë‹¤</li>
</ul>
<hr />
<h2 id="1">1. ê²½ì‚¬ í•˜ê°•ë²• ê¸°ë³¸<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 ê¸°ë³¸ ì›ë¦¬<a class="header-link" href="#11" title="Permanent link">&para;</a></h3>
<p>ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent)ì€ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ë°˜ë³µì ìœ¼ë¡œ ì´ë™í•˜ëŠ” 1ì°¨ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.</p>
<p><strong>ì—…ë°ì´íŠ¸ ê·œì¹™:</strong></p>
<p>$$
x_{t+1} = x_t - \eta \nabla f(x_t)
$$</p>
<ul>
<li>$x_t$: $t$ ì‹œì ì˜ íŒŒë¼ë¯¸í„°</li>
<li>$\eta$: í•™ìŠµë¥  (learning rate, step size)</li>
<li>$\nabla f(x_t)$: $x_t$ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸</li>
</ul>
<p><strong>ì§ê´€:</strong>
- ê·¸ë˜ë””ì–¸íŠ¸ $\nabla f(x)$ëŠ” í•¨ìˆ˜ê°€ ê°€ì¥ ë¹ ë¥´ê²Œ ì¦ê°€í•˜ëŠ” ë°©í–¥
- ìŒì˜ ê·¸ë˜ë””ì–¸íŠ¸ $-\nabla f(x)$ëŠ” ê°€ì¥ ë¹ ë¥´ê²Œ ê°ì†Œí•˜ëŠ” ë°©í–¥ (ìµœëŒ€ ê²½ì‚¬ í•˜ê°•)
- í•™ìŠµë¥  $\eta$ëŠ” ê° ìŠ¤í…ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆ</p>
<h3 id="12-1">1.2 1ì°¨ í…Œì¼ëŸ¬ ê·¼ì‚¬<a class="header-link" href="#12-1" title="Permanent link">&para;</a></h3>
<p>ê²½ì‚¬ í•˜ê°•ë²•ì€ 1ì°¨ í…Œì¼ëŸ¬ ê·¼ì‚¬ì— ê¸°ë°˜í•©ë‹ˆë‹¤:</p>
<p>$$
f(x + \Delta x) \approx f(x) + \nabla f(x)^T \Delta x
$$</p>
<p>$\Delta x = -\eta \nabla f(x)$ë¡œ ì„ íƒí•˜ë©´:</p>
<p>$$
f(x - \eta \nabla f(x)) \approx f(x) - \eta \|\nabla f(x)\|^2
$$</p>
<p>$\eta$ê°€ ì¶©ë¶„íˆ ì‘ìœ¼ë©´ í•¨ìˆ˜ ê°’ì´ ê°ì†Œí•©ë‹ˆë‹¤.</p>
<h3 id="13">1.3 êµ¬í˜„ ë° ì‹œê°í™”<a class="header-link" href="#13" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.animation</span><span class="w"> </span><span class="kn">import</span> <span class="n">FuncAnimation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">HTML</span>

<span class="c1"># ëª©ì  í•¨ìˆ˜: f(x,y) = (x-1)^2 + 2(y-2)^2</span>
<span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">df_dx</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">df_dy</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">df_dx</span><span class="p">,</span> <span class="n">df_dy</span><span class="p">])</span>

<span class="c1"># ê²½ì‚¬ í•˜ê°•ë²•</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ê¸°ë³¸ ê²½ì‚¬ í•˜ê°•ë²•&quot;&quot;&quot;</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>

<span class="c1"># ì´ˆê¸°ì </span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

<span class="c1"># ì—¬ëŸ¬ í•™ìŠµë¥ ë¡œ ì‹¤í—˜</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># ë“±ê³ ì„  ê·¸ë¦¬ë“œ</span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="c1"># ë“±ê³ ì„ </span>
    <span class="n">contour</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># ê²½ì‚¬ í•˜ê°•ë²• ê¶¤ì </span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GD ê¶¤ì &#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;g*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ì‹œì‘ì &#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;r*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ìµœì†Ÿê°’&#39;</span><span class="p">)</span>

    <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ ë²¡í„° í‘œì‹œ (ì²˜ìŒ ëª‡ ê°œ)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">x_curr</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">x_curr</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_curr</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="n">x_curr</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_curr</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">angles</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale_units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;í•™ìŠµë¥  Î· = </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1"> iterations)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># ìˆ˜ë ´ ì •ë³´</span>
    <span class="n">final_x</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">final_loss</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">final_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">final_x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">distance_to_optimum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">final_x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;ìµœì¢… ì†ì‹¤: </span><span class="si">{</span><span class="n">final_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s1">ìµœì†Ÿê°’ê¹Œì§€ ê±°ë¦¬: </span><span class="si">{</span><span class="n">distance_to_optimum</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">,</span>
            <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;wheat&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;gradient_descent_learning_rates.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;í•™ìŠµë¥ ì˜ ì˜í–¥:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Î· ë„ˆë¬´ ì‘ìŒ: ìˆ˜ë ´ ëŠë¦¼&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Î· ì ì ˆí•¨: ë¹ ë¥¸ ìˆ˜ë ´&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Î· ë„ˆë¬´ í¼: ë°œì‚° ë˜ëŠ” ì§„ë™&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="14">1.4 í•™ìŠµë¥ ì˜ ì„ íƒ<a class="header-link" href="#14" title="Permanent link">&para;</a></h3>
<p><strong>í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ìœ¼ë©´:</strong>
- ìˆ˜ë ´ì´ ë§¤ìš° ëŠë¦¼
- ë§ì€ ë°˜ë³µ í•„ìš”</p>
<p><strong>í•™ìŠµë¥ ì´ ë„ˆë¬´ í¬ë©´:</strong>
- ìµœì†Ÿê°’ ì£¼ë³€ì—ì„œ ì§„ë™
- ë°œì‚° ê°€ëŠ¥</p>
<p><strong>ì ì ˆí•œ í•™ìŠµë¥ :</strong>
- ì´ë¡ ì  ìƒí•œ: $\eta \leq \frac{1}{L}$ (L: ë¦½ì‹œì¸  ìƒìˆ˜)
- ì‹¤ì „: ê·¸ë¦¬ë“œ ì„œì¹˜ ë˜ëŠ” í•™ìŠµë¥  ìŠ¤ì¼€ì¤„</p>
<div class="highlight"><pre><span></span><code><span class="c1"># í•™ìŠµë¥ ì— ë”°ë¥¸ ìˆ˜ë ´ ê³¡ì„ </span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">objective</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trajectory</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Î· = </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;í•™ìŠµë¥ ì— ë”°ë¥¸ ì†ì‹¤ ê°ì†Œ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;learning_rate_convergence.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<h2 id="2-convergence-analysis">2. ìˆ˜ë ´ ë¶„ì„ (Convergence Analysis)<a class="header-link" href="#2-convergence-analysis" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 ë¦½ì‹œì¸  ì—°ì† ê·¸ë˜ë””ì–¸íŠ¸<a class="header-link" href="#21" title="Permanent link">&para;</a></h3>
<p>í•¨ìˆ˜ $f$ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ë¦½ì‹œì¸  ì—°ì†ì´ë¼ëŠ” ê²ƒì€ ë‹¤ìŒì„ ë§Œì¡±í•˜ëŠ” ìƒìˆ˜ $L > 0$ì´ ì¡´ì¬í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤:</p>
<p>$$
\|\nabla f(x) - \nabla f(y)\| \leq L\|x - y\|, \quad \forall x, y
$$</p>
<p>ì´ëŠ” $\nabla^2 f(x) \preceq LI$ (í—¤ì‹œì•ˆì´ $LI$ë¡œ ìƒí•œ bounded)ì™€ ë™ë“±í•©ë‹ˆë‹¤.</p>
<h3 id="22">2.2 ë³¼ë¡ í•¨ìˆ˜ì—ì„œì˜ ìˆ˜ë ´<a class="header-link" href="#22" title="Permanent link">&para;</a></h3>
<p><strong>ì •ë¦¬ (ë³¼ë¡ í•¨ìˆ˜):</strong>
$f$ê°€ ë³¼ë¡ì´ê³  ê·¸ë˜ë””ì–¸íŠ¸ê°€ $L$-ë¦½ì‹œì¸  ì—°ì†ì´ë©´, í•™ìŠµë¥  $\eta = \frac{1}{L}$ì¼ ë•Œ:</p>
<p>$$
f(x_t) - f(x^*) \leq \frac{L\|x_0 - x^*\|^2}{2t}
$$</p>
<p>ì¦‰, <strong>ì„œë¸Œì„ í˜• (sublinear) ìˆ˜ë ´</strong>: $O(1/t)$</p>
<h3 id="23">2.3 ê°•ë³¼ë¡ í•¨ìˆ˜ì—ì„œì˜ ìˆ˜ë ´<a class="header-link" href="#23" title="Permanent link">&para;</a></h3>
<p>í•¨ìˆ˜ $f$ê°€ $m$-ê°•ë³¼ë¡ì´ë¼ëŠ” ê²ƒì€:</p>
<p>$$
f(y) \geq f(x) + \nabla f(x)^T(y-x) + \frac{m}{2}\|y-x\|^2
$$</p>
<p>ë˜ëŠ” ë™ë“±í•˜ê²Œ $\nabla^2 f(x) \succeq mI$.</p>
<p><strong>ì •ë¦¬ (ê°•ë³¼ë¡ í•¨ìˆ˜):</strong>
$f$ê°€ $m$-ê°•ë³¼ë¡ì´ê³  ê·¸ë˜ë””ì–¸íŠ¸ê°€ $L$-ë¦½ì‹œì¸  ì—°ì†ì´ë©´, í•™ìŠµë¥  $\eta = \frac{1}{L}$ì¼ ë•Œ:</p>
<p>$$
\|x_t - x^*\|^2 \leq \left(1 - \frac{m}{L}\right)^t \|x_0 - x^*\|^2
$$</p>
<p>ì¦‰, <strong>ì„ í˜• ìˆ˜ë ´ (linear convergence)</strong>: $O(\rho^t)$, where $\rho = 1 - \frac{m}{L} < 1$</p>
<p><strong>ì¡°ê±´ìˆ˜ (Condition Number):</strong>
$$\kappa = \frac{L}{m}$$</p>
<p>ì¡°ê±´ìˆ˜ê°€ í´ìˆ˜ë¡ (ill-conditioned) ìˆ˜ë ´ì´ ëŠë¦½ë‹ˆë‹¤.</p>
<h3 id="24">2.4 ìˆ˜ë ´ ì†ë„ ì‹œë®¬ë ˆì´ì…˜<a class="header-link" href="#24" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># ì´ì°¨ í˜•ì‹: f(x) = 0.5 * x^T A x</span>
<span class="c1"># ê°•ë³¼ë¡: eigenvalues(A) &gt; 0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_quadratic</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ê°•ë³¼ë¡ ì´ì°¨ í•¨ìˆ˜ ìƒì„± (ì¡°ê±´ìˆ˜ Îº = L/m)&quot;&quot;&quot;</span>
    <span class="c1"># ê³ ìœ ê°’ì„ mê³¼ L ì‚¬ì´ì— ê· ë“± ë¶„í¬</span>
    <span class="n">eigenvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
    <span class="c1"># ëœë¤ ì§êµ í–‰ë ¬</span>
    <span class="n">Q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
    <span class="c1"># A = Q Î› Q^T</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eigenvalues</span><span class="p">)</span> <span class="o">@</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">A</span>

<span class="k">def</span><span class="w"> </span><span class="nf">quadratic_objective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">@</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">quadratic_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gd_quadratic</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ì´ì°¨ í•¨ìˆ˜ì— ëŒ€í•œ ê²½ì‚¬ í•˜ê°•ë²•&quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># ||x - x*||^2, x* = 0</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">quadratic_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trajectory</span>

<span class="c1"># ì‹¤í—˜ ì„¤ì •</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># ì—¬ëŸ¬ ì¡°ê±´ìˆ˜ë¡œ ì‹¤í—˜</span>
<span class="n">condition_numbers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">kappa</span> <span class="ow">in</span> <span class="n">condition_numbers</span><span class="p">:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">kappa</span> <span class="o">*</span> <span class="n">m</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">create_quadratic</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="c1"># ì´ˆê¸°ì </span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="c1"># ê²½ì‚¬ í•˜ê°•ë²•</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">L</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="n">gd_quadratic</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">)</span>

    <span class="c1"># ì„ í˜• ìŠ¤ì¼€ì¼</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trajectory</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Îº = </span><span class="si">{</span><span class="n">kappa</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># ë¡œê·¸ ìŠ¤ì¼€ì¼</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">trajectory</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Îº = </span><span class="si">{</span><span class="n">kappa</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># ì´ë¡ ì  ìˆ˜ë ´ ì†ë„</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">m</span><span class="o">/</span><span class="n">L</span>
    <span class="n">theoretical</span> <span class="o">=</span> <span class="p">[</span><span class="n">trajectory</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rho</span> <span class="o">**</span> <span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">theoretical</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
                     <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;ì´ë¡  (Îº=</span><span class="si">{</span><span class="n">kappa</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$\|x_t - x^*\|^2$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ìˆ˜ë ´ ê³¡ì„  (ì„ í˜• ìŠ¤ì¼€ì¼)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$\|x_t - x^*\|^2$ (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ìˆ˜ë ´ ê³¡ì„  (ë¡œê·¸ ìŠ¤ì¼€ì¼): ì„ í˜• ìˆ˜ë ´&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;convergence_analysis_condition_number.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ì¡°ê±´ìˆ˜ì˜ ì˜í–¥:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Îº = 1: ì™„ë²½í•œ ì¡°ê±´ (ëª¨ë“  ë°©í–¥ ë™ì¼í•œ ê³¡ë¥ )&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Îº &gt;&gt; 1: ill-conditioned (ì¼ë¶€ ë°©í–¥ ë§¤ìš° í‰íƒ„)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  ìˆ˜ë ´ ì†ë„: O((1 - 1/Îº)^t)&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="3-stochastic-gradient-descent">3. í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²• (Stochastic Gradient Descent)<a class="header-link" href="#3-stochastic-gradient-descent" title="Permanent link">&para;</a></h2>
<h3 id="31-vs">3.1 ë°°ì¹˜ vs ë¯¸ë‹ˆë°°ì¹˜<a class="header-link" href="#31-vs" title="Permanent link">&para;</a></h3>
<p><strong>ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²• (Batch GD):</strong>
ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°:
$$x_{t+1} = x_t - \eta \nabla f(x_t) = x_t - \eta \frac{1}{n}\sum_{i=1}^n \nabla f_i(x_t)$$</p>
<p><strong>í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²• (SGD):</strong>
ëœë¤í•˜ê²Œ ì„ íƒí•œ í•˜ë‚˜ì˜ ìƒ˜í”Œë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •:
$$x_{t+1} = x_t - \eta \nabla f_{i_t}(x_t)$$</p>
<p><strong>ë¯¸ë‹ˆë°°ì¹˜ SGD:</strong>
$B$ ê°œ ìƒ˜í”Œì˜ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •:
$$x_{t+1} = x_t - \eta \frac{1}{|B|}\sum_{i \in B} \nabla f_i(x_t)$$</p>
<h3 id="32-sgd">3.2 SGDì˜ ì¥ì ê³¼ ë‹¨ì <a class="header-link" href="#32-sgd" title="Permanent link">&para;</a></h3>
<p><strong>ì¥ì :</strong>
- <strong>ê³„ì‚° íš¨ìœ¨</strong>: ë§¤ ë°˜ë³µë§ˆë‹¤ ì „ì²´ ë°ì´í„° ë¶ˆí•„ìš”
- <strong>ë©”ëª¨ë¦¬ íš¨ìœ¨</strong>: í° ë°ì´í„°ì…‹ì— ì í•©
- <strong>ì •ê·œí™” íš¨ê³¼</strong>: ë…¸ì´ì¦ˆê°€ ë‚ ì¹´ë¡œìš´ ìµœì†Ÿê°’ íƒˆì¶œ ë„ì›€
- <strong>ì˜¨ë¼ì¸ í•™ìŠµ</strong>: ë°ì´í„°ê°€ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë„ì°©í•´ë„ ê°€ëŠ¥</p>
<p><strong>ë‹¨ì :</strong>
- <strong>ë…¸ì´ì¦ˆ</strong>: ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •ì´ ë¶ˆì•ˆì •
- <strong>í•™ìŠµë¥  ì¡°ì •</strong>: ë°°ì¹˜ GDë³´ë‹¤ ë¯¼ê°
- <strong>ìˆ˜ë ´ ì†ë„</strong>: ì´ë¡ ì ìœ¼ë¡œ ëŠë¦¼ (í•˜ì§€ë§Œ ì‹¤ì „ì—ì„œëŠ” ë¹ ë¦„)</p>
<h3 id="33">3.3 ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°ì˜ ì˜í–¥<a class="header-link" href="#33" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># í•©ì„± ë°ì´í„°: ì„ í˜• íšŒê·€</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">true_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">true_w</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MSE ì†ì‹¤&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mse_gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MSE ê·¸ë˜ë””ì–¸íŠ¸&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sgd_minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ë¯¸ë‹ˆë°°ì¹˜ SGD&quot;&quot;&quot;</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># ë°ì´í„° ì…”í”Œ</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="n">X_shuffled</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">y_shuffled</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="c1"># ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>

            <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì—…ë°ì´íŠ¸</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">mse_gradient</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>

        <span class="c1"># ì—í¬í¬ë§ˆë‹¤ ì „ì²´ ì†ì‹¤ ê¸°ë¡</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">losses</span>

<span class="c1"># ì—¬ëŸ¬ ë°°ì¹˜ í¬ê¸°ë¡œ ì‹¤í—˜</span>
<span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="n">batch_sizes</span><span class="p">:</span>
    <span class="n">w_final</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">sgd_minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>

    <span class="c1"># ì†ì‹¤ ê³¡ì„ </span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Batch size = </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Batch size = </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ë°°ì¹˜ í¬ê¸°ì— ë”°ë¥¸ ìˆ˜ë ´&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ë°°ì¹˜ í¬ê¸°ì— ë”°ë¥¸ ìˆ˜ë ´ (ë¡œê·¸ ìŠ¤ì¼€ì¼)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;sgd_batch_size_effect.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ë°°ì¹˜ í¬ê¸°ì˜ ì˜í–¥:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  ì‘ì€ ë°°ì¹˜: ë…¸ì´ì¦ˆ í¬ê³  ë¶ˆì•ˆì •, ì •ê·œí™” íš¨ê³¼, ë©”ëª¨ë¦¬ íš¨ìœ¨&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  í° ë°°ì¹˜: ì•ˆì •ì  ê·¸ë˜ë””ì–¸íŠ¸, ë¹ ë¥¸ ìˆ˜ë ´, ê³„ì‚° ë³‘ë ¬í™”&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  ì‹¤ì „: 32, 64, 128, 256 ë“± 2ì˜ ê±°ë“­ì œê³± (GPU ìµœì í™”)&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="34-sgd">3.4 SGDì˜ ë¶„ì‚°ê³¼ í•™ìŠµë¥ <a class="header-link" href="#34-sgd" title="Permanent link">&para;</a></h3>
<p>SGD ê·¸ë˜ë””ì–¸íŠ¸ì˜ ê¸°ëŒ“ê°’ì€ ì°¸ ê·¸ë˜ë””ì–¸íŠ¸ì™€ ê°™ì§€ë§Œ, ë¶„ì‚°ì´ ì¡´ì¬í•©ë‹ˆë‹¤:</p>
<p>$$
\mathbb{E}[\nabla f_i(x)] = \nabla f(x), \quad \text{Var}[\nabla f_i(x)] = \sigma^2
$$</p>
<p>ë¶„ì‚°ì´ í¬ë©´ ìˆ˜ë ´ì´ ëŠë ¤ì§€ê³  ë¶ˆì•ˆì •í•´ì§‘ë‹ˆë‹¤. í•´ê²°ì±…:
- <strong>í•™ìŠµë¥  ê°ì†Œ (learning rate decay)</strong>: $\eta_t = \frac{\eta_0}{\sqrt{t}}$
- <strong>ë¯¸ë‹ˆë°°ì¹˜ ì¦ê°€</strong>: ë¶„ì‚° $\propto 1/|B|$
- <strong>ì ì‘ì  ë°©ë²•</strong>: Adam, RMSProp</p>
<h2 id="4">4. ëª¨ë©˜í…€ ê¸°ë°˜ ë°©ë²•<a class="header-link" href="#4" title="Permanent link">&para;</a></h2>
<h3 id="41-sgd">4.1 ëª¨ë©˜í…€ SGD<a class="header-link" href="#41-sgd" title="Permanent link">&para;</a></h3>
<p>ê¸°ë³¸ ëª¨ë©˜í…€ (Heavy Ball):</p>
<p>$$
\begin{align}
v_t &= \beta v_{t-1} + \nabla f(x_t) \\
x_{t+1} &= x_t - \eta v_t
\end{align}
$$</p>
<p>ì—¬ê¸°ì„œ $\beta \in [0, 1)$ì€ ëª¨ë©˜í…€ ê³„ìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 0.9).</p>
<p><strong>ë¬¼ë¦¬ì  ì§ê´€:</strong>
- ê³µì´ ì–¸ë•ì„ êµ¬ë¥´ëŠ” ê²ƒì²˜ëŸ¼, ê³¼ê±° ë°©í–¥ì˜ ê´€ì„± ìœ ì§€
- ì¼ê´€ëœ ë°©í–¥ìœ¼ë¡œ ê°€ì†, ì§„ë™ ê°ì‡ 
- ì§€ì—­ ìµœì†Ÿê°’ê³¼ ì•ˆì¥ì  íƒˆì¶œì— ë„ì›€</p>
<h3 id="42-nag">4.2 ë„¤ìŠ¤í…Œë¡œí”„ ê°€ì† ê²½ì‚¬ë²• (NAG)<a class="header-link" href="#42-nag" title="Permanent link">&para;</a></h3>
<p><strong>Nesterov Accelerated Gradient:</strong></p>
<p>$$
\begin{align}
v_t &= \beta v_{t-1} + \nabla f(x_t - \beta v_{t-1}) \\
x_{t+1} &= x_t - \eta v_t
\end{align}
$$</p>
<p><strong>í•µì‹¬ ì•„ì´ë””ì–´:</strong>
- "ë¯¸ë˜"ë¥¼ ë¨¼ì € ë‚´ë‹¤ë³´ê³  ($x_t - \beta v_{t-1}$) ê·¸ê³³ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
- ëª¨ë©˜í…€ë³´ë‹¤ ë” ë˜‘ë˜‘í•œ look-ahead
- ì´ë¡ ì ìœ¼ë¡œ ë” ë‚˜ì€ ìˆ˜ë ´ ì†ë„</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Rosenbrock í•¨ìˆ˜</span>
<span class="k">def</span><span class="w"> </span><span class="nf">rosenbrock</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span><span class="w"> </span><span class="nf">rosenbrock_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">df_dx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">df_dy</span> <span class="o">=</span> <span class="mi">200</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">df_dx</span><span class="p">,</span> <span class="n">df_dy</span><span class="p">])</span>

<span class="c1"># ê¸°ë³¸ GD</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">rosenbrock_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>

<span class="c1"># ëª¨ë©˜í…€ GD</span>
<span class="k">def</span><span class="w"> </span><span class="nf">momentum_gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">rosenbrock_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="n">grad</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">v</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>

<span class="c1"># Nesterov GD</span>
<span class="k">def</span><span class="w"> </span><span class="nf">nesterov_gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="c1"># Look-ahead</span>
        <span class="n">x_lookahead</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">v</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">rosenbrock_gradient</span><span class="p">(</span><span class="n">x_lookahead</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_lookahead</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="n">grad</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">v</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>

<span class="c1"># ì‹œê°í™”</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">trajectories</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;GD&#39;</span><span class="p">:</span> <span class="n">gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">),</span>
    <span class="s1">&#39;Momentum&#39;</span><span class="p">:</span> <span class="n">momentum_gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">),</span>
    <span class="s1">&#39;Nesterov&#39;</span><span class="p">:</span> <span class="n">nesterov_gd</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># ë“±ê³ ì„ </span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">rosenbrock</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># ì™¼ìª½: ê¶¤ì  ë¹„êµ</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">levels</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;GD&#39;</span><span class="p">:</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;Momentum&#39;</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;Nesterov&#39;</span><span class="p">:</span> <span class="s1">&#39;green&#39;</span><span class="p">}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
            <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;k*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ìµœì†Ÿê°’ (1, 1)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Rosenbrock í•¨ìˆ˜: ëª¨ë©˜í…€ vs Nesterov&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># ì˜¤ë¥¸ìª½: ì†ì‹¤ ê³¡ì„ </span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">rosenbrock</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ì†ì‹¤ ê°ì†Œ ë¹„êµ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;momentum_vs_nesterov.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ëª¨ë©˜í…€ì˜ íš¨ê³¼:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì¼ê´€ëœ ë°©í–¥ìœ¼ë¡œ ê°€ì†&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì§„ë™ ê°ì‡  (íŠ¹íˆ ill-conditioned ë¬¸ì œ)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì•ˆì¥ì  ë” ë¹ ë¥´ê²Œ í†µê³¼&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Nesterovì˜ ì¥ì :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Look-aheadë¡œ ë” í˜„ëª…í•œ ì—…ë°ì´íŠ¸&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì´ë¡ ì ìœ¼ë¡œ ë” ë‚˜ì€ ìˆ˜ë ´ ì†ë„&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="5">5. ì ì‘ì  í•™ìŠµë¥  ë°©ë²•<a class="header-link" href="#5" title="Permanent link">&para;</a></h2>
<h3 id="51-adagrad">5.1 AdaGrad<a class="header-link" href="#51-adagrad" title="Permanent link">&para;</a></h3>
<p><strong>Adaptive Gradient Algorithm:</strong></p>
<p>$$
\begin{align}
G_t &= G_{t-1} + \nabla f(x_t) \odot \nabla f(x_t) \quad \text{(ëˆ„ì  ì œê³±)} \\
x_{t+1} &= x_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot \nabla f(x_t)
\end{align}
$$</p>
<ul>
<li>$\odot$: ì›ì†Œë³„ ê³±ì…ˆ (Hadamard product)</li>
<li>$\epsilon$: ìˆ˜ì¹˜ ì•ˆì •ì„± ($10^{-8}$)</li>
</ul>
<p><strong>íŠ¹ì§•:</strong>
- ìì£¼ ì—…ë°ì´íŠ¸ë˜ëŠ” íŒŒë¼ë¯¸í„°: í•™ìŠµë¥  ê°ì†Œ
- ë“œë¬¼ê²Œ ì—…ë°ì´íŠ¸ë˜ëŠ” íŒŒë¼ë¯¸í„°: í•™ìŠµë¥  ìœ ì§€
- <strong>ë¬¸ì œì </strong>: $G_t$ê°€ ê³„ì† ì¦ê°€ â†’ í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ì•„ì§</p>
<h3 id="52-rmsprop">5.2 RMSProp<a class="header-link" href="#52-rmsprop" title="Permanent link">&para;</a></h3>
<p><strong>Root Mean Square Propagation:</strong></p>
<p>$$
\begin{align}
G_t &= \beta G_{t-1} + (1-\beta) \nabla f(x_t) \odot \nabla f(x_t) \quad \text{(ì§€ìˆ˜ ì´ë™ í‰ê· )} \\
x_{t+1} &= x_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot \nabla f(x_t)
\end{align}
$$</p>
<p><strong>AdaGrad ê°œì„ :</strong>
- ëˆ„ì  ëŒ€ì‹  ì§€ìˆ˜ ì´ë™ í‰ê·  (EMA)
- ì˜¤ë˜ëœ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ì˜í–¥ ê°ì‡ 
- í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ì•„ì§€ëŠ” ë¬¸ì œ í•´ê²°</p>
<h3 id="53-adam">5.3 Adam<a class="header-link" href="#53-adam" title="Permanent link">&para;</a></h3>
<p><strong>Adaptive Moment Estimation:</strong></p>
<p>$$
\begin{align}
m_t &= \beta_1 m_{t-1} + (1-\beta_1) \nabla f(x_t) \quad \text{(1ì°¨ ëª¨ë©˜íŠ¸, í‰ê· )} \\
v_t &= \beta_2 v_{t-1} + (1-\beta_2) \nabla f(x_t) \odot \nabla f(x_t) \quad \text{(2ì°¨ ëª¨ë©˜íŠ¸, ë¶„ì‚°)} \\
\hat{m}_t &= \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t} \quad \text{(í¸í–¥ ë³´ì •)} \\
x_{t+1} &= x_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot \hat{m}_t
\end{align}
$$</p>
<p><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„°:</strong>
- $\beta_1 = 0.9$ (1ì°¨ ëª¨ë©˜íŠ¸ ê°ì‡ )
- $\beta_2 = 0.999$ (2ì°¨ ëª¨ë©˜íŠ¸ ê°ì‡ )
- $\eta = 0.001$ (í•™ìŠµë¥ )
- $\epsilon = 10^{-8}$</p>
<p><strong>íŠ¹ì§•:</strong>
- ëª¨ë©˜í…€ + ì ì‘ì  í•™ìŠµë¥ 
- í¸í–¥ ë³´ì •: ì´ˆê¸° ë‹¨ê³„ì—ì„œ ëª¨ë©˜íŠ¸ ì¶”ì •ì˜ í¸í–¥ ì œê±°
- ëŒ€ë¶€ë¶„ì˜ ë”¥ëŸ¬ë‹ ë¬¸ì œì—ì„œ ì˜ ì‘ë™</p>
<h3 id="54">5.4 êµ¬í˜„ ë° ë¹„êµ<a class="header-link" href="#54" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># ìµœì í™” ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Optimizer</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Momentum</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">+</span> <span class="n">grad</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdaGrad</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">+=</span> <span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RMSProp</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Adam</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="c1"># í¸í–¥ ë³´ì •</span>
        <span class="n">m_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
        <span class="n">v_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">m_hat</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_hat</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

<span class="c1"># í…ŒìŠ¤íŠ¸ í•¨ìˆ˜: Beale í•¨ìˆ˜</span>
<span class="k">def</span><span class="w"> </span><span class="nf">beale</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mf">1.5</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mf">2.25</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mf">2.625</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span><span class="w"> </span><span class="nf">beale_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">df_dx</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">2.25</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> \
            <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">2.625</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">df_dy</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">2.25</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> \
            <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mf">2.625</span> <span class="o">-</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">df_dx</span><span class="p">,</span> <span class="n">df_dy</span><span class="p">])</span>

<span class="c1"># ìµœì í™” ì‹¤í–‰</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">500</span>

<span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;SGD&#39;</span><span class="p">:</span> <span class="n">SGD</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="s1">&#39;Momentum&#39;</span><span class="p">:</span> <span class="n">Momentum</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="s1">&#39;AdaGrad&#39;</span><span class="p">:</span> <span class="n">AdaGrad</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="s1">&#39;RMSProp&#39;</span><span class="p">:</span> <span class="n">RMSProp</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="s1">&#39;Adam&#39;</span><span class="p">:</span> <span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">trajectories</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">beale_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>
        <span class="n">traj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="n">trajectories</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span>

<span class="c1"># ì‹œê°í™”</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># ë“±ê³ ì„ </span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">beale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># ì™¼ìª½: ê¶¤ì </span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">levels</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;SGD&#39;</span><span class="p">:</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;Momentum&#39;</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;AdaGrad&#39;</span><span class="p">:</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span>
          <span class="s1">&#39;RMSProp&#39;</span><span class="p">:</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;Adam&#39;</span><span class="p">:</span> <span class="s1">&#39;orange&#39;</span><span class="p">}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
            <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;k*&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ìµœì†Ÿê°’&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Beale í•¨ìˆ˜: ì˜µí‹°ë§ˆì´ì € ë¹„êµ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># ì˜¤ë¥¸ìª½: ì†ì‹¤ ê³¡ì„ </span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">beale</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ì†ì‹¤ ê°ì†Œ ë¹„êµ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;optimizer_comparison.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ì˜µí‹°ë§ˆì´ì € íŠ¹ì§•:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  SGD: ë‹¨ìˆœ, ëŠë¦¼&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Momentum: ê°€ì†, ì§„ë™ ê°ì‡ &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  AdaGrad: í¬ì†Œ ë°ì´í„° ì í•©, í•™ìŠµë¥  ê°ì†Œ ë¬¸ì œ&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  RMSProp: AdaGrad ê°œì„ , ì•ˆì •ì &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Adam: ëŒ€ë¶€ë¶„ ìƒí™©ì—ì„œ ìš°ìˆ˜, ì‚¬ì‹¤ìƒ í‘œì¤€&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="55-adam-bias-correction">5.5 Adamì˜ í¸í–¥ ë³´ì • (Bias Correction)<a class="header-link" href="#55-adam-bias-correction" title="Permanent link">&para;</a></h3>
<p>ì´ˆê¸° ë‹¨ê³„ì—ì„œ $m_t$ì™€ $v_t$ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ë¯€ë¡œ 0ìœ¼ë¡œ í¸í–¥ë©ë‹ˆë‹¤. í¸í–¥ ë³´ì •ì€ ì´ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.</p>
<p>$$
\mathbb{E}[m_t] = \mathbb{E}\left[\sum_{i=1}^t \beta_1^{t-i}(1-\beta_1)g_i\right] = \mathbb{E}[g_t](1 - \beta_1^t)
$$</p>
<p>ë”°ë¼ì„œ $\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$ëŠ” ë¶ˆí¸ ì¶”ì •ëŸ‰ì…ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># í¸í–¥ ë³´ì • íš¨ê³¼ ì‹œê°í™”</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span>
<span class="n">t_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>

<span class="n">correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span> <span class="o">**</span> <span class="n">t_vals</span><span class="p">)</span>
<span class="n">correction2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span> <span class="o">**</span> <span class="n">t_vals</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_vals</span><span class="p">,</span> <span class="n">correction1</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;1ì°¨ ëª¨ë©˜íŠ¸ ë³´ì • (Î²â‚=</span><span class="si">{</span><span class="n">beta1</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_vals</span><span class="p">,</span> <span class="n">correction2</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;2ì°¨ ëª¨ë©˜íŠ¸ ë³´ì • (Î²â‚‚=</span><span class="si">{</span><span class="n">beta2</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;ë³´ì • ì—†ìŒ&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration t&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;ë³´ì • ê³„ìˆ˜&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Adam í¸í–¥ ë³´ì • ê³„ìˆ˜&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;adam_bias_correction.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;í¸í–¥ ë³´ì •ì˜ ì¤‘ìš”ì„±:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì´ˆê¸° ìŠ¤í…ì—ì„œ ëª¨ë©˜íŠ¸ê°€ 0ìœ¼ë¡œ í¸í–¥&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ë³´ì • ì—†ìœ¼ë©´ ì´ˆê¸° í•™ìŠµë¥ ì´ ê³¼ë„í•˜ê²Œ ì‘ìŒ&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ìˆ˜ì‹­ iteration í›„ ë³´ì • íš¨ê³¼ ì‚¬ë¼ì§&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="6">6. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„<a class="header-link" href="#6" title="Permanent link">&para;</a></h2>
<h3 id="61">6.1 ì£¼ìš” ìŠ¤ì¼€ì¤„ë§ ì „ëµ<a class="header-link" href="#61" title="Permanent link">&para;</a></h3>
<p><strong>Step Decay:</strong>
$$\eta_t = \eta_0 \cdot \gamma^{\lfloor t/k \rfloor}$$</p>
<p><strong>Exponential Decay:</strong>
$$\eta_t = \eta_0 \cdot e^{-\lambda t}$$</p>
<p><strong>Cosine Annealing:</strong>
$$\eta_t = \eta_{\min} + \frac{1}{2}(\eta_{\max} - \eta_{\min})\left(1 + \cos\left(\frac{t}{T}\pi\right)\right)$$</p>
<p><strong>1-Cycle Policy:</strong>
- ì´ˆê¸°: í•™ìŠµë¥  ì¦ê°€ (warm-up)
- ì¤‘ê°„: ìµœëŒ€ í•™ìŠµë¥  ìœ ì§€
- ë§ˆì§€ë§‰: í•™ìŠµë¥  ê°ì†Œ (annealing)</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">step_decay</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">eta0</span> <span class="o">*</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">**</span> <span class="p">(</span><span class="n">t</span> <span class="o">//</span> <span class="n">k</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">exponential_decay</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">eta0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lam</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">cosine_annealing</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">eta_max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">eta_min</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">eta_max</span> <span class="o">-</span> <span class="n">eta_min</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="n">T</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">one_cycle</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">eta_max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">warmup_frac</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">warmup_frac</span> <span class="o">*</span> <span class="n">T</span><span class="p">:</span>
        <span class="c1"># Warm-up</span>
        <span class="k">return</span> <span class="n">eta_min</span> <span class="o">+</span> <span class="p">(</span><span class="n">eta_max</span> <span class="o">-</span> <span class="n">eta_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="p">(</span><span class="n">warmup_frac</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Annealing</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">warmup_frac</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">warmup_frac</span><span class="p">)</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eta_min</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">eta_max</span> <span class="o">-</span> <span class="n">eta_min</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">progress</span><span class="p">))</span>

<span class="c1"># ì‹œê°í™”</span>
<span class="n">t_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">schedules</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;Step Decay&#39;</span><span class="p">,</span> <span class="n">step_decay</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span>
    <span class="p">(</span><span class="s1">&#39;Exponential Decay&#39;</span><span class="p">,</span> <span class="n">exponential_decay</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="p">(</span><span class="s1">&#39;Cosine Annealing&#39;</span><span class="p">,</span> <span class="n">cosine_annealing</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span>
    <span class="p">(</span><span class="s1">&#39;1-Cycle Policy&#39;</span><span class="p">,</span> <span class="n">one_cycle</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">schedules</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;Cosine Annealing&#39;</span><span class="p">:</span>
        <span class="n">lr_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">t_vals</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;1-Cycle Policy&#39;</span><span class="p">:</span>
        <span class="n">lr_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">t_vals</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lr_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">t_vals</span><span class="p">]</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_vals</span><span class="p">,</span> <span class="n">lr_vals</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Learning Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;learning_rate_schedules.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ì˜ ì—­í• :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì´ˆê¸°: í° í•™ìŠµë¥ ë¡œ ë¹ ë¥´ê²Œ ì¢‹ì€ ì˜ì—­ íƒìƒ‰&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - í›„ë°˜: ì‘ì€ í•™ìŠµë¥ ë¡œ ë¯¸ì„¸ ì¡°ì •&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Warm-up: ì´ˆê¸° ë¶ˆì•ˆì •ì„± ë°©ì§€&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - Cosine/1-Cycle: ë¶€ë“œëŸ¬ìš´ ê°ì†Œ, Transformer ë“±ì—ì„œ ì¸ê¸°&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="7">7. ì‹ ê²½ë§ ìµœì í™”ì˜ ì‹¤ì „ ê³ ë ¤ì‚¬í•­<a class="header-link" href="#7" title="Permanent link">&para;</a></h2>
<h3 id="71">7.1 ì†ì‹¤ ì§€í˜•ì˜ ê¸°í•˜í•™<a class="header-link" href="#71" title="Permanent link">&para;</a></h3>
<p>ì‹ ê²½ë§ì˜ ì†ì‹¤ í•¨ìˆ˜ëŠ”:
- <strong>ë¹„ë³¼ë¡</strong>: ì—¬ëŸ¬ ì§€ì—­ ìµœì†Ÿê°’
- <strong>ê³ ì°¨ì›</strong>: íŒŒë¼ë¯¸í„°ê°€ ìˆ˜ë°±ë§Œ~ìˆ˜ì‹­ì–µ ê°œ
- <strong>ì•ˆì¥ì  (Saddle Points)</strong>: ì–´ë–¤ ë°©í–¥ì€ ìµœì†Ÿê°’, ë‹¤ë¥¸ ë°©í–¥ì€ ìµœëŒ“ê°’
- <strong>í‰íƒ„ ì˜ì—­ (Plateaus)</strong>: ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê±°ì˜ 0</p>
<h3 id="72-sharp-minima-vs-flat-minima">7.2 Sharp Minima vs Flat Minima<a class="header-link" href="#72-sharp-minima-vs-flat-minima" title="Permanent link">&para;</a></h3>
<p><strong>Sharp Minima:</strong>
- ì¢ê³  ë‚ ì¹´ë¡œìš´ ìµœì†Ÿê°’
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¼ë°˜í™” ì„±ëŠ¥ ë‚®ìŒ
- í° ë°°ì¹˜ í¬ê¸°ì—ì„œ ìì£¼ ë°œìƒ</p>
<p><strong>Flat Minima:</strong>
- ë„“ê³  í‰íƒ„í•œ ìµœì†Ÿê°’
- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¼ë°˜í™” ì„±ëŠ¥ ë†’ìŒ
- ì‘ì€ ë°°ì¹˜ í¬ê¸° + SGD ë…¸ì´ì¦ˆë¡œ ì„ í˜¸</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes3D</span>

<span class="c1"># ì†ì‹¤ ì§€í˜• ì‹œë®¬ë ˆì´ì…˜</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sharp_minimum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ë‚ ì¹´ë¡œìš´ ìµœì†Ÿê°’&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">flat_minimum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;í‰íƒ„í•œ ìµœì†Ÿê°’&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Sharp minimum</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">Z_sharp</span> <span class="o">=</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">Y</span><span class="o">**</span><span class="mi">2</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z_sharp</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Sharp Minimum (ì¼ë°˜í™” ë‚®ìŒ)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;wâ‚&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;wâ‚‚&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

<span class="c1"># Flat minimum</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">Z_flat</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">Y</span><span class="o">**</span><span class="mi">2</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z_flat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Flat Minimum (ì¼ë°˜í™” ë†’ìŒ)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;wâ‚&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;wâ‚‚&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;sharp_vs_flat_minima.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sharp vs Flat Minima:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Sharp: íŒŒë¼ë¯¸í„° ì‘ì€ ë³€í™”ì— ì†ì‹¤ í¬ê²Œ ë³€í•¨ â†’ ê³¼ì í•©&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Flat: íŒŒë¼ë¯¸í„° ë³€í™”ì— ì†ì‹¤ ë‘”ê° â†’ ì¼ë°˜í™”&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  SGDì˜ ë…¸ì´ì¦ˆê°€ Flat Minima ì„ í˜¸í•˜ë„ë¡ ì•”ë¬µì  ì •ê·œí™”&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="73-gradient-clipping">7.3 ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (Gradient Clipping)<a class="header-link" href="#73-gradient-clipping" title="Permanent link">&para;</a></h3>
<p>RNN/Transformer ë“±ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ í­ë°œí•˜ëŠ” ë¬¸ì œ ë°©ì§€:</p>
<p><strong>Norm-based Clipping:</strong>
$$
\tilde{g} = \begin{cases}
g & \text{if } \|g\| \leq \theta \\
\theta \frac{g}{\|g\|} & \text{otherwise}
\end{cases}
$$</p>
<p><strong>Value-based Clipping:</strong>
$$
\tilde{g}_i = \max(-\theta, \min(\theta, g_i))
$$</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gradient_clipping_demo</span><span class="p">():</span>
    <span class="c1"># ê°„ë‹¨í•œ RNN ì‹œë®¬ë ˆì´ì…˜</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># í° ê°€ì¤‘ì¹˜</span>

    <span class="c1"># ìˆœë°©í–¥ (ì—¬ëŸ¬ ì‹œê°„ ìŠ¤í…)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">W</span> <span class="o">@</span> <span class="n">h</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;í´ë¦¬í•‘ ì „ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„: </span><span class="si">{</span><span class="n">grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘</span>
    <span class="n">max_norm</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">([</span><span class="n">W</span><span class="p">],</span> <span class="n">max_norm</span><span class="p">)</span>

    <span class="n">clipped_grad_norm</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;í´ë¦¬í•‘ í›„ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„: </span><span class="si">{</span><span class="n">clipped_grad_norm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">gradient_clipping_demo</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - RNN/Transformerì—ì„œ í•„ìˆ˜&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - ì¼ë°˜ì ìœ¼ë¡œ max_norm = 1.0 ë˜ëŠ” 5.0&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  - í•™ìŠµ ì•ˆì •ì„± í¬ê²Œ í–¥ìƒ&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="74">7.4 ì‹¤ì „ ìµœì í™” ë ˆì‹œí”¼<a class="header-link" href="#74" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># PyTorch ìŠ¤íƒ€ì¼ ìµœì í™” ì„¤ì • ì˜ˆì œ</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SimpleNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>

<span class="c1"># 1. ì˜µí‹°ë§ˆì´ì € ì„ íƒ: Adam (ëŒ€ë¶€ë¶„ì˜ ê²½ìš°)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>

<span class="c1"># 2. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬: Cosine Annealing</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># 3. í•™ìŠµ ë£¨í”„ (ê°€ìƒ)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Forward &amp; Backward</span>
    <span class="c1"># loss.backward()</span>

    <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (RNN/Transformer)</span>
    <span class="c1"># torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)</span>

    <span class="c1"># ì˜µí‹°ë§ˆì´ì € ìŠ¤í…</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># í•™ìŠµë¥  ì—…ë°ì´íŠ¸</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">, LR: </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ì‹¤ì „ ìµœì í™” íŒ:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  1. Adamì„ ê¸°ë³¸ìœ¼ë¡œ ì‹œì‘ (lr=1e-3)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  2. Cosine Annealing ë˜ëŠ” Step Decay ì ìš©&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  3. Warm-up ì‚¬ìš© (Transformer ë“±)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  4. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (RNN/Transformer)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  5. ë°°ì¹˜ í¬ê¸°: 32-256 (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  6. Weight Decay (L2 ì •ê·œí™”): 1e-4 ~ 1e-5&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="_2">ì—°ìŠµ ë¬¸ì œ<a class="header-link" href="#_2" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>ìˆ˜ë ´ ì†ë„ ë¶„ì„</strong>: $f(x) = \frac{1}{2}x^T A x$ (ì´ì°¨ í˜•ì‹)ì— ëŒ€í•´, ì¡°ê±´ìˆ˜ $\kappa = 10$ì¼ ë•Œì™€ $\kappa = 100$ì¼ ë•Œ ê²½ì‚¬ í•˜ê°•ë²•ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  ë¹„êµí•˜ì‹œì˜¤. ì´ë¡ ì  ìˆ˜ë ´ ì†ë„ $O((1 - 1/\kappa)^t)$ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ì‹œì˜¤.</p>
</li>
<li>
<p><strong>SGD vs ë°°ì¹˜ GD</strong>: MNIST ë°ì´í„°ì…‹ì—ì„œ ê°„ë‹¨í•œ 2ì¸µ ì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚¤ë˜, ë°°ì¹˜ GD, ë¯¸ë‹ˆë°°ì¹˜ SGD (ë°°ì¹˜ í¬ê¸° 32, 128, 512), ê·¸ë¦¬ê³  full SGD (ë°°ì¹˜ í¬ê¸° 1)ë¥¼ ë¹„êµí•˜ì‹œì˜¤. ìˆ˜ë ´ ì†ë„, ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„, ê·¸ë¦¬ê³  ê³„ì‚° ì‹œê°„ì„ ë¹„êµ ë¶„ì„í•˜ì‹œì˜¤.</p>
</li>
<li>
<p><strong>ì˜µí‹°ë§ˆì´ì € êµ¬í˜„</strong>: Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ NumPyë¡œ ì²˜ìŒë¶€í„° êµ¬í˜„í•˜ê³ , í¸í–¥ ë³´ì •ì˜ ìœ ë¬´ì— ë”°ë¥¸ ì°¨ì´ë¥¼ ì‹œê°í™”í•˜ì‹œì˜¤. Rosenbrock í•¨ìˆ˜ë‚˜ Beale í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì‹œì˜¤.</p>
</li>
<li>
<p><strong>ëª¨ë©˜í…€ vs Nesterov</strong>: ill-conditioned ì´ì°¨ í•¨ìˆ˜ ($\kappa = 100$)ì—ì„œ ëª¨ë©˜í…€ SGDì™€ Nesterov ê°€ì† ê²½ì‚¬ë²•ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ë¹„êµí•˜ì‹œì˜¤. ì–´ë–¤ ìƒí™©ì—ì„œ Nesterovê°€ ë” ìš°ìˆ˜í•œì§€ ë¶„ì„í•˜ì‹œì˜¤.</p>
</li>
<li>
<p><strong>í•™ìŠµë¥  ìŠ¤ì¼€ì¤„</strong>: ê°„ë‹¨í•œ CNNì„ CIFAR-10ì—ì„œ í•™ìŠµì‹œí‚¤ë˜, ë‹¤ìŒ ìŠ¤ì¼€ì¤„ì„ ë¹„êµí•˜ì‹œì˜¤: (1) ê³ ì • í•™ìŠµë¥ , (2) Step Decay, (3) Cosine Annealing, (4) 1-Cycle Policy. ê° ë°©ë²•ì˜ í•™ìŠµ ê³¡ì„ ê³¼ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ë³´ê³ í•˜ì‹œì˜¤.</p>
</li>
</ol>
<h2 id="_3">ì°¸ê³  ìë£Œ<a class="header-link" href="#_3" title="Permanent link">&para;</a></h2>
<ul>
<li>Ruder, S. (2016). "An Overview of Gradient Descent Optimization Algorithms". arXiv:1609.04747</li>
<li>ëª¨ë“  ì£¼ìš” ì˜µí‹°ë§ˆì´ì €ì˜ í¬ê´„ì  ë¦¬ë·°</li>
<li>Bottou, L., Curtis, F. E., &amp; Nocedal, J. (2018). "Optimization Methods for Large-Scale Machine Learning". <em>SIAM Review</em>, 60(2), 223-311</li>
<li>ëŒ€ê·œëª¨ ML ìµœì í™”ì˜ ì´ë¡ ê³¼ ì‹¤ì „</li>
<li>Kingma, D. P., &amp; Ba, J. (2015). "Adam: A Method for Stochastic Optimization". ICLR</li>
<li>Adam ë…¼ë¬¸ ì›ë¬¸</li>
<li>Sutskever, I., et al. (2013). "On the Importance of Initialization and Momentum in Deep Learning". ICML</li>
<li>ëª¨ë©˜í…€ì˜ ì¤‘ìš”ì„±</li>
<li>Keskar, N. S., et al. (2017). "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima". ICLR</li>
<li>Sharp vs Flat Minima</li>
<li>Smith, L. N. (2017). "Cyclical Learning Rates for Training Neural Networks". WACV</li>
<li>1-Cycle Policy</li>
<li>PyTorch Optimization Documentation: https://pytorch.org/docs/stable/optim.html</li>
<li>Stanford CS231n Lecture Notes: http://cs231n.github.io/neural-networks-3/</li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Math_for_AI/06_Optimization_Fundamentals.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">06. ìµœì í™” ê¸°ì´ˆ (Optimization Fundamentals)</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
        <a href="/study/ko/Math_for_AI/08_Probability_for_ML.html" class="nav-next">
            <span class="nav-label">Next</span>
            <span class="nav-title">08. ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ í™•ë¥ ë¡  (Probability for Machine Learning)</span>
        </a>
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}