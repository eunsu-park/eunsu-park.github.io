{% raw %}
<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>18. ìƒì„± ëª¨ë¸ì˜ ìˆ˜í•™ - Study Materials</title>
    <link rel="stylesheet" href="/study/static/css/style.css">
    <link rel="stylesheet" href="/study/static/css/highlight.css">
    <!-- KaTeX for LaTeX math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
    
</head>
<body>
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-header">
                <a href="/study/ko/" class="logo">Study Materials</a>
                <button class="sidebar-toggle" id="sidebar-toggle" aria-label="Toggle sidebar">
                    <span></span>
                </button>
            </div>

            <nav class="sidebar-nav">
                <a href="/study/ko/" class="nav-item ">
                    <span class="nav-icon">ğŸ </span>
                    <span class="nav-text">Home</span>
                </a>
                <a href="/study/examples/" class="nav-item ">
                    <span class="nav-icon">ğŸ’»</span>
                    <span class="nav-text">Examples</span>
                </a>
            </nav>

            <div class="sidebar-search">
                <form action="/study/ko/search.html" method="get" id="search-form">
                    <input type="search" name="q" placeholder="Search..." id="search-sidebar-input">
                </form>
            </div>

            <!-- Language Selector -->
            <div class="sidebar-lang">
                <select id="lang-select" class="lang-selector" onchange="switchLanguage(this.value)">
                    
                    <option value="en" >
                        English
                    </option>
                    
                    <option value="ko" selected>
                        í•œêµ­ì–´
                    </option>
                    
                </select>
            </div>

            <div class="sidebar-footer">
                <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme">
                    <span class="theme-icon light">â˜€ï¸</span>
                    <span class="theme-icon dark">ğŸŒ™</span>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="main-header">
                <button class="menu-toggle" id="menu-toggle" aria-label="Open menu">
                    <span></span>
                </button>
                
<nav class="breadcrumb">
    <a href="/study/ko/">Topics</a>
    <span class="separator">/</span>
    <a href="/study/ko/Math_for_AI/">Math for AI</a>
    <span class="separator">/</span>
    <span class="current">18. ìƒì„± ëª¨ë¸ì˜ ìˆ˜í•™</span>
</nav>

            </header>

            <div class="content">
                
<article class="lesson-article">
    <header class="lesson-header">
        <h1>18. ìƒì„± ëª¨ë¸ì˜ ìˆ˜í•™</h1>
    </header>

    
<div class="lesson-toolbar lesson-toolbar--top">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Math_for_AI/17_Math_of_Attention_and_Transformers.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">17. ì–´í…ì…˜ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ìˆ˜í•™</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
    </div>
</div>


    
    <nav class="toc" id="toc">
        <h2>Table of Contents</h2>
        <div class="toc">
<ul>
<li><a href="#_1">í•™ìŠµ ëª©í‘œ</a></li>
<li><a href="#1">1. ìƒì„± ëª¨ë¸ì˜ ëª©í‘œ</a><ul>
<li><a href="#11">1.1 ë°ì´í„° ë¶„í¬ í•™ìŠµ</a></li>
<li><a href="#12-vs">1.2 ëª…ì‹œì  vs ì•”ë¬µì  ë°€ë„</a></li>
<li><a href="#13">1.3 í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„</a></li>
</ul>
</li>
<li><a href="#2-vae-elbo">2. VAEì˜ ìˆ˜í•™: ELBO ì™„ì „ ìœ ë„</a><ul>
<li><a href="#21">2.1 ì ì¬ ë³€ìˆ˜ ëª¨ë¸</a></li>
<li><a href="#22-elbo-1">2.2 ELBO ìœ ë„ (ë°©ë²• 1: ì˜Œì„¼ ë¶€ë“±ì‹)</a></li>
<li><a href="#23-elbo-2-kl">2.3 ELBO ìœ ë„ (ë°©ë²• 2: KL ë¶„í•´)</a></li>
<li><a href="#24-elbo">2.4 ELBOì˜ ë‘ í•­ í•´ì„</a></li>
<li><a href="#25-reparameterization-trick">2.5 ì¬ë§¤ê°œë³€ìˆ˜í™” íŠ¸ë¦­ (Reparameterization Trick)</a></li>
<li><a href="#26-kl">2.6 ê°€ìš°ì‹œì•ˆ ê°„ KL ë°œì‚°ì˜ ë‹«íŒ í˜•íƒœ</a></li>
</ul>
</li>
<li><a href="#3-gan">3. GANì˜ ìˆ˜í•™</a><ul>
<li><a href="#31">3.1 ë¯¸ë‹ˆë§¥ìŠ¤ ê²Œì„</a></li>
<li><a href="#32">3.2 ìµœì  íŒë³„ì</a></li>
<li><a href="#33-js">3.3 JS ë°œì‚°ê³¼ì˜ ê´€ê³„</a></li>
<li><a href="#34">3.4 í•™ìŠµ ë¶ˆì•ˆì •ì„±ì˜ ìˆ˜í•™ì  ì›ì¸</a></li>
</ul>
</li>
<li><a href="#4-wasserstein-wgan">4. Wasserstein ê±°ë¦¬ì™€ WGAN</a><ul>
<li><a href="#41-optimal-transport">4.1 ìµœì  ìˆ˜ì†¡ (Optimal Transport)</a></li>
<li><a href="#42-">4.2 ì¹¸í† ë¡œë¹„ì¹˜-ë£¨ë¹ˆìŠˆíƒ€ì¸ ìŒëŒ€ì„±</a></li>
<li><a href="#43-wgan">4.3 WGANì˜ ëª©ì  í•¨ìˆ˜</a></li>
<li><a href="#44">4.4 ë¦½ì‹œì¸  ì œì•½: ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹°</a></li>
</ul>
</li>
<li><a href="#5-diffusion-models">5. í™•ì‚° ëª¨ë¸ì˜ ìˆ˜í•™ (Diffusion Models)</a><ul>
<li><a href="#51-forward-process">5.1 ì •ë°©í–¥ ê³¼ì • (Forward Process)</a></li>
<li><a href="#52-reverse-process">5.2 ì—­ë°©í–¥ ê³¼ì • (Reverse Process)</a></li>
<li><a href="#53-ddpm">5.3 DDPM ì†ì‹¤ ìœ ë„</a></li>
<li><a href="#54">5.4 ìŠ¤ì½”ì–´ ë§¤ì¹­ê³¼ì˜ ê´€ê³„</a></li>
<li><a href="#55-langevin-dynamics">5.5 ë‘ì£¼ë±… ì—­í•™ (Langevin Dynamics)</a></li>
</ul>
</li>
<li><a href="#6-flow-matching-cnf">6. ìµœì‹  ë°œì „: Flow Matchingê³¼ CNF</a><ul>
<li><a href="#61-continuous-normalizing-flow">6.1 ì—°ì† ì •ê·œí™” íë¦„ (Continuous Normalizing Flow)</a></li>
<li><a href="#62-flow-matching">6.2 Flow Matching</a></li>
<li><a href="#63-consistency-models">6.3 ì¼ê´€ì„± ëª¨ë¸ (Consistency Models)</a></li>
</ul>
</li>
<li><a href="#_2">ì—°ìŠµ ë¬¸ì œ</a><ul>
<li><a href="#1-elbo">ë¬¸ì œ 1: ELBO ìœ ë„ì˜ ë‘ ë°©ë²•</a></li>
<li><a href="#2-vae">ë¬¸ì œ 2: VAE êµ¬í˜„ê³¼ ì‹¤í—˜</a></li>
<li><a href="#3-gan_1">ë¬¸ì œ 3: GANì˜ ìµœì  íŒë³„ì ì¦ëª…</a></li>
<li><a href="#4">ë¬¸ì œ 4: í™•ì‚° ëª¨ë¸ì˜ ì •ë°©í–¥ ê³¼ì •</a></li>
<li><a href="#5-flow-matching-vs">ë¬¸ì œ 5: Flow Matching vs í™•ì‚° ëª¨ë¸</a></li>
</ul>
</li>
<li><a href="#_3">ì°¸ê³  ìë£Œ</a><ul>
<li><a href="#_4">ë…¼ë¬¸</a></li>
<li><a href="#_5">ì˜¨ë¼ì¸ ìë£Œ</a></li>
<li><a href="#_6">ë¼ì´ë¸ŒëŸ¬ë¦¬</a></li>
</ul>
</li>
</ul>
</div>

    </nav>
    

    <div class="lesson-content markdown-body">
        <h1 id="18">18. ìƒì„± ëª¨ë¸ì˜ ìˆ˜í•™<a class="header-link" href="#18" title="Permanent link">&para;</a></h1>
<h2 id="_1">í•™ìŠµ ëª©í‘œ<a class="header-link" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>ìƒì„± ëª¨ë¸ì˜ ëª©í‘œì™€ ëª…ì‹œì /ì•”ë¬µì  ë°€ë„ ëª¨ë¸ì˜ ì°¨ì´ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤</li>
<li>VAEì˜ ELBOë¥¼ ì™„ì „íˆ ìœ ë„í•˜ê³  ì¬êµ¬ì„± í•­ê³¼ KL í•­ì˜ ì˜ë¯¸ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤</li>
<li>GANì˜ ë¯¸ë‹ˆë§¥ìŠ¤ ê²Œì„ ì´ë¡ ê³¼ JS ë°œì‚°ì˜ ê´€ê³„ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤</li>
<li>Wasserstein ê±°ë¦¬ì™€ ìµœì  ìˆ˜ì†¡ ì´ë¡ ì˜ ê¸°ì´ˆë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤</li>
<li>í™•ì‚° ëª¨ë¸ì˜ ì •ë°©í–¥/ì—­ë°©í–¥ ê³¼ì •ê³¼ ìŠ¤ì½”ì–´ ë§¤ì¹­ì˜ ìˆ˜í•™ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤</li>
<li>Flow Matchingê³¼ ì—°ì† ì •ê·œí™” íë¦„(CNF)ì˜ ìµœì‹  ë°œì „ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤</li>
</ul>
<hr />
<h2 id="1">1. ìƒì„± ëª¨ë¸ì˜ ëª©í‘œ<a class="header-link" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 ë°ì´í„° ë¶„í¬ í•™ìŠµ<a class="header-link" href="#11" title="Permanent link">&para;</a></h3>
<p><strong>ëª©í‘œ</strong>: ê´€ì¸¡ëœ ë°ì´í„° $\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(n)}\} \sim p_{\text{data}}(\mathbf{x})$ë¡œë¶€í„° ì§„ì§œ ë°ì´í„° ë¶„í¬ $p_{\text{data}}$ë¥¼ í•™ìŠµ</p>
<p><strong>ì‘ìš©</strong>:
- <strong>ìƒ˜í”Œë§</strong>: ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
- <strong>ë°€ë„ ì¶”ì •</strong>: $p(\mathbf{x})$ ê³„ì‚° (ì´ìƒ íƒì§€)
- <strong>ì¡°ê±´ë¶€ ìƒì„±</strong>: $p(\mathbf{y}|\mathbf{x})$ (ì´ë¯¸ì§€-í…ìŠ¤íŠ¸, ìŠ¤íƒ€ì¼ ë³€í™˜)</p>
<h3 id="12-vs">1.2 ëª…ì‹œì  vs ì•”ë¬µì  ë°€ë„<a class="header-link" href="#12-vs" title="Permanent link">&para;</a></h3>
<p><strong>ëª…ì‹œì  ë°€ë„ ëª¨ë¸</strong>:
- í™•ë¥  ë°€ë„ $p_\theta(\mathbf{x})$ë¥¼ ì§ì ‘ ì •ì˜
- ìš°ë„ $\log p_\theta(\mathbf{x})$ë¥¼ ìµœëŒ€í™”
- ì˜ˆ: VAE, ìê¸°íšŒê·€ ëª¨ë¸, ì •ê·œí™” íë¦„</p>
<p><strong>ì•”ë¬µì  ë°€ë„ ëª¨ë¸</strong>:
- ë°€ë„ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šê³  ìƒ˜í”Œë§ ê³¼ì •ë§Œ ì •ì˜
- $\mathbf{x} = G_\theta(\mathbf{z})$, $\mathbf{z} \sim p(\mathbf{z})$
- ì˜ˆ: GAN</p>
<h3 id="13">1.3 í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„<a class="header-link" href="#13" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>ë°©ë²•</th>
<th>ëª©ì  í•¨ìˆ˜</th>
<th>ìƒ˜í”Œë§</th>
<th>ë°€ë„ í‰ê°€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>VAE</strong></td>
<td>ELBO ìµœëŒ€í™”</td>
<td>ë¹ ë¦„</td>
<td>ê·¼ì‚¬</td>
</tr>
<tr>
<td><strong>GAN</strong></td>
<td>ì ëŒ€ì  ê²Œì„</td>
<td>ë¹ ë¦„</td>
<td>ë¶ˆê°€</td>
</tr>
<tr>
<td><strong>ì •ê·œí™” íë¦„</strong></td>
<td>ì •í™•í•œ ìš°ë„</td>
<td>ë¹ ë¦„</td>
<td>ì •í™•</td>
</tr>
<tr>
<td><strong>í™•ì‚° ëª¨ë¸</strong></td>
<td>ë…¸ì´ì¦ˆ ì˜ˆì¸¡</td>
<td>ëŠë¦¼ (ë°˜ë³µ)</td>
<td>ì•”ë¬µì </td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># ê°„ë‹¨í•œ 1D ë°ì´í„° ë¶„í¬ (í˜¼í•© ê°€ìš°ì‹œì•ˆ)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_data</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ì§„ì§œ ë°ì´í„° ë¶„í¬: ë‘ ê°œì˜ ê°€ìš°ì‹œì•ˆ í˜¼í•©&quot;&quot;&quot;</span>
    <span class="n">modes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">modes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True data distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Example data distribution (mixture of Gaussians)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;data_distribution.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ë°ì´í„° ë¶„í¬ ì‹œê°í™” ì €ì¥ ì™„ë£Œ&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="2-vae-elbo">2. VAEì˜ ìˆ˜í•™: ELBO ì™„ì „ ìœ ë„<a class="header-link" href="#2-vae-elbo" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 ì ì¬ ë³€ìˆ˜ ëª¨ë¸<a class="header-link" href="#21" title="Permanent link">&para;</a></h3>
<p><strong>ìƒì„± ê³¼ì •</strong>:
1. ì ì¬ ë³€ìˆ˜ ìƒ˜í”Œë§: $\mathbf{z} \sim p(\mathbf{z})$ (ë³´í†µ $\mathcal{N}(\mathbf{0}, I)$)
2. ë°ì´í„° ìƒì„±: $\mathbf{x} \sim p_\theta(\mathbf{x}|\mathbf{z})$</p>
<p><strong>ëª©í‘œ</strong>: ì£¼ë³€ ìš°ë„(marginal likelihood) ìµœëŒ€í™”</p>
<p>$$\log p_\theta(\mathbf{x}) = \log \int p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z}) d\mathbf{z}$$</p>
<p><strong>ë¬¸ì œ</strong>: ì ë¶„ì´ ë‹¤ë£¨ê¸° ì–´ë ¤ì›€ (intractable)</p>
<h3 id="22-elbo-1">2.2 ELBO ìœ ë„ (ë°©ë²• 1: ì˜Œì„¼ ë¶€ë“±ì‹)<a class="header-link" href="#22-elbo-1" title="Permanent link">&para;</a></h3>
<p>ë¡œê·¸ì˜ ì˜¤ëª©ì„±ê³¼ ì˜Œì„¼ ë¶€ë“±ì‹ ì´ìš©:</p>
<p>$$\log p_\theta(\mathbf{x}) = \log \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \frac{p_\theta(\mathbf{x}, \mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})} \right]$$</p>
<p>$$\geq \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \log \frac{p_\theta(\mathbf{x}, \mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})} \right]$$</p>
<p>$$= \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \log p_\theta(\mathbf{x}|\mathbf{z}) + \log p(\mathbf{z}) - \log q_\phi(\mathbf{z}|\mathbf{x}) \right]$$</p>
<p>$$= \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \log p_\theta(\mathbf{x}|\mathbf{z}) \right] - D_{\text{KL}}(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))$$</p>
<p>ì´ê²ƒì´ <strong>ELBO</strong> (Evidence Lower BOund):</p>
<p>$$\mathcal{L}(\theta, \phi; \mathbf{x}) = \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \log p_\theta(\mathbf{x}|\mathbf{z}) \right] - D_{\text{KL}}(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))$$</p>
<h3 id="23-elbo-2-kl">2.3 ELBO ìœ ë„ (ë°©ë²• 2: KL ë¶„í•´)<a class="header-link" href="#23-elbo-2-kl" title="Permanent link">&para;</a></h3>
<p>í›„ë°© ë¶„í¬ $p_\theta(\mathbf{z}|\mathbf{x})$ì™€ ê·¼ì‚¬ $q_\phi(\mathbf{z}|\mathbf{x})$ì˜ KL ë°œì‚°:</p>
<p>$$D_{\text{KL}}(q_\phi(\mathbf{z}|\mathbf{x}) \| p_\theta(\mathbf{z}|\mathbf{x})) = \mathbb{E}_{q_\phi} \left[ \log \frac{q_\phi(\mathbf{z}|\mathbf{x})}{p_\theta(\mathbf{z}|\mathbf{x})} \right]$$</p>
<p>ë² ì´ì¦ˆ ì •ë¦¬: $p_\theta(\mathbf{z}|\mathbf{x}) = \frac{p_\theta(\mathbf{x}|\mathbf{z})p(\mathbf{z})}{p_\theta(\mathbf{x})}$</p>
<p>$$D_{\text{KL}}(q_\phi \| p_\theta) = \mathbb{E}_{q_\phi} \left[ \log q_\phi(\mathbf{z}|\mathbf{x}) - \log p_\theta(\mathbf{x}|\mathbf{z}) - \log p(\mathbf{z}) + \log p_\theta(\mathbf{x}) \right]$$</p>
<p>ì •ë¦¬í•˜ë©´:</p>
<p>$$\log p_\theta(\mathbf{x}) = D_{\text{KL}}(q_\phi \| p_\theta) + \mathcal{L}(\theta, \phi; \mathbf{x})$$</p>
<p>$D_{\text{KL}} \geq 0$ì´ë¯€ë¡œ $\mathcal{L}$ì€ $\log p_\theta(\mathbf{x})$ì˜ í•˜í•œì…ë‹ˆë‹¤.</p>
<h3 id="24-elbo">2.4 ELBOì˜ ë‘ í•­ í•´ì„<a class="header-link" href="#24-elbo" title="Permanent link">&para;</a></h3>
<p>$$\mathcal{L} = \underbrace{\mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} \left[ \log p_\theta(\mathbf{x}|\mathbf{z}) \right]}_{\text{ì¬êµ¬ì„± í•­}} - \underbrace{D_{\text{KL}}(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))}_{\text{ì •ê·œí™” í•­}}$$</p>
<p><strong>ì¬êµ¬ì„± í•­</strong>:
- ì ì¬ í‘œí˜„ $\mathbf{z}$ì—ì„œ $\mathbf{x}$ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë³µì›í•˜ëŠ”ê°€
- ë””ì½”ë” $p_\theta(\mathbf{x}|\mathbf{z})$ì˜ í’ˆì§ˆ</p>
<p><strong>ì •ê·œí™” í•­</strong>:
- ì¸ì½”ë” ë¶„í¬ë¥¼ ì‚¬ì „ ë¶„í¬ì— ê°€ê¹ê²Œ ìœ ì§€
- ì ì¬ ê³µê°„ì˜ êµ¬ì¡°í™”
- ê³¼ì í•© ë°©ì§€</p>
<h3 id="25-reparameterization-trick">2.5 ì¬ë§¤ê°œë³€ìˆ˜í™” íŠ¸ë¦­ (Reparameterization Trick)<a class="header-link" href="#25-reparameterization-trick" title="Permanent link">&para;</a></h3>
<p><strong>ë¬¸ì œ</strong>: $\nabla_\phi \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})} [f(\mathbf{z})]$ë¥¼ ì–´ë–»ê²Œ ê³„ì‚°?</p>
<p><strong>í•´ê²°</strong>: $\mathbf{z}$ë¥¼ ê²°ì •ë¡ ì  í•¨ìˆ˜ + ë…¸ì´ì¦ˆë¡œ í‘œí˜„</p>
<p>ê°€ìš°ì‹œì•ˆì˜ ê²½ìš°: $q_\phi(\mathbf{z}|\mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}_\phi(\mathbf{x}), \boldsymbol{\sigma}_\phi^2(\mathbf{x}))$</p>
<p>$$\mathbf{z} = \boldsymbol{\mu}_\phi(\mathbf{x}) + \boldsymbol{\sigma}_\phi(\mathbf{x}) \odot \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, I)$$</p>
<p>ì´ì œ $\mathbf{z}$ê°€ $\phi$ì— ëŒ€í•´ ë¯¸ë¶„ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># ì¸ì½”ë”</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

        <span class="c1"># ë””ì½”ë”</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ì¸ì½”ë”: x -&gt; (mu, logvar)&quot;&quot;&quot;</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ì¬ë§¤ê°œë³€ìˆ˜í™”: z = mu + sigma * epsilon&quot;&quot;&quot;</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">eps</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ë””ì½”ë”: z -&gt; x_recon&quot;&quot;&quot;</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="n">x_recon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x_recon</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">x_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>

<span class="k">def</span><span class="w"> </span><span class="nf">vae_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    VAE ì†ì‹¤ í•¨ìˆ˜</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        ì›ë³¸ ì…ë ¥</span>
<span class="sd">    x_recon : Tensor</span>
<span class="sd">        ì¬êµ¬ì„±ëœ ì¶œë ¥</span>
<span class="sd">    mu, logvar : Tensor</span>
<span class="sd">        ì ì¬ ë¶„í¬ì˜ í‰ê· ê³¼ ë¡œê·¸ ë¶„ì‚°</span>

<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    loss : Tensor</span>
<span class="sd">        ì´ ì†ì‹¤ (ì¬êµ¬ì„± + KL)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># ì¬êµ¬ì„± ì†ì‹¤ (Bernoulli ë¶„í¬ ê°€ì •)</span>
    <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>

    <span class="c1"># KL ë°œì‚° (ê°€ìš°ì‹œì•ˆ ê°„ì˜ ë‹«íŒ í˜•íƒœ)</span>
    <span class="c1"># KL(N(mu, sigma^2) || N(0, 1)) = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="n">kl_loss</span><span class="p">,</span> <span class="n">recon_loss</span><span class="p">,</span> <span class="n">kl_loss</span>

<span class="c1"># ì˜ˆì œ: ê°„ë‹¨í•œ 2D ì ì¬ ê³µê°„</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">x_recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">x_sample</span><span class="p">)</span>
<span class="n">total_loss</span><span class="p">,</span> <span class="n">recon</span><span class="p">,</span> <span class="n">kl</span> <span class="o">=</span> <span class="n">vae_loss</span><span class="p">(</span><span class="n">x_sample</span><span class="p">,</span> <span class="n">x_recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì´ ì†ì‹¤: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ì¬êµ¬ì„± ì†ì‹¤: </span><span class="si">{</span><span class="n">recon</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KL ì†ì‹¤: </span><span class="si">{</span><span class="n">kl</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="26-kl">2.6 ê°€ìš°ì‹œì•ˆ ê°„ KL ë°œì‚°ì˜ ë‹«íŒ í˜•íƒœ<a class="header-link" href="#26-kl" title="Permanent link">&para;</a></h3>
<p>$q = \mathcal{N}(\boldsymbol{\mu}, \text{diag}(\boldsymbol{\sigma}^2))$, $p = \mathcal{N}(\mathbf{0}, I)$ì¼ ë•Œ:</p>
<p>$$D_{\text{KL}}(q \| p) = \frac{1}{2} \sum_{i=1}^{d} \left( \sigma_i^2 + \mu_i^2 - 1 - \log \sigma_i^2 \right)$$</p>
<p><strong>ìœ ë„</strong>: KL ë°œì‚°ì˜ ì •ì˜ì™€ ê°€ìš°ì‹œì•ˆì˜ ì—”íŠ¸ë¡œí”¼ ê³µì‹ ì‚¬ìš©</p>
<h2 id="3-gan">3. GANì˜ ìˆ˜í•™<a class="header-link" href="#3-gan" title="Permanent link">&para;</a></h2>
<h3 id="31">3.1 ë¯¸ë‹ˆë§¥ìŠ¤ ê²Œì„<a class="header-link" href="#31" title="Permanent link">&para;</a></h3>
<p><strong>ìƒì„±ì</strong> (Generator) $G$: $\mathbf{z} \sim p(\mathbf{z}) \mapsto G(\mathbf{z}) \approx p_{\text{data}}$</p>
<p><strong>íŒë³„ì</strong> (Discriminator) $D$: $\mathbf{x} \mapsto D(\mathbf{x}) \in [0, 1]$ (ì§„ì§œ í™•ë¥ )</p>
<p><strong>ëª©ì  í•¨ìˆ˜</strong>:</p>
<p>$$\min_G \max_D \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}} [\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p(\mathbf{z})} [\log(1 - D(G(\mathbf{z})))]$$</p>
<p><strong>í•´ì„</strong>:
- $D$ëŠ” ì§„ì§œ ë°ì´í„°ì— ë†’ì€ í™•ë¥ , ê°€ì§œì— ë‚®ì€ í™•ë¥ ì„ ë¶€ì—¬í•˜ë ¤ í•¨
- $G$ëŠ” $D$ë¥¼ ì†ì´ë ¤ í•¨ (ê°€ì§œê°€ ì§„ì§œì²˜ëŸ¼ ë³´ì´ê²Œ)</p>
<h3 id="32">3.2 ìµœì  íŒë³„ì<a class="header-link" href="#32" title="Permanent link">&para;</a></h3>
<p>$G$ê°€ ê³ ì •ë˜ì—ˆì„ ë•Œ, ìµœì  íŒë³„ìëŠ”:</p>
<p>$$D^*(x) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_g(\mathbf{x})}$$</p>
<p>ì—¬ê¸°ì„œ $p_g$ëŠ” ìƒì„±ìê°€ ìœ ë„í•˜ëŠ” ë¶„í¬ì…ë‹ˆë‹¤.</p>
<p><strong>ì¦ëª…</strong>: ëª©ì  í•¨ìˆ˜ë¥¼ $D(\mathbf{x})$ì— ëŒ€í•´ ë¯¸ë¶„í•˜ê³  0ìœ¼ë¡œ ì„¤ì •</p>
<p>$$\frac{\partial}{\partial D(\mathbf{x})} \left[ p_{\text{data}}(\mathbf{x}) \log D(\mathbf{x}) + p_g(\mathbf{x}) \log(1 - D(\mathbf{x})) \right] = 0$$</p>
<p>$$\frac{p_{\text{data}}(\mathbf{x})}{D(\mathbf{x})} - \frac{p_g(\mathbf{x})}{1 - D(\mathbf{x})} = 0$$</p>
<h3 id="33-js">3.3 JS ë°œì‚°ê³¼ì˜ ê´€ê³„<a class="header-link" href="#33-js" title="Permanent link">&para;</a></h3>
<p>ìµœì  íŒë³„ì $D^*$ë¥¼ ëŒ€ì…í•˜ë©´, ìƒì„±ìì˜ ëª©ì  í•¨ìˆ˜ëŠ”:</p>
<p>$$C(G) = -\log 4 + 2 \cdot \text{JS}(p_{\text{data}} \| p_g)$$</p>
<p>ì—¬ê¸°ì„œ <strong>Jensen-Shannon ë°œì‚°</strong>:</p>
<p>$$\text{JS}(p \| q) = \frac{1}{2} D_{\text{KL}}\left(p \middle\| \frac{p+q}{2}\right) + \frac{1}{2} D_{\text{KL}}\left(q \middle\| \frac{p+q}{2}\right)$$</p>
<p><strong>ê²°ë¡ </strong>: GANì„ í•™ìŠµí•˜ëŠ” ê²ƒì€ JS ë°œì‚°ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<h3 id="34">3.4 í•™ìŠµ ë¶ˆì•ˆì •ì„±ì˜ ìˆ˜í•™ì  ì›ì¸<a class="header-link" href="#34" title="Permanent link">&para;</a></h3>
<p><strong>ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤</strong>:
- $p_g$ì™€ $p_{\text{data}}$ê°€ ê²¹ì¹˜ì§€ ì•Šìœ¼ë©´ $D$ê°€ ì™„ë²½í•´ì§
- $\nabla_\theta \log(1 - D(G(\mathbf{z}))) \approx 0$</p>
<p><strong>ëª¨ë“œ ë¶•ê´´</strong> (Mode Collapse):
- ìƒì„±ìê°€ ì¼ë¶€ ëª¨ë“œë§Œ ìƒì„± ($p_g$ê°€ $p_{\text{data}}$ì˜ ì¼ë¶€ë§Œ ì»¤ë²„)
- JS ë°œì‚°ì€ ì—¬ì „íˆ ì‘ì„ ìˆ˜ ìˆìŒ</p>
<div class="highlight"><pre><span></span><code><span class="c1"># ê°„ë‹¨í•œ GAN ì˜ˆì œ (1D)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># ëª¨ë¸ ì´ˆê¸°í™”</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># ì†ì‹¤ í•¨ìˆ˜</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="c1"># ì˜µí‹°ë§ˆì´ì €</span>
<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">)</span>
<span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">)</span>

<span class="c1"># ê°„ë‹¨í•œ í•™ìŠµ ë£¨í”„</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_gan_step</span><span class="p">(</span><span class="n">real_data</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">optimizer_G</span><span class="p">,</span> <span class="n">optimizer_D</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GAN 1 ìŠ¤í… í•™ìŠµ&quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># ë ˆì´ë¸”</span>
    <span class="n">real_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">fake_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># íŒë³„ì í•™ìŠµ</span>
    <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># ì§„ì§œ ë°ì´í„°</span>
    <span class="n">D_real</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
    <span class="n">loss_D_real</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">D_real</span><span class="p">,</span> <span class="n">real_labels</span><span class="p">)</span>

    <span class="c1"># ê°€ì§œ ë°ì´í„°</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
    <span class="n">fake_data</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">D_fake</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">fake_data</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">loss_D_fake</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">D_fake</span><span class="p">,</span> <span class="n">fake_labels</span><span class="p">)</span>

    <span class="n">loss_D</span> <span class="o">=</span> <span class="n">loss_D_real</span> <span class="o">+</span> <span class="n">loss_D_fake</span>
    <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># ìƒì„±ì í•™ìŠµ</span>
    <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
    <span class="n">fake_data</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">D_fake</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
    <span class="n">loss_G</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">D_fake</span><span class="p">,</span> <span class="n">real_labels</span><span class="p">)</span>  <span class="c1"># ì§„ì§œë¡œ ë¶„ë¥˜ë˜ê¸¸ ì›í•¨</span>

    <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss_D</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">loss_G</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># ì˜ˆì œ ë°ì´í„°</span>
<span class="n">real_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">generate_data</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">loss_d</span><span class="p">,</span> <span class="n">loss_g</span> <span class="o">=</span> <span class="n">train_gan_step</span><span class="p">(</span><span class="n">real_samples</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">optimizer_G</span><span class="p">,</span> <span class="n">optimizer_D</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;íŒë³„ì ì†ì‹¤: </span><span class="si">{</span><span class="n">loss_d</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ìƒì„±ì ì†ì‹¤: </span><span class="si">{</span><span class="n">loss_g</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="4-wasserstein-wgan">4. Wasserstein ê±°ë¦¬ì™€ WGAN<a class="header-link" href="#4-wasserstein-wgan" title="Permanent link">&para;</a></h2>
<h3 id="41-optimal-transport">4.1 ìµœì  ìˆ˜ì†¡ (Optimal Transport)<a class="header-link" href="#41-optimal-transport" title="Permanent link">&para;</a></h3>
<p>ë‘ í™•ë¥  ë¶„í¬ $P, Q$ ê°„ì˜ <strong>Wasserstein-1 ê±°ë¦¬</strong> (Earth Mover's Distance):</p>
<p>$$W_1(P, Q) = \inf_{\gamma \in \Pi(P, Q)} \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim \gamma} \left[ \|\mathbf{x} - \mathbf{y}\| \right]$$</p>
<p>ì—¬ê¸°ì„œ $\Pi(P, Q)$ëŠ” $P$ì™€ $Q$ë¥¼ ì£¼ë³€ ë¶„í¬ë¡œ í•˜ëŠ” ëª¨ë“  ê²°í•© ë¶„í¬ì…ë‹ˆë‹¤.</p>
<p><strong>ì§ê´€</strong>: $P$ë¥¼ $Q$ë¡œ "ìš´ë°˜"í•˜ëŠ” ìµœì†Œ ë¹„ìš©</p>
<h3 id="42-">4.2 ì¹¸í† ë¡œë¹„ì¹˜-ë£¨ë¹ˆìŠˆíƒ€ì¸ ìŒëŒ€ì„±<a class="header-link" href="#42-" title="Permanent link">&para;</a></h3>
<p><strong>ìŒëŒ€ ë¬¸ì œ</strong>:</p>
<p>$$W_1(P, Q) = \sup_{f: \|f\|_L \leq 1} \mathbb{E}_{\mathbf{x} \sim P}[f(\mathbf{x})] - \mathbb{E}_{\mathbf{y} \sim Q}[f(\mathbf{y})]$$</p>
<p>ì—¬ê¸°ì„œ $\|f\|_L \leq 1$ëŠ” <strong>1-ë¦½ì‹œì¸  í•¨ìˆ˜</strong> ì œì•½:</p>
<p>$$|f(\mathbf{x}_1) - f(\mathbf{x}_2)| \leq \|\mathbf{x}_1 - \mathbf{x}_2\|$$</p>
<h3 id="43-wgan">4.3 WGANì˜ ëª©ì  í•¨ìˆ˜<a class="header-link" href="#43-wgan" title="Permanent link">&para;</a></h3>
<p><strong>íŒë³„ìë¥¼ critic $f_w$ë¡œ ëŒ€ì²´</strong> (ì¶œë ¥ì´ í™•ë¥ ì´ ì•„ë‹˜):</p>
<p>$$\min_G \max_{w: f_w \text{ is 1-Lipschitz}} \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[f_w(\mathbf{x})] - \mathbb{E}_{\mathbf{z} \sim p(\mathbf{z})}[f_w(G(\mathbf{z}))]$$</p>
<p><strong>ì¥ì </strong>:
- í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ
- ì˜ë¯¸ ìˆëŠ” ì†ì‹¤ ê°’ (ê±°ë¦¬ ê·¼ì‚¬)
- ëª¨ë“œ ë¶•ê´´ ì™„í™”</p>
<h3 id="44">4.4 ë¦½ì‹œì¸  ì œì•½: ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹°<a class="header-link" href="#44" title="Permanent link">&para;</a></h3>
<p><strong>ì›ë˜ WGAN</strong>: ê°€ì¤‘ì¹˜ í´ë¦¬í•‘ (weight clipping) â†’ ì œí•œì </p>
<p><strong>WGAN-GP</strong>: ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹°</p>
<p>$$\mathcal{L} = \mathbb{E}_{\tilde{\mathbf{x}}} [f(\tilde{\mathbf{x}})] - \mathbb{E}_{\mathbf{x}} [f(\mathbf{x})] + \lambda \mathbb{E}_{\hat{\mathbf{x}}} \left[ (\|\nabla_{\hat{\mathbf{x}}} f(\hat{\mathbf{x}})\| - 1)^2 \right]$$</p>
<p>ì—¬ê¸°ì„œ $\hat{\mathbf{x}} = \epsilon \mathbf{x} + (1 - \epsilon) \tilde{\mathbf{x}}$ëŠ” ì§„ì§œì™€ ê°€ì§œ ì‚¬ì´ì˜ ë³´ê°„ì…ë‹ˆë‹¤.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">gradient_penalty</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">fake_data</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹° ê³„ì‚° (WGAN-GP)</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    D : nn.Module</span>
<span class="sd">        íŒë³„ì (critic)</span>
<span class="sd">    real_data : Tensor</span>
<span class="sd">        ì§„ì§œ ë°ì´í„°</span>
<span class="sd">    fake_data : Tensor</span>
<span class="sd">        ê°€ì§œ ë°ì´í„°</span>
<span class="sd">    device : str</span>
<span class="sd">        ë””ë°”ì´ìŠ¤</span>

<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    gp : Tensor</span>
<span class="sd">        ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹°</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># ëœë¤ ë³´ê°„</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">interpolates</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">real_data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_data</span>
    <span class="n">interpolates</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># íŒë³„ì ì¶œë ¥</span>
    <span class="n">D_interpolates</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>

    <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">D_interpolates</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">D_interpolates</span><span class="p">),</span>
        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ norm</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">gradient_norm</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># íŒ¨ë„í‹°</span>
    <span class="n">gp</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradient_norm</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">gp</span>

<span class="c1"># ì˜ˆì œ</span>
<span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">D_critic</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gp</span> <span class="o">=</span> <span class="n">gradient_penalty</span><span class="p">(</span><span class="n">D_critic</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ê·¸ë˜ë””ì–¸íŠ¸ íŒ¨ë„í‹°: </span><span class="si">{</span><span class="n">gp</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="5-diffusion-models">5. í™•ì‚° ëª¨ë¸ì˜ ìˆ˜í•™ (Diffusion Models)<a class="header-link" href="#5-diffusion-models" title="Permanent link">&para;</a></h2>
<h3 id="51-forward-process">5.1 ì •ë°©í–¥ ê³¼ì • (Forward Process)<a class="header-link" href="#51-forward-process" title="Permanent link">&para;</a></h3>
<p>ë°ì´í„° $\mathbf{x}_0 \sim q(\mathbf{x}_0)$ì— ì ì§„ì ìœ¼ë¡œ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€:</p>
<p>$$q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t I)$$</p>
<p><strong>ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„</strong>: $\beta_1, \ldots, \beta_T$ (ë³´í†µ $10^{-4} \to 0.02$)</p>
<p><strong>ë‹«íŒ í˜•íƒœ</strong>: $\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$</p>
<p>$$q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t) I)$$</p>
<p>ì¦‰, í•œ ë²ˆì— $\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}$, $\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, I)$</p>
<h3 id="52-reverse-process">5.2 ì—­ë°©í–¥ ê³¼ì • (Reverse Process)<a class="header-link" href="#52-reverse-process" title="Permanent link">&para;</a></h3>
<p><strong>ëª©í‘œ</strong>: $\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, I)$ì—ì„œ $\mathbf{x}_0$ë¡œ ë³µì›</p>
<p>$$p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t))$$</p>
<p><strong>ì´ë¡ </strong>: $\beta_t$ê°€ ì¶©ë¶„íˆ ì‘ìœ¼ë©´, ì—­ë°©í–¥ë„ ê°€ìš°ì‹œì•ˆì…ë‹ˆë‹¤.</p>
<h3 id="53-ddpm">5.3 DDPM ì†ì‹¤ ìœ ë„<a class="header-link" href="#53-ddpm" title="Permanent link">&para;</a></h3>
<p>ë³€ë¶„ í•˜í•œ(ELBO)ì„ ìœ ë„í•˜ë©´ (VAEì™€ ìœ ì‚¬):</p>
<p>$$\mathcal{L} = \mathbb{E}_q \left[ D_{\text{KL}}(q(\mathbf{x}_T|\mathbf{x}_0) \| p(\mathbf{x}_T)) + \sum_{t=2}^T D_{\text{KL}}(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)) - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \right]$$</p>
<p><strong>í•µì‹¬</strong>: í›„ë°© ë¶„í¬ $q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)$ì˜ ë‹«íŒ í˜•íƒœ ì¡´ì¬</p>
<p>$$q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t I)$$</p>
<p>ì—¬ê¸°ì„œ:</p>
<p>$$\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) = \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0 + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t$$</p>
<p><strong>ë…¸ì´ì¦ˆ ì˜ˆì¸¡ìœ¼ë¡œ ì¬ë§¤ê°œë³€ìˆ˜í™”</strong>:</p>
<p>$\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon})$ë¥¼ ëŒ€ì…í•˜ë©´,</p>
<p><strong>ê°„ë‹¨í•œ ì†ì‹¤</strong>:</p>
<p>$$\mathcal{L}_{\text{simple}} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \right]$$</p>
<p>ì¦‰, <strong>ë…¸ì´ì¦ˆ ì˜ˆì¸¡</strong> ë¬¸ì œë¡œ ê·€ê²°ë©ë‹ˆë‹¤!</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">beta_start</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">beta_end</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ì„ í˜• ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">beta_start</span><span class="p">,</span> <span class="n">beta_end</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_diffusion_parameters</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;í™•ì‚° ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³„ì‚°&quot;&quot;&quot;</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="n">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">betas</span>
    <span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
    <span class="n">alphas_cumprod_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;betas&#39;</span><span class="p">:</span> <span class="n">betas</span><span class="p">,</span>
        <span class="s1">&#39;alphas&#39;</span><span class="p">:</span> <span class="n">alphas</span><span class="p">,</span>
        <span class="s1">&#39;alphas_cumprod&#39;</span><span class="p">:</span> <span class="n">alphas_cumprod</span><span class="p">,</span>
        <span class="s1">&#39;alphas_cumprod_prev&#39;</span><span class="p">:</span> <span class="n">alphas_cumprod_prev</span><span class="p">,</span>
        <span class="s1">&#39;sqrt_alphas_cumprod&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">),</span>
        <span class="s1">&#39;sqrt_one_minus_alphas_cumprod&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
    <span class="p">}</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">get_diffusion_parameters</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># ë…¸ì´ì¦ˆ ì¶”ê°€ ì˜ˆì œ</span>
<span class="k">def</span><span class="w"> </span><span class="nf">q_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ì •ë°©í–¥ ê³¼ì •: x_0ì—ì„œ x_t ìƒ˜í”Œë§</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    x_0 : Tensor</span>
<span class="sd">        ì›ë³¸ ë°ì´í„°</span>
<span class="sd">    t : int</span>
<span class="sd">        íƒ€ì„ìŠ¤í…</span>
<span class="sd">    params : dict</span>
<span class="sd">        í™•ì‚° íŒŒë¼ë¯¸í„°</span>
<span class="sd">    noise : Tensor, optional</span>
<span class="sd">        ë…¸ì´ì¦ˆ (Noneì´ë©´ ìƒ˜í”Œë§)</span>

<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    x_t : Tensor</span>
<span class="sd">        ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ë°ì´í„°</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>

    <span class="n">sqrt_alpha_cumprod_t</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;sqrt_alphas_cumprod&#39;</span><span class="p">][</span><span class="n">t</span><span class="p">]</span>
    <span class="n">sqrt_one_minus_alpha_cumprod_t</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;sqrt_one_minus_alphas_cumprod&#39;</span><span class="p">][</span><span class="n">t</span><span class="p">]</span>

    <span class="n">x_t</span> <span class="o">=</span> <span class="n">sqrt_alpha_cumprod_t</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">sqrt_one_minus_alpha_cumprod_t</span> <span class="o">*</span> <span class="n">noise</span>

    <span class="k">return</span> <span class="n">x_t</span>

<span class="c1"># ì˜ˆì œ: 1D ë°ì´í„°ì— ë…¸ì´ì¦ˆ ì¶”ê°€</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">]])</span>
<span class="n">timesteps_to_visualize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">750</span><span class="p">,</span> <span class="mi">999</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps_to_visualize</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps_to_visualize</span><span class="p">):</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="n">q_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_t</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;t=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;diffusion_forward_process.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;í™•ì‚° ì •ë°©í–¥ ê³¼ì • ì‹œê°í™” ì €ì¥ ì™„ë£Œ&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="54">5.4 ìŠ¤ì½”ì–´ ë§¤ì¹­ê³¼ì˜ ê´€ê³„<a class="header-link" href="#54" title="Permanent link">&para;</a></h3>
<p><strong>ìŠ¤ì½”ì–´ í•¨ìˆ˜</strong>: $\nabla_{\mathbf{x}} \log p(\mathbf{x})$</p>
<p><strong>ìŠ¤ì½”ì–´ ë§¤ì¹­</strong>: ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ ì‹ ê²½ë§ìœ¼ë¡œ ê·¼ì‚¬</p>
<p>$$\mathcal{L}_{\text{score}} = \mathbb{E}_{p(\mathbf{x})} \left[ \left\| \nabla_{\mathbf{x}} \log p(\mathbf{x}) - s_\theta(\mathbf{x}) \right\|^2 \right]$$</p>
<p><strong>ì—°ê²°</strong>: ë…¸ì´ì¦ˆ ì˜ˆì¸¡ $\boldsymbol{\epsilon}_\theta$ì™€ ìŠ¤ì½”ì–´ ì¶”ì •ì˜ ê´€ê³„</p>
<p>$$\nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t|\mathbf{x}_0) = -\frac{\boldsymbol{\epsilon}}{\sqrt{1 - \bar{\alpha}_t}}$$</p>
<p>ë”°ë¼ì„œ $\boldsymbol{\epsilon}_\theta$ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì€ ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.</p>
<h3 id="55-langevin-dynamics">5.5 ë‘ì£¼ë±… ì—­í•™ (Langevin Dynamics)<a class="header-link" href="#55-langevin-dynamics" title="Permanent link">&para;</a></h3>
<p><strong>ìƒ˜í”Œë§ ë°©ë²•</strong>: ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ë§ˆë¥´ì½”í”„ ì²´ì¸ ëª¬í…Œì¹´ë¥¼ë¡œ</p>
<p>$$\mathbf{x}_{t+1} = \mathbf{x}_t + \epsilon \nabla_{\mathbf{x}} \log p(\mathbf{x}_t) + \sqrt{2\epsilon} \mathbf{z}_t$$</p>
<p>ì—¬ê¸°ì„œ $\mathbf{z}_t \sim \mathcal{N}(\mathbf{0}, I)$</p>
<p>í™•ì‚° ëª¨ë¸ì˜ ì—­ë°©í–¥ ê³¼ì •ì€ <strong>ì´ì‚°í™”ëœ ë‘ì£¼ë±… ì—­í•™</strong>ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<h2 id="6-flow-matching-cnf">6. ìµœì‹  ë°œì „: Flow Matchingê³¼ CNF<a class="header-link" href="#6-flow-matching-cnf" title="Permanent link">&para;</a></h2>
<h3 id="61-continuous-normalizing-flow">6.1 ì—°ì† ì •ê·œí™” íë¦„ (Continuous Normalizing Flow)<a class="header-link" href="#61-continuous-normalizing-flow" title="Permanent link">&para;</a></h3>
<p><strong>ì•„ì´ë””ì–´</strong>: ODEë¡œ ë°ì´í„° ë¶„í¬ ë³€í™˜</p>
<p>$$\frac{d\mathbf{x}(t)}{dt} = f_\theta(\mathbf{x}(t), t)$$</p>
<p><strong>ì‹œê°„ $t=0$</strong>: $\mathbf{x}(0) \sim p_0$ (ë…¸ì´ì¦ˆ)
<strong>ì‹œê°„ $t=1$</strong>: $\mathbf{x}(1) \sim p_1$ (ë°ì´í„°)</p>
<p><strong>Neural ODE</strong>: ì‹ ê²½ë§ìœ¼ë¡œ $f_\theta$ ë§¤ê°œë³€ìˆ˜í™”</p>
<h3 id="62-flow-matching">6.2 Flow Matching<a class="header-link" href="#62-flow-matching" title="Permanent link">&para;</a></h3>
<p><strong>ëª©í‘œ</strong>: ë²¡í„° í•„ë“œ $u_t(\mathbf{x})$ë¥¼ ì§ì ‘ í•™ìŠµ</p>
<p><strong>ì¡°ê±´ë¶€ íë¦„ ë§¤ì¹­</strong> (Conditional Flow Matching):</p>
<p>$$\mathcal{L}_{\text{CFM}} = \mathbb{E}_{t, \mathbf{x}_0, \mathbf{x}_1} \left[ \left\| u_t(\mathbf{x}_t) - \frac{d\mathbf{x}_t}{dt} \right\|^2 \right]$$</p>
<p>ì—¬ê¸°ì„œ $\mathbf{x}_t = (1-t)\mathbf{x}_0 + t\mathbf{x}_1$ëŠ” ì„ í˜• ë³´ê°„ì…ë‹ˆë‹¤.</p>
<p><strong>ì¥ì </strong>:
- ì‹œë®¬ë ˆì´ì…˜ ì—†ëŠ” í•™ìŠµ (simulation-free training)
- í™•ì‚° ëª¨ë¸ë³´ë‹¤ ë¹ ë¥¸ ìƒ˜í”Œë§
- ì•ˆì •ì ì¸ í•™ìŠµ</p>
<h3 id="63-consistency-models">6.3 ì¼ê´€ì„± ëª¨ë¸ (Consistency Models)<a class="header-link" href="#63-consistency-models" title="Permanent link">&para;</a></h3>
<p><strong>ì•„ì´ë””ì–´</strong>: ODE ê¶¤ì  ìœ„ì˜ ëª¨ë“  ì ì„ ê°™ì€ ì ìœ¼ë¡œ ë§¤í•‘</p>
<p>$$f_\theta(\mathbf{x}_t, t) = f_\theta(\mathbf{x}_{t'}, t') \quad \forall t, t'$$</p>
<p><strong>ì¼ê´€ì„± ì†ì‹¤</strong>:</p>
<p>$$\mathcal{L} = \mathbb{E} \left[ d(f_\theta(\mathbf{x}_{t_{n+1}}, t_{n+1}), f_{\theta^-}(\mathbf{x}_{t_n}, t_n)) \right]$$</p>
<p>ì—¬ê¸°ì„œ $\theta^-$ëŠ” EMA(exponential moving average) íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.</p>
<p><strong>ì¥ì </strong>: 1-ìŠ¤í… ìƒì„± ê°€ëŠ¥ (í™•ì‚° ëª¨ë¸ì€ ìˆ˜ë°± ìŠ¤í… í•„ìš”)</p>
<div class="highlight"><pre><span></span><code><span class="c1"># ê°„ë‹¨í•œ Flow Matching ì˜ˆì œ</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FlowMatchingModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>  <span class="c1"># x + t</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ë²¡í„° í•„ë“œ ì˜ˆì¸¡&quot;&quot;&quot;</span>
        <span class="n">t_expanded</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">xt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">t_expanded</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">flow_matching_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flow Matching ì†ì‹¤</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    model : nn.Module</span>
<span class="sd">        ë²¡í„° í•„ë“œ ëª¨ë¸</span>
<span class="sd">    x0 : Tensor</span>
<span class="sd">        ì‹œì‘ ë¶„í¬ ìƒ˜í”Œ (ë…¸ì´ì¦ˆ)</span>
<span class="sd">    x1 : Tensor</span>
<span class="sd">        ëª©í‘œ ë¶„í¬ ìƒ˜í”Œ (ë°ì´í„°)</span>

<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    loss : Tensor</span>
<span class="sd">        Flow Matching ì†ì‹¤</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># ëœë¤ ì‹œê°„</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># ì„ í˜• ë³´ê°„</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x1</span>

    <span class="c1"># ì§„ì§œ ë²¡í„° í•„ë“œ (ì„ í˜• ë³´ê°„ì˜ ë„í•¨ìˆ˜)</span>
    <span class="n">true_velocity</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span>

    <span class="c1"># ì˜ˆì¸¡ ë²¡í„° í•„ë“œ</span>
    <span class="n">pred_velocity</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="c1"># ì†ì‹¤</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">pred_velocity</span><span class="p">,</span> <span class="n">true_velocity</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># ì˜ˆì œ</span>
<span class="n">fm_model</span> <span class="o">=</span> <span class="n">FlowMatchingModel</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x0_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x1_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">flow_matching_loss</span><span class="p">(</span><span class="n">fm_model</span><span class="p">,</span> <span class="n">x0_samples</span><span class="p">,</span> <span class="n">x1_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Flow Matching ì†ì‹¤: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h2 id="_2">ì—°ìŠµ ë¬¸ì œ<a class="header-link" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="1-elbo">ë¬¸ì œ 1: ELBO ìœ ë„ì˜ ë‘ ë°©ë²•<a class="header-link" href="#1-elbo" title="Permanent link">&para;</a></h3>
<ol>
<li>ì˜Œì„¼ ë¶€ë“±ì‹ì„ ì´ìš©í•œ ELBO ìœ ë„ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‘ì„±í•˜ì‹œì˜¤.</li>
<li>KL ë¶„í•´ë¥¼ ì´ìš©í•œ ìœ ë„ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‘ì„±í•˜ì‹œì˜¤.</li>
<li>ë‘ ë°©ë²•ì´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì£¼ëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•˜ì‹œì˜¤.</li>
</ol>
<h3 id="2-vae">ë¬¸ì œ 2: VAE êµ¬í˜„ê³¼ ì‹¤í—˜<a class="header-link" href="#2-vae" title="Permanent link">&para;</a></h3>
<p>2D ê°€ìš°ì‹œì•ˆ í˜¼í•© ë°ì´í„°ì— ëŒ€í•´:
1. 2D ì ì¬ ê³µê°„ì„ ê°€ì§„ VAEë¥¼ êµ¬í˜„í•˜ì‹œì˜¤.
2. ì¬êµ¬ì„± ì†ì‹¤ê³¼ KL ì†ì‹¤ì˜ í•™ìŠµ ê³¡ì„ ì„ í”Œë¡œíŒ…í•˜ì‹œì˜¤.
3. ì ì¬ ê³µê°„ì„ ì‹œê°í™”í•˜ê³ , ê·¸ë¦¬ë“œ ìƒ˜í”Œë§ìœ¼ë¡œ ë””ì½”ë”ì˜ ì¶œë ¥ ì‹œê°í™”í•˜ì‹œì˜¤.
4. $\beta$-VAEë¥¼ êµ¬í˜„í•˜ê³  (KL í•­ì— ê°€ì¤‘ì¹˜ $\beta$), $\beta$ì˜ ì˜í–¥ ë¶„ì„í•˜ì‹œì˜¤.</p>
<h3 id="3-gan_1">ë¬¸ì œ 3: GANì˜ ìµœì  íŒë³„ì ì¦ëª…<a class="header-link" href="#3-gan_1" title="Permanent link">&para;</a></h3>
<p>$G$ê°€ ê³ ì •ë˜ì—ˆì„ ë•Œ, íŒë³„ìì˜ ëª©ì  í•¨ìˆ˜:</p>
<p>$$\max_D \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}} [\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{x} \sim p_g} [\log(1 - D(\mathbf{x}))]$$</p>
<p>ê°€ $D^*(\mathbf{x}) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_g(\mathbf{x})}$ì—ì„œ ìµœëŒ“ê°’ì„ ê°€ì§ì„ ì¦ëª…í•˜ì‹œì˜¤.</p>
<h3 id="4">ë¬¸ì œ 4: í™•ì‚° ëª¨ë¸ì˜ ì •ë°©í–¥ ê³¼ì •<a class="header-link" href="#4" title="Permanent link">&para;</a></h3>
<ol>
<li>$q(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)I)$ë¥¼ ìœ ë„í•˜ì‹œì˜¤ (ì¬ê·€ì ìœ¼ë¡œ).</li>
<li>1D ë°ì´í„°ì— ëŒ€í•´ ë‹¤ì–‘í•œ $t$ì—ì„œ $\mathbf{x}_t$ì˜ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ì‹œì˜¤.</li>
<li>$T \to \infty$ì¼ ë•Œ $\mathbf{x}_T \approx \mathcal{N}(\mathbf{0}, I)$ì„ì„ ë³´ì´ì‹œì˜¤.</li>
</ol>
<h3 id="5-flow-matching-vs">ë¬¸ì œ 5: Flow Matching vs í™•ì‚° ëª¨ë¸<a class="header-link" href="#5-flow-matching-vs" title="Permanent link">&para;</a></h3>
<ol>
<li>ê°„ë‹¨í•œ Flow Matching ëª¨ë¸ê³¼ DDPMì„ êµ¬í˜„í•˜ì‹œì˜¤.</li>
<li>ë™ì¼í•œ 2D ë°ì´í„°ì— ëŒ€í•´ ë‘ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì‹œì˜¤.</li>
<li>ìƒ˜í”Œë§ ì†ë„ (ìŠ¤í… ìˆ˜) ë¹„êµí•˜ì‹œì˜¤.</li>
<li>ìƒì„± í’ˆì§ˆ (FID, Inception Score ë“±) ë¹„êµí•˜ì‹œì˜¤.</li>
</ol>
<h2 id="_3">ì°¸ê³  ìë£Œ<a class="header-link" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="_4">ë…¼ë¬¸<a class="header-link" href="#_4" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>VAE</strong>: Kingma, D. P., &amp; Welling, M. (2014). "Auto-Encoding Variational Bayes." <em>ICLR</em>.</li>
<li><strong>GAN</strong>: Goodfellow, I., et al. (2014). "Generative Adversarial Nets." <em>NeurIPS</em>.</li>
<li><strong>WGAN</strong>: Arjovsky, M., et al. (2017). "Wasserstein Generative Adversarial Networks." <em>ICML</em>.</li>
<li><strong>WGAN-GP</strong>: Gulrajani, I., et al. (2017). "Improved Training of Wasserstein GANs." <em>NeurIPS</em>.</li>
<li><strong>DDPM</strong>: Ho, J., et al. (2020). "Denoising Diffusion Probabilistic Models." <em>NeurIPS</em>.</li>
<li><strong>Score-Based Models</strong>: Song, Y., &amp; Ermon, S. (2019). "Generative Modeling by Estimating Gradients of the Data Distribution." <em>NeurIPS</em>.</li>
<li><strong>Flow Matching</strong>: Lipman, Y., et al. (2023). "Flow Matching for Generative Modeling." <em>ICLR</em>.</li>
<li><strong>Consistency Models</strong>: Song, Y., et al. (2023). "Consistency Models." <em>ICML</em>.</li>
</ul>
<h3 id="_5">ì˜¨ë¼ì¸ ìë£Œ<a class="header-link" href="#_5" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://lilianweng.github.io/posts/2018-08-12-vae/">Lil'Log: From Autoencoder to Beta-VAE (Lilian Weng)</a></li>
<li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">Lil'Log: What are Diffusion Models? (Lilian Weng)</a></li>
<li><a href="https://arxiv.org/abs/2208.11970">Understanding Diffusion Models (Calvin Luo)</a></li>
<li><a href="https://huggingface.co/blog/annotated-diffusion">The Annotated Diffusion Model</a></li>
</ul>
<h3 id="_6">ë¼ì´ë¸ŒëŸ¬ë¦¬<a class="header-link" href="#_6" title="Permanent link">&para;</a></h3>
<ul>
<li><code>torch</code>: PyTorch êµ¬í˜„</li>
<li><code>diffusers</code> (Hugging Face): í™•ì‚° ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬</li>
<li><code>stable-diffusion</code>: Stable Diffusion êµ¬í˜„</li>
</ul>
    </div>

    
<div class="lesson-toolbar lesson-toolbar--bottom">
    <div class="toolbar-nav toolbar-nav--prev">
        
        <a href="/study/ko/Math_for_AI/17_Math_of_Attention_and_Transformers.html" class="nav-prev">
            <span class="nav-label">Previous</span>
            <span class="nav-title">17. ì–´í…ì…˜ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ìˆ˜í•™</span>
        </a>
        
    </div>
    <div class="toolbar-actions">
        <button class="btn btn-copy-link" data-action="copy-link" title="Copy link">
            <span class="icon">ğŸ”—</span>
            <span class="text">Copy link</span>
        </button>
        <a href="/study/ko/Math_for_AI/" class="btn btn-topic-link" title="Back to topic list">
            <span class="icon">ğŸ“‹</span>
            <span class="text">Topic list</span>
        </a>
    </div>
    <div class="toolbar-nav toolbar-nav--next">
        
    </div>
</div>


    <div class="toolbar-keyboard-hint">
        <kbd>&larr;</kbd> <kbd>&rarr;</kbd> to navigate between lessons
    </div>
</article>

<!-- Scroll to top floating button -->
<button class="scroll-to-top" id="scroll-to-top" title="Scroll to top" aria-label="Scroll to top">â†‘</button>

            </div>
        </main>
    </div>

    <script src="/study/static/js/app.js"></script>
    <script>
        function switchLanguage(newLang) {
            const path = window.location.pathname;
            const base = '/study';
            const currentLang = 'ko';
            const newPath = path.replace(base + '/' + currentLang + '/', base + '/' + newLang + '/');
            window.location.href = newPath + window.location.search;
        }
    </script>
    
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Copy link - independent feedback per button
        document.querySelectorAll('[data-action="copy-link"]').forEach(function(btn) {
            btn.addEventListener('click', function() {
                navigator.clipboard.writeText(window.location.href);
                var textEl = this.querySelector('.text');
                var originalText = textEl.textContent;
                textEl.textContent = 'Copied!';
                setTimeout(function() { textEl.textContent = originalText; }, 2000);
            });
        });

        // Add copy buttons to code blocks
        document.querySelectorAll('.lesson-content pre').forEach(function(pre) {
            var copyBtn = document.createElement('button');
            copyBtn.className = 'code-copy-btn';
            copyBtn.textContent = 'Copy';
            copyBtn.addEventListener('click', function() {
                var code = pre.querySelector('code');
                var text = code ? code.textContent : pre.textContent;
                navigator.clipboard.writeText(text);
                copyBtn.textContent = 'Copied!';
                setTimeout(function() { copyBtn.textContent = 'Copy'; }, 2000);
            });
            pre.style.position = 'relative';
            pre.appendChild(copyBtn);
        });

        // Scroll to top button
        var scrollBtn = document.getElementById('scroll-to-top');
        window.addEventListener('scroll', function() {
            scrollBtn.classList.toggle('visible', window.scrollY > 300);
        });
        scrollBtn.addEventListener('click', function() {
            window.scrollTo({ top: 0, behavior: 'smooth' });
        });

        // Keyboard shortcuts: left/right arrows for lesson navigation
        document.addEventListener('keydown', function(e) {
            var tag = document.activeElement.tagName;
            if (tag === 'INPUT' || tag === 'TEXTAREA' || tag === 'SELECT') return;

            if (e.key === 'ArrowLeft') {
                var prevLink = document.querySelector('.nav-prev');
                if (prevLink) prevLink.click();
            } else if (e.key === 'ArrowRight') {
                var nextLink = document.querySelector('.nav-next');
                if (nextLink) nextLink.click();
            }
        });
    });
</script>

</body>
</html>
{% endraw %}